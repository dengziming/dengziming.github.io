<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>design-data-intensive-architecture - 数据分析师之旅</title>
  <link rel="alternate" hreflang="zh-cn" href="https://dengziming.github.io/" />

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="邓子明" />
  <meta name="description" content="第一部分、前言 ACID，bigdata，NoSql ，bigTable ，CAP，2PC，3PC，quorum，raft，paxos，cloud" />

  <meta name="keywords" content="大数据, AI, 机器学习" />






<meta name="generator" content="Hugo 0.26" />


<link rel="canonical" href="https://dengziming.github.io/post/data-intensive-architecture/design-data-intensive-architecture/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" href="/favicon.ico" />
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<link href="/dist/jane.min.css?v=2.7.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="design-data-intensive-architecture" />
<meta property="og:description" content="第一部分、前言 ACID，bigdata，NoSql ，bigTable ，CAP，2PC，3PC，quorum，raft，paxos，cloud" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://dengziming.github.io/post/data-intensive-architecture/design-data-intensive-architecture/" />



<meta property="article:published_time" content="2018-12-22T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-12-22T00:00:00&#43;00:00"/>











<meta itemprop="name" content="design-data-intensive-architecture">
<meta itemprop="description" content="第一部分、前言 ACID，bigdata，NoSql ，bigTable ，CAP，2PC，3PC，quorum，raft，paxos，cloud">


<meta itemprop="dateModified" content="2018-12-22T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="16923">



<meta itemprop="keywords" content="架构,大数据," />
<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="design-data-intensive-architecture"/>
<meta name="twitter:description" content="第一部分、前言 ACID，bigdata，NoSql ，bigTable ，CAP，2PC，3PC，quorum，raft，paxos，cloud"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Dengziming</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">列表</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="https://gohugo.io">
        <li class="mobile-menu-item">站外链接</li>
      </a>
  </ul>
</nav>

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">Dengziming</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        
        <a class="menu-item-link" href="/">Home</a>
        
      </li><li class="menu-item">
        
        <a class="menu-item-link" href="/post/">列表</a>
        
      </li><li class="menu-item">
        
        <a class="menu-item-link" href="/tags/">标签</a>
        
      </li><li class="menu-item">
        
        <a class="menu-item-link" href="/categories/">分类</a>
        
      </li><li class="menu-item">
        
        <a class="menu-item-link" href="/about/">About</a>
        
      </li><li class="menu-item">
        
        <a class="menu-item-link" href="https://gohugo.io" target="_blank">
          站外链接
          <i class="iconfont icon-new-window"></i>
        </a>
        
      </li>
  </ul>
</nav>
  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">design-data-intensive-architecture</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-12-22 </span>
        <div class="post-category">
            
              <a href="/categories/%E8%AE%BE%E8%AE%A1%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/"> 设计高并发架构 </a>
            
          </div>
        <span class="more-meta"> 16923 words </span>
        <span class="more-meta"> 34 min read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Table of Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#第一部分-前言">第一部分、前言</a></li>
<li><a href="#第二部分-数据系统的基础">第二部分、数据系统的基础</a>
<ul>
<li><a href="#一-reliable-scalable-和-maintainable-的含义">一、Reliable,Scalable 和 Maintainable 的含义</a>
<ul>
<li><a href="#1-reliable">1. Reliable</a></li>
<li><a href="#2-scalable">2. Scalable</a></li>
<li><a href="#3-maintainable">3. Maintainable</a></li>
</ul></li>
<li><a href="#二-数据模型和查询语言">二、数据模型和查询语言</a>
<ul>
<li><a href="#1-关系型与文档型">1.关系型与文档型</a></li>
<li><a href="#2-nosql">2.NoSQL</a></li>
<li><a href="#3-object-relational-mismatch">3. Object-Relational Mismatch</a></li>
<li><a href="#4-many-to-one-and-many-to-many-relationships">4. Many-to-One and Many-to-Many Relationships</a></li>
<li><a href="#5-query-languages-for-data">5. Query Languages for Data</a></li>
<li><a href="#6-graph-like-data-models">6.Graph-Like Data Models</a></li>
</ul></li>
<li><a href="#三-storage-and-retrieval">三、Storage and Retrieval</a>
<ul>
<li><a href="#1-hash-indexes">1. Hash Indexes</a></li>
<li><a href="#2-sstables-and-lsm-trees">2. SSTables and LSM-Trees</a></li>
<li><a href="#3-b-trees">3. B-Trees</a></li>
<li><a href="#4-multi-column-indexes">4. Multi-column indexes</a></li>
<li><a href="#5-full-text-search-and-fuzzy-indexes">5. Full-text search and fuzzy indexes</a></li>
<li><a href="#6-keeping-everything-in-memory">6.Keeping everything in memory</a></li>
<li><a href="#7-olap-vs-oltp">7. OLAP vs OLTP</a></li>
<li><a href="#8-数据仓库">8. 数据仓库</a></li>
<li><a href="#9-stars-and-snowflakes-schemas-for-analytics">9. Stars and Snowflakes: Schemas for Analytics</a></li>
<li><a href="#10-column-oriented-storage">10. Column-Oriented Storage</a></li>
<li><a href="#11-column-compression">11. Column Compression</a></li>
<li><a href="#12-sort-order-in-column-storage">12. Sort Order in Column Storage</a></li>
<li><a href="#13-writing-to-column-oriented-storage">13. Writing to Column-Oriented Storage</a></li>
<li><a href="#14-aggregation-data-cubes-and-materialized-views">14. Aggregation: Data Cubes and Materialized Views</a></li>
</ul></li>
<li><a href="#四-encoding-and-evolution">四、Encoding and Evolution</a>
<ul>
<li><a href="#1-formats-for-encoding-data">1. Formats for Encoding Data</a>
<ul>
<li><a href="#1-language-specific-formats">(1) Language-Specific Formats</a></li>
<li><a href="#2-json-xml-and-binary-variants">(2) JSON, XML, and Binary Variants</a></li>
<li><a href="#3-thrift-and-protocol-buffers">(3) Thrift and Protocol Buffers</a></li>
<li><a href="#4-field-tags-and-schema-evolution">(4) Field tags and schema evolution</a></li>
<li><a href="#5-datatypes-and-schema-evolution">(5) Datatypes and schema evolution</a></li>
<li><a href="#6-avro">(6) avro</a></li>
<li><a href="#7-dynamically-generated-schemas">(7) Dynamically generated schemas</a></li>
<li><a href="#8-code-generation-and-dynamically-typed-languages">(8) Code generation and dynamically typed languages</a></li>
<li><a href="#9-the-merits-of-schemas">(9) The Merits of Schemas</a></li>
</ul></li>
<li><a href="#二-modes-of-dataflow">二、 Modes of Dataflow</a>
<ul>
<li><a href="#1-dataflow-through-databases">1.Dataflow Through Databases</a></li>
<li><a href="#2-dataflow-through-services-rest-and-rpc">2.Dataflow Through Services: REST and RPC</a></li>
<li><a href="#3-message-passing-dataflow">3.  Message-Passing Dataflow</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#第二部分-分布式">第二部分、分布式</a></li>
<li><a href="#一-replication">一、Replication</a>
<ul>
<li><a href="#1-leaders-and-followers">1. Leaders and Followers</a>
<ul>
<li><a href="#1-synchronous-versus-asynchronous-replication">(1) Synchronous Versus Asynchronous Replication</a></li>
<li><a href="#2-setting-up-new-followers">(2) Setting Up New Followers</a></li>
<li><a href="#3-handling-node-outages">(3) Handling Node Outages</a></li>
<li><a href="#4-implementation-of-replication-logs">(4) Implementation of Replication Logs</a></li>
<li><a href="#5-problems-with-replication-lag">(5) Problems with Replication Lag</a>
<ul>
<li><a href="#1-read-your-own-writes">1. Read your own writes</a></li>
<li><a href="#2-monotonic-reads">2. Monotonic Reads</a></li>
<li><a href="#3-consistent-prefix-reads">3. Consistent Prefix Reads</a></li>
</ul></li>
<li><a href="#6-solutions-for-replication-lag">(6). Solutions for Replication Lag</a></li>
</ul></li>
<li><a href="#2-multi-leader-replication">2. Multi-Leader Replication</a>
<ul>
<li><a href="#1-use-cases-for-multi-leader-replication">(1). “Use Cases for Multi-Leader Replication”</a>
<ul>
<li><a href="#multi-datacenter-operation">Multi-datacenter operation</a></li>
<li><a href="#clients-with-offline-operation">“Clients with offline operation”</a></li>
<li><a href="#collaborative-editing">Collaborative editing</a></li>
<li><a href="#handling-write-conflicts">Handling Write Conflicts</a></li>
<li><a href="#what-is-a-conflict">What is a conflict?</a></li>
</ul></li>
<li><a href="#2-multi-leader-replication-topologies">(2) Multi-Leader Replication Topologies</a></li>
</ul></li>
<li><a href="#3-leaderless-replication">3. Leaderless Replication</a>
<ul>
<li><a href="#1-writing-to-the-database-when-a-node-is-down">(1) Writing to the Database When a Node Is Down</a>
<ul>
<li><a href="#read-repair-and-anti-entropy">Read repair and anti-entropy</a></li>
<li><a href="#quorums-for-reading-and-writing">Quorums for reading and writing</a></li>
<li><a href="#monitoring-staleness">Monitoring staleness</a></li>
</ul></li>
<li><a href="#sloppy-quorums-and-hinted-handoff">“Sloppy Quorums and Hinted Handoff”</a></li>
<li><a href="#multi-datacenter-operation-1">Multi-datacenter operation</a></li>
<li><a href="#detecting-concurrent-writes">Detecting Concurrent Writes</a>
<ul>
<li><a href="#last-write-wins-discarding-concurrent-writes">Last write wins (discarding concurrent writes)</a></li>
<li><a href="#the-happens-before-relationship-and-concurrency">The “happens-before” relationship and concurrency</a></li>
<li><a href="#capturing-the-happens-before-relationship">Capturing the happens-before relationship</a></li>
<li><a href="#merging-concurrently-written-values">Merging concurrently written values</a></li>
<li><a href="#version-vectors">Version vectors</a></li>
</ul></li>
</ul></li>
<li><a href="#summary">SUMmary</a></li>
</ul></li>
<li><a href="#二-partitioning">二、Partitioning</a></li>
<li><a href="#三-transactions">三、Transactions</a>
<ul>
<li><a href="#1-the-slippery-concept-of-a-transaction">1. The Slippery Concept of a Transaction</a></li>
<li><a href="#2-the-meaning-of-acid">2. The Meaning of ACID</a>
<ul>
<li><a href="#1-atomicity">(1) Atomicity</a></li>
<li><a href="#2-consistency">(2) Consistency</a></li>
<li><a href="#3-isolation">(3) Isolation</a></li>
<li><a href="#4-durability">(4) Durability</a></li>
</ul></li>
<li><a href="#single-object-and-multi-object-operations">Single-Object and Multi-Object Operations</a>
<ul>
<li><a href="#1-single-object-writes">(1) Single-object writes</a></li>
<li><a href="#2-the-need-for-multi-object-transactions">(2) The need for multi-object transactions</a></li>
<li><a href="#3-handling-errors-and-aborts">(3) Handling errors and aborts</a></li>
</ul></li>
<li><a href="#2-weak-isolation-levels">2. Weak Isolation Levels</a>
<ul>
<li><a href="#1-read-committed">(1) Read Committed</a>
<ul>
<li><a href="#no-dirty-reads">No dirty reads</a></li>
<li><a href="#no-dirty-writes">No dirty writes</a></li>
<li><a href="#implementing-read-committed">Implementing read committed</a></li>
</ul></li>
<li><a href="#2-snapshot-isolation-and-repeatable-read">(2) Snapshot Isolation and Repeatable Read</a></li>
<li><a href="#3-indexes-and-snapshot-isolation">(3) Indexes and snapshot isolation</a></li>
<li><a href="#4-repeatable-read-and-naming-confusion">(4) Repeatable read and naming confusion</a></li>
</ul></li>
<li><a href="#3-preventing-lost-updates">3. Preventing Lost Updates</a>
<ul>
<li><a href="#1-atomic-write-operations">(1) Atomic write operations</a></li>
<li><a href="#2-explicit-locking">(2) Explicit locking</a></li>
<li><a href="#3-automatically-detecting-lost-updates">(3) Automatically detecting lost updates</a></li>
<li><a href="#4-compare-and-set">(4) Compare-and-set</a></li>
<li><a href="#5-conflict-resolution-and-replication">(5) Conflict resolution and replication</a></li>
</ul></li>
<li><a href="#4-write-skew-and-phantoms">4. Write Skew and Phantoms</a>
<ul>
<li><a href="#1-characterizing-write-skew">(1) Characterizing write skew</a></li>
<li><a href="#2-phantoms-causing-write-skew">(2) Phantoms causing write skew</a></li>
<li><a href="#3-materializing-conflicts">(3) Materializing conflicts</a></li>
</ul></li>
<li><a href="#4-serializability">4. Serializability</a>
<ul>
<li><a href="#1-actual-serial-execution">(1) Actual Serial Execution</a>
<ul>
<li><a href="#encapsulating-transactions-in-stored-procedures">Encapsulating transactions in stored procedures</a></li>
</ul></li>
<li><a href="#2-two-phase-locking-2pl">(2) Two-Phase Locking (2PL)</a>
<ul>
<li><a href="#implementation-of-two-phase-locking">Implementation of two-phase locking</a></li>
<li><a href="#performance-of-two-phase-locking">Performance of two-phase locking</a></li>
<li><a href="#predicate-locks">Predicate locks</a></li>
<li><a href="#index-range-locks">Index-range locks</a></li>
</ul></li>
<li><a href="#serializable-snapshot-isolation-ssi">Serializable Snapshot Isolation (SSI)</a>
<ul>
<li><a href="#pessimistic-versus-optimistic-concurrency-control">Pessimistic versus optimistic concurrency control</a></li>
</ul></li>
<li><a href="#decisions-based-on-an-outdated-premise">Decisions based on an outdated premise</a>
<ul>
<li><a href="#detecting-stale-mvcc-reads">Detecting stale MVCC reads</a></li>
<li><a href="#detecting-writes-that-affect-prior-reads">Detecting writes that affect prior reads</a></li>
<li><a href="#performance-of-serializable-snapshot-isolation">Performance of serializable snapshot isolation</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#第五部分-案例">第五部分、案例</a></li>
<li><a href="#第六部分-资料">第六部分、资料</a></li>
</ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      

<h1 id="第一部分-前言">第一部分、前言</h1>

<p>ACID，bigdata，NoSql ，bigTable ，CAP，2PC，3PC，quorum，raft，paxos，cloud，real-time，高并发架构将会逐渐成为基础。</p>

<p>主要内容：
（一）基础</p>

<ol>
<li>“reliability, scalability, and maintainability”</li>
<li>数据模型</li>
<li>存储引擎</li>
<li>数据结构</li>
</ol>

<p>（二）分布式</p>

<ol>
<li>replication</li>
<li>partitioning/sharding</li>
<li>transaction</li>
<li>distributed system</li>
<li>consistency and consensus</li>
</ol>

<p>（三）交互</p>

<ol>
<li>batch process</li>
<li>realtime</li>
<li>put everything together</li>
</ol>

<p>（四）案例及资料</p>

<h1 id="第二部分-数据系统的基础">第二部分、数据系统的基础</h1>

<h2 id="一-reliable-scalable-和-maintainable-的含义">一、Reliable,Scalable 和 Maintainable 的含义</h2>

<p>数据系统分为 data-intensive 和 compute-intensive，一般的大数据应用会采用的技术：
1. 存储，方便后续的查询 &ndash; databases
2. 缓存，加速访问 &ndash; caches
3. 允许用户通过关键字搜索、按照过滤  &ndash; indexes
4. 给另一个进程发送消息，异步处理  &ndash; streaming process
5. 周期性处理全量数据  &ndash; batch process</p>

<p>这一切都是需要数据系统，我们并不会从头开始搭建存储、计算系统，因为有很多现成的技术可以应用。数据库、消息队列功能都很相似，但是实现完全不同，导致不同的性能，所以我们用处不同，我们为什么要将他们结合到一起呢？</p>

<p>其实许多工具功能比较重复，redis 其实也可以当消息队列，kafka 也可以做数据持久化。这些工具的界限越来越模糊。第二是我们得系统一般比较复杂，一个工具完成不了，我们必须组件一个数据系统。组件的过程
有很多需要考虑的事情，其中最重要的三点：
Reliable： 系统必须一致能够提供服务，即便是发生了一些不可预知的错误
Scalable： 系统升级、功能扩展、访问量增加，导致我们需要能够很方便扩展我们的系统
Maintainable： 随着时间推移，可能有很多其他人接受项目，必须方便别人进行维护</p>

<p>有关这三点的介绍，我们逐渐展开：</p>

<h3 id="1-reliable">1. Reliable</h3>

<h3 id="2-scalable">2. Scalable</h3>

<h3 id="3-maintainable">3. Maintainable</h3>

<h2 id="二-数据模型和查询语言">二、数据模型和查询语言</h2>

<p>数据模型是最重要的一部分，</p>

<h3 id="1-关系型与文档型">1.关系型与文档型</h3>

<h3 id="2-nosql">2.NoSQL</h3>

<h3 id="3-object-relational-mismatch">3. Object-Relational Mismatch</h3>

<h3 id="4-many-to-one-and-many-to-many-relationships">4. Many-to-One and Many-to-Many Relationships</h3>

<h3 id="5-query-languages-for-data">5. Query Languages for Data</h3>

<h3 id="6-graph-like-data-models">6.Graph-Like Data Models</h3>

<h2 id="三-storage-and-retrieval">三、Storage and Retrieval</h2>

<h3 id="1-hash-indexes">1. Hash Indexes</h3>

<h3 id="2-sstables-and-lsm-trees">2. SSTables and LSM-Trees</h3>

<h3 id="3-b-trees">3. B-Trees</h3>

<h3 id="4-multi-column-indexes">4. Multi-column indexes</h3>

<h3 id="5-full-text-search-and-fuzzy-indexes">5. Full-text search and fuzzy indexes</h3>

<h3 id="6-keeping-everything-in-memory">6.Keeping everything in memory</h3>

<h3 id="7-olap-vs-oltp">7. OLAP vs OLTP</h3>

<h3 id="8-数据仓库">8. 数据仓库</h3>

<h3 id="9-stars-and-snowflakes-schemas-for-analytics">9. Stars and Snowflakes: Schemas for Analytics</h3>

<h3 id="10-column-oriented-storage">10. Column-Oriented Storage</h3>

<h3 id="11-column-compression">11. Column Compression</h3>

<h3 id="12-sort-order-in-column-storage">12. Sort Order in Column Storage</h3>

<h3 id="13-writing-to-column-oriented-storage">13. Writing to Column-Oriented Storage</h3>

<p>前面写的有关列存储的优化在数据仓库中很重要，排序、位图索引、压缩都能加速查询，但是会让写数据更加麻烦。</p>

<p>以 BTree 为理论的写方法，在这里完全没有用，如果你要在数据中插入一条数据，你需要重写所有的数据。</p>

<p>但是还好的是，如果是 LSM-tree 的方式，首先写进内存排序，然后写磁盘。查询的时候，也是两部分结果进行合并，Vertica 数据仓库就是这么做的。</p>

<h3 id="14-aggregation-data-cubes-and-materialized-views">14. Aggregation: Data Cubes and Materialized Views</h3>

<p>并不是所有的数据仓库都是使用列存储，很多其他存储方式也会用到，但是列存储确实能够很大程度加快访问，所以越来越流行。</p>

<p>另一种值得一提的数据仓库技术就是 materialized aggregates。前面所说的，查询经常会遇到一些聚合， 例如 count，sum，如果一个查询被很多查询共用，可以将结果缓存。
其中一种方法就是 materialized view，类似查询视图，只不过这个视图的结果已经计算好保存起来了。如果数据改变了，你的 materialized view 也要改变。</p>

<p>一种常见的案例就是 data cube 后者 OLAP cube，就是根据不同纬度就行聚合后的结果。举个列子，如果表格有 日期、商品种类、销售额三列，我们可以计算销售额在 日期、商品种类 两个维度下的聚合只，得到一个二维表格。
二维表格的两个维度分别为日期和商品种类，表格的值就是销售额，然后如果要计算每个维度下的 sum，只需要将对应维度所有值 sum 到一起。</p>

<p>实际上，表格都不止两个维度，假如有五个维度，情况就很复杂了。但是原则不变，每个 cell 保存五个维度组合下的聚合值。</p>

<p>通过 cube 可以加速某些查询，但是如果要计算订单额度大于 100 的比例，那就没法计算了，因为额度很难作为一个维度。所以一般只作为一个加快部分查询的工具。</p>

<h2 id="四-encoding-and-evolution">四、Encoding and Evolution</h2>

<p>服务总是要变的，服务变了，服务之间的代码也要变。服务端可以做滚动升级，也就是部分服务器先升级，保证没错的话，其他的继续升级。
而客户端也就是用户端，代码变化必须做到向前向后兼容，也就是说，高版本要能够处理低版本的数据，这很简单；低版本的代码，必须能从高版本的架构读数据，这是比较难的。
接下来我们将会看一些数据结构，JSON, XML, Protocol Buffers, Thrift, and Avro ，主要看他们在这些data storage and for communication系统中如何使用：
in web services, Representational State Transfer (REST), and remote procedure calls (RPC), as well as message-passing systems such as actors and message queues</p>

<h3 id="1-formats-for-encoding-data">1. Formats for Encoding Data</h3>

<p>一般的应用都会处理两种数据。内存主要是通过对象、数组、树、hash表等，而需要保存、传输时候，需要进行序列化，由于指针引用序列化后是没用的，所以序列化后的结构和内存结构完全不用。
从设计模式角度考虑，我们需要进行一个适配，两边都要适配的话，实际上就是做一个转换。内存到 byte sequence 的过程称为 encoding（或者 serialization、marshalling），反过来讲decoding（deserialization、parsing、unmarshalling）</p>

<p>** 专业术语冲突
serialization 在数据库的事务中也会用到，但是完全是另外一码子事情，后续会进行介绍。这里使用的时候我们以 encoding 为主，虽然平时 serialization 用的更多。</p>

<p>这里我们将会以一条数据为例,对它进行编码：</p>

<pre><code class="language-json">{
    &quot;userName&quot;: &quot;Martin&quot;,
    &quot;favoriteNumber&quot;: 1337,
    &quot;interests&quot;: [&quot;daydreaming&quot;, &quot;hacking&quot;]
}
</code></pre>

<h4 id="1-language-specific-formats">(1) Language-Specific Formats</h4>

<p>java.io.Serializable 属于java 自带的序列化机制，很多编程语言都自带了。当然也有很多第三方的，比如 Kryo for Java。这些很方便，因为你只需要直接读然后调用java对应的方法即可。但是问题也很多。</p>

<ol>
<li>通用性问题，不多说。</li>
<li>数据会有类型，例如java 序列化必须只能解析为特定的类。所以会定义很多类，这样可能导致一些人得到你的类信息，然后远程植入代码。</li>
<li>版本问题。</li>
<li>效率问题。</li>
</ol>

<h4 id="2-json-xml-and-binary-variants">(2) JSON, XML, and Binary Variants</h4>

<p>JSON, XML 一般都很熟悉，优缺点都很明显，二进制的编码在某些内网的应用中很常见，还能节约空间。例如 MassagePack 就是二进制的 json。</p>

<h4 id="3-thrift-and-protocol-buffers">(3) Thrift and Protocol Buffers</h4>

<p>Thrift and Protocol Buffers 很多人都知道，作为两种序列化的框架，当然还提供了别的功能，例如 RPC 通信接口。都需要定义一个schema：</p>

<p>Thrift 的定义格式：</p>

<pre><code class="language-java">struct Person {
  1: required string       userName,
  2: optional i64          favoriteNumber,
  3: optional list&lt;string&gt; interests
}
</code></pre>

<p>pb 的定义格式：</p>

<pre><code class="language-java">message Person {
    required string user_name       = 1;
    optional int64  favorite_number = 2;
    repeated string interests       = 3;
}
</code></pre>

<p>然后他们都有代码生成的工具，可以针对各种语言生成相应的代码，用来 encode 和 decode 数据。thrift 的格式有两种 BinaryProtocol and CompactProtocol。</p>

<p>BinaryProtocol 表示上面的数据格式需要 59 bytes ：</p>

<pre><code>0b 00 01 00 00 00 06 4d 61 72 74 69 6e     0b 是 type代表 String，紧接着 00 01 代表 field tag 为1，然后 00 00 00 06 代表长度为6，剩下的六bytes 代表数据。
0a 00 02 00 00 00 00 00 00 05 39           和刚才一样， 0a 代表int64 ，
0f 00 03 0b 00 00 00 02                    0f 代表list，00 03代表 field tag 为3，0b 代表 item type 为 string，00 00 00 02 代表长度为2，
	00 00 00 0b 64 61 79 ....              长度和数据
	00 00 00 07 68 ..... 				   长度和数据
00											结束标志
</code></pre>

<p>CompactProtocol 和 BinaryProtocol 的结构类似，但是进行了一些压缩，需要 33 bytes</p>

<pre><code>18 06 4d ....  							  18 是 00011000 field type and tag number 合在一起，0001 是 tag，
										  1000 是 type 是string （为什么8 代表 string，上面是11），06 长度，后面是数据
										  另外int类型并不是占了 64位，这里的 06是两位，共 8 字节，
										  最高位代表数据是否已经完整，剩下的七位是数据。如果数据不完整，需要再占8位。这样 -64 到 63 之间的数据只占了1byte
										  
16 f2 14 								  16 是 00010110，0001 代表 field tag 比上一个加一，0110 数据类型 后面的 f214 是数据，f2 最高位是1，数据没完，需要往下一位读。
19 28
    0b 64 .....
    07 68 ....
00
</code></pre>

<p>ProtocolBuffer 和 Thrift 的 CompactProtocol 类似，需要 33 bytes</p>

<pre><code>0a 06 4d 61 72 74 69 6e       			  0a 是 tag(00001) 和 type(010), 06 是长度。 后面是数据
10 b9 0a 								  10 是tag (00010) 和 type（000）,后面是长度+数据
1a 0b ........							  1a 是 tag 和 type，后面是长度+数据
1a 07 ........							  1a 是 tag 和 type，后面是长度+数据
</code></pre>

<p>和 CompactProtocol 稍微有些不一样，tag+type 为两位，另外 list 类型直接存两个。</p>

<p>需要注意的是，前面我们的例子中，数据要么是 要么是 required or optional，实际上这对于数据的存储没有任何影响，都是一样的存储，只是在最后解析的时候影响，例如你设置的是 required ，但是没有解析出来，会失败。</p>

<h4 id="4-field-tags-and-schema-evolution">(4) Field tags and schema evolution</h4>

<p>前面讲过数据需要改变，那 pb 和 thrift 如何应对schema 的变化，做到向前向后兼容呢？
其实我们从上面的数据可以看出，最重要就是 field tag 了，只要 field tag 唯一，哪怕是增加了数据，减少了数据，最终的结果其实还是一样的。你可以改变变量名字，但是不能改变 tag。
首先是向后兼容，只要你新加的 field tag 不被设置为 required，就不会报错，另外删除数据也是，不能删除 required 的数据。
另外是向前兼容，如果是旧的代码读取新的数据，如果遇到不认识的 field tag ，会直接忽略。</p>

<h4 id="5-datatypes-and-schema-evolution">(5) Datatypes and schema evolution</h4>

<p>数据类型发生变化，一方面可能是数据精度收到影响，另一方面，我们可以看出 pb 是可以讲啊 list 类型变成 optional 的，但是 thrift 不行，因为 thrift 提供了 list 类型，但是这样可以用来写嵌套数据。</p>

<h4 id="6-avro">(6) avro</h4>

<p>avro 也是一个序列胡框架，他和 pb、thrift 不同点在于没有 tagNumber，这其实很适合动态生成schema，我们不介绍了。</p>

<h4 id="7-dynamically-generated-schemas">(7) Dynamically generated schemas</h4>

<p>如果我们的数据增加了一列，并且减少了一列，对于 avro 来说，只需要重新生成一个 schema 即可，而如果使用 pb、thrift，需要手动进行配置tag和field 的映射，</p>

<h4 id="8-code-generation-and-dynamically-typed-languages">(8) Code generation and dynamically typed languages</h4>

<p>代码生成，例如 pb 可以生成 java 和 python 的代码。</p>

<h4 id="9-the-merits-of-schemas">(9) The Merits of Schemas</h4>

<h3 id="二-modes-of-dataflow">二、 Modes of Dataflow</h3>

<p>我们需要在进程之间发送数据，</p>

<h4 id="1-dataflow-through-databases">1.Dataflow Through Databases</h4>

<h4 id="2-dataflow-through-services-rest-and-rpc">2.Dataflow Through Services: REST and RPC</h4>

<h4 id="3-message-passing-dataflow">3.  Message-Passing Dataflow</h4>

<h1 id="第二部分-分布式">第二部分、分布式</h1>

<p>使用分布式的原因很多，例如 Scalability，high available，latency。数据分布式有很多种方式，首先是副本、分区，也就是 Replication 和 Partition。</p>

<h1 id="一-replication">一、Replication</h1>

<p>Replication 就是将你的数据放在多个节点，这样有很多好处。数据从地理上可以隔用户更近，保持高可用，增加吞吐量。</p>

<p>本章我们假设数据都是完整的进行副本存放，后面再讲分区。数据的副本解决难点就是数据变化的一致性，如果数据一致不变，那就太简单了，没什么可以讨论的。</p>

<p>对于数据变化的副本存储，有很多需要注意的地方，例如每次写数据操作数据复制是同步的还是异步的，节点挂了怎么办，数据一致性问题，时效性问题。
我们的学习主要分为三种设计：single-leader, multi-leader, and leaderless</p>

<h2 id="1-leaders-and-followers">1. Leaders and Followers</h2>

<p>每个节点上面的副本叫做 replica ，当有 multi replica 的时候，一个问题出现了，怎么保证数据写到了每一个副本。
数据库的每一次写都必须保证被每个副本处理，否则就会出现不一致。
最常用的解决方案就是 leader-based-replication，也叫 active-passive、master-slave。</p>

<p>在主从结构中，写只能发送给 leader，leader 写的时候会发送数据给 follower，而读操作可以读任何一个节点。</p>

<h3 id="1-synchronous-versus-asynchronous-replication">(1) Synchronous Versus Asynchronous Replication</h3>

<p>replicated 系统重要特点就是 同步写还是异步写，一般关系型数据库可以配置，其他的都是硬编码写死的。</p>

<p>客户端发送数据给leader，然后leader转发给follower，最后通知client。如果 leader 收到 follower 的确认消息再回复client，这就是同步。
如果leader发送给了 follower后就直接回复client，就是异步。一般情况，系统都只有一个follower是同步，其余的都是异步。这叫 semi-synchronous。</p>

<p>为了效率经常设置为 Asynchronous，这样如何 leader 失败了而且不恢复，那还没有被副本保存的数据就丢失了，
这样的好处就是可以提供持续服务，尽管follower很慢。即便是配置使用 Synchronous，实际上也是有一台是同步，其余的是异步。</p>

<p>Weakening durability 可能是一个比较糟糕的 trade-off，但是 Asynchronous 还是很常用，尤其是地理上分布式的集群。</p>

<p>当然也有很多其他的方案在研究中，例如 Azure 使用了 chain replication。</p>

<h3 id="2-setting-up-new-followers">(2) Setting Up New Followers</h3>

<p>系统有时候需要添加新的节点，如何保证新节点和leader的数据一致呢？直接复制数据过来肯定是不行的，leader 一直处在 flux 中，一般步骤有四步：
1. leader 在某个确定一致性的时间点拍一个 snapshot 而不用锁住系统，大部分数据库都提供了这个功能，有的能通过第三方工具提供这个功能。
2. follower 将数据复制过去。
3. follower 将从这个时间点以后的数据复制过去，这需要拍 snapshot 时候的日志位置，这个点的名字叫 Log sequence number 或者 binlog coordinates。
4. 当 follower 将所有的change都同步后，我们称之为 catch up，就可以和其他follower一样，处理 leader 发生的变化了。</p>

<p>真正的步骤其实是有很多不同，有时候可以自动配置，有时候需要手动配置。</p>

<h3 id="3-handling-node-outages">(3) Handling Node Outages</h3>

<p>有时候节点会挂掉，可能是我们不知道的原因，也可能是为了安装系统模块而重启，这时候应该怎么保证集群的高可用</p>

<ol>
<li>follower 挂掉</li>
</ol>

<p>follower 挂点然后重启的步骤是很简单的，类似前面的添加新节点，启动以后，根据日志能找到最后一个处理的事务，然后从leader请求这个时间点以后的更改，然后进行更改，完成后就 catch up。</p>

<ol>
<li>leader failover</li>
</ol>

<p>leader 挂掉后可能麻烦一点，必须马上选择一名新的leader，这个过程被称为 failover</p>

<p>failover的具体步骤有4：
1. 确定leader失败了，失败的原因很多，磁盘、电源等等，目前用的最多的是 timeout 方法，节点相互 bounce message，如果突然在某个时间点收不到，就是失败了。
2. 选择新的 leader，需要在大多数的follwer 进行选举，最好是选一个数据最新的。所有的节点同意这个节点成为 consensus。
3. 告知系统使用新的leader，client 发送数据到新的 leader，旧的 leader 回复后也要认同新的 leader。</p>

<p>failover 总是会有些不期而遇的问题：
1. 如果是 asynchronous replica ，可能遇到一些数据没有同步过来，导致数据少了，如果这时候 older leader起来了，就会发生错误，这时候一般选择 discard 这部分数据。
2. 如果系统和别的系统进行结合，discard 是很危险的，github 发生了一次 mysql leader挂掉，然后discard 了一部分，删掉了部分自增的primary key，可是这部分pk已经保存到 redis了，导致了错误
3. 有时候两个节点都认为自己是 leader，这个叫做 split brain，这时候一半需要去掉一个，但是有可能两个都被去掉了。
4. timeout 的具体值多少合适？如果太长了，可能导致发现的晚。如果太短了可能误判，尤其是系统压力大的时候，还重新换一次会造成更大的压力。</p>

<p>这些问题解决起来还是很棘手的，所以有很多算法，我们后续会介绍。</p>

<h3 id="4-implementation-of-replication-logs">(4) Implementation of Replication Logs</h3>

<p>上面各种恢复，添加，都涉及到日志，日志记录了数据的更改，实际上我们学习 Hadoop 的时候，也知道里面有日志，现在我们来研究一下，日志怎么实现。</p>

<ol>
<li>Statement-based replication</li>
</ol>

<p>基于 statement 的 replication，这是最简单的方法，数据库记录每一次更新，也就是说，你的 UPDATE、INSERT、DELETE都会记录到日志中，然后发送给follower。
这样的问题是：
对于 current_timestamp、random 这样的方法返回值不一样，基于判断的例如 update &hellip; where &hellip; 必须按照顺序，一些触发器、存储过程等 side effects。</p>

<p>对于这些问题，当然也有特定的解决方案，例如先计算一些可能导致不一致的函数。</p>

<ol>
<li>WAL-log</li>
</ol>

<p>前面讲过 B-Tree 和 LSM-Tree，都是基于WAL-log，是一种只能 append 的二进制日志，leader 不仅将 wal-log 保存到磁盘，而且发送到 followers。</p>

<p>WAL 的 disadvantage 是太底层，wal 包含了磁盘那个位置的 block 需要修改哪些 bytes，这样耦合性比较高，如果format 改变了，基本上很难让 leader和follower 使用不同版本。</p>

<p>这个问题看起来更像是实现的问题，如果 replication 的协议支持follower 使用新的版本，就能完成 zore-downtime 的 upgrade。
首先更新 follower的版本，然后让leader failover，选择一个 follower 为 leader。如果replication 的协议不支持版本不一直，这就叫做 wal-shipping，会造成 upgrade-downtime。</p>

<ol>
<li>Logical (row-based) log replication</li>
</ol>

<p>这种方式就是 replication log 和具体的 storage device 解耦，使用不同格式。 relational database 的 logical log 一般都是一系列表示行的recorders。一个改变很多行的 statement 会
产生很多行这样的日志，后面有一个transaction 完成的标识符。这种方式是解耦的，所以可以容忍不同的版本，甚至不同的存储引擎。这也让外部的系统容易获得数据，
例如数仓、二级索引，外部缓存，这个技术叫做 change data capture。</p>

<ol>
<li>trigger based replication</li>
</ol>

<p>前面讲的都是数据库系统的，有时候我们需要更灵活的，例如你只想一部分数据，或者你想从一个数据库迁移到另一个数据库。这样你就应该将replication 提升到应用程序层面。
很多数据库提供了工具完成这个事情。许多关系型数据库提供了一项功能：triggers and stored procedures。
trigger 能让你注册用户代码，一旦数据发生改变，将会将数据放到另一给表格，外部系统可以访问。</p>

<h3 id="5-problems-with-replication-lag">(5) Problems with Replication Lag</h3>

<p>之前说了 Replication 是保证数据安全、忍受 node failures，实际上还可以提高 scalability。</p>

<p>Leader-based 需要所有的 write 请求都通过 master，将 read 分发到 slave，增加节点就能增加扩展性，
节点太多了就只能使用 异步的数据同步方式，否则可用性就很差。</p>

<p>然而一旦 slave 的数据 fallen behind 了，可能访问的数据过时了，这看起来问题不大，毕竟等等就行，这叫做  eventual consistency。</p>

<p>这个 eventually 是一个很NB的词，并没有告诉你具体时间，只是说最终会一致。我们称时间差为 the replication lag。这个 lag导致的问题我们接下来会讨论。</p>

<h4 id="1-read-your-own-writes">1. Read your own writes</h4>

<p>之前的 qq 空间有这个问题，当你发表了评论后页面会刷新，但是刷新后看不到自己发表的评论。
这时候你以为评论失败了，所以重新评论一下，然后刷新发现了自己评论了两次。</p>

<p>这种问题被叫做 “read-after-write consistency”，也叫做 “read-your-writes consistency”。有一些解决方案：</p>

<ol>
<li>如果是用户可以修改的信息，从 master 读。</li>
<li>如果是一分钟之内修改过的数据，从 master 读，或者可以监控 lag 大于1分钟的follow 排除。</li>
<li>客户端保存最近一次写的 timestamp，这样服务端保证读的时候先等 slave 的数据同步已经到了这个时间。这里的 timestamp 可以是逻辑时间。</li>
<li>如果有多个数据中心，可能更复杂。</li>
</ol>

<p>上面的解决方案只是一个 client，如果用户同事有多个 client 访问，例如手机和pc，这时候要考虑更多问题。</p>

<h4 id="2-monotonic-reads">2. Monotonic Reads</h4>

<p>类似上面，如果连续两次访问来自于不同的 slave，可能出现时间倒退，例如看球赛的时候刚开始比分 1:1,刷新一下变成 1:0 了！</p>

<p>Monotonic Reads 就是保证上面的异常不发生的一致性。他比 eventually consistency 更强，比 strong consistency 更弱。</p>

<p>这种一致性的解决方案就是保证每个 userid 都从同一个 slave 读数据，例如根据 userid 的 hash。</p>

<h4 id="3-consistent-prefix-reads">3. Consistent Prefix Reads</h4>

<p>在一个群聊系统，如果你发现两个人的对话顺序反了，就是 Consistent Prefix Reads 没有得到保证。</p>

<p>这个问题解决方案需要保证有相互依赖的数据都按顺序写入。后续再  causal dependencies 和 happens-before 会讨论。</p>

<h3 id="6-solutions-for-replication-lag">(6). Solutions for Replication Lag</h3>

<p>后续会讲解 事务 和 分布式事务。</p>

<h2 id="2-multi-leader-replication">2. Multi-Leader Replication</h2>

<p>一个 leader 可能会有一些问题，例如写太多了可能会有性能问题。也有一些其他的选择， 例如多个 leader 。</p>

<h3 id="1-use-cases-for-multi-leader-replication">(1). “Use Cases for Multi-Leader Replication”</h3>

<p>一般情况如果只有一个 datacenter 是不需要用多个 leader 的，所以在多个 datacenter 的时候会使用 multi-leader</p>

<h4 id="multi-datacenter-operation">Multi-datacenter operation</h4>

<p>如果有多个 datacenter ，那么每个 datacenter 一个 leader 是一个不错的选择。
我们对比一下在 multi-datacenter 中使用 single-leader 和    multi-leader 的fare</p>

<ol>
<li>Performance ，multi-datacenter 的性能可能好一些</li>
<li>Tolerance of datacenter outages ，multi-datacenter 不用担心leader 没了，所以更简单一点</li>
<li>Tolerance of network problems，由于 datacenter 之间的网络稳定性肯定不如 datacenter 内部，所以 multi-leader 更好点</li>
</ol>

<p>总之，如果有多个 datacenter ，选择 multi-leader。尽管如此也会有缺点，
例如需要同时修改一份数据，可能发生冲突导致一边成功一边失败了，后面的 handle write conflict 会讨论。</p>

<p>同时，multi-leader 可能会有一些陷阱、和数据库的其他特性放一起经常出问题，例如主键自增。所以 multi-leader 需要尽量避免。</p>

<h4 id="clients-with-offline-operation">“Clients with offline operation”</h4>

<p>以 印象笔记、icloud 为例，我们在手机、电脑 的笔记可以在线编辑，也可能离线编辑。
这个架构就和 Multi-Leader 类似，每个设备是一个 datacenter，服务端也是一个 datacenter，网络连接并不靠谱。</p>

<h4 id="collaborative-editing">Collaborative editing</h4>

<p>以 Google docs、wiki 为例，大家可以同事协同编辑，相关的算法就是 automatic conflict resolution。
你可能以为这个和 multi-leader 的 replication 不一样，实际上很类似。
一个人编辑的时候，change 马上就出现在 local replica ，然后是异步同步到服务器和其他的人。
如果你希望保证没有冲突，Application 需要在文档上面加锁，其余人获得锁之前不能编辑，这种就类似与 single-leader 的replica。
但是为了快速工作，你可能将锁分的很小，大家可以同时编辑，这就类似 multi-leader ，同时带来了 conflict resolution。</p>

<h4 id="handling-write-conflicts">Handling Write Conflicts</h4>

<p>如果两个人同时编辑，一个修改了标题一个修改了内容这不会有冲突，但是如果两个人都修改了标题该如何解决这个问题。
如果是 single-leader，并不会有这种问题，因为写都是有时间顺序的。后面的那个要么等待前面的修改事务成功或者失败，要么自己让让写任务失败。</p>

<ul>
<li>“Synchronous versus asynchronous conflict detection”</li>
</ul>

<p>如果两个任务修改同一个数据都成功了，然后异步发现了冲突，这时候解决已经晚了，因为不知道放弃哪个。
当然原则上也可以通过同步修改的方式避免冲突，这样就和 single-leader 没什么区别了。</p>

<ul>
<li>Conflict avoidance</li>
</ul>

<p>避免冲突是目前最好的方法了，例如用户可以修改自己信息的话，就让所有的修改都发送到同一个 datacenter 的 leader。</p>

<p>有时候也可能某个 datacenter 挂了或者用户去了另一个地方需要 datacenter 换了，需要使用别的方法避免冲突。这时候还是需要处理冲突。</p>

<ul>
<li>Converging toward a consistent state</li>
</ul>

<p>对于 single-leader 的 writes 都有一个 sequential order，统一数据的最后一次写决定了数据。
对于 multi-leader 就不一样了，并不知道哪个 datacenter 的才是正确的，如果不进行修改就会出现各个 datacenter 不一致，
所以所有的更改必须 最终是 convergent ，也就是说 最终一致性。几种常见的 convergent 方法：</p>

<ol>
<li>简单粗暴，直接每个操作一个 uuid，例如 hash，或者时间戳，最大的那个胜出，如果使用时间戳，这种方法就叫做 Last-Write—wins（LLW）。</li>
<li>给每个 replica 一个 id，id 最高的占主导地位，和上面的类似。</li>
<li>合并数据，例如 一个标题是A，一个是B，最后就是 A|B</li>
<li>用户自己实现冲突合并逻辑。</li>
</ol>

<ul>
<li>Custom conflict resolution logic</li>
</ul>

<p>自己实现冲突解决一般有两种方案：On Read 和 On Write ，相关细节比较简单</p>

<h4 id="what-is-a-conflict">What is a conflict?</h4>

<p>上面说的两个人同时修改标题的冲突很明显，所以可以通过一些程序控制，实际上也有一些不明显的的冲突。</p>

<p>例如两个人预定会议室，同一个会议室同一时间只能有一个人预定成功，但如果是 multi-leader 可能两个人都预订成功了。
或者注册的时候要求 username 不重复，但是有可能两个人同时申请同一个 username。</p>

<h3 id="2-multi-leader-replication-topologies">(2) Multi-Leader Replication Topologies</h3>

<p>Replication Topologies 是用来描述数据在节点间传播的路径。例如 circular 、star、all-2-all。</p>

<p>每一种都有优势和劣势。</p>

<h2 id="3-leaderless-replication">3. Leaderless Replication</h2>

<p>实际上 cassandra 采用了 leaderless 的架构，没有主节点。</p>

<h3 id="1-writing-to-the-database-when-a-node-is-down">(1) Writing to the Database When a Node Is Down</h3>

<p>leaderless 中，不存在 failover，因为没有主节点，因为一个节点在读数据的时候，并不需要从所有的节点都读数据，
二是给每个节点发送数据，然后每个节点都返回数据，根据 Version numbers 决定哪个是正确的。</p>

<h4 id="read-repair-and-anti-entropy">Read repair and anti-entropy</h4>

<p>系统需要保证每个 replica 上面的数据都是最终一致的，如果出现了节点挂掉然后恢复，如何保证它的数据是一致？</p>

<ol>
<li>Read repair ，当用户读书节的时候，能够发现 stale 的值并且修复</li>
<li>Anti-entropy process 通过后台进程扫描数据发现不一致</li>
</ol>

<h4 id="quorums-for-reading-and-writing">Quorums for reading and writing</h4>

<p>也就是上面所说的，读和写不需要全成功，只要保证 读成功数 r 和 写成功数 w 满足 r+w&gt;n即可。这个叫做仲裁原理，类似抽屉原理，
n个抽屉，里面有 w 个抽屉放了一样的纸条，打开r个抽屉，想要看到纸条内容，只要 r + w &gt;n。
一般情况下 r=w=(n+1)/2</p>

<ul>
<li>Limitations of Quorum Consistency</li>
</ul>

<p>上面我们说了 r=w=(n+1)/2，但是如果你的数据库写的量特别小，读特别大，你也可以设置 r=n，w=1，总之只要覆盖即可。</p>

<p>如果你对一致性要求不高，也可以使用 w+r &lt;= n，这样返回值可能 stale，不过这样的可用性更高。</p>

<p>然而尽管使 w+r &gt; n，也会有一些其他的异常情况：</p>

<ol>
<li>sloppy quorum 下无法保证</li>
<li>concurrently 写，和上一节类似，出现了写冲突？</li>
<li>读和写 concurrently，这时候写只提交了一部分，其他的可能还未完全在 w 个节点成功</li>
<li>如果写 成功不够w，但是这时候也没法 rollback，后续可能会读到失败的值，也可能读不到</li>
<li>如果保存了 new value 的节点失败重启，从另一个保存了 old value 的节点修复数据，导致包含 new value 数据的节点少于 n</li>
<li>还有极端情况，例如  “Linearizability and quorums”.</li>
</ol>

<p>因此，即便是 达到了 quorum 的条件，也没法真正的实现一致性。
特别的，至于在 single-leader 中的 “reading your writes, monotonic reads, consistent prefix reads” 等弱一致性也没法得到保障。
所以前面说的异常可能也会发生，强一致性需要 consensus 或者 transaction 来保证。</p>

<h4 id="monitoring-staleness">Monitoring staleness</h4>

<p>对于应用而言，是否返回最新版本的数据是很重要的。对于 leader-based 的设计，所有的问题都可以交给 replication-lag 来解决，
可以通过监控 replication-lag 监控系统
对于 leaderless 的设计，所有的数据并没有确定的顺序，监控很困难，而且如果没有 anti-entropy，数据可能过时很久都不修复。</p>

<h3 id="sloppy-quorums-and-hinted-handoff">“Sloppy Quorums and Hinted Handoff”</h3>

<p>简单介绍一下，例如 cassandra 中，保存三副本，读写都要成功 2 个 replica，我们写数据要成功 2个，
但是如果此时这三个节点挂了两个，只能写成功一个，可以先将另一份数据放到其他的节点上。
等对应的剩下的节点都恢复了，再将数据放回去，这个过程就是 hinted handoff。</p>

<h3 id="multi-datacenter-operation-1">Multi-datacenter operation</h3>

<p>这时候我们还是有N个副本，我们需要保证每在 每个 datacenter 都达到了 对应的 n/2 个副本。</p>

<h3 id="detecting-concurrent-writes">Detecting Concurrent Writes</h3>

<p>类似之前的 handling write conflict，也是由于顺序不一样导致，所以也需要有保证 converge 的方法，
这样的方案也就是我们前面说的一样。但是我们这里讨论的更细致一点。</p>

<h4 id="last-write-wins-discarding-concurrent-writes">Last write wins (discarding concurrent writes)</h4>

<p>对于不知道哪个 happens-first 的操作，我们称之为 concurrent，他们的 order 是不知道的。</p>

<p>尽管他们没有 order，我们可以人为给一个 order，例如 timestamp，也就是 Last write wins。</p>

<p>llw 解决了冲突问题，但是丢失了一些数据。所有使用 cassandra 的时候有人会给每个 key 后面加一个 uuid，这样能保证每个 key 多次写都不会丢失。</p>

<h4 id="the-happens-before-relationship-and-concurrency">The “happens-before” relationship and concurrency</h4>

<p>happens-before 的关系是决定是否并发的关键，以下情况下我们称两个操作是 concurrency：
“neither happens before the other (neither knows about the other)”</p>

<p>因此，对于任何两个操作 A 和 B，只有两种可能，A happens-before B，B happens-before A，A 和 B 是 concurrency。</p>

<h4 id="capturing-the-happens-before-relationship">Capturing the happens-before relationship</h4>

<p>上面已经知道两个操作只能有 3 种关系，我们如果发现 happens-before  的关系呢？其实有算法的。</p>

<p>首先假如 A 和 B两个人都在往同一个购物车添加商品，一开始 A添加了 商品1，B添加了商品 2，这两个是 concurrency的，
然后 A再添加 3，B添加4，这时候 这两个操作都是 3和4是 concurrency的，但是1和2 都是 happens-before 3 和4 的。</p>

<p>发现 concurrency 关系的算法如下：</p>

<ol>
<li>server 的每个key有一个 version number，每次更新写这个 key 的时候，version number 就 +1并且跟新数据。</li>
<li>当 client 读数据，返回所有没有 overwritten 的数据和最新的 version number。</li>
<li>client 写数据的时候，必须包含之前读到的那个 version number，并且合并所有的数据，</li>
<li>当 server 收到带 version number 的写请求，覆盖所有小于等于 version number 的数据，保留大于 version number 的数据。</li>
</ol>

<p>这样的算法就能发现所有的 happens-before 关系</p>

<h4 id="merging-concurrently-written-values">Merging concurrently written values</h4>

<p>类似前面的 conflict resolution，上面的算法需要 client 进行数据合并，合并算法大家自己查资料，例如 CRDT 。</p>

<h4 id="version-vectors">Version vectors</h4>

<p>上面的算法是 single-replica 情况，对于 multi-replica 的情况，需要每个副本一个 Version number，这被叫做 Version vectors。</p>

<h2 id="summary">SUMmary</h2>

<p>通过上面的讨论，我们明白了一句话，其实分布式 replica 最大的问题就是发现 happens-before 的依赖关系，也就是操作的顺序。</p>

<p>另外有大神说过，分布式只有两个问题， exactly-once 和 order。其中 exactly-once 后续会讨论，order 就是我们这里讨论最多的。</p>

<h1 id="二-partitioning">二、Partitioning</h1>

<p>分区，also known as Sharding。相对其他的理论，这部分很简单了。主要就是跨分区的事务稍微复杂点。</p>

<h1 id="三-transactions">三、Transactions</h1>

<p>在一个数据系统中，很多东西可能出错，有可能是网络问题，硬件问题，系统 bug。为了可靠，我们必须让系统可靠，事务就是一个选择。
事务是我们设计应用的时候遵循的的一套规定，但实际上他并不是理所当然的，二是要通过设计底层算法来满足的，这次我们就看看这些算法。
这一节我们主要将重点放在单机的事务，下一节将会讨论分布式事务。</p>

<h2 id="1-the-slippery-concept-of-a-transaction">1. The Slippery Concept of a Transaction</h2>

<p>现在几乎所有的 relational databases，以及一些 NoSql 都支持 transaction，但是 transaction 的定义到底是什么？
实际上一些 NoSql 摆脱了事务的约束，因为事务有时候严重影响了扩展性。都是一些  trade-offs</p>

<h2 id="2-the-meaning-of-acid">2. The Meaning of ACID</h2>

<p>不同数据库的 ACID 实现方式是不同的，例如 isolation 的定义有很多，除了 ACID 还有一种约束叫做 BASE，就更加模糊了，一个一个看吧。</p>

<h3 id="1-atomicity">(1) Atomicity</h3>

<p>原子性其实有很多种定义，一般代表一个事物不可分，例如同时如果是多线程，另一个线程不可能看到转账中间的状态。</p>

<p>但是在事务中，并不是这个意思，上面的问题是 隔离性讨论范畴，Atomic 是说，例如一个转账的事务，分为两步，不可能只完成一步而另一步失败。</p>

<p>没有原子性保证，如果一个事物中途失败，我们没法知道哪些改变了哪些没改变。</p>

<h3 id="2-consistency">(2) Consistency</h3>

<p>Consistency 是一个被严重重载的词，前面的 replica 中它是说主备不一致；CAP 中指的是 线性一致性，这里指的是一种 good state。</p>

<p>这个定义很模糊，因为他很难描述清楚。一是转账的时候，事务前后两个人的总金额要一样，
注册用户名的时候保证用户名不重复，不能违背外键约束，这都是一致性的问题。
AID 都是 properties of databases，数据库可能依赖 AID 来实现 Consistency，所以严格来说 Consistency 并不属于 ACID</p>

<h3 id="3-isolation">(3) Isolation</h3>

<p>大部分数据都是多线程操作的，如果多个线程访问了同一条数据，就会出现类似前面讨论的 concurrency-write 问题，但是这里还有 read 的问题。
有的经典课本将它改为 serializability，意思是每个线程都可以假设只有他一个线程在操作数据库，数据库保证并发执行的结果和顺序执行的结果是一样的。
实际上真正的数据库很少会让操作只在一个线程里面，这样性能太低。</p>

<h3 id="4-durability">(4) Durability</h3>

<p>这个就是说事务一旦提交就持久化了，例如已经存入了 nonvolatile storage，例如 hard drive or SSD，结合 write-ahead log 等方式实现。
在 replicated databases 中，可能意味着已经复制到了好几个副本之中。
perfect durability 是不可能存在的，如果你的机房被恐怖分子炸掉了，硬盘都没了。</p>

<p>自从分布式理论有了以后， REPLICATION AND DURABILITY 就出现了一些变化，相关的可以查看资料。</p>

<h2 id="single-object-and-multi-object-operations">Single-Object and Multi-Object Operations</h2>

<p>上面我们知道了，atomicity 和 isolation 描述了在客户端执行多个操作时候 ，数据库的做法。
前者表示如果事务进行到一半失败了必须删掉所有修改的数据，后者表示各个线程互不干扰。接下来看一个例子。</p>

<p>一个邮件系统需要显示未读邮件数量，如果每次用户登录都执行 count 操作会比较耗时，所以添加了一个变量 counter 表示未读邮件。</p>

<p>这时候每次收到一个邮件就 counter++ ，读了一份邮件就 counter &ndash;。
atomicity 能够保证 不会出现异常（例如已经没用邮件但是 counter &gt;0）,不会出现 消息标记为已读但是 counter&ndash; 执行失败。
如果标记已读的时候，突然收到一份邮件，这时候 counter 的 ++ 和 &ndash; 是并发的，Isolation 保证不会出现异常。</p>

<p>Multi-object transactions 需要决定哪个读和写操作是同一个 事务。
对于 relational，就是同一个 tcp 连接的一个 start 和 commit 之间的操作属于同一个事务。
但是对于 Nosql，并没有相应的方法，尽管提供了对于的API，但是实际上不一定能保证事务。</p>

<h3 id="1-single-object-writes">(1) Single-object writes</h3>

<p>如果一个事务修改了一个 json 文件，但是由于网络问题，修改了一半。或者多个事务同时修改了一个字段，这时候也和上面一样需要进行单个对象事务控制。</p>

<p>一些数据库提供了 更复杂的 atomic 操作，例如 increment 可以避免 read-modify-write，类似的有 compare-and-set ，思想类似了乐观锁。
这样的操作实际上和 ACID 类似，compare-and-set 实际上也是 lightweight transactions，或者是市场化的 ACID。</p>

<h3 id="2-the-need-for-multi-object-transactions">(2) The need for multi-object transactions</h3>

<p>许多 NoSql 放弃了 multi-object transactions， 因为需要在不同的 partitions 上面实现事务。
我们真的需要 multi-object transactions 么？我们的应用能否只通过 single-object operations 实现。考虑以下情形：</p>

<ol>
<li>外键约束 关系型数据库可能有外键，我们执行一个操作的时候，需要考虑满足这些约束</li>
<li>document databases 很难 join，所以会有 denormalization，对应的修改必须是同时修改。</li>
<li>考虑 secondary indexes，值修改了索引也要进行修改。</li>
</ol>

<p>这些情形可以不用事务，但是容错就会相当复杂。</p>

<h3 id="3-handling-errors-and-aborts">(3) Handling errors and aborts</h3>

<p>ACID 的主要目的是如果发生了错误，我可以完全丢弃掉这些改变，但是也有例外。
leaderless replication 在你的数据出现错误以后并不会进行修改。
如果发生了错误就直接 abort 然后重试也不是很好的选择：</p>

<ol>
<li>如果事务已经 succeeded，但是网络问题导致没有返回成功消息，你可能会标记为失败，然后重试会执行两次？</li>
<li>如果集群 load 过高你这时候再次重试反而会是问题严重。</li>
<li>有时候重试再多次也是失败的</li>
<li>如果事物内部有一些操作，例如发邮件？你总不能每次重试就发一次邮件吧。</li>
</ol>

<h2 id="2-weak-isolation-levels">2. Weak Isolation Levels</h2>

<p>上面说过 serializable 并不是最好的隔离方式，还有一些其他的方式。</p>

<h3 id="1-read-committed">(1) Read Committed</h3>

<p>Read Committed 有两个保证，1 是读数据的时候只能看到提交成功的数据，2 是写数据的时候只会覆盖写成功的数据。也就是没有脏读和脏写。</p>

<h4 id="no-dirty-reads">No dirty reads</h4>

<p>如果你读了别的事务还没提交的数据就是脏读，如果覆盖了别的事务还没提交的数据就是脏写。
举个例子，如果你的账户余额为0，查看余额的时候，有人刚好在给你转账，
先给你加了 500，然后他的账户余额不够事务失败了，然后又 rollback，结果你刷新发现又变成了0。你看到 500 是脏数据，所以是脏读。
同理如果你给自己存钱的时候覆盖了这个 500，就是脏写。</p>

<p>Read Committed 隔离级别数据库需要保证不会出现脏读，也就是看到的数据是已经 commit 的。</p>

<h4 id="no-dirty-writes">No dirty writes</h4>

<p>同样需要保证不会出现脏写，一般需要加锁，等待前一个事务 commit 或者 abort</p>

<h4 id="implementing-read-committed">Implementing read committed</h4>

<p>简单粗暴的方式就是加锁，这也是大部分数据库 保证 没有 No dirty writes 的方式，但是脏读也加锁就会降低性能。
所以脏读一般是通过保存两份数据，一个是未提交的数据，一个是已经提交的数据。读的时候返回已经提交的数据。</p>

<h3 id="2-snapshot-isolation-and-repeatable-read">(2) Snapshot Isolation and Repeatable Read</h3>

<p>貌似 上面已经很完美了，但是看看下面的例子：
还是两个人转账，A 把 500 块转给 B，首先把 A 设置为 0，然后 B 设置为 500。
此时B 查看了两个用户的账户，在还没开始的时候查看了A的，结束的时候查看了B的，发现两个人都是 0.</p>

<p>上面的问题和之前的反了过来。脏读是读了修改到一半的数据，不可重复读是修改了读到一半的数据。
这貌似不是一个大问题，只要等一会儿再读，就发现是正确的。但是注意以下情况：</p>

<ol>
<li>Backups 如果我再备份数据，类似这里的读。</li>
<li>Analytic queries</li>
</ol>

<p>Snapshot isolation 就是解决这个问题的方法。实现 快照隔离需要用 MVCC 算法。
之前每条数据都有两个版本，未提交的和提交的，现在改成多个，也就是每一条保存多个版本的数据，算法如下：</p>

<ol>
<li>每个事务都有一个 txid。</li>
<li>每一行数据有一个 created_by 段包含了 tx_id。</li>
<li>每一行数据有一个 deleted_by 字段默认空值，如果数据删除了，实际上不会删的，二是 deleted_by 会有一个 txid 标志它被删掉。</li>
<li>如果确定没有实物能访问到被删掉的数据，就真的删了被删掉的数据。</li>
<li>update 等于 delete + create</li>
</ol>

<p>读数据时候的 Visibility rules 如下：</p>

<ol>
<li>每个 transaction 开始的时候会将所有正在执行的 transactions 列出，这些事务的修改无论成功与否都 ignore。</li>
<li>所有 abort 的事务做的修改 都 ignore。</li>
<li>比它大的 txid 做出的修改都 ignore。</li>
<li>其他的修改都是 可见的。</li>
<li>这里的修改指的是 create 和 delete</li>
</ol>

<p>换个方式，只有下面的情况才是 visible：</p>

<ol>
<li>transaction 开始的时候，已经 commit 的数据</li>
<li>别的事物虽然已经删了数据，但是还没有提交的。</li>
</ol>

<h3 id="3-indexes-and-snapshot-isolation">(3) Indexes and snapshot isolation</h3>

<p>在 multi-version 的 databases 里面 index 如何工作? 可以和数据一样，有多个索引，但也可以在有多个版本的时候避免索引更新。
还有的结构是 appendOnly 的结构。。。。</p>

<h3 id="4-repeatable-read-and-naming-confusion">(4) Repeatable read and naming confusion</h3>

<p>Repeatable read 其实一开始是没有的，也是慢慢被发现的，所以它的名字有很多，实现方式也不一样，提供的一致性保证也不一定一样。</p>

<h2 id="3-preventing-lost-updates">3. Preventing Lost Updates</h2>

<p>前面只讨论了 dirty writes，类似我们讨论的并发写，还有一些问题我们没有讨论。最有名的就是  Lost Updates，例如并发给某个数据 +1.
一般可能出现的情况：
1. 查询数据并增加，例如：转账的时候同时转账。
2. 同时编辑某个 wiki 文档的一个部分。
3. 修改一个 json 字符串</p>

<h3 id="1-atomic-write-operations">(1) Atomic write operations</h3>

<p>大部分 relational db 都支持 atomic 写，即 <code>UPDATE counters SET value = value + 1 WHERE key = 'foo';</code> 而不需要 read-modify-write。</p>

<p>一般情况下都是通过 exclusive lock 方式实现，这种方式也被称为  cursor stability，另一种就是强制要求所有的操作在一个线程里。</p>

<p>但是有些 orm 框架让你很容易写出 unsafe 的并发更新bug而且很难查出来。</p>

<h3 id="2-explicit-locking">(2) Explicit locking</h3>

<pre><code>SELECT * FROM figures
  WHERE name = 'robot' AND game_id = 222
  FOR UPDATE;
</code></pre>

<p>这样直接锁住记录</p>

<h3 id="3-automatically-detecting-lost-updates">(3) Automatically detecting lost updates</h3>

<p>加锁的方式是让操作序列化执行，同样可以让每个并发执行，如果发生了错误就 abort 重试。
Lost update detection 是一种很高级的特性。</p>

<h3 id="4-compare-and-set">(4) Compare-and-set</h3>

<p>这种方式就是写之前先读，如果数据没有变化再写。
但是如果写之前读的是还没提交的数据，可能还是有问题的。</p>

<h3 id="5-conflict-resolution-and-replication">(5) Conflict resolution and replication</h3>

<p>如果有多个副本，写数据都是并发，同步数据是异步的，这时候 locks 和 compare-and-set 的方式以及没法保证数据一致性了。</p>

<h2 id="4-write-skew-and-phantoms">4. Write Skew and Phantoms</h2>

<p>除了上面的问题，可能还有新的问题。看下嘛的例子：
我们有个医生门诊应用，每个医生可以请假，但是至少保证有一个医生没有请假。医生请假的时候会查询目前在岗的医生，发现有人就可以请假。
但是如果有一个时间所有的医生都同时查看，发现大家都在，然后大家都一起请假，就违背了约束。</p>

<h3 id="1-characterizing-write-skew">(1) Characterizing write skew</h3>

<p>这种问题叫做 write skew，既不是脏写也不是 lost update。对应的读问题叫做 phantoms read。
因为两个事务更新的是两个数据（每个医生设置自己的状态为请假），这里的冲突不太明显，但是确实违背了约束。</p>

<p>write skew 可以看出广义的 lost update，write skew 是多个事务读了同一个数据然后更新了其中的部分数据。
如果更新的是同一条数据就会得到 dirty write 或者 lost update。</p>

<p>lost update 我们有很多种方案可以解决，但是貌似这里就不行了：
1. Atomic single-object 没法解决，因为 这里有多个 obj
2. automatic detection 很难，因为这种问题需要 Serializable 的隔离级别
3. 通过添加唯一位数、主键约束都不一定可以，例如这里有多个医生的在岗状态，如果加约束需要每次都扫描全表。</p>

<p>还有很多 write skew 的问题，
会议室预约系统如何保证一个会议室在同一时间不会被两个人预定？
Multiplayer game 怎么保证两个用户不会出现在同一个点，
用户名唯一性约束等</p>

<h3 id="2-phantoms-causing-write-skew">(2) Phantoms causing write skew</h3>

<p>上面的问题有一个共同点：
1. 查询是否满足多个条件
2. 根据上面的结果做出更新
3. 第二步的更新导致第一步的条件不成立</p>

<p>注意一定是有更改，如果是只读的， snapshot isolation 就能保证不会出现异常。</p>

<h3 id="3-materializing-conflicts">(3) Materializing conflicts</h3>

<p>貌似有的问题是我们没法加锁，例如第一个 不知道给哪个医生加锁？但是如果能够物化冲突，找到加锁的地方就能够解决了。</p>

<p>会议室预定的，我们可以给每个会议室每个时间段创建一条记录，然后加锁。问题在于有的我们很难物化，例如用户名唯一性，
不可能给每个用户名都创建一个索引。大多数还是使用 Serializability 的隔离级别</p>

<h2 id="4-serializability">4. Serializability</h2>

<p>这是目前 strongest isolation level，让数据库表现的类似所有的事务都 execute in parallel。</p>

<p>如何实现  implementing 并且它的效率如何是需要考虑的问题。目前三种实现：顺序执行、2PL、SSI</p>

<h3 id="1-actual-serial-execution">(1) Actual Serial Execution</h3>

<h4 id="encapsulating-transactions-in-stored-procedures">Encapsulating transactions in stored procedures</h4>

<h3 id="2-two-phase-locking-2pl">(2) Two-Phase Locking (2PL)</h3>

<p>很久一段时间，实现 serial 只有一种方法，那就是 2PL，注意这里的 2pl 和 后面的 2pc 不一样。</p>

<p>我们知道锁的作用就是更新时候保证一个是在另一个完成后进行的。2PL类似，很多个线程都可以同时读一条数据，
但是如果想要更改数据，就需要使用 exclusive access ：
1. A 如果读了数据 然后 B 想更改这条数据，B 需要等待 A 事务 commit 或者 abort
2. A 如果修改了数据 然后 B 想读这条数据，B 需要等待 A 事务 commit 或者 abort</p>

<p>2PL 和 前面的锁不一样的地方在于，writers 不仅会锁住其他的 writers，还会锁住其他的 readers，反过来也一样。
这就是和 snapshot isolation 不一样的地方，所以他能够防止前面所有的错误。</p>

<h4 id="implementation-of-two-phase-locking">Implementation of two-phase locking</h4>

<p>实现 2PL 的方式就是给每个记录加锁，锁可以是 shared 或者 exclusive。使用方式如下：
1. 如果线程 A 想读 一个记录，需要获得 shared mode 的锁。所谓 shared mode 就是多个 shared mode 的线程可以共用锁
2. 如果线程 A 想写 一个记录，需要获得 exclusive mode 的锁。所谓 exclusive mode，就是只能一个人获得锁
3. 如果一个事务先 读然后写，需要将对应的 shared mode 的锁 升级为 exclusive mode 的锁。
4. 一个事务获得了锁，就需要一个 hold 住，知道结束（commit或者 abort）.</p>

<p>这就是 two-phase 的由来，phase1 就是 acquired lock(execute transaction), phase2 就是 release locks(end of the transaction)
由于使用了很多 locks，很容易出现 A 等待 B释放锁，同时 B 等待 A，这就是 死锁，数据库一般可以自动发现死锁。</p>

<h4 id="performance-of-two-phase-locking">Performance of two-phase locking</h4>

<p>一直依赖不用 2PC 的原因就是性能太差了，一方面获得锁释放锁有性能开销，更重要的还是并发度太低。
而且一旦出现事务等待，不知道要等待多久。另外死锁出现的概率大了很多。</p>

<h4 id="predicate-locks">Predicate locks</h4>

<p>上面的预定会议室程序，如果一个用户预定了一个某个时间段的某个地点，另一个用户此时还可以预约，只要不是相同的时间和地点。</p>

<p>这时候我们可以使用 Predicate locks，和 2PL 类似，但是不一样的是 2PL 对查询的某一条数据加锁，
Predicate locks 是加在所有的符合某个条件的所有数据。</p>

<p>这里的关键在于 Predicate locks 不仅可以加在目前存在的记录上面，还可以加在未来会写进来的数据上。
如果 2PL 包含了 Predicate locks，就可以防止任何形式的 phantom，也就成了 Serializable。</p>

<h4 id="index-range-locks">Index-range locks</h4>

<p>Predicate locks 并不好用，如果有太多 lock，判断每个lock 很耗时，所以很多 2PL 使用的是 index-range locking。</p>

<p>例如我们要锁住 某个会议室在 明天下午三点 ，这判断起来很麻烦，我们可以直接将这个会议室锁起来！或者把所有的会议室 下午三点都锁起来。
由于 room_id 或者 time 可能有索引，所以判断起来会比较快。</p>

<p>index-range locks 并没有 Predicate locks 精确，但是可以降低查询量，也是一个好的折中。
如果没有索引，就锁住整个表格，这样就会降低性能，但是也是一个折中。</p>

<h3 id="serializable-snapshot-isolation-ssi">Serializable Snapshot Isolation (SSI)</h3>

<p>前面我们发现，提供的隔离性越好，性能就越差？貌似性能和隔离性一定是 odds？不一定，有个 SSI 算法比较新，提供了很好的性能。</p>

<h4 id="pessimistic-versus-optimistic-concurrency-control">Pessimistic versus optimistic concurrency control</h4>

<p>2PL 是 pessimistic 悲观锁，如果可能会出错那么就等待安全了再操作，类似 mutual exclusion。
Serial execution ，就是极端的 pessimistic。</p>

<p>serializable snapshot isolation 是一种 optimistic concurrency control technique.
先假定不会出错，然后 commit 的时候判断有没有出错。</p>

<h3 id="decisions-based-on-an-outdated-premise">Decisions based on an outdated premise</h3>

<p>我们前面出现的 write skew 的时候，都有一个通用的模式：
一个 transaction 读一些数据，检查结果并且做一些动作，但是提交数据的时候，这些数据可能已经被另一个事务更改。</p>

<p>transaction 会基于 premise 做出一些 action，等后面准备 commit 的时候，这个 premise 已经不正确了。
换句话说，读的数据和写的数据之间有一个 causal dependency。如何发现 outdated premise，主要有两种：</p>

<ol>
<li>Detecting reads of a stale MVCC object version (uncommitted write occurred before the read)</li>
<li>Detecting writes that affect prior reads (the write occurs after the read)</li>
</ol>

<h4 id="detecting-stale-mvcc-reads">Detecting stale MVCC reads</h4>

<p>在 snapshot isolation 中使用了 multi-version 的数据，每个事务不会读到当前还没有提交的数据，
所以其他的线程可能修改了这个数据，为了防着这种情况发生，db 需要记录由于 MVCC visibility rules 而忽略的数据，
当这个事务 commit 的时候，检查这些数据是否提交，如果提交了就 abort。</p>

<p>为何要等待 commit 的时候判断而不是直接放弃？因为 当前事务可能是只读，或者另一个事务会失败，或者另一个事务会持续很久。</p>

<h4 id="detecting-writes-that-affect-prior-reads">Detecting writes that affect prior reads</h4>

<p>当一个 transaction 写数据的时候，他需要查看最近读了这个数据的事务，通知这些事务他们的他们的数据已经过时了。</p>

<h4 id="performance-of-serializable-snapshot-isolation">Performance of serializable snapshot isolation</h4>

<p>和 2PL 相比，SSI 不用阻塞线程。读写之间是不会阻塞，导致延迟低。</p>

<p>aborts rate 对性能影响很大。但是 SSI 对 长事务 的敏感程度 肯定比 2PL 和 real serial 低。</p>

<h1 id="第五部分-案例">第五部分、案例</h1>

<p><a href="https://medium.freecodecamp.org/how-to-system-design-dda63ed27e26">https://medium.freecodecamp.org/how-to-system-design-dda63ed27e26</a></p>

<p><a href="http://blog.gainlo.co/index.php/2015/10/22/8-things-you-need-to-know-before-system-design-interviews/">http://blog.gainlo.co/index.php/2015/10/22/8-things-you-need-to-know-before-system-design-interviews/</a></p>

<p><a href="https://engineering.videoblocks.com/web-architecture-101-a3224e126947">https://engineering.videoblocks.com/web-architecture-101-a3224e126947</a></p>

<h1 id="第六部分-资料">第六部分、资料</h1>

<p>es设计架构，良心参考资料：
<a href="https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db">https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db</a>
<a href="https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571">https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571</a>
<a href="https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d">https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d</a></p>

<p>lsm b+tree 资料
<a href="https://medium.com/databasss/on-disk-io-part-3-lsm-trees-8b2da218496f">https://medium.com/databasss/on-disk-io-part-3-lsm-trees-8b2da218496f</a></p>

    </div>

    
    
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">邓子明</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">2018-12-22</span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>

    
    
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">Reward</label>
  <div class="qr-code">
    
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="https://github.com/dengziming/blogs/blob/master/images/wechat.jpg?raw=true">
        <span>Wechat</span>
      </label>
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="https://github.com/dengziming/blogs/blob/master/images/alipay.jpg?raw=true">
        <span>Alipay</span>
      </label>
  </div>
</div>

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/%E6%9E%B6%E6%9E%84/">架构</a>
          
          <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/data-intensive-architecture/replication/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">分布式存储-replication</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/data-intensive-architecture/partition/">
            <span class="next-text nav-default">分布式存储-partition</span>
            <span class="prev-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
    

  

  

  <div id="comments-gitment"></div>
  <link rel="stylesheet" href="/lib/gitment/gitment-0.0.3.min.css">
    <script src="/lib/gitment/gitment-0.0.3.min.js"></script>
  <script type="text/javascript">
  const gitment = new Gitment({
    id: '2018-12-22 00:00:00 \x2b0000 UTC',
    title: 'design-data-intensive-architecture',
    link: decodeURI(location.href),
    desc: '第一部分、前言 ACID，bigdata，NoSql ，bigTable ，CAP，2PC，3PC，quorum，raft，paxos，cloud',
    owner: 'dengziming',
    repo: 'https:\/\/github.com\/dengziming\/comment.oi.git',
    oauth: {
      client_id: '1eb2e794cac943b9af79',
      client_secret: 'a4f7d62a2a52b5c43e51c0c476a3b605029ac372'
    }
  })
  gitment.render('comments-gitment')
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://github.com/imsun/gitment">comments powered by gitment.</a></noscript>
  </article>
        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="zmdeng@aliyun.com" rel="me" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" rel="me" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://twitter.com/dengziming2/" rel="me" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.facebook.com/deng.ziming.7" rel="me" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://www.linkedin.com/in/%E5%AD%90-%E9%82%93-72a924133/" rel="me" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="dengziming1993@gmail.com" rel="me" class="iconfont icon-google" title="google"></a>
      <a href="http://www.github.com/dengziming" rel="me" class="iconfont icon-github" title="github"></a>
      <a href="http://localhost:1313" rel="me" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" rel="me" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="http://localhost:1313" rel="me" class="iconfont icon-douban" title="douban"></a>
      <a href="http://localhost:1313" rel="me" class="iconfont icon-pocket" title="pocket"></a>
      <a href="http://localhost:1313" rel="me" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="http://localhost:1313" rel="me" class="iconfont icon-instagram" title="instagram"></a>
      <a href="http://en.xianmin.org/hugo-theme-jane/" rel="me" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="http://en.xianmin.org/hugo-theme-jane/" rel="me" class="iconfont icon-goodreads" title="goodreads"></a>
  <a href="https://dengziming.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy; 
    
      2016 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">邓子明</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>
<script type="text/javascript" src="/dist/jane.min.js?v=2.7.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML'></script>





</body>
</html>
