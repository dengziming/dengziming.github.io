<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>设计高并发架构 on 数据分析师之旅</title>
    <link>https://dengziming.github.io/categories/%E8%AE%BE%E8%AE%A1%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/</link>
    <description>Recent content in 设计高并发架构 on 数据分析师之旅</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 22 Dec 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://dengziming.github.io/categories/%E8%AE%BE%E8%AE%A1%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>design-data-intensive-architecture</title>
      <link>https://dengziming.github.io/post/data-intensive-architecture/design-data-intensive-architecture/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/data-intensive-architecture/design-data-intensive-architecture/</guid>
      
        <description>

&lt;h1 id=&#34;第一部分-前言&#34;&gt;第一部分、前言&lt;/h1&gt;

&lt;p&gt;ACID，bigdata，NoSql ，bigTable ，CAP，2PC，3PC，quorum，raft，paxos，cloud，real-time，高并发架构将会逐渐成为基础。&lt;/p&gt;

&lt;p&gt;主要内容：
（一）基础&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;“reliability, scalability, and maintainability”&lt;/li&gt;
&lt;li&gt;数据模型&lt;/li&gt;
&lt;li&gt;存储引擎&lt;/li&gt;
&lt;li&gt;数据结构&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;（二）分布式&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;replication&lt;/li&gt;
&lt;li&gt;partitioning/sharding&lt;/li&gt;
&lt;li&gt;transaction&lt;/li&gt;
&lt;li&gt;distributed system&lt;/li&gt;
&lt;li&gt;consistency and consensus&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;（三）交互&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;batch process&lt;/li&gt;
&lt;li&gt;realtime&lt;/li&gt;
&lt;li&gt;put everything together&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;（四）案例及资料&lt;/p&gt;

&lt;h1 id=&#34;第二部分-数据系统的基础&#34;&gt;第二部分、数据系统的基础&lt;/h1&gt;

&lt;h2 id=&#34;一-reliable-scalable-和-maintainable-的含义&#34;&gt;一、Reliable,Scalable 和 Maintainable 的含义&lt;/h2&gt;

&lt;p&gt;数据系统分为 data-intensive 和 compute-intensive，一般的大数据应用会采用的技术：
1. 存储，方便后续的查询 &amp;ndash; databases
2. 缓存，加速访问 &amp;ndash; caches
3. 允许用户通过关键字搜索、按照过滤  &amp;ndash; indexes
4. 给另一个进程发送消息，异步处理  &amp;ndash; streaming process
5. 周期性处理全量数据  &amp;ndash; batch process&lt;/p&gt;

&lt;p&gt;这一切都是需要数据系统，我们并不会从头开始搭建存储、计算系统，因为有很多现成的技术可以应用。数据库、消息队列功能都很相似，但是实现完全不同，导致不同的性能，所以我们用处不同，我们为什么要将他们结合到一起呢？&lt;/p&gt;

&lt;p&gt;其实许多工具功能比较重复，redis 其实也可以当消息队列，kafka 也可以做数据持久化。这些工具的界限越来越模糊。第二是我们得系统一般比较复杂，一个工具完成不了，我们必须组件一个数据系统。组件的过程
有很多需要考虑的事情，其中最重要的三点：
Reliable： 系统必须一致能够提供服务，即便是发生了一些不可预知的错误
Scalable： 系统升级、功能扩展、访问量增加，导致我们需要能够很方便扩展我们的系统
Maintainable： 随着时间推移，可能有很多其他人接受项目，必须方便别人进行维护&lt;/p&gt;

&lt;p&gt;有关这三点的介绍，我们逐渐展开：&lt;/p&gt;

&lt;h3 id=&#34;1-reliable&#34;&gt;1. Reliable&lt;/h3&gt;

&lt;h3 id=&#34;2-scalable&#34;&gt;2. Scalable&lt;/h3&gt;

&lt;h3 id=&#34;3-maintainable&#34;&gt;3. Maintainable&lt;/h3&gt;

&lt;h2 id=&#34;二-数据模型和查询语言&#34;&gt;二、数据模型和查询语言&lt;/h2&gt;

&lt;p&gt;数据模型是最重要的一部分，&lt;/p&gt;

&lt;h3 id=&#34;1-关系型与文档型&#34;&gt;1.关系型与文档型&lt;/h3&gt;

&lt;h3 id=&#34;2-nosql&#34;&gt;2.NoSQL&lt;/h3&gt;

&lt;h3 id=&#34;3-object-relational-mismatch&#34;&gt;3. Object-Relational Mismatch&lt;/h3&gt;

&lt;h3 id=&#34;4-many-to-one-and-many-to-many-relationships&#34;&gt;4. Many-to-One and Many-to-Many Relationships&lt;/h3&gt;

&lt;h3 id=&#34;5-query-languages-for-data&#34;&gt;5. Query Languages for Data&lt;/h3&gt;

&lt;h3 id=&#34;6-graph-like-data-models&#34;&gt;6.Graph-Like Data Models&lt;/h3&gt;

&lt;h2 id=&#34;三-storage-and-retrieval&#34;&gt;三、Storage and Retrieval&lt;/h2&gt;

&lt;h3 id=&#34;1-hash-indexes&#34;&gt;1. Hash Indexes&lt;/h3&gt;

&lt;h3 id=&#34;2-sstables-and-lsm-trees&#34;&gt;2. SSTables and LSM-Trees&lt;/h3&gt;

&lt;h3 id=&#34;3-b-trees&#34;&gt;3. B-Trees&lt;/h3&gt;

&lt;h3 id=&#34;4-multi-column-indexes&#34;&gt;4. Multi-column indexes&lt;/h3&gt;

&lt;h3 id=&#34;5-full-text-search-and-fuzzy-indexes&#34;&gt;5. Full-text search and fuzzy indexes&lt;/h3&gt;

&lt;h3 id=&#34;6-keeping-everything-in-memory&#34;&gt;6.Keeping everything in memory&lt;/h3&gt;

&lt;h3 id=&#34;7-olap-vs-oltp&#34;&gt;7. OLAP vs OLTP&lt;/h3&gt;

&lt;h3 id=&#34;8-数据仓库&#34;&gt;8. 数据仓库&lt;/h3&gt;

&lt;h3 id=&#34;9-stars-and-snowflakes-schemas-for-analytics&#34;&gt;9. Stars and Snowflakes: Schemas for Analytics&lt;/h3&gt;

&lt;h3 id=&#34;10-column-oriented-storage&#34;&gt;10. Column-Oriented Storage&lt;/h3&gt;

&lt;h3 id=&#34;11-column-compression&#34;&gt;11. Column Compression&lt;/h3&gt;

&lt;h3 id=&#34;12-sort-order-in-column-storage&#34;&gt;12. Sort Order in Column Storage&lt;/h3&gt;

&lt;h3 id=&#34;13-writing-to-column-oriented-storage&#34;&gt;13. Writing to Column-Oriented Storage&lt;/h3&gt;

&lt;p&gt;前面写的有关列存储的优化在数据仓库中很重要，排序、位图索引、压缩都能加速查询，但是会让写数据更加麻烦。&lt;/p&gt;

&lt;p&gt;以 BTree 为理论的写方法，在这里完全没有用，如果你要在数据中插入一条数据，你需要重写所有的数据。&lt;/p&gt;

&lt;p&gt;但是还好的是，如果是 LSM-tree 的方式，首先写进内存排序，然后写磁盘。查询的时候，也是两部分结果进行合并，Vertica 数据仓库就是这么做的。&lt;/p&gt;

&lt;h3 id=&#34;14-aggregation-data-cubes-and-materialized-views&#34;&gt;14. Aggregation: Data Cubes and Materialized Views&lt;/h3&gt;

&lt;p&gt;并不是所有的数据仓库都是使用列存储，很多其他存储方式也会用到，但是列存储确实能够很大程度加快访问，所以越来越流行。&lt;/p&gt;

&lt;p&gt;另一种值得一提的数据仓库技术就是 materialized aggregates。前面所说的，查询经常会遇到一些聚合， 例如 count，sum，如果一个查询被很多查询共用，可以将结果缓存。
其中一种方法就是 materialized view，类似查询视图，只不过这个视图的结果已经计算好保存起来了。如果数据改变了，你的 materialized view 也要改变。&lt;/p&gt;

&lt;p&gt;一种常见的案例就是 data cube 后者 OLAP cube，就是根据不同纬度就行聚合后的结果。举个列子，如果表格有 日期、商品种类、销售额三列，我们可以计算销售额在 日期、商品种类 两个维度下的聚合只，得到一个二维表格。
二维表格的两个维度分别为日期和商品种类，表格的值就是销售额，然后如果要计算每个维度下的 sum，只需要将对应维度所有值 sum 到一起。&lt;/p&gt;

&lt;p&gt;实际上，表格都不止两个维度，假如有五个维度，情况就很复杂了。但是原则不变，每个 cell 保存五个维度组合下的聚合值。&lt;/p&gt;

&lt;p&gt;通过 cube 可以加速某些查询，但是如果要计算订单额度大于 100 的比例，那就没法计算了，因为额度很难作为一个维度。所以一般只作为一个加快部分查询的工具。&lt;/p&gt;

&lt;h2 id=&#34;四-encoding-and-evolution&#34;&gt;四、Encoding and Evolution&lt;/h2&gt;

&lt;p&gt;服务总是要变的，服务变了，服务之间的代码也要变。服务端可以做滚动升级，也就是部分服务器先升级，保证没错的话，其他的继续升级。
而客户端也就是用户端，代码变化必须做到向前向后兼容，也就是说，高版本要能够处理低版本的数据，这很简单；低版本的代码，必须能从高版本的架构读数据，这是比较难的。
接下来我们将会看一些数据结构，JSON, XML, Protocol Buffers, Thrift, and Avro ，主要看他们在这些data storage and for communication系统中如何使用：
in web services, Representational State Transfer (REST), and remote procedure calls (RPC), as well as message-passing systems such as actors and message queues&lt;/p&gt;

&lt;h3 id=&#34;1-formats-for-encoding-data&#34;&gt;1. Formats for Encoding Data&lt;/h3&gt;

&lt;p&gt;一般的应用都会处理两种数据。内存主要是通过对象、数组、树、hash表等，而需要保存、传输时候，需要进行序列化，由于指针引用序列化后是没用的，所以序列化后的结构和内存结构完全不用。
从设计模式角度考虑，我们需要进行一个适配，两边都要适配的话，实际上就是做一个转换。内存到 byte sequence 的过程称为 encoding（或者 serialization、marshalling），反过来讲decoding（deserialization、parsing、unmarshalling）&lt;/p&gt;

&lt;p&gt;** 专业术语冲突
serialization 在数据库的事务中也会用到，但是完全是另外一码子事情，后续会进行介绍。这里使用的时候我们以 encoding 为主，虽然平时 serialization 用的更多。&lt;/p&gt;

&lt;p&gt;这里我们将会以一条数据为例,对它进行编码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;userName&amp;quot;: &amp;quot;Martin&amp;quot;,
    &amp;quot;favoriteNumber&amp;quot;: 1337,
    &amp;quot;interests&amp;quot;: [&amp;quot;daydreaming&amp;quot;, &amp;quot;hacking&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;1-language-specific-formats&#34;&gt;(1) Language-Specific Formats&lt;/h4&gt;

&lt;p&gt;java.io.Serializable 属于java 自带的序列化机制，很多编程语言都自带了。当然也有很多第三方的，比如 Kryo for Java。这些很方便，因为你只需要直接读然后调用java对应的方法即可。但是问题也很多。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;通用性问题，不多说。&lt;/li&gt;
&lt;li&gt;数据会有类型，例如java 序列化必须只能解析为特定的类。所以会定义很多类，这样可能导致一些人得到你的类信息，然后远程植入代码。&lt;/li&gt;
&lt;li&gt;版本问题。&lt;/li&gt;
&lt;li&gt;效率问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-json-xml-and-binary-variants&#34;&gt;(2) JSON, XML, and Binary Variants&lt;/h4&gt;

&lt;p&gt;JSON, XML 一般都很熟悉，优缺点都很明显，二进制的编码在某些内网的应用中很常见，还能节约空间。例如 MassagePack 就是二进制的 json。&lt;/p&gt;

&lt;h4 id=&#34;3-thrift-and-protocol-buffers&#34;&gt;(3) Thrift and Protocol Buffers&lt;/h4&gt;

&lt;p&gt;Thrift and Protocol Buffers 很多人都知道，作为两种序列化的框架，当然还提供了别的功能，例如 RPC 通信接口。都需要定义一个schema：&lt;/p&gt;

&lt;p&gt;Thrift 的定义格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;struct Person {
  1: required string       userName,
  2: optional i64          favoriteNumber,
  3: optional list&amp;lt;string&amp;gt; interests
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pb 的定义格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;message Person {
    required string user_name       = 1;
    optional int64  favorite_number = 2;
    repeated string interests       = 3;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后他们都有代码生成的工具，可以针对各种语言生成相应的代码，用来 encode 和 decode 数据。thrift 的格式有两种 BinaryProtocol and CompactProtocol。&lt;/p&gt;

&lt;p&gt;BinaryProtocol 表示上面的数据格式需要 59 bytes ：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0b 00 01 00 00 00 06 4d 61 72 74 69 6e     0b 是 type代表 String，紧接着 00 01 代表 field tag 为1，然后 00 00 00 06 代表长度为6，剩下的六bytes 代表数据。
0a 00 02 00 00 00 00 00 00 05 39           和刚才一样， 0a 代表int64 ，
0f 00 03 0b 00 00 00 02                    0f 代表list，00 03代表 field tag 为3，0b 代表 item type 为 string，00 00 00 02 代表长度为2，
	00 00 00 0b 64 61 79 ....              长度和数据
	00 00 00 07 68 ..... 				   长度和数据
00											结束标志
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CompactProtocol 和 BinaryProtocol 的结构类似，但是进行了一些压缩，需要 33 bytes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;18 06 4d ....  							  18 是 00011000 field type and tag number 合在一起，0001 是 tag，
										  1000 是 type 是string （为什么8 代表 string，上面是11），06 长度，后面是数据
										  另外int类型并不是占了 64位，这里的 06是两位，共 8 字节，
										  最高位代表数据是否已经完整，剩下的七位是数据。如果数据不完整，需要再占8位。这样 -64 到 63 之间的数据只占了1byte
										  
16 f2 14 								  16 是 00010110，0001 代表 field tag 比上一个加一，0110 数据类型 后面的 f214 是数据，f2 最高位是1，数据没完，需要往下一位读。
19 28
    0b 64 .....
    07 68 ....
00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ProtocolBuffer 和 Thrift 的 CompactProtocol 类似，需要 33 bytes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0a 06 4d 61 72 74 69 6e       			  0a 是 tag(00001) 和 type(010), 06 是长度。 后面是数据
10 b9 0a 								  10 是tag (00010) 和 type（000）,后面是长度+数据
1a 0b ........							  1a 是 tag 和 type，后面是长度+数据
1a 07 ........							  1a 是 tag 和 type，后面是长度+数据
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和 CompactProtocol 稍微有些不一样，tag+type 为两位，另外 list 类型直接存两个。&lt;/p&gt;

&lt;p&gt;需要注意的是，前面我们的例子中，数据要么是 要么是 required or optional，实际上这对于数据的存储没有任何影响，都是一样的存储，只是在最后解析的时候影响，例如你设置的是 required ，但是没有解析出来，会失败。&lt;/p&gt;

&lt;h4 id=&#34;4-field-tags-and-schema-evolution&#34;&gt;(4) Field tags and schema evolution&lt;/h4&gt;

&lt;p&gt;前面讲过数据需要改变，那 pb 和 thrift 如何应对schema 的变化，做到向前向后兼容呢？
其实我们从上面的数据可以看出，最重要就是 field tag 了，只要 field tag 唯一，哪怕是增加了数据，减少了数据，最终的结果其实还是一样的。你可以改变变量名字，但是不能改变 tag。
首先是向后兼容，只要你新加的 field tag 不被设置为 required，就不会报错，另外删除数据也是，不能删除 required 的数据。
另外是向前兼容，如果是旧的代码读取新的数据，如果遇到不认识的 field tag ，会直接忽略。&lt;/p&gt;

&lt;h4 id=&#34;5-datatypes-and-schema-evolution&#34;&gt;(5) Datatypes and schema evolution&lt;/h4&gt;

&lt;p&gt;数据类型发生变化，一方面可能是数据精度收到影响，另一方面，我们可以看出 pb 是可以讲啊 list 类型变成 optional 的，但是 thrift 不行，因为 thrift 提供了 list 类型，但是这样可以用来写嵌套数据。&lt;/p&gt;

&lt;h4 id=&#34;6-avro&#34;&gt;(6) avro&lt;/h4&gt;

&lt;p&gt;avro 也是一个序列胡框架，他和 pb、thrift 不同点在于没有 tagNumber，这其实很适合动态生成schema，我们不介绍了。&lt;/p&gt;

&lt;h4 id=&#34;7-dynamically-generated-schemas&#34;&gt;(7) Dynamically generated schemas&lt;/h4&gt;

&lt;p&gt;如果我们的数据增加了一列，并且减少了一列，对于 avro 来说，只需要重新生成一个 schema 即可，而如果使用 pb、thrift，需要手动进行配置tag和field 的映射，&lt;/p&gt;

&lt;h4 id=&#34;8-code-generation-and-dynamically-typed-languages&#34;&gt;(8) Code generation and dynamically typed languages&lt;/h4&gt;

&lt;p&gt;代码生成，例如 pb 可以生成 java 和 python 的代码。&lt;/p&gt;

&lt;h4 id=&#34;9-the-merits-of-schemas&#34;&gt;(9) The Merits of Schemas&lt;/h4&gt;

&lt;h3 id=&#34;二-modes-of-dataflow&#34;&gt;二、 Modes of Dataflow&lt;/h3&gt;

&lt;p&gt;我们需要在进程之间发送数据，&lt;/p&gt;

&lt;h4 id=&#34;1-dataflow-through-databases&#34;&gt;1.Dataflow Through Databases&lt;/h4&gt;

&lt;h4 id=&#34;2-dataflow-through-services-rest-and-rpc&#34;&gt;2.Dataflow Through Services: REST and RPC&lt;/h4&gt;

&lt;h4 id=&#34;3-message-passing-dataflow&#34;&gt;3.  Message-Passing Dataflow&lt;/h4&gt;

&lt;h1 id=&#34;第二部分-分布式&#34;&gt;第二部分、分布式&lt;/h1&gt;

&lt;p&gt;使用分布式的原因很多，例如 Scalability，high available，latency。数据分布式有很多种方式，首先是副本、分区，也就是 Replication 和 Partition。&lt;/p&gt;

&lt;h2 id=&#34;一-replication&#34;&gt;一、Replication&lt;/h2&gt;

&lt;p&gt;Replication 就是将你的数据放在多个节点，这样有很多好处。首先是数据从地理上可以隔用户更近，保持高可用，增加吞吐量。&lt;/p&gt;

&lt;p&gt;本章我们假设数据都是完整的进行副本存放，后面再讲分区。数据的副本解决难点就是数据变化的一致性，如果数据一致不变，那就太简单了。
对于变化，有三种设计：single-leader, multi-leader, and leaderless&lt;/p&gt;

&lt;h3 id=&#34;1-leaders-and-followers&#34;&gt;1. Leaders and Followers&lt;/h3&gt;

&lt;p&gt;每个节点上面的副本叫做 replica ，当有 multi replica 的时候，一个问题出现了，怎么保证数据写到了每一个副本。数据库的每一次写都必须保证被每个副本处理，否则就会出现不一致。
最常用的解决方案就是 leader-based-replication，也叫 active-passive、master-slave。&lt;/p&gt;

&lt;p&gt;在主从结构中，写只能发送给 leader，leader 写的时候会发送数据给 follower，而读操作可以读任何一个节点。&lt;/p&gt;

&lt;h4 id=&#34;1-synchronous-versus-asynchronous-replication&#34;&gt;(1) Synchronous Versus Asynchronous Replication&lt;/h4&gt;

&lt;p&gt;replicated 系统重要特点就是 同步写还是异步写，一般关系型数据库可以配置，其他的都是硬编码写死的。&lt;/p&gt;

&lt;p&gt;客户端发送数据给leader，然后leader转发给follower，最后通知client。如果 leader 收到 follower 的确认消息再回复client，这就是同步。
如果leader发送给了 follower后就直接回复client，就是异步。一般情况，系统都只有一个follower是同步，其余的都是异步。这叫 semi-synchronous。&lt;/p&gt;

&lt;p&gt;为了效率经常设置为 Asynchronous，这样如何 leader 失败了而且不恢复，那还没有被副本保存的数据就丢失了，这样的好处就是可以提供持续服务，尽管follower很慢。&lt;/p&gt;

&lt;p&gt;Weakening durability 可能是一个比较糟糕的 trade-off，但是 Asynchronous 还是很常用，尤其是地理上分布式的集群。&lt;/p&gt;

&lt;p&gt;当然也有很多其他的方案在研究中，例如 Azure 使用了 chain replication。&lt;/p&gt;

&lt;h4 id=&#34;2-setting-up-new-followers&#34;&gt;(2) Setting Up New Followers&lt;/h4&gt;

&lt;p&gt;系统有时候需要添加新的节点，如何保证新节点和leader的数据一致呢？直接复制数据过来肯定是不行的，leader 一直处在 flux 中，一般步骤有四步：
1. leader 在某个确定一致性的时间点拍一个 snapshot 而不用锁住系统，大部分数据库都提供了这个功能，有的能通过第三方工具提供这个功能。
2. follower 将数据复制过去。
3. follower 将从这个时间点以后的数据复制过去，这需要拍 snapshot 时候的日志位置，这个点的名字叫 Log sequence number 或者 binlog coordinates。
4. 当 follower 将所有的change都同步后，我们称之为 catch up，就可以和其他follower一样，处理 leader 发生的变化了。&lt;/p&gt;

&lt;p&gt;真正的步骤其实是有很多不同，有时候可以自动配置，有时候需要手动配置。&lt;/p&gt;

&lt;h4 id=&#34;3-handling-node-outages&#34;&gt;(3) Handling Node Outages&lt;/h4&gt;

&lt;p&gt;有时候节点会挂掉，可能是我们不知道的原因，也可能是为了安装系统模块而重启，这时候应该怎么保证集群的高可用&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;follower 挂掉&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;follower 挂点然后重启的步骤是很简单的，类似前面的添加新节点，启动以后，根据日志能找到最后一个处理的事务，然后从leader请求这个时间点以后的更改，然后进行更改，完成后就 catch up。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;leader failover&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;leader 挂掉后可能麻烦一点，必须马上选择一名新的leader，这个过程被称为 failover&lt;/p&gt;

&lt;p&gt;failover的具体步骤有4：
1. 确定leader失败了，失败的原因很多，磁盘、电源等等，目前用的最多的是 timeout 方法，节点相互 bounce message，如果突然在某个时间点收不到，就是失败了。
2. 选择新的 leader，需要在大多数的follwer 进行选举，最好是选一个数据最新的。所有的节点同意这个节点成为 consensus。
3. 告知系统使用新的leader，client 发送数据到新的 leader，旧的 leader 回复后也要认同新的 leader。&lt;/p&gt;

&lt;p&gt;failover 总是会有些不期而遇的问题：
1. 如果是 asynchronous replica ，可能遇到一些数据没有同步过来，导致数据少了，如果这时候 older leader起来了，就会发生错误，这时候一般选择 discard 这部分数据。
2. 如果系统和别的系统进行结合，discard 是很危险的，github 发生了一次 mysql leader挂掉，然后discard 了一部分，删掉了部分自增的primary key，可是这部分pk已经保存到 redis了，导致了错误
3. 有时候两个节点都认为自己是 leader，这个叫做 split brain，这时候需要去掉一个，有可能两个都被去掉了。
4. timeout 的具体值多少合适？如果太长了，可能导致发现的晚。如果太短了可能误判，尤其是系统压力大的时候，还重新换一次会造成更大的压力。&lt;/p&gt;

&lt;p&gt;这些问题解决起来还是很棘手的，所以有很多算法，我们后续会介绍。&lt;/p&gt;

&lt;h4 id=&#34;4-implementation-of-replication-logs&#34;&gt;(4) Implementation of Replication Logs&lt;/h4&gt;

&lt;p&gt;上面各种恢复，添加，都涉及到日志，日志记录了数据的更改，实际上我们学习Hadoop 的时候，也知道里面有日志，现在我们来研究一下，日志怎么实现。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Statement-based replication&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基于 statement 的 replication，这是最简单的方法，数据库记录每一次更新，也就是说，你的 UPDATE、INSERT、DELETE都会记录到日志中，然后发送给follower。
这样的问题是：
对于 current_timestamp、random 这样的方法返回值不一样，基于判断的例如 update &amp;hellip; where &amp;hellip; 必须按照顺序，一些触发器、存储过程等 side effects。&lt;/p&gt;

&lt;p&gt;对于这些问题，当然也有特定的解决方案，例如先计算一些可能导致不一致的函数。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;WAL-log&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;前面讲过 B-Tree 和 LSM-Tree，都是基于WAL-log，是一种只能 append 的二进制日志，leader 不仅将 wal-log 保存到磁盘，而且发送到 followers。&lt;/p&gt;

&lt;p&gt;WAL 的 disadvantage 是太底层，wal 包含了磁盘那个位置的 block 需要修改哪些 bytes，这样耦合性比较高，如果format 改变了，基本上很难让 leader和follower 使用不同版本。&lt;/p&gt;

&lt;p&gt;这个问题看起来更像是实现的问题，如果 replication 的协议支持follower 使用新的版本，就能完成 zore-downtime 的 upgrade。
首先更新 follower的版本，然后让leader failover，选择一个 follower 为 leader。如果replication 的协议不支持版本不一直，这就叫做 wal-shipping，会造成 upgrade-downtime。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Logical (row-based) log replication&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这种方式就是 replication log 和具体的 storage device 解耦，使用不同格式。 relational database 的 logical log 一般都是一系列表示行的recorders。一个改变很多行的 statement 会
产生很多行这样的日志，后面有一个transaction 完成的标识符。这种方式是解耦的，所以可以容忍不同的版本，甚至不同的存储引擎。这也让外部的系统容易获得数据，
例如数仓、二级索引，外部缓存，这个技术叫做 change data capture。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;trigger based replication&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;前面讲的都是数据库系统的，有时候我们需要更灵活的，例如你只想一部分数据，或者你想从一个数据库迁移到另一个数据库。这样你就应该将replication 提升到应用程序层面。
很多数据库提供了工具完成这个事情。许多关系型数据库提供了一项功能：triggers and stored procedures。trigger 能让你注册用户代码，一旦数据发生改变，将会将数据放到另一给表格，外部系统可以访问。&lt;/p&gt;

&lt;h4 id=&#34;5-problems-with-replication-lag&#34;&gt;(5) Problems with Replication Lag&lt;/h4&gt;

&lt;h1 id=&#34;第五部分-案例&#34;&gt;第五部分、案例&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.freecodecamp.org/how-to-system-design-dda63ed27e26&#34;&gt;https://medium.freecodecamp.org/how-to-system-design-dda63ed27e26&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.gainlo.co/index.php/2015/10/22/8-things-you-need-to-know-before-system-design-interviews/&#34;&gt;http://blog.gainlo.co/index.php/2015/10/22/8-things-you-need-to-know-before-system-design-interviews/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://engineering.videoblocks.com/web-architecture-101-a3224e126947&#34;&gt;https://engineering.videoblocks.com/web-architecture-101-a3224e126947&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;第六部分-资料&#34;&gt;第六部分、资料&lt;/h1&gt;

&lt;p&gt;es设计架构，良心参考资料：
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;lsm b+tree 资料
&lt;a href=&#34;https://medium.com/databasss/on-disk-io-part-3-lsm-trees-8b2da218496f&#34;&gt;https://medium.com/databasss/on-disk-io-part-3-lsm-trees-8b2da218496f&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>