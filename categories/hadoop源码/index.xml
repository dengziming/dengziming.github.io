<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop源码 on 数据分析师之旅</title>
    <link>https://dengziming.github.io/categories/hadoop%E6%BA%90%E7%A0%81/</link>
    <description>Recent content in Hadoop源码 on 数据分析师之旅</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 23 May 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://dengziming.github.io/categories/hadoop%E6%BA%90%E7%A0%81/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>yarn-api使用</title>
      <link>https://dengziming.github.io/post/hadoop/yarn-api%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/yarn-api%E4%BD%BF%E7%94%A8/</guid>
      
        <description>

&lt;p&gt;参考： &lt;a href=&#34;https://ieevee.com/tech/2015/05/05/yarn-dist-shell.html&#34;&gt;https://ieevee.com/tech/2015/05/05/yarn-dist-shell.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;distributeshell&#34;&gt;distributeshell&lt;/h1&gt;

&lt;h2 id=&#34;client解析&#34;&gt;Client解析&lt;/h2&gt;

&lt;p&gt;distShell主要有2个类组成，Client和ApplicationMaster。两个类都带有main入口。Client的主要工作是启动AM，真正要做的任务由AM来调度。 Client的简化框架如下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args) {
    boolean result = false;
    try {
      Client client = new Client();  //1 创建Client对象
      try {
        boolean doRun = client.init(args);  //2 初始化
        if (!doRun) {
          System.exit(0);
        }
      }
      result = client.run();   //3 运行
    }
    if (result) {
      System.exit(0);
    }
    System.exit(2);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;1-创建client对象&#34;&gt;1 创建Client对象&lt;/h3&gt;

&lt;p&gt;创建时会指定本Client要用到的AM。 创建yarnClient。yarn将client与RM的交互抽象出了编程库YarnClient，用以应用程序提交、状态查询和控制等，简化应用程序。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  public Client(Configuration conf) throws Exception  {
    this(		//指定AM
      &amp;quot;org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster&amp;quot;,
      conf);
  Client(String appMasterMainClass, Configuration conf) {
    this.conf = conf;
    this.appMasterMainClass = appMasterMainClass;
    yarnClient = YarnClient.createYarnClient();		//创建yarnClient
    yarnClient.init(conf);
    opts = new Options();	//创建opts，后面解析参数的时候用
    opts.addOption(&amp;quot;appname&amp;quot;, true, &amp;quot;Application Name. Default value - DistributedShell&amp;quot;);
    opts.addOption(&amp;quot;priority&amp;quot;, true, &amp;quot;Application Priority. Default 0&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-初始化&#34;&gt;2 初始化&lt;/h3&gt;

&lt;p&gt;init会解析命令行传入的参数，例如使用的jar包、内存大小、cpu个数等。 代码里使用GnuParser解析：init时定义所有的参数opts（可以认为是一个模板），
然后将opts和实际的args传入解析后得到一个CommnadLine对象，后面查询选项直接操作该CommnadLine对象即可，如cliParser.hasOption(&amp;ldquo;help&amp;rdquo;)和cliParser.getOptionValue(&amp;ldquo;jar&amp;rdquo;)。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; public boolean init(String[] args) throws ParseException {
    CommandLine cliParser = new GnuParser().parse(opts, args);
    amMemory = Integer.parseInt(cliParser.getOptionValue(&amp;quot;master_memory&amp;quot;, &amp;quot;10&amp;quot;));
    amVCores = Integer.parseInt(cliParser.getOptionValue(&amp;quot;master_vcores&amp;quot;, &amp;quot;1&amp;quot;));
    shellCommand = cliParser.getOptionValue(&amp;quot;shell_command&amp;quot;);
    appMasterJar = cliParser.getOptionValue(&amp;quot;jar&amp;quot;);
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-运行&#34;&gt;3 运行&lt;/h3&gt;

&lt;p&gt;先启动yarnClient，会建立跟RM的RPC连接，之后就跟调用本地方法一样。通过此yarnClient查询NM个数、NM详细信息（ID/地址/Container个数等）、Queue info（其实没用到，示例里只是打印了下调试用）。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class Client {
  public boolean run() throws IOException, YarnException {
    yarnClient.start();
    YarnClusterMetrics clusterMetrics = yarnClient.getYarnClusterMetrics();
    List&amp;lt;NodeReport&amp;gt; clusterNodeReports = yarnClient.getNodeReports(
收集提交AM所需的信息。
    YarnClientApplication app = yarnClient.createApplication();	//创建app
    GetNewApplicationResponse appResponse = app.getNewApplicationResponse();
...
    ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();
    //AM需要的本地资源，如jar包、log文件
    Map&amp;lt;String, LocalResource&amp;gt; localResources = new HashMap&amp;lt;String, LocalResource&amp;gt;();

    FileSystem fs = FileSystem.get(conf);
    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),
        localResources, null);
    ...	//添加localResource

    vargs.add(Environment.JAVA_HOME.$$() + &amp;quot;/bin/java&amp;quot;);
    vargs.add(&amp;quot;-Xmx&amp;quot; + amMemory + &amp;quot;m&amp;quot;);
    vargs.add(appMasterMainClass);
...
    for (CharSequence str : vargs) {
      command.append(str).append(&amp;quot; &amp;quot;);	//重新组织命令行
    }
	//创建Container加载上下文，包含本地资源，环境变量，实际命令。
    ContainerLaunchContext amContainer = ContainerLaunchContext.newInstance(
      localResources, env, commands, null, null, null);

    Resource capability = Resource.newInstance(amMemory, amVCores);
    appContext.setResource(capability);		//请求使用的内存、cpu

    appContext.setAMContainerSpec(amContainer);
    appContext.setQueue(amQueue);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新组织出来的commands如下：&lt;/p&gt;

&lt;p&gt;$JAVA_HOME/bin/java -Xmx10m org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster &amp;ndash;container_memory 10
提交AM（即appContext），并启动监控。 Client只关心自己提交到RM的AM是否正常运行，而AM内部的多个task，由AM管理。如果Client要查询应用程序的任务信息，需要自己设计与AM的交互。
    yarnClient.submitApplication(appContext);   //客户端提交AM到RM
    return monitorApplication(appId);
总的来说，Client做的事情比较简单，即建立与RM的连接，提交AM，监控AM运行状态。&lt;/p&gt;

&lt;p&gt;有个疑问，走读代码没有看到jar包是怎么送到NM上去的。&lt;/p&gt;

&lt;h2 id=&#34;application-master解析&#34;&gt;Application Master解析&lt;/h2&gt;

&lt;p&gt;AM简化框架如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;

      boolean doRun = appMaster.init(args);
      if (!doRun) {
        System.exit(0);
      }
      appMaster.run();
      result = appMaster.finish();
// yarn抽象了两个编程库，AMRMClient和NMClient(AM和RM都可以用)，简化AM编程。

// 1 设置RM、NM消息的异步处理方法
    AMRMClientAsync.CallbackHandler allocListener = new RMCallbackHandler();
    amRMClient = AMRMClientAsync.createAMRMClientAsync(1000, allocListener);
    amRMClient.init(conf);
    amRMClient.start();

    containerListener = createNMCallbackHandler();
    nmClientAsync = new NMClientAsyncImpl(containerListener);
    nmClientAsync.init(conf);
    nmClientAsync.start();
// 2 向RM注册
    RegisterApplicationMasterResponse response = amRMClient.registerApplicationMaster(appMasterHostname,
        appMasterRpcPort, appMasterTrackingUrl);
// 3 计算需要的Container，向RM发起请求
    // Setup ask for containers from RM
    // Send request for containers to RM
    // Until we get our fully allocated quota, we keep on polling RM for
    // containers
    // Keep looping until all the containers are launched and shell script
    // executed on them ( regardless of success/failure).
    for (int i = 0; i &amp;lt; numTotalContainersToRequest; ++i) {
      ContainerRequest containerAsk = setupContainerAskForRM();
      amRMClient.addContainerRequest(containerAsk);		//请求指定个数的Container
    }

  private ContainerRequest setupContainerAskForRM() {
    Resource capability = Resource.newInstance(containerMemory,
      containerVirtualCores);		//指定需要的memory/cpu能力
    ContainerRequest request = new ContainerRequest(capability, null, null,
        pri);


4 // RM分配Container给AM，AM启动任务RMCallbackHandler RM消息的响应，由RMCallbackHandler处理。示例中主要对前两种消息进行了处理。

  private class RMCallbackHandler implements AMRMClientAsync.CallbackHandler {
    //处理消息：Container执行完毕。在RM返回的心跳应答中携带。如果心跳应答中有已完成和新分配两种Container，先处理已完成
    public void onContainersCompleted(List&amp;lt;ContainerStatus&amp;gt; completedContainers) {
...
    //处理消息：RM新分配Container。在RM返回的心跳应答中携带
    public void onContainersAllocated(List&amp;lt;Container&amp;gt; allocatedContainers) {

    public void onShutdownRequest() {done = true;}

    //节点状态变化
    public void onNodesUpdated(List&amp;lt;NodeReport&amp;gt; updatedNodes) {}

    public float getProgress() {
onContainersAllocated收到分配的Container之后，会提交任务到NM。

    public void onContainersAllocated(List&amp;lt;Container&amp;gt; allocatedContainers) {
        LaunchContainerRunnable runnableLaunchContainer =   //创建runnable容器
            new LaunchContainerRunnable(allocatedContainer, containerListener);
        Thread launchThread = new Thread(runnableLaunchContainer);	//新建线程

        // launch and start the container on a separate thread to keep
        // the main thread unblocked
        // as all containers may not be allocated at one go.
        launchThreads.add(launchThread);
        launchThread.start();	//线程中提交Container到NM，不影响主流程

//简单分析下LaunchContainerRunnable。该类实现自Runnable，其run方法准备任务命令（本例即为date）。

  private class LaunchContainerRunnable implements Runnable {
    public LaunchContainerRunnable(
        Container lcontainer, NMCallbackHandler containerListener) {
      this.container = lcontainer;		//创建时记录待使用的Container
      this.containerListener = containerListener;
    }
    public void run() {
      vargs.add(shellCommand);		//待执行的shell命令
      vargs.add(shellArgs);			//shell命令参数
      List&amp;lt;String&amp;gt; commands = new ArrayList&amp;lt;String&amp;gt;();
      commands.add(command.toString());	//转为commands

      //根据命令、环境变量、本地资源等创建Container加载上下文
      ContainerLaunchContext ctx = ContainerLaunchContext.newInstance(
              localResources, shellEnv, commands, null, allTokens.duplicate(), null);
      containerListener.addContainer(container.getId(), container);
      //异步启动Container
      nmClientAsync.startContainerAsync(container, ctx);
// onContainersCompleted的功能比较简单，收到Container执行完毕的消息，检查其执行结果，如果执行失败，则重新发起请求，直到全部完成。

// NMCallbackHandler NM消息的响应，由NMCallbackHandler处理。

//在distShell示例里，回调句柄对NM通知过来的各种事件的处理比较简单，只是修改AM维护的Container执行完成、失败的个数。这样等到有Container执行完毕后，可以重启发起请求。失败处理和上面Container执行完毕消息的处理类似，达到了上面问题里所说的loopback效果。

  static class NMCallbackHandler
    implements NMClientAsync.CallbackHandler {

    @Override
    public void onContainerStopped(ContainerId containerId) {

    @Override
    public void onContainerStatusReceived(ContainerId containerId,

    @Override
    public void onContainerStarted(ContainerId containerId,
...
总的来说，AM做的事就是向RM/NM注册回调函数，然后请求Container；得到Container后提交任务，并跟踪这些任务的执行情况，如果失败了则重新提交，直到全部任务完成。
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;unmanagedam&#34;&gt;UnmanagedAM&lt;/h1&gt;

&lt;p&gt;distShell的Client提交AM到RM后，由RM将AM分配到某一个NM上的Container，这样给AM调试带来了困难。yarn提供了一个参数，Client可以设置为Unmanaged，提交AM后，会在客户端本地起一个单独的进程来运行AM。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class UnmanagedAMLauncher {
  public void launchAM(ApplicationAttemptId attemptId)
    //创建新进程
    Process amProc = Runtime.getRuntime().exec(amCmd, envAMList.toArray(envAM));
    try {
      int exitCode = amProc.waitFor();  //等待AM进程结束
    } finally {
      amCompleted = true;
    }

  public boolean run() throws IOException, YarnException {
      appContext.setUnmanagedAM(true);		//设置为Unmanaged
      rmClient.submitApplication(appContext);	//提交AM

      ApplicationReport appReport =		//监控AM状态，如果状态变为ACCEPTED，则跳出循环，launchAM。
          monitorApplication(appId, EnumSet.of(YarnApplicationState.ACCEPTED,
            YarnApplicationState.KILLED, YarnApplicationState.FAILED,
            YarnApplicationState.FINISHED));

      if (appReport.getYarnApplicationState() == YarnApplicationState.ACCEPTED) {
        launchAM(attemptId);
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>yarn-基础库</title>
      <link>https://dengziming.github.io/post/hadoop/yarn-%E5%9F%BA%E7%A1%80%E5%BA%93/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/yarn-%E5%9F%BA%E7%A1%80%E5%BA%93/</guid>
      
        <description>

&lt;h1 id=&#34;yarn-事件库和服务库&#34;&gt;yarn-事件库和服务库&lt;/h1&gt;

&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;新建Event和EventType&lt;/li&gt;
&lt;li&gt;新建 AsyncDispatcher 并给 AsyncDispatcher 注册 Event 和对应的 EventHandler&lt;Event&gt;&lt;/li&gt;
&lt;li&gt;调用 AsyncDispatcher 的 getEventHandler 得到 EventHandler 然后调用 handler 的 handle 方法处理 Event&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;基本原理&#34;&gt;基本原理：&lt;/h2&gt;

&lt;p&gt;AsyncDispatcher 注册 EventHandler&lt;Event&gt; 的过程实际上生成了一个 map，保存了每个事件对应的handler。同时有一个 队列，用于放置 Event&lt;/p&gt;

&lt;p&gt;调用 handle 的时候 将Event放进queue中，内部启动一个线程不断处理 queue的任务。&lt;/p&gt;

&lt;h1 id=&#34;yarn-状态机&#34;&gt;yarn-状态机&lt;/h1&gt;

&lt;h2 id=&#34;使用-1&#34;&gt;使用&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;初始化&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;StateMachineFactory
.addTransition(JobStateInternal.NEW, JobStateInternal.INITED, JobEventType.JOB_INIT,new InitTransition())
.addTransition(JobStateInternal.INITED, JobStateInternal.SETUP, JobEventType.JOB_START,new StartTransition())
.installTopology()
.make()
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新建对应的 Transition&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static class InitTransition implements SingleArcTransition&amp;lt;JobStateMachine,JobEvent&amp;gt;{

        @Override
        public void transition(JobStateMachine job, JobEvent event) {
            System.out.println(&amp;quot;Receiving event &amp;quot; + event);
        }

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;调用 StateMachine 的 doTransition(event.getType(), event)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;

&lt;p&gt;installTopology的时候创建一个拓扑图，记录每个 State 能接受的 Event，以及接受该 Event 后的操作，以及操作后的 State。&lt;/p&gt;

&lt;p&gt;每次有Event传入，调用对应的 Transition ，并且将 此时刻 的状态变为 操作后的状态。&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>