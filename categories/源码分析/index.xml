<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>源码分析 on 数据分析师之旅</title>
    <link>https://dengziming.github.io/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
    <description>Recent content in 源码分析 on 数据分析师之旅</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 27 Jul 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://dengziming.github.io/categories/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>tinkerpop 的 step</title>
      <link>https://dengziming.github.io/post/tinkerpop/tinkerpop%E7%9A%84step/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/tinkerpop/tinkerpop%E7%9A%84step/</guid>
      
        <description>

&lt;h2 id=&#34;一-简单调试&#34;&gt;一、简单调试&lt;/h2&gt;

&lt;p&gt;api地址： &lt;a href=&#34;http://tinkerpop.apache.org/javadocs/current/full/&#34;&gt;http://tinkerpop.apache.org/javadocs/current/full/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;第一步：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraph graph = JanusGraphFactory.open(&amp;quot;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;quot;);

GraphTraversalSource g = graph.traversal();

g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).path();

List&amp;lt;Path&amp;gt; paths = path.toList();

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一步一步看整个调用过程：&lt;/p&gt;

&lt;p&gt;进入: fill:179, Traversal (org.apache.tinkerpop.gremlin.process.traversal)&lt;/p&gt;

&lt;p&gt;fill 方法的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Step&amp;lt;?, E&amp;gt; endStep = this.asAdmin().getEndStep();
while (true) {
    final Traverser&amp;lt;E&amp;gt; traverser = endStep.next();
    TraversalHelper.addToCollection(collection, traverser.get(), traverser.bulk());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;asAdmin 得到 endStep，有点类似 spark 的 stage 拆分后得到 shuffleMapTask。然后调用 endStep.next() 得到 traverser。&lt;/p&gt;

&lt;p&gt;这里的代码我们前面已经熟悉过了，再看一下。进入： next:128, AbstractStep (org.apache.tinkerpop.gremlin.process.traversal.step.util)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Traverser.Admin&amp;lt;E&amp;gt; traverser = this.processNextStart();
if (null != traverser.get() &amp;amp;&amp;amp; 0 != traverser.bulk())
    return this.prepareTraversalForNextStep(traverser);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入 processNextStart:118, PathStep (org.apache.tinkerpop.gremlin.process.traversal.step.map)
&lt;code&gt;return PathProcessor.processTraverserPathLabels(super.processNextStart(), this.keepLabels);&lt;/code&gt;
可以看出调用了父类的 processNextStart 方法，&lt;/p&gt;

&lt;p&gt;进入 processNextStart:36, MapStep (org.apache.tinkerpop.gremlin.process.traversal.step.map)&lt;/p&gt;

&lt;p&gt;由于是 mapStep，所以类似 spark 的 mapPartitionsRdd ，逻辑就是得到前面的 rdd，然后执行 map 方法的逻辑。
所以这里 mapStep 也是一样，得到  starts 的 next，然后调用map。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Traverser.Admin&amp;lt;S&amp;gt; traverser = this.starts.next();
return traverser.split(this.map(traverser), this);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入 next:50, ExpandableStepIterator (org.apache.tinkerpop.gremlin.process.traversal.step.util)，我们说过这就是对 hostStep 的一个封装。主要就是&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;if (this.hostStep.getPreviousStep().hasNext())
   return this.hostStep.getPreviousStep().next();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 hostStep 就是上面的 mapStep。这里有 getPreviousStep 然后 next。&lt;/p&gt;

&lt;p&gt;然后又进入到了 processNextStart:142, GraphStep (org.apache.tinkerpop.gremlin.process.traversal.step.map)，
这里的 iteratorSupplier 变量其实是在 GraphStep 或者他的子类中赋值的，所以 get 方法得到的就是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public JanusGraphStep(final GraphStep&amp;lt;S, E&amp;gt; originalStep) {
    super(originalStep.getTraversal(), originalStep.getReturnClass(), originalStep.isStartStep(), originalStep.getIds());
    originalStep.getLabels().forEach(this::addLabel);
    this.setIteratorSupplier(() -&amp;gt; {
        if (this.ids == null) {
            return Collections.emptyIterator();
        }
        else if (this.ids.length &amp;gt; 0) {
            final Graph graph = (Graph)traversal.asAdmin().getGraph().get();
            return iteratorList((Iterator)graph.vertices(this.ids));
        }
        if (hasLocalContainers.isEmpty()) {
            hasLocalContainers.put(new ArrayList&amp;lt;&amp;gt;(), new QueryInfo(new ArrayList&amp;lt;&amp;gt;(), 0, BaseQuery.NO_LIMIT));
        }
        final JanusGraphTransaction tx = JanusGraphTraversalUtil.getTx(traversal);
        final GraphCentricQuery globalQuery = buildGlobalGraphCentricQuery(tx);

        final Multimap&amp;lt;Integer, GraphCentricQuery&amp;gt; queries = ArrayListMultimap.create();
        if (globalQuery != null &amp;amp;&amp;amp; !globalQuery.getSubQuery(0).getBackendQuery().isEmpty()) {
            queries.put(0, globalQuery);
        } else {
            hasLocalContainers.entrySet().forEach(c -&amp;gt; queries.put(c.getValue().getLowLimit(), buildGraphCentricQuery(tx, c)));
        }

        final GraphCentricQueryBuilder builder = (GraphCentricQueryBuilder) tx.query();
        final List&amp;lt;Iterator&amp;lt;E&amp;gt;&amp;gt; responses = new ArrayList&amp;lt;&amp;gt;();
        queries.entries().forEach(q -&amp;gt;  executeGraphCentryQuery(builder, responses, q));

        return new MultiDistinctOrderedIterator&amp;lt;E&amp;gt;(lowLimit, highLimit, responses, orders);
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从这段代码，结合前面我们分析过的 GraphStep ，我们看出和图相关的 GraphStep 主要就是有一个 iteratorSupplier。因为这个step 就是为了从图拿数据。&lt;/p&gt;

&lt;p&gt;我们再看看别的 Step。&lt;/p&gt;

&lt;h2 id=&#34;简单-step-查看&#34;&gt;简单 Step 查看&lt;/h2&gt;

&lt;p&gt;其实我们查看 Step 主要就是了解 processNextStart 的行为，接下来先看几个简单的。&lt;/p&gt;

&lt;p&gt;简单的 step 一般只处理一个逻辑，类似 spark 中的 map flatMap filter 等方法。&lt;/p&gt;

&lt;h3 id=&#34;mapstep&#34;&gt;MapStep&lt;/h3&gt;

&lt;p&gt;MapStep 是抽象类，表示这个Step有很多实现，需要自己继承。processNextStart 方法就是调用 starts 的next 返回一个Traverser，然后调用 map(返回一个Traverser);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;protected Traverser.Admin&amp;lt;E&amp;gt; processNextStart() {
    final Traverser.Admin&amp;lt;S&amp;gt; traverser = this.starts.next();
    return traverser.split(this.map(traverser), this);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MapStep 有很多的实现类，例如：PropertyKeyStep LabelStep PropertyValueStep PathStep MathStep EdgeOtherVertexStep 等，他们的 map 方法实现很简单。&lt;/p&gt;

&lt;h3 id=&#34;filterstep&#34;&gt;FilterStep&lt;/h3&gt;

&lt;p&gt;和 MapStep 类似，它的子类有 WhereStep HasStep NotStep CoinStep IsStep 等。&lt;/p&gt;

&lt;h3 id=&#34;flatmapstep&#34;&gt;FlatMapStep&lt;/h3&gt;

&lt;p&gt;和 MapStep 类似，它的子类有 EdgeVertexStep VertexStep PropertiesStep 等。&lt;/p&gt;

&lt;h3 id=&#34;aggregatestep&#34;&gt;AggregateStep&lt;/h3&gt;

&lt;p&gt;听名字是聚合的意思，应该是多个结果合并。内部有个 TraverserSet&lt;S&gt; barrier 代表所有待合并的 Traverser。&lt;/p&gt;

&lt;h3 id=&#34;groupstep&#34;&gt;GroupStep&lt;/h3&gt;

&lt;p&gt;我们可以写一段代码测试一下：g.V().group().by(T.label).next()&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;this.asAdmin().addStep(new GroupStep&amp;lt;&amp;gt;(this.asAdmin()));&lt;/li&gt;
&lt;li&gt;this.asAdmin().getEndStep()).modulateBy(token);&lt;/li&gt;
&lt;li&gt;1. new TokenTraversal(token)&lt;/li&gt;
&lt;li&gt;2. GroupStep.modulateBy(final Traversal.Admin&amp;lt;?, ?&amp;gt; kvTraversal)&lt;/li&gt;
&lt;li&gt;1. this.seed = this.reducingBiOperator.apply(this.seed, this.projectTraverser(this.starts.next()));&lt;/li&gt;
&lt;li&gt;2. GroupStep.doFinalReduction((Map&lt;K, Object&gt;) object, this.valueTraversal);&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph主要类分析</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%905-%E4%B8%BB%E8%A6%81%E7%B1%BB/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%905-%E4%B8%BB%E8%A6%81%E7%B1%BB/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>janusgraph一次给janusgraph提交源码的过程</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph 了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-相关问题&#34;&gt;一、相关问题&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/JanusGraph/janusgraph/issues/1157&#34;&gt;https://github.com/JanusGraph/janusgraph/issues/1157&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;reindex 的时候，一直等待三分钟。并且打印日志：
&amp;ldquo;&amp;ldquo;2018-06-10 09:03:19 [Thread-15] ERROR o.j.g.d.management.ManagementLogger - Evicted [6@6d56b8c524955-pc-jblur-com3] from cache but waiting too long for transactions to close. Stale transaction alert on: [standardjanusgraphtx[0x67a3ba21], standardjanusgraphtx[0x6cf78315], standardjanusgraphtx[0x48ce7bcd], standardjanusgraphtx[0x1862c45e], standardjanusgraphtx[0x04c1309d], standardjanusgraphtx[0x13bda0b2], standardjanusgraphtx[0x1187c9e8]]&lt;/p&gt;

&lt;p&gt;实际上原因是
There is a bug when we are reindexing a new index in an empty database. The process tries to fetch data from the database but there are no data. Because of that, the process tries to get some data for 3 minutes with the similar error logged as this one:&lt;/p&gt;

&lt;p&gt;我已经做了修复并提交到 janusgraph 的源码，等待merge。
&lt;a href=&#34;https://github.com/JanusGraph/janusgraph/pull/1162&#34;&gt;https://github.com/JanusGraph/janusgraph/pull/1162&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;现在已经被合并了，我也成了janusgraph的contributor&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析1-下载编译启动</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E4%B8%8B%E8%BD%BD%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E4%B8%8B%E8%BD%BD%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph 了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-下载编译&#34;&gt;一、下载编译&lt;/h2&gt;

&lt;p&gt;我直接使用github desktop打开了 janusgraph 的源码，使用IDEA打开，然后编译：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 编译完整的
mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests clean install
# 只编译core部分
mvn -pl janusgraph-core -am clean install -Dlicense.skip=true -DskipTests -P prod

-rf :janusgraph-test
mvn -pl janusgraph-test -am clean install -Dlicense.skip=true -DskipTests -P prod
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们在 &lt;code&gt;janusgraph-test&lt;/code&gt; 下面编写一个例子 &lt;code&gt;FirstTest&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class FirstTest {

    public static void main(String[] args) {

        /*
         * The example below will open a JanusGraph graph instance and load The Graph of the Gods dataset diagrammed above.
         * JanusGraphFactory provides a set of static open methods,
         * each of which takes a configuration as its argument and returns a graph instance.
         * This tutorial calls one of these open methods on a configuration
         * that uses the BerkeleyDB storage backend and the Elasticsearch index backend,
         * then loads The Graph of the Gods using the helper class GraphOfTheGodsFactory.
         * This section skips over the configuration details, but additional information about storage backends,
         * index backends, and their configuration are available in
         * Part III, “Storage Backends”, Part IV, “Index Backends”, and Chapter 13, Configuration Reference.
         */

        // Loading the Graph of the Gods Into JanusGraph
        JanusGraph graph = JanusGraphFactory
                .open(&amp;quot;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;quot;);

        GraphOfTheGodsFactory.load(graph);
        GraphTraversalSource g = graph.traversal();

        /*
         * The typical pattern for accessing data in a graph database is to first locate the entry point into the graph
         * using a graph index. That entry point is an element (or set of elements) 
         * — i.e. a vertex or edge. From the entry elements,
         * a Gremlin path description describes how to traverse to other elements in the graph via the explicit graph structure.
         * Given that there is a unique index on name property, the Saturn vertex can be retrieved.
         * The property map (i.e. the key/value pairs of Saturn) can then be examined.
         * As demonstrated, the Saturn vertex has a name of &amp;quot;saturn, &amp;quot; an age of 10000, and a type of &amp;quot;titan.&amp;quot;
         * The grandchild of Saturn can be retrieved with a traversal that expresses:
         * &amp;quot;Who is Saturn’s grandchild?&amp;quot; (the inverse of &amp;quot;father&amp;quot; is &amp;quot;child&amp;quot;). The result is Hercules.
         */
        // Global Graph Indices
        Vertex saturn = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).next();
        GraphTraversal&amp;lt;Vertex, Map&amp;lt;String, Object&amp;gt;&amp;gt; vertexMapGraphTraversal = g.V(saturn).valueMap();

        GraphTraversal&amp;lt;Vertex, Object&amp;gt; values = g.V(saturn).in(&amp;quot;father&amp;quot;).in(&amp;quot;father&amp;quot;).values(&amp;quot;name&amp;quot;);

        /*
         * The property place is also in a graph index. The property place is an edge property.
         * Therefore, JanusGraph can index edges in a graph index.
         * It is possible to query The Graph of the Gods for all events that have happened within 50 kilometers of Athens
          * (latitude:37.97 and long:23.72).
          * Then, given that information, which vertices were involved in those events.
         */
		System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50))));
        System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50)))
                .as(&amp;quot;source&amp;quot;).inV()
                .as(&amp;quot;god2&amp;quot;)
                .select(&amp;quot;source&amp;quot;).outV()
                .as(&amp;quot;god1&amp;quot;).select(&amp;quot;god1&amp;quot;, &amp;quot;god2&amp;quot;)
                .by(&amp;quot;name&amp;quot;));
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在&amp;rdquo;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;rdquo; 文件中，将注释掉的内容取消注释。&lt;/p&gt;

&lt;p&gt;运行发现依赖挺麻烦。
首先运行报错了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.IllegalArgumentException: Could not find implementation class: org.janusgraph.diskstorage.berkeleyje.BerkeleyJEStoreManager
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;找到报错处的代码，我们发现 &lt;code&gt;janusgraph-core&lt;/code&gt; 中通过反射创建一个类，但是这个类在 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt; 中，而前者不依赖后者，所以找不到这个类，我们可以将后者加到前者的依赖，
但是我们发现后者依赖前者，如果加了依赖两个就相互依赖了，这是 Janus 官方设计的问题。我们只好在 FirstTest 所在的module中把两个依赖都加进来试试。
（注意，如果我们将所有的都打进一个包，这个问题就不存在了，但是在本地运行是不一样的，各自模块的编译输出文件在不同的地方。）在 &lt;code&gt;janusgraph-test&lt;/code&gt; 中添加：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.janusgraph&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;janusgraph-berkeleyje&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;0.3.0-SNAPSHOT&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;也依赖了 &lt;code&gt;janusgraph-test&lt;/code&gt;,又相互依赖了，好麻烦。我们写写代码一定要注意这个问题。这里我的解决方法是直接把 代码放到 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt; 中运行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.IllegalArgumentException: Could not find implementation class: org.janusgraph.diskstorage.es.ElasticSearchIndex
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和上面一样，还依赖了 &lt;code&gt;janusgraph-es&lt;/code&gt;,我只好吧代码复制到 &lt;code&gt;janusgraph-es&lt;/code&gt; 的test代码块中运行（注意一点是test代码中），顺便在 &lt;code&gt;janusgraph-es&lt;/code&gt; 中 添加上&lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;的依赖。
运行成功了，但是报了连接失败，是因为我本地没有启动es，我启动一下es：&lt;code&gt;elasticsearch&lt;/code&gt;
然后在运行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Exception in thread &amp;quot;main&amp;quot; org.janusgraph.core.SchemaViolationException: Adding this property for key [~T$SchemaName] and value [rtname] violates a uniqueness constraint [SystemIndex#~T$SchemaName]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过google查到原因： &lt;a href=&#34;https://groups.google.com/forum/#!topic/aureliusgraphs/vZ_nTXlXj4k&#34;&gt;https://groups.google.com/forum/#!topic/aureliusgraphs/vZ_nTXlXj4k&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This exception is thrown only when you already have added property key to index. So &amp;quot;name&amp;quot; is already added and next time when you run your program somewhere it is again adding &amp;quot;name&amp;quot; property key. So check if that particular code is running twice
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们可以在我们传入的配置文件找到：storage.directory=../db/berkeley  ，直接删除这个目录，再重新运行，就成功了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;11:20:17,051  INFO GraphDatabaseConfiguration:1285 - Set default timestamp provider MICRO
11:20:17,296  INFO GraphDatabaseConfiguration:1492 - Generated unique-instance-id=c0a815a789637-dengzimings-MacBook-Pro-local1
11:20:17,547  INFO Backend:462 - Configuring index [search]
11:20:19,279  INFO Backend:177 - Initiated backend operations thread pool of size 8
11:20:19,461  INFO KCVSLog:753 - Loaded unidentified ReadMarker start time 2018-04-26T03:20:19.408Z into org.janusgraph.diskstorage.log.kcvs.KCVSLog$MessagePuller@73cd37c0
[GraphStep(edge,[]), HasStep([place.geoWithin(BUFFER (POINT (23.72 37.97), 0.44966))])]
[GraphStep(edge,[]), HasStep([place.geoWithin(BUFFER (POINT (23.72 37.97), 0.44966))])@[source], EdgeVertexStep(IN)@[god2], SelectOneStep(last,source), EdgeVertexStep(OUT)@[god1], SelectStep(last,[god1, god2],[value(name)])]
11:20:29,578  INFO ManagementLogger:192 - Received all acknowledgements for eviction [1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们可以去 ../db/berkeley  目录查看，多了一些文件，这些文件的作用我们后续再分析。
然后我们取es查看：&lt;code&gt;curl -XGET &#39;localhost:9200/_cat/indices?v&amp;amp;pretty&#39;&lt;/code&gt; ，发现多了两个index:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yellow open   janusgraph_edges    QT-E7AV6SMWr8Cu_ywKsXg   5   1          6            0     13.7kb         13.7kb
yellow open   janusgraph_vertices gE4TSXFATnSZUWYdAf46Xg   5   1          6            0     10.9kb         10.9kb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还可以具体查看内容。例如名字是titan的内容：&lt;code&gt;curl -XGET &#39;localhost:9200/janusgraph_vertices/_search?q=name:titan&amp;amp;pretty&#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;到现在我们第一个案例就结束了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50)))
                .as(&amp;quot;source&amp;quot;).inV()
                .as(&amp;quot;god2&amp;quot;)
                .select(&amp;quot;source&amp;quot;).outV()
                .as(&amp;quot;god1&amp;quot;).select(&amp;quot;god1&amp;quot;, &amp;quot;god2&amp;quot;)
                .by(&amp;quot;name&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种风格的代码实际上是groovy语言的代码，大家可以研究一下groovy语言。&lt;/p&gt;

&lt;p&gt;注意事项：
上述第一次运行问题的原因是 &lt;code&gt;janusgraph-core&lt;/code&gt;需要用到 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;的类，
但是&lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;是依赖 &lt;code&gt;janusgraph-core&lt;/code&gt;的，所以两个相互依赖了。
janus的做法是在core中使用反射，所以编译通过了，打包到了一起就没问题了。但是本地运行没法成功。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析1-下载编译启动</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9010-gremin/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9010-gremin/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph 了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-调试&#34;&gt;一、调试&lt;/h2&gt;

&lt;p&gt;首先阅读以下 &lt;a href=&#34;http://tinkerpop.apache.org/docs/3.3.3/reference/#traversal&#34;&gt;http://tinkerpop.apache.org/docs/3.3.3/reference/#traversal&lt;/a&gt; ，了解一下。&lt;/p&gt;

&lt;p&gt;GraphTraversalSource g = graph.traversal();&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析2-实例debug</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%AE%9E%E4%BE%8Bdebug/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%AE%9E%E4%BE%8Bdebug/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-第一遍调试&#34;&gt;一、第一遍调试&lt;/h2&gt;

&lt;p&gt;还是上次的例子 &lt;code&gt;FirstTest&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class FirstTest {

    public static void main(String[] args) {

        /*
         * The example below will open a JanusGraph graph instance and load The Graph of the Gods dataset diagrammed above.
         * JanusGraphFactory provides a set of static open methods,
         * each of which takes a configuration as its argument and returns a graph instance.
         * This tutorial calls one of these open methods on a configuration
         * that uses the BerkeleyDB storage backend and the Elasticsearch index backend,
         * then loads The Graph of the Gods using the helper class GraphOfTheGodsFactory.
         * This section skips over the configuration details, but additional information about storage backends,
         * index backends, and their configuration are available in
         * Part III, “Storage Backends”, Part IV, “Index Backends”, and Chapter 13, Configuration Reference.
         */

        // Loading the Graph of the Gods Into JanusGraph
        JanusGraph graph = JanusGraphFactory
                .open(&amp;quot;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;quot;);

        GraphOfTheGodsFactory.load(graph);
        GraphTraversalSource g = graph.traversal();

        /*
         * The typical pattern for accessing data in a graph database is to first locate the entry point into the graph
         * using a graph index. That entry point is an element (or set of elements) 
         * — i.e. a vertex or edge. From the entry elements,
         * a Gremlin path description describes how to traverse to other elements in the graph via the explicit graph structure.
         * Given that there is a unique index on name property, the Saturn vertex can be retrieved.
         * The property map (i.e. the key/value pairs of Saturn) can then be examined.
         * As demonstrated, the Saturn vertex has a name of &amp;quot;saturn, &amp;quot; an age of 10000, and a type of &amp;quot;titan.&amp;quot;
         * The grandchild of Saturn can be retrieved with a traversal that expresses:
         * &amp;quot;Who is Saturn’s grandchild?&amp;quot; (the inverse of &amp;quot;father&amp;quot; is &amp;quot;child&amp;quot;). The result is Hercules.
         */
        // Global Graph Indices
        Vertex saturn = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).next();
        GraphTraversal&amp;lt;Vertex, Map&amp;lt;String, Object&amp;gt;&amp;gt; vertexMapGraphTraversal = g.V(saturn).valueMap();

        GraphTraversal&amp;lt;Vertex, Object&amp;gt; values = g.V(saturn).in(&amp;quot;father&amp;quot;).in(&amp;quot;father&amp;quot;).values(&amp;quot;name&amp;quot;);

        /*
         * The property place is also in a graph index. The property place is an edge property.
         * Therefore, JanusGraph can index edges in a graph index.
         * It is possible to query The Graph of the Gods for all events that have happened within 50 kilometers of Athens
          * (latitude:37.97 and long:23.72).
          * Then, given that information, which vertices were involved in those events.
         */
		System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50))));
        System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50)))
                .as(&amp;quot;source&amp;quot;).inV()
                .as(&amp;quot;god2&amp;quot;)
                .select(&amp;quot;source&amp;quot;).outV()
                .as(&amp;quot;god1&amp;quot;).select(&amp;quot;god1&amp;quot;, &amp;quot;god2&amp;quot;)
                .by(&amp;quot;name&amp;quot;));
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;删除 db 文件夹，打上断点，开始debug，首先进入：JanusGraphFactory.open&lt;/p&gt;

&lt;p&gt;JanusGraphFactory is used to open or instantiate a JanusGraph graph database.
Opens a {@link JanusGraph} database configured according to the provided configuration.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static JanusGraph open(ReadConfiguration configuration, String backupName) {
    final ModifiableConfiguration config = new ModifiableConfiguration(ROOT_NS, (WriteConfiguration) configuration, BasicConfiguration.Restriction.NONE);
    final String graphName = config.has(GRAPH_NAME) ? config.get(GRAPH_NAME) : backupName;
    final JanusGraphManager jgm = JanusGraphManagerUtility.getInstance();
    if (null != graphName) {
        Preconditions.checkState(jgm != null, JANUS_GRAPH_MANAGER_EXPECTED_STATE_MSG);
        return (JanusGraph) jgm.openGraph(graphName, gName -&amp;gt; new StandardJanusGraph(new GraphDatabaseConfiguration(configuration)));
    } else {
        if (jgm != null) {
            log.warn(&amp;quot;...&amp;quot;);
        }
        return new StandardJanusGraph(new GraphDatabaseConfiguration(configuration));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前面的部分先跳过，然后进入：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. return new StandardJanusGraph(new GraphDatabaseConfiguration(configuration));
    // 构造方法，分为静态代码和构造方法，这部分目前是跳过，但是后续是重点和核心。
    1. 父类：JanusGraphBlueprintsGraph
        static {
        TraversalStrategies graphStrategies = TraversalStrategies.GlobalCache.getStrategies(Graph.class).clone()
                .addStrategies(AdjacentVertexFilterOptimizerStrategy.instance(), JanusGraphLocalQueryOptimizerStrategy.instance(), JanusGraphStepStrategy.instance());

        //Register with cache
        TraversalStrategies.GlobalCache.registerStrategies(StandardJanusGraph.class, graphStrategies);
        TraversalStrategies.GlobalCache.registerStrategies(StandardJanusGraphTx.class, graphStrategies);
        }
    2. 新建配置，A graph database configuration is uniquely associated with a graph database and must not be used for multiple databases
    
    new GraphDatabaseConfiguration(configuration)
        1. storeManager 
        final KeyColumnValueStoreManager storeManager = Backend.getStorageManager(localBasicConfiguration);
        final StoreFeatures storeFeatures = storeManager.getFeatures();
        2. 检查参数，配置等
    
    3. 然后是构造方法
        1. 成员变量
        private final SchemaCache.StoreRetrieval typeCacheRetrieval = new SchemaCache.StoreRetrieval() {}
        2. backend
        this.backend = configuration.getBackend();
            1. Backend backend = new Backend(configuration);
                1. KeyColumnValueStoreManager manager = getStorageManager(configuration);
                2. indexes = getIndexes(configuration);
                
                3. //这里的 KCVS 是 keycolumnvaluestorageManager
                managementLogManager = getKCVSLogManager(MANAGEMENT_LOG);
        		txLogManager = getKCVSLogManager(TRANSACTION_LOG);
        		userLogManager = getLogManager(USER_LOG);
        		
        		4. scanner = new StandardScanner(storeManager);
                
            2. backend.initialize(configuration);
                1. store 新建
                KeyColumnValueStore idStore = storeManager.openDatabase(config.get(IDS_STORE_NAME));
                KeyColumnValueStore edgeStoreRaw = storeManagerLocking.openDatabase(EDGESTORE_NAME);
            	KeyColumnValueStore indexStoreRaw = storeManagerLocking.openDatabase(INDEXSTORE_NAME);
                
                2. cacheEnabled
                edgeStore = new NoKCVSCache(edgeStoreRaw);
                indexStore = new NoKCVSCache(indexStoreRaw);
            3. storeFeatures = backend.getStoreFeatures();
        3. 初始化
        this.idAssigner = config.getIDAssigner(backend);
        this.idManager = idAssigner.getIDManager();
        this.serializer = config.getSerializer();
        StoreFeatures storeFeatures = backend.getStoreFeatures();
        this.indexSerializer = new IndexSerializer(configuration.getConfiguration(), this.serializer,
        this.backend.getIndexInformation(), storeFeatures.isDistributed() &amp;amp;&amp;amp; storeFeatures.isKeyOrdered());
        this.edgeSerializer = new EdgeSerializer(this.serializer);
        this.vertexExistenceQuery = edgeSerializer.getQuery(BaseKey.VertexExists, Direction.OUT, new EdgeSerializer.TypedInterval[0]).setLimit(1);
        this.queryCache = new RelationQueryCache(this.edgeSerializer);
        this.schemaCache = configuration.getTypeCache(typeCacheRetrieval);
        this.times = configuration.getTimestampProvider();
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后是open完成后：GraphOfTheGodsFactory.load(graph);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;1. 得到management
JanusGraphManagement management = graph.openManagement();
    
    1. new ManagementSystem
        1. 启动 tx
        this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();
            1.  graph.newTransaction(immutable);
                StandardJanusGraphTx tx = new StandardJanusGraphTx(this, configuration);
            	tx.setBackendTransaction(openBackendTransaction(tx));
            	openTransactions.add(tx);
2. 得到 PropertyKey
final PropertyKey name = management.makePropertyKey(&amp;quot;name&amp;quot;).dataType(String.class).make();
    1. return transaction.makePropertyKey(name);
        1. return new StandardPropertyKeyMaker(this, name, indexSerializer, attributeHandler);
            1. super(tx, name, indexSerializer, attributeHandler);
    2. public StandardPropertyKeyMaker dataType(Class&amp;lt;?&amp;gt; clazz)
    3. public PropertyKey make()
        1. TypeDefinitionMap definition = makeDefinition();        
        2. return tx.makePropertyKey(getName(), definition);
            1. return (PropertyKey) makeSchemaVertex(JanusGraphSchemaCategory.PROPERTYKEY, name, definition);
                1. ... 先跳过。
            
3. 新建 index
JanusGraphManagement.IndexBuilder nameIndexBuilder = management.buildIndex(&amp;quot;name&amp;quot;, Vertex.class).addKey(name);
    1. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用：JanusGraphManagement management = graph.openManagement();然后：management.makeEdgeLabel(&amp;ldquo;father&amp;rdquo;).multiplicity(Multiplicity.MANY2ONE).make();&lt;/p&gt;

&lt;p&gt;然后就是查询数据库：&lt;code&gt;Vertex saturn = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).next();&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;二-第2遍调试&#34;&gt;二、第2遍调试&lt;/h2&gt;

&lt;p&gt;这次我们多关注一点细节实现，包括几个部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Backend backend = new Backend(configuration);
backend.~~~

this.idAssigner = config.getIDAssigner(backend);
this.idManager = idAssigner.getIDManager();

JanusGraphManagement management = graph.openManagement();
management.makePropertyKey(&amp;quot;name&amp;quot;).dataType(String.class).make();
management.buildIndex(&amp;quot;name&amp;quot;, Vertex.class).addKey(name);

Vertex tartarus = tx.addVertex(T.label, &amp;quot;location&amp;quot;, &amp;quot;name&amp;quot;, &amp;quot;tartarus&amp;quot;);
jupiter.addEdge(&amp;quot;father&amp;quot;, saturn);


&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;backend&#34;&gt;Backend&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public StandardJanusGraph(GraphDatabaseConfiguration configuration) 
{
    this.backend = configuration.getBackend();
    {
        Backend backend = new Backend(configuration);
        {
            this.configuration = configuration;
            KeyColumnValueStoreManager manager = getStorageManager(configuration);
            {
                反射生成一个 KeyColumnValueStoreManager 实现类
            }
            indexes = getIndexes(configuration);
            {
                IndexProvider provider = getImplementationClass(config.restrictTo(index), config.get(INDEX_BACKEND,index),
                    StandardIndexProvider.getAllProviderClasses());
                -- org.janusgraph.diskstorage.es.ElasticSearchIndex
                builder.put(index, provider);
                builder.build();
            }
            storeFeatures = storeManager.getFeatures();
            {
                ...
            }
            ...
        }
        
        backend.initialize(configuration);
        {
            KeyColumnValueStore idStore = storeManager.openDatabase(config.get(IDS_STORE_NAME));
            {
                openDatabase(&amp;quot;janusgraph_ids&amp;quot;, EMPTY)
                {
                    if (!stores.containsKey(name) || stores.get(name).isClosed()) {
                         OrderedKeyValueStoreAdapter store = wrapKeyValueStore(manager.openDatabase(name), keyLengths);
                         {
                             public BerkeleyJEKeyValueStore openDatabase(String name) throws BackendException 
                             {
                                 Database db = environment.openDatabase(null, name, dbConfig);
                                 BerkeleyJEKeyValueStore store = new BerkeleyJEKeyValueStore(name, db, this);
                                 stores.put(name, store);
                             }
                         }
                         stores.put(name, store);
                     }
                     return stores.get(name);
                }
            }
            
            KeyColumnValueStore edgeStoreRaw = storeManagerLocking.openDatabase(EDGESTORE_NAME);
            {
                同上：  
                openDatabase(&amp;quot;edgestore&amp;quot;, EMPTY)
            }
            KeyColumnValueStore indexStoreRaw = storeManagerLocking.openDatabase(INDEXSTORE_NAME);
            {
                同上：  
                openDatabase(&amp;quot;graphindex&amp;quot;, EMPTY)
            }
            
            txLogManager.openLog(SYSTEM_TX_LOG_NAME);
            managementLogManager.openLog(SYSTEM_MGMT_LOG_NAME);
            txLogStore = new NoKCVSCache(storeManager.openDatabase(SYSTEM_TX_LOG_NAME));
            
            KeyColumnValueStore systemConfigStore = storeManagerLocking.openDatabase(SYSTEM_PROPERTIES_STORE_NAME);
            {
                同上：  
                openDatabase(&amp;quot;system_properties&amp;quot;, EMPTY)
            }
            
        }
        storeFeatures = backend.getStoreFeatures();
    }
    
    this.idAssigner = config.getIDAssigner(backend);
    this.idManager = idAssigner.getIDManager();
    
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;management&#34;&gt;management&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraphManagement management = graph.openManagement();
{
   new ManagementSystem(this,backend.getGlobalSystemConfig(),backend.getSystemMgmtLog(), managementLogger, schemaCache);
   //参数分别是 graph config Log managementLogger schemaCache
   {
       this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();
       {
           graph.buildTransaction()
           {
               new StandardTransactionBuilder(getConfiguration(), this);
               {
                   
               }
           }
           disableBatchLoading()
           {
               
           }
           start()
           {
               new ImmutableTxCfg
               graph.newTransaction(immutable);
               {
                    StandardJanusGraphTx tx = new StandardJanusGraphTx(this, configuration);
                    {
                        父类： JanusGraphBlueprintsTransaction
                        太过复杂，跳过
                    }
                    tx.setBackendTransaction(openBackendTransaction(tx));
                    {
                        openBackendTransaction(tx)
                        {
                            IndexSerializer.IndexInfoRetriever retriever = indexSerializer.getIndexInfoRetriever(tx);
                            return backend.beginTransaction(tx.getConfiguration(), retriever);
                            {
                                StoreTransaction tx = storeManagerLocking.beginTransaction(configuration);
                                CacheTransaction cacheTx = new CacheTransaction(tx, storeManagerLocking, bufferSize, maxWriteTime, configuration.hasEnabledBatchLoading());
                                final Map&amp;lt;String, IndexTransaction&amp;gt; indexTx = new HashMap&amp;lt;&amp;gt;(indexes.size());
        						for (Map.Entry&amp;lt;String, IndexProvider&amp;gt; entry : indexes.entrySet()) {
        						    indexTx.put(entry.getKey(), new IndexTransaction(entry.getValue(), indexKeyRetriever.get(entry.getKey()), configuration, maxWriteTime));
        						}
        						return new BackendTransaction(cacheTx, configuration, storeFeatures,
                					edgeStore, indexStore, txLogStore,
                					maxReadTime, indexTx, threadPool);
                            }
                        }
                    }
                    openTransactions.add(tx);
                    return tx;
               }
           }
           
       }
   }
}

final PropertyKey name = management.makePropertyKey(&amp;quot;name&amp;quot;).dataType(String.class).make();
{
    management.makePropertyKey(&amp;quot;name&amp;quot;)
    {
        transaction.makePropertyKey(name);
        {
            new StandardPropertyKeyMaker(this, name, indexSerializer, attributeHandler);
            {
                super
                {
                    StandardRelationTypeMaker
                }
            }
        }
    }
    dataType(String.class)
    {
        dataType = clazz;
    }
    make();
    {
        new TypeDefinitionMap();
        tx.makePropertyKey(getName(), definition);
        {
            (PropertyKey) makeSchemaVertex(JanusGraphSchemaCategory.PROPERTYKEY, name, definition);
            {
                schemaVertex = new PropertyKeyVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.UserPropertyKey, temporaryIds.nextID()), ElementLifeCycle.New);
                {
                    //一层层嵌套
                    
                }
            }
        }
    }
}

management.buildIndex(&amp;quot;name&amp;quot;, Vertex.class).addKey(name).unique().buildCompositeIndex();
{
    new IndexBuilder(indexName, ElementCategory.getByClazz(elementType));
    {
        
    }
    addKey(name)
    {
        keys.put(key, null);
    }
    unique()
    {
        unique = true;
    }
    buildCompositeIndex()
    {
        createCompositeIndex(indexName, elementCategory, unique, constraint, keyArr);
        {
            JanusGraphSchemaVertex indexVertex = transaction.makeSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX, indexName, def);
            {
                schemaVertex = new JanusGraphSchemaVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.GenericSchemaType,temporaryIds.nextID()), ElementLifeCycle.New);
                {
                    //一层层嵌套
                    
                }
            }
            addSchemaEdge(indexVertex, keys[i], TypeDefinitionCategory.INDEX_FIELD, paras);
            
            updateSchemaVertex(indexVertex);
            JanusGraphIndexWrapper index = new JanusGraphIndexWrapper(indexVertex.asIndexType());
            updateIndex(index, SchemaAction.REGISTER_INDEX);
            return index;
        }
    }
    
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;containsvertexlabel&#34;&gt;containsVertexLabel&lt;/h3&gt;

&lt;p&gt;mgmt.getVertexLabels().iterator()
mgmt.containsVertexLabel(label)
这两个方法都可以得到 VertexLABEL&lt;/p&gt;

&lt;p&gt;首先看 mgmt.getVertexLabels().iterator(), 这里面首先通过了 guava 的 abstractIterator 转到一个 ResultSetIterator&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public ResultSetIterator(Iterator&amp;lt;R&amp;gt; inner, int limit) {
    this.iter = inner;
    this.limit = limit;
    count = 0;
    this.current = null;
    this.next = nextInternal();
    {
        QueryProcessor$LimitAdajustingIterator.hasNext()
        {
            ....省去一步调用
            executor.execute(query, backendQuery, executionInfo, profiler);
            {
                iter = new SubqueryIterator(indexQuery.getQuery(0), indexSerializer, txHandle, indexCache, indexQuery.getLimit(), getConversionFunction(query.getResultType()),
                        retrievals.isEmpty() ? null: QueryUtil.processIntersectingRetrievals(retrievals, indexQuery.getLimit()));
                {
                    stream = indexSerializer.query(subQuery, tx).map(r -&amp;gt; {
                        currentIds.add(r);
                        return r;
                    });
                    {
                        final List&amp;lt;EntryList&amp;gt; rs = sq.execute(tx);
                        {
                            EntryList next =tx.indexQuery(ksq.updateLimit(getLimit()-total));
                            {
                                return exe.call();
                                {
                                    return cacheEnabled?indexStore.getSlice(query, storeTx):
                                        indexStore.getSliceNoCache(query, storeTx);
                                    {
                                        CassandraThriftKeyColumnValueStore.getNamesSlice(ImmutableList.of(key),query,txh);
                                    }
                                }
                            }
                        }
                        
                    }
                }
            }
        }
        
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这上面已经是省略很多步骤的调用栈。。。&lt;/p&gt;

&lt;p&gt;mgmt.containsVertexLabel(label) 调用栈稍微少了一点：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraphSchemaVertex getSchemaVertex(String schemaName)
{
    id = retriever.retrieveSchemaByName(schemaName);
    {
        JanusGraphVertex v = Iterables.getOnlyElement(QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName), null);
        {
            new ResultSetIterator()
            {
                ....
                runWithMetrics
                iter = new SubqueryIterator(indexQuery.getQuery(0), indexSerializer, txHandle, indexCache, indexQuery.getLimit(), getConversionFunction(query.getResultType()),
                        retrievals.isEmpty() ? null: QueryUtil.processIntersectingRetrievals(retrievals, indexQuery.getLimit()));
                {
                    类似上面
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;makevertexlabel&#34;&gt;makeVertexLabel&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt.makeVertexLabel(vType.toString()).make();
{
    StandardVertexLabelMaker.make
    return (VertexLabelVertex)tx.makeSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL,name,def);
    {
        
        public final JanusGraphSchemaVertex makeSchemaVertex(JanusGraphSchemaCategory schemaCategory, String name, TypeDefinitionMap definition) 
        {
            1. new VertexLabelVertex
            schemaVertex = new VertexLabelVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.GenericSchemaType,temporaryIds.nextID()), ElementLifeCycle.New);
            2. graph.assignID(schemaVertex, BaseVertexLabel.DEFAULT_VERTEXLABEL);
            
            3. addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));
            
            4. updateSchemaVertex(schemaVertex);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;assignID应该是 生产者消费者模式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;IDBlock idBlock = idAuthority.getIDBlock(partition, idNamespace, renewTimeout);
{
    long nextStart = getCurrentID(partitionKey);
    {
        ......
        return idStore.getSlice(new KeySliceQuery(partitionKey, LOWER_SLICE, UPPER_SLICE).setLimit(5), txh);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;containspropertykey&#34;&gt;containsPropertyKey&lt;/h3&gt;

&lt;h3 id=&#34;makepropertykey&#34;&gt;makePropertyKey&lt;/h3&gt;

&lt;h3 id=&#34;containsedgelabel&#34;&gt;containsEdgeLabel&lt;/h3&gt;

&lt;h3 id=&#34;makeedgelabel&#34;&gt;makeEdgeLabel&lt;/h3&gt;

&lt;p&gt;基本上和上面类似，接下来深入分析一下这些调用栈涉及到的类。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析3-调用栈</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-%E8%B0%83%E7%94%A8%E6%A0%88/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-%E8%B0%83%E7%94%A8%E6%A0%88/</guid>
      
        <description>

&lt;p&gt;我们可以在比较关键的地方大断点，然后分析整个调用栈，进行进一步分析。哪里是关键点是需要一定经验判断的。&lt;/p&gt;

&lt;p&gt;例如我们基于 hadoop spark 等框架的时候，我们写的代码就是关键的，打断点可以看到合适调用，怎么被调用。
我们关心怎么写数据，可以在和底层数据交互的地方打断点。总之我们关心谁就在哪里打断点。&lt;/p&gt;

&lt;p&gt;记住：打断点的地方基本上是最终的调用点。&lt;/p&gt;

&lt;h2 id=&#34;整体调试找关键&#34;&gt;整体调试找关键&lt;/h2&gt;

&lt;p&gt;首先是存储类，我们使用本地文件存储，存储使用类是：&lt;code&gt;com.sleepycat.je.Database&lt;/code&gt; 这个类具体功能是啥可以具体研究。我们发现它有 get delete put 等方法，我们可以打上断点。然后查看调用栈。&lt;/p&gt;

&lt;p&gt;得到 普通 的调用信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;main@1&amp;quot; prio=5 tid=0x1 nid=NA runnable
  java.lang.Thread.State: RUNNABLE
	  at com.sleepycat.je.Database.put(Database.java:1574)
	  at com.sleepycat.je.Database.put(Database.java:1627)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:195)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:184)
	  at org.janusgraph.diskstorage.keycolumnvalue.keyvalue.OrderedKeyValueStoreAdapter.mutate(OrderedKeyValueStoreAdapter.java:99)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration$2.call(KCVSConfiguration.java:154)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration$2.call(KCVSConfiguration.java:149)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:147)
	  at org.janusgraph.diskstorage.util.BackendOperation$1.call(BackendOperation.java:161)
	  at org.janusgraph.diskstorage.util.BackendOperation.executeDirect(BackendOperation.java:68)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:54)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:158)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration.set(KCVSConfiguration.java:149)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration.set(KCVSConfiguration.java:126)
	  at org.janusgraph.diskstorage.configuration.ModifiableConfiguration.set(ModifiableConfiguration.java:40)
	  at org.janusgraph.diskstorage.configuration.ModifiableConfiguration.setAll(ModifiableConfiguration.java:47)
	  at org.janusgraph.graphdb.configuration.GraphDatabaseConfiguration.&amp;lt;init&amp;gt;(GraphDatabaseConfiguration.java:1266)
	  at org.janusgraph.core.JanusGraphFactory.open(JanusGraphFactory.java:160)
	  at org.janusgraph.core.JanusGraphFactory.open(JanusGraphFactory.java:131)
	  at org.janusgraph.core.JanusGraphFactory.open(JanusGraphFactory.java:78)
	  at org.janusgraph.test.dengziming.FirstTest.main(FirstTest.java:37)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从下往上可以看出，顺序：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new GraphDatabaseConfiguration
ModifiableConfiguration.setAll(getGlobalSubset(localBasicConfiguration.getAll())); 
KCVSConfiguration.set(key,value,null,false);
BackendOperation.execute(new BackendOperation.Transactional&amp;lt;Boolean&amp;gt;() {@Override public Boolean call}
然后调用 上面new 的 BackendOperation.Transactional 的 call 方法
然后是 store.mutate
status = db.put(tx, key.as(ENTRY_FACTORY), value.as(ENTRY_FACTORY));
put(txn, key, data, Put.OVERWRITE, null);
result = cursor.putInternal(key, data, putType, options);
最终调用的是 cursor.putNotify 插入数据。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 put 会多次调用，config 会设置 &amp;ldquo;startup-time&amp;rdquo; 等属性，都是通过这个put方法实现。&lt;/p&gt;

&lt;p&gt;第二次用到这个方法是 创建 VertexLabel 的时候会分配 id， 这时候我们可以看一下更详细的调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;JanusGraphID(0)(4)[0]@5358&amp;quot; prio=5 tid=0x24 nid=NA runnable
  java.lang.Thread.State: RUNNABLE
	  at com.sleepycat.je.dbi.CursorImpl.insertRecordInternal(CursorImpl.java:1364)
	  at com.sleepycat.je.dbi.CursorImpl.insertOrUpdateRecord(CursorImpl.java:1221)
	  at com.sleepycat.je.Cursor.putNoNotify(Cursor.java:2962)
	  at com.sleepycat.je.Cursor.putNotify(Cursor.java:2800)
	  at com.sleepycat.je.Cursor.putNoDups(Cursor.java:2647)
	  at com.sleepycat.je.Cursor.putInternal(Cursor.java:2478)
	  - locked &amp;lt;0x1536&amp;gt; (a com.sleepycat.je.Transaction)
	  at com.sleepycat.je.Cursor.putInternal(Cursor.java:830)
	  at com.sleepycat.je.Database.put(Database.java:1574)
	  at com.sleepycat.je.Database.put(Database.java:1627)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:195)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:184)
	  at org.janusgraph.diskstorage.keycolumnvalue.keyvalue.OrderedKeyValueStoreAdapter.mutate(OrderedKeyValueStoreAdapter.java:99)
	  at org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority.lambda$getIDBlock$1(ConsistentKeyIDAuthority.java:261)
	  at org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority$$Lambda$71.1795053717.call(Unknown Source:-1)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:147)
	  at org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority.getIDBlock(ConsistentKeyIDAuthority.java:260)
	  - locked &amp;lt;0x14f8&amp;gt; (a org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority)
	  at org.janusgraph.graphdb.database.idassigner.StandardIDPool$IDBlockGetter.call(StandardIDPool.java:288)
	  at org.janusgraph.graphdb.database.idassigner.StandardIDPool$IDBlockGetter.call(StandardIDPool.java:255)
	  ...
	  at java.lang.Thread.run(Thread.java:745)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的调用栈没有显示这么多，实际上我们也没必要关心 &lt;code&gt;com.sleepycat.je.Database.put(Database.java:1627)&lt;/code&gt; 之后的东西，
因为这些东西都是 数据库的写 API，而生产环境我们会使用 hbase和cassandra ，所以每次只要 debug 到 KeyColumnValueStore 的 相应方法即可，再 debug 就是数据库的方法。&lt;/p&gt;

&lt;p&gt;到这里我们明白，增删改查都是 通过 KeyColumnValueStore 类完成。接下来我们直接在 BerkeleyJEKeyValueStore 的 增删改查方法 打断点就行。&lt;/p&gt;

&lt;h3 id=&#34;management-commit&#34;&gt;management.commit();&lt;/h3&gt;

&lt;p&gt;management 是用来操作 schema 的类，我们可以猜测 schema 也是以系统属性的方式存在数据库中。通过打断点发现，前面的操作都没有触发 BerkeleyJEKeyValueStore 的insert ，直到 commit，
先取出调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;main@1&amp;quot; prio=5 tid=0x1 nid=NA runnable
  java.lang.Thread.State: RUNNABLE
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:195)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:184)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEStoreManager.mutateMany(BerkeleyJEStoreManager.java:208)
	  at org.janusgraph.diskstorage.keycolumnvalue.keyvalue.OrderedKeyValueStoreManagerAdapter.mutateMany(OrderedKeyValueStoreManagerAdapter.java:125)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction$1.call(CacheTransaction.java:94)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction$1.call(CacheTransaction.java:91)
	  at org.janusgraph.diskstorage.util.BackendOperation.executeDirect(BackendOperation.java:68)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:54)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction.persist(CacheTransaction.java:91)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction.flushInternal(CacheTransaction.java:139)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction.commit(CacheTransaction.java:196)
	  at org.janusgraph.diskstorage.BackendTransaction.commitStorage(BackendTransaction.java:134)
	  at org.janusgraph.graphdb.database.StandardJanusGraph.commit(StandardJanusGraph.java:733)
	  at org.janusgraph.graphdb.transaction.StandardJanusGraphTx.commit(StandardJanusGraphTx.java:1372)
	  - locked &amp;lt;0x113a&amp;gt; (a org.janusgraph.graphdb.transaction.StandardJanusGraphTx)
	  at org.janusgraph.graphdb.database.management.ManagementSystem.commit(ManagementSystem.java:239)
	  - locked &amp;lt;0x102b&amp;gt; (a org.janusgraph.graphdb.database.management.ManagementSystem)
	  at org.janusgraph.example.GraphOfTheGodsFactory.load(GraphOfTheGodsFactory.java:111)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里面好像还有锁，这个先不讨论。&lt;/p&gt;

&lt;p&gt;主要的几个调用：&lt;/p&gt;

&lt;p&gt;StandardJanusGraphTx.commit()&lt;/p&gt;

&lt;p&gt;StandardJanusGraph.commit(addedRelations.getAll(), deletedRelations.values(), this); &amp;ndash; 这个 commit 的逻辑挺复杂，需要仔细查看。&lt;/p&gt;

&lt;p&gt;BackendTransaction.commitStorage();&lt;/p&gt;

&lt;p&gt;CacheTransaction.commit()&lt;/p&gt;

&lt;p&gt;OrderedKeyValueStoreManagerAdapter.mutateMany&lt;/p&gt;

&lt;p&gt;BerkeleyJEStoreManager.mutateMany(subMutations, tx);&lt;/p&gt;

&lt;p&gt;BerkeleyJEKeyValueStore.insert();&lt;/p&gt;

&lt;p&gt;然后接下来就是一个个分析这几个类每一个的属性和方法。&lt;/p&gt;

&lt;p&gt;首先看一下类的继承结构&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SchemaInspector	
	StandardJanusGraphTx (org.janusgraph.graphdb.transaction)
	SchemaManager (org.janusgraph.core.schema)
	    Transaction (org.janusgraph.core)
	        JanusGraphTransaction (org.janusgraph.core)
	            JanusGraphBlueprintsTransaction (org.janusgraph.graphdb.tinkerpop)
	                StandardJanusGraphTx (org.janusgraph.graphdb.transaction)
	        JanusGraph (org.janusgraph.core)
	            JanusGraphBlueprintsGraph (org.janusgraph.graphdb.tinkerpop)
	                StandardJanusGraph (org.janusgraph.graphdb.database)
	    JanusGraphManagement (org.janusgraph.core.schema)
	        ManagementSystem (org.janusgraph.graphdb.database.management)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SchemaInspector 接口定义了检查 schema 的一些方法，
例如：containsRelationType getRelationType containsPropertyKey getOrCreatePropertyKey getEdgeLabel getOrCreateVertexLabel
这些方法有四类，分别是是 RelationType 相关的，PropertyKey 相关，EdgeLabel 相关，VertexLabel 相关。这四个代表啥大家应该都清楚了。&lt;/p&gt;

&lt;p&gt;SchemaManager 接口 在 SchemaInspector 的基础上添加了 6 个方法 ：makePropertyKey makeEdgeLabel makeVertexLabel addProperties addProperties addConnection 。
其实前三个返回的是 Maker，后面三个返回的就是 Label。这六个方法左右主要是给 schema 添加更多信息，例如添加 properties。&lt;/p&gt;

&lt;p&gt;Transaction 继承自 SchemaManager 和 Graph ，定义了 addVertex 和 query 等操作。很奇怪为什么只有 addVertex 没有 addEdge 和 addProperty 的操作。&lt;/p&gt;

&lt;p&gt;JanusGraphManagement 继承自 SchemaManager 和 JanusGraphConfiguration ，定义了 buildEdgeIndex buildPropertyIndex commit 等操作
大部分都和 index 相关，例如构建查询更新。还有 getRelationTypes getVertexLabels 两个方法。&lt;/p&gt;

&lt;p&gt;ManagementSystem 继承自 JanusGraphManagement ，通过代理 StandardJanusGraphTx ，实现了 getGraphIndex commit 等操作。&lt;/p&gt;

&lt;p&gt;JanusGraphTransaction 继承自 Transaction ，定义了 addVertex getVertex commit rollback 等，和 Transaction 不同的是他的这些方法操作的都是 id，而后者操作的是 用户传入的 String&lt;/p&gt;

&lt;p&gt;JanusGraphBlueprintsTransaction 继承自 JanusGraphTransaction ，目前看到的就是简单封装一下抽象方法，同时实现了 addVertex 方法。&lt;/p&gt;

&lt;p&gt;StandardJanusGraphTx 继承自 JanusGraphBlueprintsTransaction ，实现了抽象的方法。&lt;/p&gt;

&lt;p&gt;JanusGraph 继承自 Transaction， 定义了 buildTransaction openManagement close 等方法。&lt;/p&gt;

&lt;p&gt;JanusGraphBlueprintsGraph 继承自 JanusGraph ，通过 ThreadLocal 实现线程隔离。
StandardJanusGraph 继承自 JanusGraphBlueprintsGraph 就是我们使用的 Graph 。&lt;/p&gt;

&lt;p&gt;所以了解janus比较重要的是 StandardJanusGraphTx ，了解多线程的 JanusGraphBlueprintsGraph。&lt;/p&gt;

&lt;p&gt;从继承结构大概可以看出所有的操作分为数据操作和 schema 操作，而分别由 JanusGraph 和 JanusGraphManagement 完成，实际上都是代理或者适配装饰了 StandardJanusGraphTx。StandardJanusGraphTx 内容很多。&lt;/p&gt;

&lt;h3 id=&#34;standardjanusgraph&#34;&gt;StandardJanusGraph&lt;/h3&gt;

&lt;p&gt;上面我们已经看出了实际上最重要的就是  StandardJanusGraphTx 的实现逻辑，我们就以他为入口，而不是 main 方法。它的构造方法里面需要用到 StandardJanusGraph ，我们先大概了解一下 。&lt;/p&gt;

&lt;h4 id=&#34;我们先看一下它的属性&#34;&gt;我们先看一下它的属性：&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;log
config
backend
idManager
idAssigner
times
indexSerializer
edgeSerializer
serializer
vertexExistenceQuery
queryCache
schemaCache
managementLogger
shutdownHook
isOpen
txCounter
openTransactions
name
typeCacheRetrieval
SCHEMA_FILTER
NO_SCHEMA_FILTER
NO_FILTER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GraphDatabaseConfiguration config 是图的配置，由于配置也是保存在数据库，所以也是需要访问数据库的。&lt;/p&gt;

&lt;p&gt;Backend backend 是在 config.getBackend 中初始化的，Backend 的构造方法很复杂，主要创建出了 StoreManager indexes txLogManager 等管理存储很重要的属性。&lt;/p&gt;

&lt;p&gt;idManager 和 idAssigner 都是和 id 相关的。 所属类为 IDManager ，VertexIDAssigner，有比较复杂的id分配算法。&lt;/p&gt;

&lt;p&gt;IndexSerializer 和 EdgeSerializer 、Serializer 用于序列化，Serializer 在 config 中初始化，其他两个都是基于 Serializer 的封装。&lt;/p&gt;

&lt;p&gt;vertexExistenceQuery:SliceQuery queryCache:RelationQueryCache schemaCache:SchemaCache 都是 cache 相关。&lt;/p&gt;

&lt;p&gt;managementLogger 是 用来记录操作日志的。&lt;/p&gt;

&lt;p&gt;typeCacheRetrieval ，看到 Retrieval 就知道是获取某些属性用的，他通过 &lt;code&gt;QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName)&lt;/code&gt; 获得 JanusGraphVertex。&lt;/p&gt;

&lt;h4 id=&#34;然后再看方法&#34;&gt;然后再看方法&lt;/h4&gt;

&lt;p&gt;除了 getset 以外，主要是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;isOpen
isClosed
close
closeInternal
prepareCommit
commit
openManagement
newTransaction
buildTransaction
newThreadBoundTransaction
newTransaction
openBackendTransaction
closeTransaction
getVertexIDs
edgeQuery
edgeMultiQuery
assignID
assignID
acquireLock
acquireLock
getTTL
getTTL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和 transaction 有关的打开关闭提交等，查询边和顶点，分配id，获得锁。这里的 edgeQuery 并不是查询边，而是查询 edgestore 这个表格，这个表格存放了所有的数据。
细心分析发现，这些方法主要都是进行查询操作，得到查询结果 List&lt;EntryList&gt;，并没有进行数据增删改查的操作 API。&lt;/p&gt;

&lt;h3 id=&#34;managementsystem&#34;&gt;ManagementSystem&lt;/h3&gt;

&lt;p&gt;StandardJanusGraph 用来操作数据，而 ManagementSystem 主要是管理 schema。&lt;/p&gt;

&lt;h4 id=&#34;属性&#34;&gt;属性：&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;LOGGER
CURRENT_INSTANCE_SUFFIX
graph
sysLog
managementLogger
transactionalConfig
modifyConfig
userConfig
schemaCache
transaction
updatedTypes
evictGraphFromCache
updatedTypeTriggers
txStartTime
graphShutdownRequired
isOpen
configVerifier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;graph 和 managementLogger 就是上面的 StandardJanusGraph 和 managementLogger。sysLog 也是和日志有关。&lt;/p&gt;

&lt;p&gt;TransactionalConfiguration 是事务的配置，实际上他应该是记录了变化，能够判断是否有改变，从而进行 commit 和 rollback&lt;/p&gt;

&lt;p&gt;SchemaCache 就是 StandardJanusGraph 的 SchemaCache。&lt;/p&gt;

&lt;p&gt;transaction 是 StandardJanusGraphTx。&lt;/p&gt;

&lt;p&gt;updatedTypes 应该也是记录更新&lt;/p&gt;

&lt;p&gt;其他的暂时还不太懂。&lt;/p&gt;

&lt;h4 id=&#34;方法&#34;&gt;方法：&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;IndexBuilder
GraphCacheEvictionCompleteTrigger
EmptyIndexJobFuture
UpdateStatusTrigger
IndexJobStatus
IndexIdentifier
ManagementSystem

getOpenInstancesInternal
getOpenInstances
forceCloseInstance
ensureOpen
commit
rollback
isOpen
close
getWrappedTx
addSchemaEdge
getSchemaElement
buildEdgeIndex
buildEdgeIndex
buildPropertyIndex
buildPropertyIndex
buildRelationTypeIndex
composeRelationTypeIndexName
containsRelationIndex
getRelationIndex
getRelationIndexes
getGraphIndexDirect
containsGraphIndex
getGraphIndex
getGraphIndexes
awaitGraphIndexStatus
awaitRelationIndexStatus
checkIndexName
createMixedIndex
addIndexKey
createCompositeIndex
buildIndex
updateIndex
evictGraphFromCache
setUpdateTrigger
setStatus
setStatusVertex
setStatusEdges
getIndexJobStatus
changeName
updateConnectionEdgeConstraints
getSchemaVertex
updateSchemaVertex
getConsistency
setConsistency
getTTL
setTTL
setTypeModifier
containsRelationType
getRelationType
containsPropertyKey
getPropertyKey
containsEdgeLabel
getOrCreateEdgeLabel
getOrCreatePropertyKey
getEdgeLabel
makePropertyKey
makeEdgeLabel
getRelationTypes
containsVertexLabel
getVertexLabel
getOrCreateVertexLabel
makeVertexLabel
addProperties
addProperties
addConnection
getVertexLabels
get
set
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;强制关闭、操作事务、添加顶点边Label属性索引。&lt;/p&gt;

&lt;p&gt;索引都是  buildRelationTypeIndex 方法，说明 RelationType(PropertyKey 和 EdgeLabel)才有索引，分别是 graphIndex 和 vertexIncdicentIndex ，VertexLabel 没有索引。
而 getVertexLabels 等带s的方法 是 调用 QueryUtil.getVertices ，说明得到所有的需要查询数据库。&lt;/p&gt;

&lt;p&gt;很多方法都是直接调用 StandardJanusGraphTx 的 对应方法。但是 build Index 并没有使用到 StandardJanusGraphTx。说明 index 并不是马上就插入数据库？或者因为 Index 建完以后还要等待？？&lt;/p&gt;

&lt;h3 id=&#34;standardjanusgraphtx&#34;&gt;StandardJanusGraphTx&lt;/h3&gt;

&lt;p&gt;上面大致了解了  StandardJanusGraph 和 ManagementSystem ，StandardJanusGraphTx 内部才是最重要的，&lt;/p&gt;

&lt;h4 id=&#34;属性-1&#34;&gt;属性：&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;log
EMPTY_DELETED_RELATIONS
UNINITIALIZED_LOCKS
LOCK_TIMEOUT
MIN_VERTEX_CACHE_SIZE
graph
config
idManager
idInspector
attributeHandler
txHandle
edgeSerializer
indexSerializer
vertexCache
addedRelations
deletedRelations
indexCache
newVertexIndexEntries
uniqueLocks
newTypeCache
temporaryIds
times
isOpen
existingVertexRetriever
externalVertexRetriever
internalVertexRetriever
edgeProcessor
edgeProcessorImpl
elementProcessor
elementProcessorImpl
vertexIDConversionFct
edgeIDConversionFct
propertyIDConversionFct
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前面的属性都是在 graph 获得的&lt;/p&gt;

&lt;p&gt;vertexCache = new GuavaVertexCache(effectiveVertexCacheSize,concurrencyLevel,config.getDirtyVertexSize()); 是缓存 vertex 的。&lt;/p&gt;

&lt;p&gt;addedRelations = new ConcurrentBufferAddedRelations(); 是缓存 Relation 的。&lt;/p&gt;

&lt;p&gt;deletedRelations 同上&lt;/p&gt;

&lt;p&gt;indexCache 缓存 index ， 类似 vertexCache ，需要传入一个  retrival&lt;/p&gt;

&lt;p&gt;existingVertexRetriever externalVertexRetriever internalVertexRetriever 都是给 vertexCache 用来查 vertex 的。&lt;/p&gt;

&lt;p&gt;edgeProcessor 是一个 QueryExecutor。用来查询的。&lt;/p&gt;

&lt;p&gt;elementProcessor 一样是用来查询的。&lt;/p&gt;

&lt;h4 id=&#34;方法-1&#34;&gt;方法&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;StandardJanusGraphTx
setBackendTransaction
verifyWriteAccess
verifyAccess
verifyOpen
getNextTx
getConfiguration
getGraph
getTxHandle
getEdgeSerializer
getIdInspector
isPartitionedVertex
getCanonicalVertex
getOtherPartitionVertex
getAllRepresentatives
containsVertex
isValidVertexId
getVertex
getVertices
getExistingVertex
getInternalVertex
addVertex
addVertex
addVertex
getInternalVertices
validDataType
verifyAttribute
removeRelation
isRemovedRelation
getLock
getLock
getUniquenessLock
checkPropertyConstraintForVertexOrCreatePropertyConstraint
checkPropertyConstraintForEdgeOrCreatePropertyConstraint
checkConnectionConstraintOrCreateConnectionConstraint
addEdge
connectRelation
addProperty
addProperty
getEdges
makeSchemaVertex
updateSchemaVertex
makePropertyKey
makeEdgeLabel
addSchemaEdge
addProperties
addProperties
addConnection
getSchemaVertex
containsRelationType
getRelationType
containsPropertyKey
containsEdgeLabel
getExistingRelationType
getPropertyKey
getOrCreatePropertyKey
getOrCreatePropertyKey
getEdgeLabel
getOrCreateEdgeLabel
makePropertyKey
makeEdgeLabel
getExistingVertexLabel
containsVertexLabel
getVertexLabel
getOrCreateVertexLabel
makeVertexLabel
query
multiQuery
multiQuery
executeMultiQuery
getConversionFunction
query
indexQuery
commit
rollback
releaseTransaction
isOpen
isClosed
hasModifications
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;schema 操作的 makeEdgeLabel makePropertyKey 等，数据操作的 getVertex addEdge 等，事务操作的 rollback 等。
好像没有 index ？因为 index 属于 schema， 相关的方法都是在 management 中完成的。
实际上，StandardJanusGraphTx 有 addEdge addProperties addVertex 等操作数据的方法，同时还有 makePropertyKey，EdgeLabel 等操作 schema 的方法。
原因是 makePropertyKey 等 schema 实际上也是以顶点的形式保存在 janus 中，所以 schema 操作本质还是数据操作，只不过这部分数据都会被读入内存。
所以 schema 操作都会触发 makeSchemaVertex 的方法，makeSchemaVertex 就是添加一个顶点，只不过是 schema 的订单。&lt;/p&gt;

&lt;h3 id=&#34;backendtransaction&#34;&gt;BackendTransaction&lt;/h3&gt;

&lt;p&gt;我们在看 StandardJanusGraphTx 代码的时候 ，发现 BackendTransaction 也很重要，看看他的继承体系&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BaseTransaction
	LoggableTransaction (org.janusgraph.diskstorage)
	    CacheTransaction (org.janusgraph.diskstorage.keycolumnvalue.cache)
	    IndexTransaction (org.janusgraph.diskstorage.indexing)
	    BackendTransaction (org.janusgraph.diskstorage)
	BaseTransactionConfigurable (org.janusgraph.diskstorage)
	    Transaction in LuceneIndex (org.janusgraph.diskstorage.lucene)
	    DefaultTransaction (org.janusgraph.diskstorage.util)
	    StoreTransaction (org.janusgraph.diskstorage.keycolumnvalue)
	        AbstractStoreTransaction (org.janusgraph.diskstorage.common)
	            CQLTransaction (org.janusgraph.diskstorage.cql)
	            BerkeleyJETx (org.janusgraph.diskstorage.berkeleyje)
	            CassandraTransaction (org.janusgraph.diskstorage.cassandra)
	            HBaseTransaction (org.janusgraph.diskstorage.hbase)
	            NoOpStoreTransaction (org.janusgraph.diskstorage.common)
	            InMemoryTransaction in InMemoryStoreManager (org.janusgraph.diskstorage.keycolumnvalue.inmemory)
	        CacheTransaction (org.janusgraph.diskstorage.keycolumnvalue.cache)
	        ExpectedValueCheckingTransaction (org.janusgraph.diskstorage.locking.consistentkey)
	IndexTransaction (org.janusgraph.diskstorage.indexing)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BaseTransaction 只有 comimit 和 roolback 两个方法。LoggableTransaction 只有 LoggableTransaction ，BaseTransactionConfigurable 多了一个 getConfiguration 。&lt;/p&gt;

&lt;p&gt;IndexTransaction BackendTransaction CacheTransaction 继承自 LoggableTransaction ， 前者是处理索引，后者可以处理其他的读写事务，最后的是内存中的事务处理。&lt;/p&gt;

&lt;p&gt;IndexTransaction 中有一个 BaseTransaction 属性，用来实现真正的事务读写，实现一般是 IndexProvider 生成，主要是 ES、LUCENE、Solr 三种实现。
CacheTransaction 中有 StoreTransaction 属性，用来实现持久化。
BackendTransaction 中则有 CacheTransaction edgeStore indexStore txLogStore Map&lt;String, IndexTransaction&gt; indexTx; 等属性，显然这才是最重要的实现事务管控的类。&lt;/p&gt;

&lt;p&gt;我们通过代码分析可以看出 BackendTransaction 的创建是在 StandardJanusGraph 完成，而使用主要是 StandardJanusGraphTx 。
StandardJanusGraph 的 newTransaction 创建 BackendTransaction 和 StandardJanusGraphTx ，并进行赋值。
StandardJanusGraph 什么时候会调用 newTransaction ？一个在 typeCacheRetrieval 中，另一个就是我们代码创建新的 transaction，还有一个是 在没有 transactional isolation 的存储系统上面， commit 的时候需要操作 schema&lt;/p&gt;

&lt;h2 id=&#34;关键类分析&#34;&gt;关键类分析&lt;/h2&gt;

&lt;p&gt;上面整体的调试已经找到了比较关键的大类，以及事务相关的类的关系，我们可以反过来再看一遍调用栈，就更清晰了。现在反过来从细节开始研究具体的类的功能。&lt;/p&gt;

&lt;h3 id=&#34;storemanager&#34;&gt;StoreManager&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;StoreManager
	KeyValueStoreManager (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    OrderedKeyValueStoreManager (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	        BerkeleyJEStoreManager (org.janusgraph.diskstorage.berkeleyje)
	AbstractStoreManager (org.janusgraph.diskstorage.common)
	    DistributedStoreManager (org.janusgraph.diskstorage.common)
	        CQLStoreManager (org.janusgraph.diskstorage.cql)
	            CachingCQLStoreManager (org.janusgraph.diskstorage.cql)
	        AbstractCassandraStoreManager (org.janusgraph.diskstorage.cassandra)
	            CassandraThriftStoreManager (org.janusgraph.diskstorage.cassandra.thrift)
	            CassandraEmbeddedStoreManager (org.janusgraph.diskstorage.cassandra.embedded)
	            AstyanaxStoreManager (org.janusgraph.diskstorage.cassandra.astyanax)
	        HBaseStoreManager (org.janusgraph.diskstorage.hbase)
	    LocalStoreManager (org.janusgraph.diskstorage.common)
	        BerkeleyJEStoreManager (org.janusgraph.diskstorage.berkeleyje)
	                    LocalStoreManagerSampleImplementation in LocalStoreManagerTest (org.janusgraph.diskstorage.common)
	            KeyColumnValueStoreManager (org.janusgraph.diskstorage.keycolumnvalue)
	    CQLStoreManager (org.janusgraph.diskstorage.cql)
	        CachingCQLStoreManager (org.janusgraph.diskstorage.cql)
	    OrderedKeyValueStoreManagerAdapter (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    InMemoryStoreManager (org.janusgraph.diskstorage.keycolumnvalue.inmemory)
	    KCVSManagerProxy (org.janusgraph.diskstorage.keycolumnvalue)
	        ExpectedValueCheckingStoreManager (org.janusgraph.diskstorage.locking.consistentkey)
	        TTLKCVSManager (org.janusgraph.diskstorage.keycolumnvalue.ttl)
	    MetricInstrumentedStoreManager (org.janusgraph.diskstorage.util)
	    AbstractCassandraStoreManager (org.janusgraph.diskstorage.cassandra)
	        CassandraThriftStoreManager (org.janusgraph.diskstorage.cassandra.thrift)
	        CassandraEmbeddedStoreManager (org.janusgraph.diskstorage.cassandra.embedded)
	        AstyanaxStoreManager (org.janusgraph.diskstorage.cassandra.astyanax)
	    HBaseStoreManager (org.janusgraph.diskstorage.hbase)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;StoreManager 接口主要功能 beginTransaction 得到一个 StoreTransaction 和 close ，clean 等，还有得到 store 相关的信息。看着上面好像很多继承类，实际上是因为有重复继承导致的。&lt;/p&gt;

&lt;p&gt;KeyValueStoreManager 是测试的。DistributedStoreManager 和 KeyColumnValueStoreManager 是两个抽象，我们使用的 cassandra 和 hbase 的 storeManager 都继承自这两个。
这几个 storeManager 就有我们需要的操作数据的方法。&lt;/p&gt;

&lt;h3 id=&#34;keycolumnvaluestore-keyvaluestore&#34;&gt;KeyColumnValueStore &amp;amp; KeyValueStore&lt;/h3&gt;

&lt;p&gt;KeyValueStore 是测试的，KeyColumnValueStore 是真正的。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;KeyColumnValueStore
	KCVSProxy (org.janusgraph.diskstorage.keycolumnvalue)
	    TTLKCVS (org.janusgraph.diskstorage.keycolumnvalue.ttl)
	    ExpectedValueCheckingStore (org.janusgraph.diskstorage.locking.consistentkey)
	    KCVSCache (org.janusgraph.diskstorage.keycolumnvalue.cache)
	        ExpirationKCVSCache (org.janusgraph.diskstorage.keycolumnvalue.cache)
	        NoKCVSCache (org.janusgraph.diskstorage.keycolumnvalue.cache)
	    ReadOnlyKeyColumnValueStore (org.janusgraph.diskstorage.keycolumnvalue)
	BaseKeyColumnValueAdapter (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    OrderedKeyValueStoreAdapter (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	CQLKeyColumnValueStore (org.janusgraph.diskstorage.cql)
	HBaseKeyColumnValueStore (org.janusgraph.diskstorage.hbase)
	CassandraEmbeddedKeyColumnValueStore (org.janusgraph.diskstorage.cassandra.embedded)
	CassandraThriftKeyColumnValueStore (org.janusgraph.diskstorage.cassandra.thrift)
	AstyanaxKeyColumnValueStore (org.janusgraph.diskstorage.cassandra.astyanax)
	MetricInstrumentedStore (org.janusgraph.diskstorage.util)
	CounterKCVS in KCVSCacheTest (org.janusgraph.diskstorage.cache)
	InMemoryKeyColumnValueStore (org.janusgraph.diskstorage.keycolumnvalue.inmemory)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;KeyColumnValueStore 的作用我暂时不是很清楚，从继承类的构造方法看，需要传入一个 StoreManager connection table columnFamily store 。大概能猜出一个 Store 代表一个表格，或者代表一个列族，应该是代表某种数据，例如索引，日志等。&lt;/p&gt;

&lt;p&gt;从他的方法可以看出主要是查询库， 如 getKeySlice mutate mutateMany 。&lt;/p&gt;

&lt;p&gt;KCVSCache 也继承自 KeyColumnValueStore，名字可以看出是放在内存的 store ，自然也有 getSlice 等方法，我们可以看他的实现类 ExpirationKCVSCache。
这个类里面有一个 Cache&lt;KeySliceQuery,EntryList&gt; cache 的对象，用来缓存查询结果。而 KCVSCache 继承自 KCVSProxy ，这个类则代理 KeyColumnValueStore 对象。其实还有一个 TTLKCVS ，应该是带过期时间的 store&lt;/p&gt;

&lt;h3 id=&#34;logmanager&#34;&gt;LogManager&lt;/h3&gt;

&lt;p&gt;LogManager 的注释：Manager interface for opening {@link Log}s against a particular Log implementation.&lt;/p&gt;

&lt;p&gt;KCVSLogManager 实现类的注释：
Implementation of {@link LogManager} against an arbitrary {@link KeyColumnValueStoreManager}.
Issues {@link Log} instances which wrap around a {@link KeyColumnValueStore}.&lt;/p&gt;

&lt;p&gt;可以看出 LogManager 主要是将 通过 KeyColumnValueStoreManager 实现 Log，而 log 则是 围绕 KeyColumnValueStore 。&lt;/p&gt;

&lt;p&gt;而我们的log包括三部分： managementLogManager txLogManager userLogManager&lt;/p&gt;

&lt;h3 id=&#34;log&#34;&gt;Log&lt;/h3&gt;

&lt;p&gt;Log 的注释：
Represents a log that allows content to be added to it in the form of messages and
to read messages and their content from the log via registered {@link MessageReader}s.&lt;/p&gt;

&lt;p&gt;KCVSLog 的注释很长。可以看出主要通过 KeyColumnValueStore 实现。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/**
 * Implementation of {@link Log} wrapped around a {@link KeyColumnValueStore}. Each message is written as a column-value pair ({@link Entry})
 * into a timeslice slot. A timeslice slot is uniquely identified by:
 * &amp;lt;ul&amp;gt;
 *     &amp;lt;li&amp;gt;The partition id: On storage backends that are key-ordered, a partition bit width can be configured which configures the number of
 *     first bits that comprise the partition id. On unordered storage backends, this is always 0&amp;lt;/li&amp;gt;
 *     &amp;lt;li&amp;gt;A bucket id: The number of parallel buckets that should be maintained is configured by
 *     {@link org.janusgraph.graphdb.configuration.GraphDatabaseConfiguration#LOG_NUM_BUCKETS}. Messages are written to the buckets
 *     in round-robin fashion and each bucket is identified by a bucket id.
 *     Having multiple buckets per timeslice allows for load balancing across multiple keys in the storage backend.&amp;lt;/li&amp;gt;
 *     &amp;lt;li&amp;gt;The start time of the timeslice: Each time slice is {@link #TIMESLICE_INTERVAL} microseconds long. And all messages that are added between
 *     start-time and start-time+{@link #TIMESLICE_INTERVAL} end up in the same timeslice. For high throughput logs that might be more messages
 *     than the underlying storage backend can handle per key. In that case, ensure that (2^(partition-bit-width) x (num-buckets) is large enough
 *     to distribute the load.&amp;lt;/li&amp;gt;
 * &amp;lt;/ul&amp;gt;
 *
 * Each message is uniquely identified by its timestamp, sender id (which uniquely identifies a particular instance of {@link KCVSLogManager}), and the
 * message id (which is auto-incrementing). These three data points comprise the column of a log message. The actual content of the message
 * is written into the value.
 * &amp;lt;/p&amp;gt;
 * When {@link MessageReader} are registered, one reader thread per partition id and bucket is created which periodically (as configured) checks for
 * new messages in the storage backend and invokes the reader. &amp;lt;/br&amp;gt;
 * Read-markers are maintained (for each partition-id &amp;amp; bucket id combination) under a dedicated key in the same {@link KeyColumnValueStoreManager} as the
 * log messages. The read markers are updated to the current position before each new iteration of reading messages from the log. If the system fails
 * while reading a batch of messages, a subsequently restarted log reader may therefore read messages twice. Hence, {@link MessageReader} implementations
 * should exhibit correct behavior for the (rare) circumstance that messages are read twice.
 *
 * Note: All time values in this class are in microseconds. Hence, there are many cases where milliseconds are converted to microseconds.
 *
 * @author Matthias Broecheler (me@matthiasb.com)
 */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;英语不好就为难了。
每个消息都由它的时间戳、发件人ID，以及消息ID（它是自动递增的）唯一标识。这三个数据组成包括日志消息的列名。消息的实际内容被写入值中。&lt;/p&gt;

&lt;h3 id=&#34;indexprovider&#34;&gt;IndexProvider&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;IndexProvider (org.janusgraph.diskstorage.indexing)
    LuceneIndex (org.janusgraph.diskstorage.lucene)
    TestMockIndexProvider (org.janusgraph.graphdb)
    SolrIndex (org.janusgraph.diskstorage.solr)
    ElasticSearchIndex (org.janusgraph.diskstorage.es)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的 IndexTransaction 包含了 对 IndexProvider的操作。&lt;/p&gt;

&lt;h3 id=&#34;vertexidassigner-standardidpool-idblock&#34;&gt;VertexIDAssigner StandardIDPool IDBlock&lt;/h3&gt;

&lt;p&gt;负责分配 id ，分配原则我们通过运行 VertexIDAssignerTest 查看。&lt;/p&gt;

&lt;h3 id=&#34;element&#34;&gt;Element&lt;/h3&gt;

&lt;p&gt;我们在操作的过程中有很多的 Vertex Property Edge 等，实际上都继承自一个 Element，继承体系确实有点吓人，这里就不展示了，几个 schema 都这么多东西，我们先分类。&lt;/p&gt;

&lt;p&gt;首先我们思考一下，为什么会有这么多。其实 gremin 语法本身定义了一堆schema ，而 janus 也有自己的schema ，两个要进行适配器模式，所以还有一组适配器的schema。所以会比较多？&lt;/p&gt;

&lt;p&gt;我们先看一下 gremin 的接口 ,主要有三个，&lt;code&gt;org.apache.tinkerpop.gremlin.structure&lt;/code&gt;下面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;VertexProperty
Vertex
Edge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;分别代表了属性，顶点，边，然后 gremin 本身对他们进行了一些实现。然后死 janusgraph 的 &lt;code&gt;org.janusgraph.core&lt;/code&gt; 包下面，有很多一些接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraphElement
    JanusGraphVertex
        InternalVertex (org.janusgraph.graphdb.internal)
        RelationType (org.janusgraph.core)
        VertexLabel (org.janusgraph.core)
	JanusGraphRelation
		JanusGraphEdge (org.janusgraph.core)
		    AbstractEdge (org.janusgraph.graphdb.relations)
		        CacheEdge (org.janusgraph.graphdb.relations)
		        StandardEdge (org.janusgraph.graphdb.relations)
		JanusGraphVertexProperty (org.janusgraph.core)
		    FulgoraVertexProperty (org.janusgraph.graphdb.olap.computer)
		    AbstractVertexProperty (org.janusgraph.graphdb.relations)
		        StandardVertexProperty (org.janusgraph.graphdb.relations)
		        CacheVertexProperty (org.janusgraph.graphdb.relations)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里展示的并不完整。整个 janus 的schema很复杂。只是大概从注释看出，
在 core 包中，JanusGraphVertex 是顶点，JanusGraphRelation 代表顶点关系，分为属性和边两种 ：JanusGraphVertexProperty 和 JanusGraphEdge。
在 internal 包中，对 core 包的类添加些 janus 特有的方法。&lt;/p&gt;

&lt;p&gt;另外在 schema 包中还有 RelationType 和 VertexLabel ，两个都是继承自 JanusGraphVertex ，意思是说 VertexLabel VertexProperty EdgeLabel 都是顶点？？？。
这样就好像明白一点，janus 中的 PropertyKey VertexLabel EdgeLabel 都是以顶点的形式保存起来的。&lt;/p&gt;

&lt;p&gt;所以我们看 Edge 类型继承体系比较简单，就是 CacheEdge (org.janusgraph.graphdb.relations) StandardEdge (org.janusgraph.graphdb.relations) 继承自
AbstractEdge ，然后继承 JanusGraphEdge，Edge。
而 Vertex 继承体系很复杂，除了类似 Edge 的继承体系以外，CacheVertex 还多了 JanusGraphSchemaVertex 这个子类，这个子类还有 RelationTypeVertex 和 VertexLabelVertex 两个子类，
实际上很明显，CacheVertex 的子类 JanusGraphSchemaVertex 代表的就是 graph 的 schema ，也是作为 Vertex 保存的。&lt;/p&gt;

&lt;p&gt;这个给别人讲一句话就懂了，但是自己分析可能要好几个小时才能明白。这也是学习和自己研究的不同。&lt;/p&gt;

&lt;h3 id=&#34;index&#34;&gt;Index&lt;/h3&gt;

&lt;p&gt;索引肯定是数据库的重点，我们到目前没有分析过和所以有关的内容。IndexTransaction 是我们遇到的可能和索引相关的内容了，就从 他开始。
IndexTransaction 中有个 BaseTransaction 的对象用来实现事务，通过 IndexProvider 来产生。我们以 ElasticSearchIndex 为例，可以看看他的方法。&lt;/p&gt;

&lt;p&gt;例如 register 方法会创建索引，还有 restore 等操作事务的方法。在 ManagementSystem 的 updateIndex 方法中，定义了各种操作 index 的方法。&lt;/p&gt;

&lt;p&gt;Index 类继承了 JanusGraphSchemaElement，主要有两类实现类 JanusGraphIndex 和 RelationTypeIndex 。&lt;/p&gt;

&lt;p&gt;JanusGraphIndex 的实现类是 JanusGraphIndexWrapper 。可以通过 JanusGraphManagement#buildIndex(String, Class) 新建 。&lt;/p&gt;

&lt;p&gt;RelationTypeIndex 的实现类是 RelationTypeIndexWrapper，可以通过
JanusGraphManagement#buildEdgeIndex(org.janusgraph.core.EdgeLabel, String, org.apache.tinkerpop.gremlin.structure.Direction, org.apache.tinkerpop.gremlin.process.traversal.Order, org.janusgraph.core.PropertyKey&amp;hellip;)
和 JanusGraphManagement#buildPropertyIndex(org.janusgraph.core.PropertyKey, String, org.apache.tinkerpop.gremlin.process.traversal.Order, org.janusgraph.core.PropertyKey&amp;hellip;)
两个方法建 RelationTypeIndex。&lt;/p&gt;

&lt;p&gt;IndexType 定义所有的 JanusGraphIndex，实现包括 CompositeIndexType 和 MixedIndexType。&lt;/p&gt;

&lt;p&gt;IndexType IndexProvider 和 Index 的不同在于，Index 和他的实现类 JanusGraphIndex RelationTypeIndexWrapper 都是继承自 JanusGraphSchemaElement ，和 Vertex 一样，代表的是 janus 中的一个顶点。
IndexType 代表了所以类型 ，IndexProvider 则代表的是和索引相关的操作方法 例如 ElasticSearchIndex SolrIndex LuceneIndex。&lt;/p&gt;

&lt;h3 id=&#34;standardscanner&#34;&gt;StandardScanner&lt;/h3&gt;

&lt;p&gt;在 Backend 构造方法最后有一句 new StandardScanner。我们看看这个是干啥用的，主要调用地方是  buildStoreIndexScanJob 这个方法，我们发现这个新建了一个 Job。
buildEdgeScanJob 主要就是在 ManagementSystem 的 updateIndex 方法使用，根据方法名可以看出，这是在遍历数据库的job。&lt;/p&gt;

&lt;p&gt;StandardScanner 的重点很明显就是它的内部类 Builder。Builder 内部有一个 ScanJob 的变量，实际上 Builder 就是有个 execute 方法，能够执行 ScanJob ，例如 IndexUpdateJob 和 IndexRepairJob。&lt;/p&gt;

&lt;p&gt;这个越看越复杂，还是后续分析吧。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph线上schema过程Debug</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-schema/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-schema/</guid>
      
        <description>

&lt;h1 id=&#34;初步调试&#34;&gt;初步调试&lt;/h1&gt;

&lt;h2 id=&#34;回顾&#34;&gt;回顾&lt;/h2&gt;

&lt;p&gt;首先我们通过 debug 官方的 GraphOfGod 大概进行一个简单的调试，然后我们仔细查看 janusgraph 调用栈，分析了关键类。
这次我们主要看看schema 的建立过程，我们上次分析已经知道，其实 schema也是以Vertex的方式存储在内存和数据库中的。
通过 CacheVertex 的子类 JanusGraphSchemaVertex 实现。JanusGraphSchemaVertex 有两个个子类，&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
AbstractElement (org.janusgraph.graphdb.internal)
	AbstractVertex (org.janusgraph.graphdb.vertices)
		StandardVertex (org.janusgraph.graphdb.vertices)
			CacheVertex (org.janusgraph.graphdb.vertices)
				JanusGraphSchemaVertex (org.janusgraph.graphdb.types.vertices)
					RelationTypeVertex (org.janusgraph.graphdb.types.vertices)
					    PropertyKeyVertex (org.janusgraph.graphdb.types.vertices)
					    EdgeLabelVertex (org.janusgraph.graphdb.types.vertices)
					VertexLabelVertex (org.janusgraph.graphdb.types)
````

中间省略了一些接口。

所以每次 new 一个 EdgeLabelVertex、VertexLabelVertex、PropertyKeyVertex 的时候，调用栈会非常深。

我们大概查看一下这些类的功能。

### AbstractElement

只有一个属性：private long id; 这个id是唯一的。小于0 的是临时id，事务提交时候会分配大于0的id，等于0的是虚拟的并不存在的，大雨0的是物理persist的。

### InternalVertex

图上没有展示 InternalVertex ，这是一个接口，继承自 JanusGraphVertex 和 InternalElement。凡是带 Internal 的都是比原来的多一个 janus 专属方法的类。
所以 InternalVertex 也是比 JanusGraphVertex 多一些 janus 专属的方法 例如： removeRelation addRelation tx()。
JanusGraphVertex 中则是 janus 和 gremin 都会有的方法 ， 例如 addEdge property label。
InternalVertex 有 query() 等方法，

### AbstractVertex

AbstractVertex 继承自 AbstractElement 和 InternalVertex，
AbstractVertex 比 AbstractElement 的 id 基础上多了一个 StandardJanusGraphTx tx 的属性。也就是多了一个事务空值对象。

### StandardVertex

StandardVertex 继承自 AbstractVertex，多了一个 lifecycle 属性和 volatile AddedRelationsContainer addedRelations 属性。应该是通过缓存空值。

### CacheVertex
CacheVertex 继承自 StandardVertex 。多了一个 queryCache 属性。

### JanusGraphSchemaVertex 

JanusGraphSchemaVertex 就是保存 Schema 的 Vertex ，分为两类 RelationTypeVertex 和 VertexLabelVertex。其中 RelationTypeVertex 分为 PropertyKeyVertex 和 EdgeLabelVertex。

## 预览

schema 操作是通过 ManagementSystem &amp;lt;: JanusGraphManagement 完成的。ManagementSystem 内容很复杂，上次已经大概看了他的方法和属性，这次我们着重看一下方法的实现，首先还是再次浏览一下方法。

### 属性

```java
private static final String CURRENT_INSTANCE_SUFFIX = &amp;quot;(current)&amp;quot;;

private final StandardJanusGraph graph;
private final Log sysLog;
private final ManagementLogger mgmtLogger;

private final KCVSConfiguration baseConfig;
private final TransactionalConfiguration transactionalConfig;
private final ModifiableConfiguration modifyConfig;
private final UserModifiableConfiguration userConfig;
private final SchemaCache schemaCache;

private final StandardJanusGraphTx transaction;

private final Set&amp;lt;JanusGraphSchemaVertex&amp;gt; updatedTypes;
private final List&amp;lt;Callable&amp;lt;Boolean&amp;gt;&amp;gt; updatedTypeTriggers;

private final Instant txStartTime;
private boolean graphShutdownRequired;
private boolean isOpen;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;构造方法&#34;&gt;构造方法&lt;/h3&gt;

&lt;p&gt;基本都是直接赋值。StandardJanusGraph 的 openManagement 方法返回一个 ManagementSystem 。&lt;/p&gt;

&lt;h3 id=&#34;instances-操作&#34;&gt;Instances 操作&lt;/h3&gt;

&lt;p&gt;getOpenInstancesInternal
getOpenInstances
forceCloseInstance&lt;/p&gt;

&lt;p&gt;判断正在运行的 instance 。&lt;/p&gt;

&lt;h3 id=&#34;commit-和-rollback&#34;&gt;commit 和 rollback&lt;/h3&gt;

&lt;p&gt;commit 方法有四步。
1. 判断 transactionalConfig 是否变化，如果变化，将变化写出。
2. transactionalConfig.commit();
3. transaction.commit();
4. 判断 updatedTypes 是否有更新，进行 expire 操作。&lt;/p&gt;

&lt;p&gt;rollback 方法，则很简单。直接调用两个 transaction 的 callback ，然后 close。&lt;/p&gt;

&lt;h3 id=&#34;getschemaelement&#34;&gt;getSchemaElement&lt;/h3&gt;

&lt;p&gt;这个方法返回一个 JanusGraphSchemaElement ，但是实际上返回的是 RelationTypeIndexWrapper 或者 JanusGraphIndexWrapper ，原因未知，这两个类上一节介绍过，。&lt;/p&gt;

&lt;h3 id=&#34;buildrelationtypeindex&#34;&gt;buildRelationTypeIndex&lt;/h3&gt;

&lt;p&gt;包括 buildPropertyIndex 和 buildEdgeIndex。
步骤都是先 生成对应的 RelationTypeMaker，然后 make，然后调用 addSchemaEdge， 最后调用 updateIndex&lt;/p&gt;

&lt;h3 id=&#34;getrelationindex&#34;&gt;getRelationIndex&lt;/h3&gt;

&lt;p&gt;得到 RelationType 的 Index。
调用 QueryUtil.getVertices(transaction, BaseKey.SchemaName, JanusGraphSchemaCategory.getRelationTypeName(composedName))
然后 return new RelationTypeIndexWrapper((InternalRelationType) v);&lt;/p&gt;

&lt;h3 id=&#34;getrelationindexes&#34;&gt;getRelationIndexes&lt;/h3&gt;

&lt;p&gt;得到所有的  Indexs。&lt;/p&gt;

&lt;h3 id=&#34;getgraphindexdirect&#34;&gt;getGraphIndexDirect&lt;/h3&gt;

&lt;p&gt;直接调用 transaction.getSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX.getSchemaName(name));
得到 GraphIndex ，GraphIndex 和 RelationTypeIndex 不一样，一个是基于关系的，前者是基于属性的。&lt;/p&gt;

&lt;h3 id=&#34;getgraphindexes&#34;&gt;getGraphIndexes&lt;/h3&gt;

&lt;p&gt;返回所有的 GraphIndex&lt;/p&gt;

&lt;h3 id=&#34;createmixedindex&#34;&gt;createMixedIndex&lt;/h3&gt;

&lt;p&gt;调用 JanusGraphSchemaVertex indexVertex = transaction.makeSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX, indexName, def); 得到 vertex
调用 addSchemaEdge(indexVertex, (JanusGraphSchemaVertex) constraint, TypeDefinitionCategory.INDEX_SCHEMA_CONSTRAINT, null); 添加关系
然后调用 updateSchemaVertex(indexVertex);
最终 new JanusGraphIndexWrapper(indexVertex.asIndexType());&lt;/p&gt;

&lt;p&gt;可以看出，这个方法其实只是添加了一个顶点，然后和另一个 constraint 顶点简历了一条关系。&lt;/p&gt;

&lt;h3 id=&#34;addindexkey&#34;&gt;addIndexKey&lt;/h3&gt;

&lt;p&gt;给已有的 index 添加一个key，这个应该很复杂，我们先跳过。&lt;/p&gt;

&lt;h3 id=&#34;createcompositeindex&#34;&gt;createCompositeIndex&lt;/h3&gt;

&lt;p&gt;创建 CompositeIndex ，GrpahIndex 分为 CompositeIndex 和 mixedIndex&lt;/p&gt;

&lt;p&gt;创建过程也是 addSchemaEdge ， updateSchemaVertex，updateIndex&lt;/p&gt;

&lt;h3 id=&#34;innerclass&#34;&gt;InnerClass&lt;/h3&gt;

&lt;p&gt;很多内部类：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IndexBuilder   -- 构建 Index
EmptyIndexJobFuture -- 提交的job
UpdateStatusTrigger -- 更新status的触发器
IndexJobStatus -- job 的 status
IndexIdentifier  --标识
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;addschemaedge&#34;&gt;addSchemaEdge&lt;/h3&gt;

&lt;p&gt;上面好几个方法都会调用 addSchemaEdge updateSchemaVertex updateIndex ，我们看看这三个方法。&lt;/p&gt;

&lt;p&gt;addSchemaEdge 是私有方法，应该是在内部会调用的。根据名字可以得出这个方法是添加边，而且添加的是 schema 的边，
我们之前已经知道实际上 schema 都是保存为 vertex，而现在就是给这些 Vertex 添加 Edge，这个边的 EdgeLabel 是 BaseLabel.SchemaDefinitionEdge。
例如 某个 PropertyKey 添加一个 Index ，实际上会有两个 SchemaVertex，然后给他们建立一个关系。
我们可以通过查看方法调用时机，基本上是修改 index 或者 schemaVertex ，一般与 updateSchemaVertex 或者 updateIndex 配合执行。&lt;/p&gt;

&lt;p&gt;方法大概步骤就是调用 transaction.addEdge(out, in, BaseLabel.SchemaDefinitionEdge) 得到 Edge，
然后调用 edge.property(BaseKey.SchemaDefinitionDesc.name(), desc);最后返回 edge。&lt;/p&gt;

&lt;h3 id=&#34;updateschemavertex&#34;&gt;updateSchemaVertex&lt;/h3&gt;

&lt;p&gt;就一句话 transaction.updateSchemaVertex(schemaVertex);&lt;/p&gt;

&lt;h3 id=&#34;updateindex&#34;&gt;updateIndex&lt;/h3&gt;

&lt;p&gt;IndexJobFuture updateIndex(Index index, SchemaAction updateAction)&lt;/p&gt;

&lt;p&gt;SchemaAction 是一个枚举，包括 REGISTER_INDEX REINDEX ENABLE_INDEX DISABLE_INDEX REMOVE_INDEX 。
IndexJobFuture 代表的是提交了的 job，等待返回结果。&lt;/p&gt;

&lt;p&gt;方法步骤：&lt;/p&gt;

&lt;p&gt;JanusGraphSchemaVertex schemaVertex = getSchemaVertex(index);&lt;/p&gt;

&lt;p&gt;更新 dependentTypes ，实际上就是为了更新 updatedTypes。&lt;/p&gt;

&lt;p&gt;根据不同的请求，调用 setStatus setUpdateTrigger setJob 。这个过程很复杂，后面再讲解。&lt;/p&gt;

&lt;h2 id=&#34;编码调试&#34;&gt;编码调试&lt;/h2&gt;

&lt;h3 id=&#34;managementsystem-构造方法&#34;&gt;ManagementSystem 构造方法&lt;/h3&gt;

&lt;p&gt;调试整个过程总是很麻烦的，我们只能专注某些部分，首先我们主要看一下 ManagementSystem 的构造过程，和使用细节。&lt;/p&gt;

&lt;p&gt;打断点进入构造方法,看这一句代码：&lt;code&gt;this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();&lt;/code&gt; 一步一步进入调用栈&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();
    return graph.newTransaction(immutable);
        tx.setBackendTransaction(openBackendTransaction(tx));
            return backend.beginTransaction(tx.getConfiguration(), retriever);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 Backend 的 beginTransaction 方法停下来，首先看看 &lt;code&gt;StoreTransaction tx = storeManagerLocking.beginTransaction(configuration)&lt;/code&gt; 的调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 这个 ExpectedValueCheckingStoreManager 继承自 KCVSManagerProxy ，它内部有个 KeyColumnValueStoreManager manager 。显然是代理模式，当然也可以认为是装饰模式。
StoreTransaction tx = storeManagerLocking.beginTransaction(configuration);
    StoreTransaction inconsistentTx = manager.beginTransaction(configuration);
        return new CassandraTransaction(config);
    StoreTransaction strongConsistentTx = manager.beginTransaction(consistentTxCfg);
        return new CassandraTransaction(config);
    ExpectedValueCheckingTransaction wrappedTx = new ExpectedValueCheckingTransaction(inconsistentTx, strongConsistentTx, maxReadTime);
    return wrappedTx;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出 tx 的大概构造，里面有两个 CassandraTransaction 一个是强一致的，一个是非强一致的。&lt;/p&gt;

&lt;p&gt;然后是 &lt;code&gt;CacheTransaction cacheTx = new CacheTransaction(tx, storeManagerLocking, bufferSize, maxWriteTime, configuration.hasEnabledBatchLoading());&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// CacheTransaction 继承自 StoreTransaction 和 LoggableTransaction ，内部有一个 StoreTransaction 对象，显然也是代理模式或者装饰模式。
CacheTransaction cacheTx = new CacheTransaction(tx, storeManagerLocking, bufferSize, maxWriteTime, configuration.hasEnabledBatchLoading());
    就是一堆赋值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CacheTransaction 内部有一个 StoreTransaction 也就是 上面的 tx， 然后还有一个 StoreManager storeManagerLocking。&lt;/p&gt;

&lt;p&gt;然后是 &lt;code&gt;indexTx.put(entry.getKey(), new IndexTransaction(entry.getValue() indexKeyRetriever.get(entry.getKey()), configuration, maxWriteTime));&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;indexTx.put(entry.getKey(), new IndexTransaction(entry.getValue(), indexKeyRetriever.get(entry.getKey()), configuration, maxWriteTime));
    new KeyInformation.IndexRetriever() {...省略代码}
    new IndexTransaction()
        index.beginTransaction(config);
            return new DefaultTransaction(config);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;backend.beginTransaction(tx.getConfiguration(), retriever); 方法中 有很多 Transaction 对象，包括了 cacheTx indexTx 等。BackendTransaction 的构造方法则比较简单，就是直接赋值。&lt;/p&gt;

&lt;p&gt;构造方法讨论到这里，我们可以猜测，ManagementSystem 无论是进行简单 schema 增删改查还是操作索引，
背后都是通过这个 BackendTransaction 完成，而 BackendTransaction 内部又有 cacheTx 和 indexTx 等对象完成。
当然还有一个 transactionalConfig 也有一些任务。&lt;/p&gt;

&lt;h3 id=&#34;managementsystem-getvertexlabels&#34;&gt;ManagementSystem getVertexLabels&lt;/h3&gt;

&lt;p&gt;getVertexLabels 方法返回 Iterable&lt;VertexLabel&gt; ，这里可能是通过 guava 进行封装，所以可能调用栈比较深。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;getVertexLabels
    QueryUtil.getVertices(transaction, BaseKey.SchemaCategory, JanusGraphSchemaCategory.VERTEXLABEL)
        tx.query().has(key,Cmp.EQUAL,equalityCondition).vertices();
            1. 
            return new GraphCentricQueryBuilder(this, graph.getIndexSerializer());
            3. 
            return has(key.name(),predicate,condition);
                // 这一步实际上就加了一个 条件，就是 `~T$SchemaCategory = VERTEXLABEL`
                constraints.add(new PredicateCondition&amp;lt;String, JanusGraphElement&amp;gt;(key, predicate, condition));
            3. 
            GraphCentricQuery query = constructQuery(ElementCategory.VERTEX);
                 GraphCentricQuery query = constructQueryWithoutProfile(resultType);
                     省略一大堆复杂代码。
                     return new GraphCentricQuery(resultType, conditions, orders, query, limit);
            // 这里是基于guava实现的懒加载模式的 filter
            Iterables.filter(new QueryProcessor&amp;lt;GraphCentricQuery, JanusGraphElement, JointIndexQuery&amp;gt;(query, tx.elementProcessor), JanusGraphVertex.class);

iterator
    return new ResultSetIterator(getUnfoldedIterator(),(query.hasLimit()) ? query.getLimit() : Query.NO_LIMIT);   
        1. QueryProcessor (org.janusgraph.graphdb.query).getUnfoldedIterator:107, 
            Iterator&amp;lt;R&amp;gt; subiter = new LimitAdjustingIterator(subq);
        2. this.next = nextInternal();
            hasNext:68, LimitAdjustingIterator (org.janusgraph.graphdb.query)
                getNewIterator:209, QueryProcessor$LimitAdjustingIterator (org.janusgraph.graphdb.query)
                    execute:1150, StandardJanusGraphTx$elementProcessorImpl (org.janusgraph.graphdb.transaction)
                        new SubqueryIterator
                            indexCache.getIfPresent(subQuery); // 这里的 schema 应该都是在启动的时候 cache 到了内存中，所以直接得到了，如果是 数据，应该要查询
                        
                    
                  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里我们就已经知道了，其实这里是构造了一个 GraphCentricQuery 封装所有的查询条件逻辑，然后通过 QueryProcessor 进行处理这个 query，调用 next 的时候会进行查询。&lt;/p&gt;

&lt;p&gt;上面我们已经得到了 ResultSetIterator ，接下来我们需要遍历这个 iterator。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;iterator.hasNext
    1. next = current
    2. tryToComputeNext()
    ...
        1. hasNext:49, ResultSetIterator (org.janusgraph.graphdb.query)
            return next != null;
            
        2. ResultSetIterator (org.janusgraph.graphdb.query).next:65, 
            1. LimitAdjustingIterator (org.janusgraph.graphdb.query).hasNext:68, 
                SubqueryIterator (org.janusgraph.graphdb.util).hasNext:79, 
            2. LimitAdjustingIterator (org.janusgraph.graphdb.query).next:94, 
                SubqueryIterator (org.janusgraph.graphdb.util).next:90, 

iterator.next()  
   return result.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的代码比较杂乱，首先是 AbstractIterator 和 Iterators 类，然后是 ResultSetIterator LimitAdjustingIterator SubqueryIterator ，然后还有一个 Stream 类。&lt;/p&gt;

&lt;p&gt;AbstractIterator 和 Iterators  是 guava 提供的工具类，AbstractIterator 通过封装一个 Iterator，达到缓存和懒加载的效果。
例如 JDBC 的 ResultSet 如果做成一个 Iterator ，每次调用 next 的时候都会移动一次游标，这样就不能多次判断 hasNext。所以可以用 guava 进行封装。&lt;/p&gt;

&lt;p&gt;ResultSetIterator 和 guava 达到的效果类似，通过内部装饰一个 ResultSetIterator 。&lt;/p&gt;

&lt;p&gt;LimitAdjustingIterator 通过一个 getNewIterator 得到一个 懒加载 Iterator，其实也是和 guava 类似，只不过你可以认为它只能查看 limit 个元素，当遍历完这 limit 个元素，会重新从 0 开始 next limit次，然后再开始。
说的简单一点，如果一个数组有一千个元素，你的迭代器 limit 是 500，那么你只能得到 500 个元素，想要得到500 - 1000 的元素，要重新查询。类似 mysql 的分页&lt;/p&gt;

&lt;p&gt;SubqueryIterator 是代表依次查询的结果。先从 indexCache 查，没有就调用查询，查询结果是一个 List ，得到对应的 iterator 后放在 elementIterator 中。&lt;/p&gt;

&lt;p&gt;到这里我们就大概明白了整个查询过程，&lt;/p&gt;

&lt;h3 id=&#34;containsvertexlabel&#34;&gt;containsVertexLabel&lt;/h3&gt;

&lt;p&gt;containsVertexLabel 方法判断是否存在，直观的方法是直接调用上面的 getVertexLabels 然后判断一下，但是实际上不是这样。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mgmt.containsVertexLabel(vType.toString())
    transaction.containsVertexLabel(name);
        return getSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name))!=null;
        1. JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name) // 这一步就是在 name 前面加上标识，例如 vl rt
        2. JanusGraphSchemaVertex getSchemaVertex(String schemaName)
            graph.getSchemaCache().getSchemaId(schemaName)
            1. getSchemaCache 
            2. StandardSchemaCache.getSchemaId
                id = retriever.retrieveSchemaByName(schemaName); // 这个 retriever 是 StandardJanusGraph 中的变量 typeCacheRetrieval ，
                    typeCacheRetrieval.retrieveSchemaByName
                        StandardJanusGraph.this.newTransaction
                            QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName)
                            return v!=null?v.longId():null;
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;containsVertexLabel 会启动一个 transation 通过 name 查询这个 schema 的 typeName 对应的 vertexId。和 getVertexLabels 不太一样。&lt;/p&gt;

&lt;h3 id=&#34;makevertexlabel&#34;&gt;makeVertexLabel&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt.makeVertexLabel(vType.toString()).make();
    1. makeVertexLabel
        transaction.makeVertexLabel(name);
            StandardVertexLabelMaker maker = new StandardVertexLabelMaker(this);
            maker.name(name);
    2. make
        TypeDefinitionMap def = new TypeDefinitionMap();
        tx.makeSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL,name,def);
            1. schemaVertex = new VertexLabelVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.GenericSchemaType,temporaryIds.nextID()), ElementLifeCycle.New);
            2. graph.assignID(schemaVertex, BaseVertexLabel.DEFAULT_VERTEXLABEL);
                ....
                element.setId(elementId);
            3. addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));
                1. StandardVertexProperty prop = new StandardVertexProperty(IDManager.getTemporaryRelationID(temporaryIds.nextID()), key, (InternalVertex) vertex, normalizedValue, ElementLifeCycle.New);
                2. connectRelation(prop);
                    addedRelations.add(r); 
            4. vertexCache.add(schemaVertex, schemaVertex.longId());
            
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;makeVertexLabel 最关键的一步就是 addedRelations.add&amp;reg;, 添加关系，这样就能在 commit 的时候写到数据库了。&lt;/p&gt;

&lt;h3 id=&#34;commit&#34;&gt;commit()&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;commit
    transactionalConfig.commit();
    transaction.commit();
         1. graph.commit(addedRelations.getAll(), deletedRelations.values(), this); // 这里的两个集合分别是改变的 schema 
             
             
             1. final BackendTransaction schemaMutator = openBackendTransaction(tx); // 打开一个 transaction
             2. commitSummary = prepareCommit(addedRelations,deletedRelations, SCHEMA_FILTER, schemaMutator, tx, acquireLocks);
             3. schemaMutator.commit();
             
             4. commitSummary = prepareCommit(addedRelations,deletedRelations, hasTxIsolation? NO_FILTER : NO_SCHEMA_FILTER, mutator, tx, acquireLocks);
             5. mutator.commit();
                 1. storeTx.commit();
                     1. flushInternal();
                     2. tx.commit();
                 2. itx.commit();
                     1. flushInternal();
                     2. indexTx.commit();
          2. releaseTransaction();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实我这里的注释和官方的不太一样，官方将 graph.commit 分为三部分：&lt;/p&gt;

&lt;p&gt;//1. Finalize transaction
//2. Assign JanusGraphVertex IDs
//3. Commit
//3.1 Log transaction (write-ahead log) if enabled
//3.2 Commit schema elements and their associated relations in a separate transaction if backend does not support transactional isolation
//[FAILURE] Exceptions during preparation here cause the entire transaction to fail on transactional systems
//or just the non-system part on others. Nothing has been persisted unless batch-loading&lt;/p&gt;

&lt;p&gt;经过我的分析，其实这里分两次 prepareCommit + commit ,是根据底层是否支持事务隔离，如果不支持，先 commit 和 schema 相关的变化，否则 schema 和 data 两边一起提交。&lt;/p&gt;

&lt;p&gt;当然这个 wal-log 和 prepareCommit 就大有文章。后续在分析。&lt;/p&gt;

&lt;h3 id=&#34;createcompositeindex-1&#34;&gt;createCompositeIndex&lt;/h3&gt;

&lt;p&gt;建索引，索引类型是 createCompositeIndex&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;buildCompositeIndex:650, ManagementSystem$IndexBuilder (org.janusgraph.graphdb.database.management)
    1.checkIndexName:489, ManagementSystem (org.janusgraph.graphdb.database.management)
        getGraphIndex:424, ManagementSystem (org.janusgraph.graphdb.database.management)
            getSchemaVertex:878, StandardJanusGraphTx (org.janusgraph.graphdb.transaction) 
                 // 这里 getSchemaVertex 的内容之前已经讨论过。
    updatedTypes.add((PropertyKeyVertex) key);
    2. transaction.makeSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX, indexName, def);
        // 这个之前已经说过，我们在简单过一遍
        1. graph.assignID(schemaVertex, BaseVertexLabel.DEFAULT_VERTEXLABEL);
        2. addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));
    3. addSchemaEdge(indexVertex, keys[i], TypeDefinitionCategory.INDEX_FIELD, paras);
    4. updateIndex(index, SchemaAction.REGISTER_INDEX);
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;updatedTypes.add((PropertyKeyVertex) key);
schema 分析主要就是这些，我们还有一些地方没细看，接下来我们把几个复杂的过程分析一下。主要包括查询数据库和 update 索引&lt;/p&gt;

&lt;h1 id=&#34;局部调试&#34;&gt;局部调试&lt;/h1&gt;

&lt;p&gt;上面的调试过程让我们大概明白了每一步的过程，大概都在做什么，接下来我们要深入一些局部，看一下每一步具体都在做什么。&lt;/p&gt;

&lt;h2 id=&#34;1-makepropertykey&#34;&gt;1. makePropertyKey&lt;/h2&gt;

&lt;p&gt;我们从简单到复杂，首先看 makePropertyKey，看之前我们大概了解几个相关类。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;JanusGraphSchemaCategory
这个是 JanusGraph 的所有 schema 的种类，有 EDGELABEL, PROPERTYKEY, VERTEXLABEL, GRAPHINDEX, TYPE_MODIFIER 五种。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;PropertyKeyVertex
我们所有的 schema 都是以顶点的形式存在数据库中，所以我们 makePropertyKey 也会创建一个顶点，这个顶点的类型是 PropertyKeyVertex 。
他继承自 RelationTypeVertex，PropertyKey， JanusGraphSchemaVertex，InternalRelationType，RelationType，InternalVertex 等类。
他有 getBaseType getRelationIndexes getKeyIndexes 等方法，&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;BaseKey
BaseKey 和 PropertyKeyVertex 类似，PropertyKeyVertex 是我们定义的 schema，而 BaseKey 则是最基本的key，是 schema 的 ProperyKey, 他们是直接放在内存中的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;JanusGraphVertexProperty&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;JanusGraphVertexProperty 代表一个顶点的 Property，和 JanusGraphEdge 一样继承自 JanusGraphRelation。
当我们给一个 JanusGraph 添加 Property，实际上会创建一条关系，同时返回一个 JanusGraphVertexProperty。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;InternalRelation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;InternalRelation 代表一个关系，实际上就是一条边，在 janus 中，分为 VertexProperty 和 Edge 两种，无论是 Edge 还是 VertexProperty ，都是连接两个顶点。
其中 VertexProperty 是连接一个用户创建的顶点和一个 PropertyKey 顶点，而 Edge 是连接两个 PropertyKey 顶点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ElementCategory&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;元素种类，有 VERTEX, EDGE, PROPERTY 三种，可以用来判断 index 的种类。&lt;/p&gt;

&lt;h3 id=&#34;进入断点&#34;&gt;进入断点&lt;/h3&gt;

&lt;p&gt;我们进入断点到： makeSchemaVertex:830, StandardJanusGraphTx (org.janusgraph.graphdb.transaction)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;schemaVertex = new PropertyKeyVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.UserPropertyKey, temporaryIds.nextID()), ElementLifeCycle.New);&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;新建一个代表 PropertyKey 的 Vertex。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
1. vertex = ((InternalVertex) vertex).it();

// 新建一个 VertexProperty 的对象
2. StandardVertexProperty prop = new StandardVertexProperty(IDManager.getTemporaryRelationID(temporaryIds.nextID()), key, (InternalVertex) vertex, normalizedValue, ElementLifeCycle.New);

3.connectRelation(InternalRelation r) 
    
    success = r.getVertex(i).addRelation(r);
        r.getVertex(i) 返回的是前面创建的 PropertyKeyVertex
        addRelation 是在这个 Vertex 内部调用 addedRelations.add(r)
    
    addedRelations.add(r); // 这个 addedRelations 是 StandardJanusGraph 的全局变量

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看出，addProperty 实际上就是给 顶点和另一个 PropertyKey 建立一条边。&lt;/p&gt;

&lt;p&gt;到这里似乎就完成了，整个过程实际上就是修改了 addedRelations 。&lt;/p&gt;

&lt;h2 id=&#34;makevertexlabel-makeedgelabel&#34;&gt;makeVertexLabel makeEdgeLabel&lt;/h2&gt;

&lt;p&gt;这两个与 PropertyKey 类似，首先 new JanusGraphSchemaVertex ，分别是 PropertyKeyVertex EdgeLabelVertex VertexLabelVertex 。 然后调用 addProperty 。
addProperty 会 new 一个 StandardVertexProperty ，然后调用 connectRelation(prop) 。将 prop 中的 Relation 都建立连接，添加到 addedRelations。&lt;/p&gt;

&lt;h2 id=&#34;commit-preparecommit&#34;&gt;commit prepareCommit&lt;/h2&gt;

&lt;p&gt;//1) Collect deleted edges and their index updates and acquire edge locks
略
//2) Collect added edges and their index updates and acquire edge locks&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
// 前面所有的关系 关系类型是 InternalRelation ，实现有 StandardVertexProperty 和 StandardEdge 两种
for (InternalRelation add : Iterables.filter(addedRelations,filter)) {
    
    // 每个 Relation 联系多个顶点，如果是 StandardVertexProperty 顶点就是 JanusGraphVertex，如果是 StandardEdge，顶点就是连接的两个 JanusGraphVertex
    for (int pos = 0; pos &amp;lt; add.getLen(); pos++) {
    	// 得到对应的顶点，可能有一个或者两个
    	InternalVertex vertex = add.getVertex(pos);
    	if (pos == 0 || !add.isLoop()) {
    	    
    	    // mutatedProperties: key 是关系连接的 vertex，value 是关系
    	    if (add.isProperty()) mutatedProperties.put(vertex,add);
    	    // mutations: key 是 vertex id, 关系是 add
    	    mutations.put(vertex.longId(), add);
    	}
    	if (!vertex.isNew() &amp;amp;&amp;amp; acquireLock(add,pos,acquireLocks)) {
    	    Entry entry = edgeSerializer.writeRelation(add, pos, tx);
    	    mutator.acquireEdgeLock(idManager.getKey(vertex.longId()), entry.getColumn());
        }
    }
    // indexUpdates : IndexSerializer.IndexUpdate
    indexUpdates.addAll(indexSerializer.getIndexUpdates(add));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//3) Collect all index update for vertices&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (InternalVertex v : mutatedProperties.keySet()) {
    indexUpdates.addAll(indexSerializer.getIndexUpdates(v,mutatedProperties.get(v)));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//4) Acquire index locks (deletions first)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (IndexSerializer.IndexUpdate update : indexUpdates) {
    if (!update.isCompositeIndex() || !update.isDeletion()) continue;
    CompositeIndexType iIndex = (CompositeIndexType) update.getIndex();
    if (acquireLock(iIndex,acquireLocks)) {
        mutator.acquireIndexLock((StaticBuffer)update.getKey(), (Entry)update.getEntry());
    }
}
for (IndexSerializer.IndexUpdate update : indexUpdates) {
    if (!update.isCompositeIndex() || !update.isAddition()) continue;
    CompositeIndexType iIndex = (CompositeIndexType) update.getIndex();
    if (acquireLock(iIndex,acquireLocks)) {
        mutator.acquireIndexLock((StaticBuffer)update.getKey(), ((Entry)update.getEntry()).getColumn());
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//5) Add relation mutations&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 遍历 mutations，
for (Long vertexid : mutations.keySet()) {
    Preconditions.checkArgument(vertexid &amp;gt; 0, &amp;quot;Vertex has no id: %s&amp;quot;, vertexid);
    List&amp;lt;InternalRelation&amp;gt; edges = mutations.get(vertexid);
    List&amp;lt;Entry&amp;gt; additions = new ArrayList&amp;lt;Entry&amp;gt;(edges.size());
    List&amp;lt;Entry&amp;gt; deletions = new ArrayList&amp;lt;Entry&amp;gt;(Math.max(10, edges.size() / 10));
    
    // 这个顶点所有的 edges
    for (InternalRelation edge : edges) {
        InternalRelationType baseType = (InternalRelationType) edge.getType();
        assert baseType.getBaseType()==null;
        // 这个 InternalRelationType 的所有 type ，这里有点不太懂
        for (InternalRelationType type : baseType.getRelationIndexes()) {
            if (type.getStatus()== SchemaStatus.DISABLED) continue;
            
            // Arity 应该是数据的量，代表的意义应该是 LIST SINGLE 等
            for (int pos = 0; pos &amp;lt; edge.getArity(); pos++) {
                if (!type.isUnidirected(Direction.BOTH) &amp;amp;&amp;amp; !type.isUnidirected(EdgeDirection.fromPosition(pos)))
                    continue; //Directionality is not covered
                if (edge.getVertex(pos).longId()==vertexid) {
                    // 序列化数据
                    StaticArrayEntry entry = edgeSerializer.writeRelation(edge, type, pos, tx);
                    if (edge.isRemoved()) {
                        deletions.add(entry);
                    } else {
                        Preconditions.checkArgument(edge.isNew());
                        int ttl = getTTL(edge);
                        if (ttl &amp;gt; 0) {
                            entry.setMetaData(EntryMetaData.TTL, ttl);
                        }
                        // 添加到 additions
                        additions.add(entry);
                    }
                }
            }
        }
    }

    StaticBuffer vertexKey = idManager.getKey(vertexid);
    // 写出数据
    mutator.mutateEdges(vertexKey, additions, deletions);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//6) Add index updates&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (IndexSerializer.IndexUpdate indexUpdate : indexUpdates) {
    assert indexUpdate.isAddition() || indexUpdate.isDeletion();
    if (indexUpdate.isCompositeIndex()) {
        IndexSerializer.IndexUpdate&amp;lt;StaticBuffer,Entry&amp;gt; update = indexUpdate;
        if (update.isAddition())
            // 直接调用 update 的方法
            mutator.mutateIndex(update.getKey(), Lists.newArrayList(update.getEntry()), KCVSCache.NO_DELETIONS);
        else
            mutator.mutateIndex(update.getKey(), KeyColumnValueStore.NO_ADDITIONS, Lists.newArrayList(update.getEntry()));
    } else {
        IndexSerializer.IndexUpdate&amp;lt;String,IndexEntry&amp;gt; update = indexUpdate;
        has2iMods = true;
        IndexTransaction itx = mutator.getIndexTransaction(update.getIndex().getBackingIndexName());
        String indexStore = ((MixedIndexType)update.getIndex()).getStoreName();
        if (update.isAddition())
            itx.add(indexStore, update.getKey(), update.getEntry(), update.getElement().isNew());
        else
            itx.delete(indexStore,update.getKey(),update.getEntry().field,update.getEntry().value,update.getElement().isRemoved());
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里我们可能比较迷惑的就是 IndexUpdate 是怎么获得的。&lt;/p&gt;

&lt;p&gt;获得 IndexUpdate 的思路大概是这样：以 CompositeIndex 为例，假如一个顶点，USER，有 name 和 sex 两个 PropertyKey，并且基于 name 和 sex 做了一个 CompositeIndex。
现在有一个顶点，假设 id 为 007，我设置了他的 name 为 &amp;ldquo;deng&amp;rdquo;，然后我们需要获得这个用户的 sex ，假设为 &amp;ldquo;male&amp;rdquo;，这时候我们需要在 index 插入一条记录 (deng,male) =&amp;gt; 007。&lt;/p&gt;

&lt;p&gt;所以我们可以看 getIndexUpdates 的源代码，首先是  IndexField[] fields = index.getFieldKeys() 得到这个 index 所有的 filedKey， 然后 new RecordEntry[fields.length]，得到一个
和 fields 长度一样的 RecordEntry 数组，然后从 pos=0 开始给 IndexField 数组赋值，直到 pos &amp;gt;= fields.length。这样就得到了所以和这个属性更新相关的索引更新。
已上面的例子为例，那么得到的 RecordEntry[] 就是 [deng,male]。&lt;/p&gt;

&lt;p&gt;然后我们得到了 indexUpdate additions 就是分别将他们写到数据库了。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janus源码分析5-复杂操作分析</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%906-%E5%A4%8D%E6%9D%82%E6%BA%90%E7%A0%81/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%906-%E5%A4%8D%E6%9D%82%E6%BA%90%E7%A0%81/</guid>
      
        <description>

&lt;h1 id=&#34;源码分析&#34;&gt;源码分析&lt;/h1&gt;

&lt;h2 id=&#34;查询操作&#34;&gt;查询操作&lt;/h2&gt;

&lt;p&gt;之前已经遇到过很多查询操作，比如查询 schema&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt.containsVertexLabel(vType.toString())
    transaction.containsVertexLabel(name);
        return getSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name))!=null;
        1. JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name) // 这一步就是在 name 前面加上标识，例如 vl rt
        2. JanusGraphSchemaVertex getSchemaVertex(String schemaName)
            graph.getSchemaCache().getSchemaId(schemaName)
            1. getSchemaCache 
            2. StandardSchemaCache.getSchemaId
                id = retriever.retrieveSchemaByName(schemaName); // 这个 retriever 是 StandardJanusGraph 中的变量 typeCacheRetrieval ，
                    typeCacheRetrieval.retrieveSchemaByName
                        StandardJanusGraph.this.newTransaction
                            QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName)
                            return v!=null?v.longId():null;
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
iterator()
return new ResultSetIterator(getUnfoldedIterator(),(query.hasLimit()) ? query.getLimit() : Query.NO_LIMIT);   
    1. QueryProcessor (org.janusgraph.graphdb.query).getUnfoldedIterator:107, 
        Iterator&amp;lt;R&amp;gt; subiter = new LimitAdjustingIterator(subq);
    2. this.next = nextInternal();
        hasNext:68, LimitAdjustingIterator (org.janusgraph.graphdb.query)
            getNewIterator:209, QueryProcessor$LimitAdjustingIterator (org.janusgraph.graphdb.query)
                execute:1150, StandardJanusGraphTx$elementProcessorImpl (org.janusgraph.graphdb.transaction)
                    new SubqueryIterator
                        indexCache.getIfPresent(subQuery); // 这里的 schema 应该都是在启动的时候 cache 到了内存中，所以直接得到了，如果是 数据，应该要查询
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实查询操作并不复杂，这是有很多层的嵌套，导致我们看起来很麻烦而已，前面我们已经大概介绍了： 首先是 AbstractIterator 和 Iterators 类，然后是 ResultSetIterator LimitAdjustingIterator SubqueryIterator ，然后还有一个 Stream 类。&lt;/p&gt;

&lt;h3 id=&#34;executing-vertex-centric-queries&#34;&gt;Executing vertex centric queries&lt;/h3&gt;

&lt;p&gt;返回结果是一个 vertex 的 所有 Relation 的 subset。通过 VertexCentricQueryBuilder 构建查询条件。查询会通过条件限制找原始，一共有三种限制：
- Cmp: Comparison constraints (==, !=, &amp;lt;, &amp;lt;=, &amp;gt;, &amp;gt;=, interval: &amp;ldquo;a &amp;lt;= x &amp;lt; b&amp;rdquo;)
- Geo: Geographic shape constraints (intersect, disjoint, within)
- Text: Text constraints (contains, starts with)&lt;/p&gt;

&lt;p&gt;查询的步骤：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VertexCentricQueryBuilder 构建 VertexCentricQuery，然后将 VertexCentricQuery 传给 QueryProcessor&lt;VertexCentricQuery, JanusGraphRelation&gt; edgeProcessor，
得到所有的 matching records。&lt;/li&gt;
&lt;li&gt;VertexCentricQuery 传给 EdgeSerializer，得到一个 FittedSliceQuery，通过在 edgestore 的 row 中 找到尽量小而且匹配所有满足条件的的 segment，结果返回一个带 byte buffers specifying begin and end of this segment.&lt;/li&gt;
&lt;li&gt;The calculated segment is traversed until enough matching records have been found or the end of the segment is reached. The segment may or may not &amp;ldquo;fit&amp;rdquo;, that is, it may or may not guarantee that all relations inside the segment are guaranteed to match. If this is not guaranteed, matching is checked explicitly for each visited relation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们一层一层进行查看：&lt;/p&gt;

&lt;h3 id=&#34;executing-global-graph-queries&#34;&gt;Executing global graph queries&lt;/h3&gt;

&lt;p&gt;一般步骤：
- ElementQuery 传给 QueryProcessor，得到满足条件的记录。
- ElementQuery 传给 IndexSerializer，如果只有 one equality constraint ，将使用自己的index， 否则使用 external index 。&lt;/p&gt;

&lt;h3 id=&#34;vertexcentricquerybuilder-和-graphcentricquerybuilder&#34;&gt;VertexCentricQueryBuilder 和 GraphCentricQueryBuilder&lt;/h3&gt;

&lt;p&gt;GraphCentricQueryBuilder 是用来构造一个 Query 的。它的很多方法都和 gremin 对接，最重要的方法还是 constructQuery ，用来构造 Query。
他的方法 iterables(final GraphCentricQuery query, final Class&lt;E&gt; aClass) 返回一个对应 GraphCentricQuery 结果迭代器。&lt;/p&gt;

&lt;p&gt;BasicVertexCentricQueryBuilder 是 VertexCentricQueryBuilder 的父类，StandardJanusGraphTx 的 query(JanusGraphVertex vertex) 会产生一个 VertexCentricQueryBuilder。&lt;/p&gt;

&lt;p&gt;继承自 JanusGraphVertexQuery 和 BasicVertexCentricQueryBuilder，用来构建 Query。它主要有 execute 方法。
BasicVertexCentricQueryBuilder 有 constructQuery 方法。&lt;/p&gt;

&lt;h3 id=&#34;query&#34;&gt;Query&lt;/h3&gt;

&lt;p&gt;继承体系：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
Query (org.janusgraph.graphdb.query)
	ElementQuery (org.janusgraph.graphdb.query)
	    GraphCentricQuery (org.janusgraph.graphdb.query.graph)
	    VertexCentricQuery (org.janusgraph.graphdb.query.vertex)
	BaseQuery (org.janusgraph.graphdb.query)
	    MultiKeySliceQuery (org.janusgraph.graphdb.query.graph)
	    JointIndexQuery (org.janusgraph.graphdb.query.graph)
	    RawQuery (org.janusgraph.diskstorage.indexing)
	    BaseVertexCentricQuery (org.janusgraph.graphdb.query.vertex)
	        VertexCentricQuery (org.janusgraph.graphdb.query.vertex)
	    SliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeyRangeQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeySliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	    KVQuery (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    IndexQuery (org.janusgraph.diskstorage.indexing)
	    IndexQueryBuilder (org.janusgraph.graphdb.query.graph)
	    GraphCentricQuery (org.janusgraph.graphdb.query.graph)
	BackendQuery (org.janusgraph.graphdb.query)
	    MultiKeySliceQuery (org.janusgraph.graphdb.query.graph)
	    JointIndexQuery (org.janusgraph.graphdb.query.graph)
	    SliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeyRangeQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeySliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	    IndexQuery (org.janusgraph.diskstorage.indexing)
	    Subquery in JointIndexQuery (org.janusgraph.graphdb.query.graph)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们主要能发现 BaseQuery 和 BackendQuery 两大子类，&lt;/p&gt;

&lt;p&gt;BaseQuery 比较简单，里面就一个 limit 属性，应该是指返回的条数。而 BackendQuery 接口更简单，只有一个方法 updateLimit(int newLimit)，返回一个新的 BackendQuery。至于有什么用后续才能知道。&lt;/p&gt;

&lt;p&gt;基于 BaseQuery 和 BackendQuery ，有很多子类。&lt;/p&gt;

&lt;p&gt;SliceQuery 有两个 StaticBuffer 类型的属性： sliceStart 和 sliceEnd 。前面说的返回一个带 byte buffers specifying begin and end of this segment.。&lt;/p&gt;

&lt;p&gt;KeySliceQuery 继承自 SliceQuery ，扩展 SliceQuery ，增加了 StaticBuffer 类型的 key，能够查询某个 key 的 slice。&lt;/p&gt;

&lt;p&gt;KeyRangeQuery 继承自 SliceQuery ，扩展 SliceQuery ，增加了两个 StaticBuffer 类型的 keyStart keyEnd 。为何这样就要查询 bigtable 相关资料了。&lt;/p&gt;

&lt;p&gt;MultiKeySliceQuery 继承自 BaseQuery 和 BackendQuery ，内部有一个 List&lt;KeySliceQuery&gt; queries。很明显这是多个 key 一起查。&lt;/p&gt;

&lt;p&gt;IndexQuery 官方注释 在 IndexProvider 中执行的外部 query，query 由两部分组成：一个是查询应该执行的 store 的标识符，另一个是查询的条件。
IndexProvider 的代码我们介绍过，是指外部索引，例如 ElasticSearchIndex ，主要有 register mutate restore query 等方法，很明显是提供一些查询。&lt;/p&gt;

&lt;p&gt;JointIndexQuery 的静态内部类 Subquery 继承自 BackendQuery ，内部有两个主要属性：  IndexType index; BackendQuery query;
Index 可以是 MixedIndexType 或者 CompositeIndexType，对应的 query 分别是 IndexQuery 和 MultiKeySliceQuery
JointIndexQuery 则有 List&lt;Subquery&gt; queries 属性代表很多个 Subquery。
我们可以看出其实 Subquery 代表的是可以在一种索引平台上执行的查询。而 JointIndexQuery 则是很多个这样的查询，可以在各自的平台上进行查询。&lt;/p&gt;

&lt;p&gt;GraphCentricQuery 包含了一个 Condition&lt;JanusGraphElement&gt; condition 作为条件，一个 BackendQueryHolder&lt;JointIndexQuery&gt; indexQuery 保存 Query 信息。
BaseVertexCentricQuery 包含了 Condition&lt;JanusGraphRelation&gt; condition 作为添加 ，List&lt;BackendQueryHolder&lt;SliceQuery&gt;&amp;gt; queries 保存 Query 信息
VertexCentricQuery 继承自 BaseVertexCentricQuery ，添加一个 InternalVertex vertex ，至于干啥的还不知道。
他们都是 ElementQuery。&lt;/p&gt;

&lt;p&gt;看到这里我们大概能看出 ：
GraphCentricQuery 是基于 JanusGraphElement 的，查询需要 JointIndexQuery ，
JointIndexQuery 内部则是 Subquery，Subquery 主要分为 MixedQuery 和 CompositeQuery，对应的查询分别为 IndexQuery 和 MultiKeySliceQuery，对应的索引分别为 MixedIndexType 和 CompositeIndexType
VertexCentricQuery 是基于 JanusGraphRelation 的，查询需要 SliceQuery ，SliceQuery 就是查询 key + cf 对应的所有的 keyvalue 。&lt;/p&gt;

&lt;p&gt;RawQuery 继承自 BaseQuery ，没什么特殊参数，我想应该是值一些粗糙的直接查询。
剩下的 IndexQueryBuilder 和 KVQuery 先不说了。&lt;/p&gt;

&lt;p&gt;我们可以看出这些 Query 只是一些描述性的东西，并没有任何执行调用的方法。通过类的关系我们也大概能总结一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一切都是为了查出 janus 中的元素，所以 是围绕 ElementQuery 展开，ElementQuery 有两个子类，GraphCentricQuery 和 VertexCentricQuery。
GraphCentricQuery 代表以 graph 为中心的查询，例如查询 name=aaa 的所有顶点，VertexCentricQuery 代表以 vertex-centric 的查询，例如查和某个人关系为同事的所有人。
为了完成 GraphCentricQuery 包括两类：IndexQuery 和 MultiKeySliceQuery ，IndexQuery 代表使用外部索引的查询，MultiKeySliceQuery 代表使用 bigtable 自带索引的查询。
这两种合在一起就是 Subquery ，而 JointIndexQuery 内部有多个 Subquery，GraphCentricQuery 中有一个 JointIndexQuery 对象。
为了完成 VertexCentricQuery，也就是加快基于 PropertyKey 和 EdgeLabel 的查询，需要使用 SliceQuery 进行配合。SliceQuery 有很多实现，除了本身还有 KeySliceQuery 和 KeyRangeQuery。&lt;/li&gt;
&lt;li&gt;而 RawQuery 看名字猜测是直接查询。&lt;/li&gt;
&lt;li&gt;IndexQueryBuilder 就是一个 Builder，内部有一个 IndexSerializer ，它的 execute 方法，实际上就是调用 IndexSerializer 的 executeQuery。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;queryexecutor&#34;&gt;QueryExecutor&lt;/h3&gt;

&lt;p&gt;之前我们已经见到介绍过 StandardJanusGraphTx ，实际上这个代表的就是一个事务，内部有很多操作图的方法，我们这次主要是看看他的 elementProcessorImpl 和 edgeProcessorImpl。
他的定义：QueryExecutor&lt;GraphCentricQuery, JanusGraphElement, JointIndexQuery&gt; elementProcessorImpl ，
QueryExecutor&lt;VertexCentricQuery, JanusGraphRelation, SliceQuery&gt; edgeProcessorImpl
听名字就知道大概是执行查询的？这是一个匿名内部类，继承自 QueryExecutor，主要方法是 execute。&lt;/p&gt;

&lt;h4 id=&#34;elementprocessorimpl&#34;&gt;elementProcessorImpl&lt;/h4&gt;

&lt;p&gt;我们只看 execute 方法，如果 indexQuery.isEmpty() 会告诉你 &amp;ldquo;Query requires iterating over all vertices [{}]. For better performance, use indexes&amp;rdquo;。
最后返回了一个
new SubqueryIterator(indexQuery.getQuery(0), indexSerializer, txHandle, indexCache, indexQuery.getLimit(),
getConversionFunction(query.getResultType()),retrievals.isEmpty() ? null: QueryUtil.processIntersectingRetrievals(retrievals, indexQuery.getLimit()));&lt;/p&gt;

&lt;p&gt;这里 SubQueryIterator 就是上面讲的。&lt;/p&gt;

&lt;h4 id=&#34;edgeprocessorimpl&#34;&gt;edgeProcessorImpl&lt;/h4&gt;

&lt;p&gt;他的 execute 方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
final InternalVertex v = query.getVertex();
final EntryList iterable = v.loadRelations(sq, query1 -&amp;gt; QueryProfiler.profile(profiler, query1, q -&amp;gt; graph.edgeQuery(v.longId(), q, txHandle)));
return RelationConstructor.readRelation(v, iterable, StandardJanusGraphTx.this).iterator();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终会调用 BackendTransation 的  edgeStoreQuery(final KeySliceQuery query)。&lt;/p&gt;

&lt;h3 id=&#34;queryprocessor&#34;&gt;QueryProcessor&lt;/h3&gt;

&lt;p&gt;Executes a given {@link ElementQuery} against a provided {@link QueryExecutor} to produce the result set of elements.&lt;/p&gt;

&lt;p&gt;看名字我们可以认为是查询处理器，他实现了 Iterable 接口，说明它是一个迭代器。
iterator 方法返回 &lt;code&gt;new ResultSetIterator(getUnfoldedIterator(),(query.hasLimit()) ? query.getLimit() : Query.NO_LIMIT);&lt;/code&gt;
ResultSetIterator 只是类似 guava 的一个封装，通过 nextInternal 方法实现 iterator 提前加载。所以我们可以不管，直接当成 getUnfoldedIterator()。&lt;/p&gt;

&lt;p&gt;getUnfoldedIterator 方法看起来比较复杂，但是主要的代码就是
&lt;code&gt;Iterator&amp;lt;R&amp;gt; newElements = executor.getNew(query);&lt;/code&gt;, &lt;code&gt;query.getSubQuery(i);new LimitAdjustingIterator(subquery);&lt;/code&gt;, 以及 &lt;code&gt;executor.execute(query, backendQuery, executionInfo, profiler)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;executor 的 getNew  方法代表返回符合条件的新元素，execute 方法应该是执行查询。&lt;/p&gt;

&lt;h3 id=&#34;indexserializer&#34;&gt;IndexSerializer&lt;/h3&gt;

&lt;p&gt;从 JointIndexQuery 我们能看出，SubQuery 是在 IndexSerializer 中执行的，我们大概了解一下 IndexSerializer。&lt;/p&gt;

&lt;p&gt;内部有一个 Map&lt;String, ? extends IndexInformation&gt; mixedIndexes，IndexInformation 有很多子类，例如 ElasticSearchIndex，
还有很多内部类 IndexInfoRetriever IndexRecords IndexUpdate RecordEntry。这应该是一直设计模式吧。
而它的 executeQuery 方法，最终会调用 backendTx.rawQuery(index.getBackingIndexName(), rawQuery) 方法。这里有点奇怪的是为什么只有 MixedIndexType&lt;/p&gt;

&lt;p&gt;另外 query 方法 有两种情况，如果是 isCompositeIndex ，会得到 MultiKeySliceQuery 并调用 sq.execute(tx)，如果是 MixedQuery ，调用 tx.indexQuery。
然后都是调用 BackendTransaction 的 indexQuery，CompositeIndex 对应的是 indexQuery(final KeySliceQuery query)，MixedIndex 是 indexQuery(final String index, final IndexQuery query)。
这两个方法将会分别跳转到 KeyColumnValueStore.getSlice(KeySliceQuery query, StoreTransaction txh) 和 IndexProvider.query(IndexQuery query, KeyInformation.IndexRetriever information, BaseTransaction tx)&lt;/p&gt;

&lt;h3 id=&#34;stream&#34;&gt;Stream&lt;/h3&gt;

&lt;p&gt;Stream 是 java 自带的类，目的是实现 lambda 编程，如 map filter reduce 等。java.util.list 调用 stream() 方法就返回一个 Stream 对象。Stream 的部分方法：
peek(Consumer) 方法主要用来调试。类似 map ，但是它返回原对象。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Stream.of(&amp;quot;one&amp;quot;, &amp;quot;two&amp;quot;, &amp;quot;three&amp;quot;, &amp;quot;four&amp;quot;)
    .filter(e -&amp;gt; e.length() &amp;gt; 3)
    .peek(e -&amp;gt; System.out.println(&amp;quot;Filtered value: &amp;quot; + e)) // 打印
    .map(String::toUpperCase)
    .peek(e -&amp;gt; System.out.println(&amp;quot;Mapped value: &amp;quot; + e))
    .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;limit(long ) 类似 sql 的 limit。
iterator() 返回一个迭代器。&lt;/p&gt;

&lt;h3 id=&#34;subqueryiterator&#34;&gt;SubqueryIterator&lt;/h3&gt;

&lt;p&gt;根据名字大概可以判断 SubqueryIterator 是一个查询结果迭代器，这里的 Subquery 就是上面我们介绍的，它的成员变量：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final JointIndexQuery.Subquery subQuery;
private final Cache&amp;lt;JointIndexQuery.Subquery, List&amp;lt;Object&amp;gt;&amp;gt; indexCache;
private Iterator&amp;lt;? extends JanusGraphElement&amp;gt; elementIterator;
private List&amp;lt;Object&amp;gt; currentIds;
private QueryProfiler profiler;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SubqueryIterator 的构造方法如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 传入了 subQuery 和 indexSerializer
public SubqueryIterator(JointIndexQuery.Subquery subQuery, IndexSerializer indexSerializer, BackendTransaction tx,
        Cache&amp;lt;JointIndexQuery.Subquery, List&amp;lt;Object&amp;gt;&amp;gt; indexCache, int limit,
        Function&amp;lt;Object, ? extends JanusGraphElement&amp;gt; function, List&amp;lt;Object&amp;gt; otherResults) {
    this.subQuery = subQuery;
    this.indexCache = indexCache;
    // 先从缓存里面取
    final List&amp;lt;Object&amp;gt; cacheResponse = indexCache.getIfPresent(subQuery);
    final Stream&amp;lt;?&amp;gt; stream;
    if (cacheResponse != null) {
        stream = cacheResponse.stream();
    } else {
        try {
            currentIds = new ArrayList&amp;lt;&amp;gt;();
            profiler = QueryProfiler.startProfile(subQuery.getProfiler(), subQuery);
            isTimerRunning = true;
            // 缓存没有就查
            stream = indexSerializer.query(subQuery, tx).peek(r -&amp;gt; currentIds.add(r));
        } catch (final Exception e) {
            throw new JanusGraphException(&amp;quot;Could not call index&amp;quot;, e.getCause());
        }
    }
    // 生成 elementIterator
    elementIterator = stream.limit(limit).filter(e -&amp;gt; otherResults == null || otherResults.contains(e)).map(function).map(r -&amp;gt; (JanusGraphElement) r).iterator();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;limitadjustingiterator&#34;&gt;LimitAdjustingIterator&lt;/h3&gt;

&lt;p&gt;QueryProcessor$LimitAdjustingIterator&lt;/p&gt;

&lt;p&gt;QueryProcessor 主要有两个属性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final Q query;
private final QueryExecutor&amp;lt;Q, R, B&amp;gt; executor;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的 query 就是上面讲的 query ，一般是 GraphCentricQuery 或者 VertexCentricQuery，executor 就是我们上面讲的 edgeProcessorImpl 和 elementProcessorImpl。
它的 iterator 方法返回一个 ResultSetIterator。
LimitAdjustingIterator 初始化的时候会调用 getNewIterator ，这时候执行 executor.execute(query, backendQuery, executionInfo, profiler)。&lt;/p&gt;

&lt;p&gt;和它类似的还有 PreSortingIterator ，加了一个排序 。&lt;/p&gt;

&lt;h3 id=&#34;小结&#34;&gt;小结&lt;/h3&gt;

&lt;p&gt;到这里我们基本搞清楚了整个查询过程。
首先我们的代码的查询会生成 GraphCentricQueryBuilder 或者 BasicVertexCentricQueryBuilder，
然后 我们调用 builder 的查询时会生成 GraphCentricQuery 或者 VertexCentricQuery，并 new QueryProcessor&amp;lt;&amp;gt;(query, tx.elementProcessor)。&lt;/p&gt;

&lt;p&gt;QueryProcessor 的 iterator 方法生成一个 ResultSetIterator 封装的 LimitAdjustingIterator ，
LimitAdjustingIterator 的 getNewIterator 会调用 QueryExecutor 的 execute 方法，生成 SubqueryIterator 或者 graph.edgeQuery(v.longId(), q, txHandle) 最终调用 edgeStore 的查询
SubqueryIterator 构造方法会调用 indexSerializer.query(subQuery, tx)，最终调用 edgeStore 或者 IndexProvider 的查询。&lt;/p&gt;

&lt;p&gt;以上使我们查看源代码的猜想，要想深入了解还需要进一步 debug 代码。通过网络查到的资料我们进一步进行总结。&lt;/p&gt;

&lt;h2 id=&#34;更新索引&#34;&gt;更新索引&lt;/h2&gt;

&lt;h3 id=&#34;index&#34;&gt;Index&lt;/h3&gt;

&lt;p&gt;Index 类继承自  JanusGraphSchemaElement ，后者我们已经讲过代表 schema 的元素，它的子类如 PropertyKeyVertex 代表 schema 的一部分。
Index 有两个子类 JanusGraphIndex 和 RelationTypeIndex ，分别代表 Graph index 和 基于 Relation 的 Index ，实现类分别是 ：JanusGraphIndexWrapper 和 RelationTypeIndexWrapper。&lt;/p&gt;

&lt;p&gt;JanusGraphIndexWrapper 包括了 composite indexes 和 mixed indexes。可以通过 JanusGraphManagement#buildIndex(String, Class) 构造，
通过 JanusGraphManagement#getGraphIndex(String) 或者 JanusGraphManagement#getGraphIndexes(Class) 获得。注意方法包括：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;getBackingIndex
getFieldKeys
getIndexedElement
getIndexStatus
getParametersFor
isCompositeIndex
isMixedIndex
isUnique
name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RelationTypeIndex 包括 EdgeIndex 和 PropertyKeyIndex ，通过 JanusGraphManagement#buildEdgeIndex(org.janusgraph.core.EdgeLabel &amp;hellip;)和 JanusGraphManagement#buildPropertyIndex(org.janusgraph.core.PropertyKey&amp;hellip;) 构造，
通过JanusGraphManagement#getRelationIndex(org.janusgraph.core.RelationType, String) 获得。主要方法包括：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;getDirection
getIndexStatus
getSortKey
getSortOrder
getType
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;indextype-internalrelationtype&#34;&gt;IndexType InternalRelationType&lt;/h3&gt;

&lt;p&gt;JanusGraphIndex 和 RelationTypeIndex 中分别有一个 IndexType 和 InternalRelationType 的属性。&lt;/p&gt;

&lt;p&gt;IndexType 又有 CompositeIndexType 和 MixedIndexTypeWrapper 两大子类， CompositeIndexType 还有一个子类是 BaseKey 的索引， 也就是 schema 默认有的索引。&lt;/p&gt;

&lt;p&gt;CompositeIndexTypeWrapper 和 MixedIndexTypeWrapper 的构造方法需要传入一个 SchemaSource 对象，也就是 JanusGraphSchemaVertex 的对象。&lt;/p&gt;

&lt;h3 id=&#34;indexbuilder&#34;&gt;IndexBuilder&lt;/h3&gt;

&lt;p&gt;IndexBuilder 是 JanusGraphManagement 内部接口，顾名思义是用来构建索引的，建造者模式。里面封装了索引的属性，例如： addKey indexOnly unique 等。&lt;/p&gt;

&lt;p&gt;实现类在 ManagementSystem 中，实现类 主要属性：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final String indexName;
private final ElementCategory elementCategory;
private boolean unique = false;
private JanusGraphSchemaType constraint = null;
private final Map&amp;lt;PropertyKey, Parameter[]&amp;gt; keys = new HashMap&amp;lt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要方法还是 createCompositeIndex 和 buildMixedIndex 。都会调用宿主类的方法。
实际上创建索引过程就是创建一个 INDEX 类型的 SchemaVertex ，然后建立到 对应的 PropertyKey 的 Edge。&lt;/p&gt;

&lt;h3 id=&#34;updatestatustrigger&#34;&gt;UpdateStatusTrigger&lt;/h3&gt;

&lt;p&gt;根据名字判断是更新 status 的触发器。它的属性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final StandardJanusGraph graph;
private final long schemaVertexId;
private final SchemaStatus newStatus;
private final Set&amp;lt;Long&amp;gt; propertyKeys;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构造方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private UpdateStatusTrigger(StandardJanusGraph graph, JanusGraphSchemaVertex vertex, SchemaStatus newStatus, Iterable&amp;lt;PropertyKeyVertex&amp;gt; keys) {
    this.graph = graph;
    this.schemaVertexId = vertex.longId();
    this.newStatus = newStatus;
    this.propertyKeys = Sets.newHashSet(Iterables.transform(keys, new Function&amp;lt;PropertyKey, Long&amp;gt;() {
        @Nullable
        @Override
        public Long apply(@Nullable PropertyKey propertyKey) {
            return propertyKey.longId();
        }
    }));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;call 方法主要就是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;management.setStatus(schemaVertex, newStatus, keys);
management.updatedTypes.addAll(keys);
management.updatedTypes.add(schemaVertex);
management.commit();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它被使用的地方是在 updateIndex 的时候，有一步： &lt;code&gt;setUpdateTrigger(new UpdateStatusTrigger(graph, schemaVertex, SchemaStatus.REGISTERED, keySubset))&lt;/code&gt;
这里的 set 方法只是将它 add 到了一个 List 中，而在调用 commit 的时候，会有个判断，然后调用 &lt;code&gt;mgmtLogger.sendCacheEviction(updatedTypes, updatedTypeTriggers, getOpenInstancesInternal());&lt;/code&gt;
这里 ManagementLogger 实际上又调用 &lt;code&gt;evictionTriggerMap.put(evictionId,new EvictionTrigger(evictionId,updatedTypeTriggers,openInstances))&lt;/code&gt; 将它封装为 EvictionTrigger 放进一个 map 中。&lt;/p&gt;

&lt;p&gt;这要从新建 StandardJanusGraph 开始说起，在它的构造方法有一句：&lt;code&gt;mgmtLog.registerReader(ReadMarker.fromNow(), mgmtLogger);&lt;/code&gt;
然后调用 KCVSLog 的 registerReader 方法，然后调用 msgPullers[pos]=new MessagePuller(partitionId,bucketId);
新建 MessagePuller 后，调用 readExecutor.scheduleWithFixedDelay 放进线程池
MessagePuller 的 run 方法会调用 prepareMessageProcessing ，然后调用 readExecutor.submit(new ProcessMessageJob(message,reader)) 放进线程池。
ProcessMessageJob 的 run 方法调用 ManagementLogger 的 read 方法，
然后会调用 EvictionTrigger evictTrigger = evictionTriggerMap.get(evictionId)，这里就取出了我们上面放进去的 evictTrigger，
调用 receivedAcknowledgement 方法，会调用 trigger.call() 方法，然后会 setStatus。&lt;/p&gt;

&lt;p&gt;我们稍微总结一下。 StandardJanusGraph 的构造方法实际上会 new 一个 KCVSLog managementLog 和一个 new ManagementLogger managementLogger，前者是日志，后者是 management 的日志。
然后调用 managementLog.registerReader(ReadMarker.fromNow(), managementLogger)，这个 managementLogger 实现了 MessageReader 接口， 也就是将 managementLogger 注册到 KCVSLog 上。
注册以后，会通过一个 ScheduledThreadPoolExecutor 定时调度，将 KCVSLog 按照分区分桶拆分成多个快，发送到 KCVSLog 的消息都会发送给 ManagementLogger。
ManagementLogger 调用 read 方法，判断 MgmtLogType，根据不同的类型，做出不同的响应。当收到 CACHED_TYPE_EVICTION_ACK 类型的消息，将会得到 evictTrigger，并且调用 call 方法。&lt;/p&gt;

&lt;h3 id=&#34;standardscanner&#34;&gt;StandardScanner&lt;/h3&gt;

&lt;p&gt;看名字是一个扫描器。内部有 KeyColumnValueStoreManager manager 和  Set&lt;KeyColumnValueStore&gt; openStores ，应该是构造的时候传进来的，来自 graph。
我们比较关心的是他的内部类： Builder ，内部有 ScanJob job，job 有 process 方法，而 Builder 则有 execute 方法，executor 会 new 一个 StandardScannerExecutor，
StandardScannerExecutor executor = new StandardScannerExecutor(job, finishJob, kcvs, storeTx,manager.getFeatures(), numProcessingThreads, workBlockSize, jobConfiguration, graphConfiguration);
executor 是继承自 Runnable 的，然后调用它的 start 方法启动这个线程。executor 的 run 方法就是关键，
StandardScannerExecutor 的 run 方法会 new Processor(job.clone(),processorQueue)，Processor 也是 Runnable ，然后调用 start ，Processor 的 run 中调用了 job 的 process。&lt;/p&gt;

&lt;p&gt;这个 job 的 process 方法就是重点。例如 SimpleScanJob 的 process 方法，就是扫描一遍数据库。&lt;/p&gt;

&lt;p&gt;StandardScanner 的使用主要是在 updateIndex 的时候，有一步： &lt;code&gt;builder.setJob(VertexJobConverter.convert(graph, new IndexRepairJob(indexId.indexName, indexId.relationTypeName)));&lt;/code&gt;
这里会设置 job，然后调用 builder.execute()，
里面会 new StandardScannerExecutor，这是一个 Runnable，然后 start。
它的 run 方法会 new Processor(job.clone(),processorQueue) ，这是一个 Runnable ，然后 start。
然后调用  job.process(row.key,row.entries,metrics)。
例如 IndexRepairJob 的 process 方法，会调用 BackendTransaction.mutateIndex 或者 restore 方法，和 IndexSerializer.reindexElement 方法，其实就是重新索引。&lt;/p&gt;

&lt;p&gt;想要了解可以在 CassandraScanJobIT 中进行简单测试。&lt;/p&gt;

&lt;p&gt;我们可以看出其实  StandardScanner 和 UpdateStatusTrigger 完成工作类似，都是通过线程调用线程，完成所以更新，只不过前者比较简单，后者操作复杂一点。&lt;/p&gt;

&lt;h3 id=&#34;managementsystem&#34;&gt;ManagementSystem&lt;/h3&gt;

&lt;p&gt;有关索引的操作也是在 ManagementSystem 中完成，最重要的就是 updateIndex 方法，&lt;/p&gt;

&lt;h3 id=&#34;reindex&#34;&gt;reindex&lt;/h3&gt;

&lt;p&gt;mgmt.updateIndex(mgmt.getGraphIndex(indexName), SchemaAction.REINDEX).get();&lt;/p&gt;

&lt;p&gt;我们发现这个步骤特别久，就算没有数据也要很久，这不科学。而且打断点也进不去，我们只能直接拍快照，通过分析某个时刻的快照，分析有没有线程死锁的情况。&lt;/p&gt;

&lt;p&gt;我们每次在程序运行的时候拍快照都会有两个线程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;Thread-61@7893&amp;quot; prio=5 tid=0x51 nid=NA waiting
  java.lang.Thread.State: WAITING
	  at sun.misc.Unsafe.park(Unsafe.java:-1)
	  at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	  at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	  at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	  at org.janusgraph.diskstorage.keycolumnvalue.scan.StandardScannerExecutor.run(StandardScannerExecutor.java:148)
	  at java.lang.Thread.run(Thread.java:745)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;Thread-65@7897&amp;quot; prio=5 tid=0x55 nid=NA waiting
  java.lang.Thread.State: WAITING
	  at sun.misc.Unsafe.park(Unsafe.java:-1)
	  at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	  at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	  at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	  at org.janusgraph.diskstorage.keycolumnvalue.scan.StandardScannerExecutor$Processor.run(StandardScannerExecutor.java:272)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;偶尔还能发现一个：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;Thread-4@4217&amp;quot; daemon prio=5 tid=0x18 nid=NA sleeping
  java.lang.Thread.State: TIMED_WAITING
	  at java.lang.Thread.sleep(Thread.java:-1)
	  at java.lang.Thread.sleep(Thread.java:340)
	  at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	  at org.janusgraph.diskstorage.util.time.TimestampProviders.sleepPast(TimestampProviders.java:152)
	  at org.janusgraph.graphdb.database.management.ManagementLogger$SendAckOnTxClose.run(ManagementLogger.java:208)
	  at java.lang.Thread.run(Thread.java:745)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前两个是常在的线程，在 index 的过程中几乎一致都在，后面那个是偶尔会有出现。&lt;/p&gt;

&lt;p&gt;中间还报：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;2018-06-30 14:16:35.282 ERROR   --- [      Thread-66] o.j.g.d.management.ManagementLogger      : 
Evicted [23@c0a8007113617-dengzimings-MacBook-Pro-local1] from cache but waiting too long for transactions to close. 
Stale transaction alert on: [standardjanusgraphtx[0x0fd51357], standardjanusgraphtx[0x42d0f747], 
standardjanusgraphtx[0x54168b3c], standardjanusgraphtx[0x27eff5b4], standardjanusgraphtx[0x20cfedd2], 
standardjanusgraphtx[0x7bd7769a], standardjanusgraphtx[0x1095d23a]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这三个可以给我们提供比较多的信息。前面两个可能是由于 poll 的参数等待时间是 100 ms 比较长，所以每次拍快照很大概率刚好在等待。&lt;/p&gt;

&lt;h1 id=&#34;debug&#34;&gt;debug&lt;/h1&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j企业版分析</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E4%BC%81%E4%B8%9A%E7%89%88%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E4%BC%81%E4%B8%9A%E7%89%88%E5%88%86%E6%9E%90/</guid>
      
        <description>&lt;p&gt;阅读neo4j源码是为了改造，所以研究一下企业版的源码。OpenEnterpriseNeoServer 和 CommunityNeoServer 稍微对比一下。&lt;/p&gt;

&lt;p&gt;CommunityNeoServer&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;protected static final GraphFactory COMMUNITY_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
                .newFacade( storeDir, config, dependencies );
    };

    public CommunityNeoServer( Config config, GraphDatabaseFacadeFactory.Dependencies dependencies,
            LogProvider logProvider )
    {
        this( config, lifecycleManagingDatabase( COMMUNITY_FACTORY ), dependencies, logProvider );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OpenEnterpriseNeoServer&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    protected static Database.Factory createDbFactory( Config config )
    {
        final Mode mode = config.get( EnterpriseEditionSettings.mode );

        switch ( mode )
        {
        case HA:
            return lifecycleManagingDatabase( HA_FACTORY );
        case ARBITER:
            // Should never reach here because this mode is handled separately by the scripts.
            throw new IllegalArgumentException( &amp;quot;The server cannot be started in ARBITER mode.&amp;quot; );
        case CORE:
            return lifecycleManagingDatabase( CORE_FACTORY );
        case READ_REPLICA:
            return lifecycleManagingDatabase( READ_REPLICA_FACTORY );
        default:
            return lifecycleManagingDatabase( ENTERPRISE_FACTORY );
        }
    }
    
    private static final GraphFactory HA_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new HighlyAvailableGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory ENTERPRISE_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new EnterpriseGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory CORE_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new CoreGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory READ_REPLICA_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new ReadReplicaGraphDatabase( storeDir, config, dependencies );
    };
    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终不一样的还是启动的 server的不一样而已。最终是在 PlatformModule EditionModule DataSourceModule 三个类负责的 中不一样的。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析1-编译打包启动</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E5%90%AF%E5%8A%A8/</guid>
      
        <description>

&lt;h2 id=&#34;1-打包&#34;&gt;1.打包&lt;/h2&gt;

&lt;h3 id=&#34;1-打包community&#34;&gt;1.打包community&lt;/h3&gt;

&lt;p&gt;进入community,neo4j-graphdb-api，
注释掉common的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.revapi&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;revapi-maven-plugin&amp;lt;/artifactId&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;里面好像涉及到了版本检查，如果某个类的最新发布版本已经没有这个方法，打包会失败，反正对打包有影响，不删除可能会失败。&lt;/p&gt;

&lt;p&gt;还可能要在主项目的pom里面注释掉：&lt;code&gt;maven-checkstyle-plugin&lt;/code&gt;，代码风格检查可能会通不过。
然后用maven命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests package install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-打包企业版&#34;&gt;2.打包企业版&lt;/h3&gt;

&lt;p&gt;进入enterprise,ha目录
进入management,注释掉 &lt;groupId&gt;org.revapi&lt;/groupId&gt;
还有其他问题，比如java文件没有license，这里不一一列举。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests package install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-打包完整的tar包&#34;&gt;3. 打包完整的tar包&lt;/h3&gt;

&lt;p&gt;进入项目路径&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn clean install -Dmaven.test.skip=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要注意两个参数的异同点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
-DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。

-Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打包的输出文件：packaging/standalone/target/neo4j-community-3.4.0-SNAPSHOT-unix.tar.gz，这个就是我们的neo4j包。解压后，放到一个目录。一方面你可以选择执行 bin/neo4j start 启动neo4j，我们要分析源码，自然会是在本地启动。&lt;/p&gt;

&lt;h2 id=&#34;二-运行&#34;&gt;二、运行&lt;/h2&gt;

&lt;h3 id=&#34;1-启动&#34;&gt;1.启动&lt;/h3&gt;

&lt;p&gt;我们在IDEA中，找到入口类：org.neo4j.server.CommunityEntryPoint，点击运行，然后会报错，我们需要添加运行参数：&lt;/p&gt;

&lt;p&gt;-server &amp;ndash;home-dir=~/neo4j-community-3.2.6 &amp;ndash;config-dir=~/neo4j-community-3.2.6/conf&lt;/p&gt;

&lt;p&gt;这里的参数是刚刚解压的neo4j目录和配置文件。然后运行成功，访问 &lt;a href=&#34;http://localhost:7474/browser/，会发现有问题。&#34;&gt;http://localhost:7474/browser/，会发现有问题。&lt;/a&gt;
通过调试前端的js代码，我们发现版本有问题，这里我们稍作修改，找到 org.neo4j.kernel.internal.Version。最后的代码注释掉，换成我们的版本，也就是将Version.class.getPackage().getImplementationVersion() 换成 3.4，然后就可以运行成功了。
打开7474端口，写cypher语言，查看。&lt;/p&gt;

&lt;h3 id=&#34;2-打断点调试&#34;&gt;2.打断点调试&lt;/h3&gt;

&lt;p&gt;既然是源码分析，我们的办法就是先看，然后打断点调试，查看调用栈，但是由于是多线程，其实还是很有难度的，容易跟丢，后续我们慢慢来吧。&lt;/p&gt;

&lt;h3 id=&#34;3-代码结构查看&#34;&gt;3.代码结构查看&lt;/h3&gt;

&lt;p&gt;看源码之前我们先大概过一下代码结构。我们主要看 community 模块的结构，里面有很多子模块。&lt;/p&gt;

&lt;p&gt;我们可以大概根据名字猜测 ：io模块是用来处理读写数据的，kernel模块是我们需要着重查看的。bolt是处理bolt连接的，server是整个项目启动的。codegen是动态生成代码的。我们要从内核部分开始看。&lt;/p&gt;

&lt;h3 id=&#34;4-架构了解&#34;&gt;4.架构了解&lt;/h3&gt;

&lt;p&gt;The node records contain only a pointer to their first property and their first relationship (in what is oftentermed the _relationship chain). From here, we can follow the (doubly) linked-list of relationships until we find the one we’re interested in, the LIKES relationship from Node 1 to Node 2 in this case. Once we’ve found the relationship record of interest, we can simply read its properties if there are any via the same singly-linked list structure as node properties, or we can examine the node records that it relates via its start node and end node IDs. These IDs, multiplied by the node record size, of course give the immediate offset of both nodes in the node store file.&lt;/p&gt;

&lt;p&gt;这段话来自&lt;Graph Databases&gt;(作者：IanRobinson) 一书。描述了neo4j的存储方式。详情可以查阅其他资料。&lt;/p&gt;

&lt;h3 id=&#34;5-源码查看&#34;&gt;5.源码查看&lt;/h3&gt;

&lt;p&gt;参考下一篇&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析2-启动源码跟踪</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E8%B7%9F%E8%B8%AA/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E8%B7%9F%E8%B8%AA/</guid>
      
        <description>

&lt;h2 id=&#34;1-第一遍调试&#34;&gt;1.第一遍调试&lt;/h2&gt;

&lt;p&gt;第一遍就是打断点，然后查看调用栈，忽略过多的线程。&lt;/p&gt;

&lt;p&gt;找到 CommunityEntryPoint，打一个断点，调试,不断F5进入，F6单步执行，F跳出。
1. &lt;code&gt;new CommunityBootstrapper(),ServerBootstrapper.start(boot,args)&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerBootstrapper&lt;/code&gt; 中的初始化关键代码： &lt;code&gt;private GraphDatabaseDependencies dependencies = GraphDatabaseDependencies.newDependencies()&lt;/code&gt;; 这个dependencies貌似来头很大。F5进入
&lt;code&gt;public static GraphDatabaseDependencies newDependencies()&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;KernelExtensionFactory factory : Service.load( KernelExtensionFactory.class)&lt;/code&gt;
这段代码似乎跳不进去，反正最后得到了7个:&lt;/p&gt;

&lt;p&gt;0 = {LuceneKernelExtensionFactory@675} &amp;ldquo;KernelExtension:LuceneKernelExtensionFactory[lucene]&amp;rdquo;
1 = {LuceneSchemaIndexProviderFactory@679} &amp;ldquo;KernelExtension:LuceneSchemaIndexProviderFactory[lucene]&amp;rdquo;
2 = {NativeLuceneFusionSchemaIndexProviderFactory@680} &amp;ldquo;KernelExtension:NativeLuceneFusionSchemaIndexProviderFactory[lucene+native]&amp;rdquo;
3 = {BoltKernelExtension@681} &amp;ldquo;KernelExtension:BoltKernelExtension[bolt-server]&amp;rdquo;
4 = {ShellServerExtensionFactory@682} &amp;ldquo;KernelExtension:ShellServerExtensionFactory[shell]&amp;rdquo;
5 = {UdcKernelExtensionFactory@683} &amp;ldquo;KernelExtension:UdcKernelExtensionFactory[kernel udc]&amp;rdquo;
6 = {JmxExtensionFactory@684} &amp;ldquo;KernelExtension:JmxExtensionFactory[kernel jmx]&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;List&amp;lt;QueryEngineProvider&amp;gt; queryEngineProviders = asList( Service.load( QueryEngineProvider.class ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这段代码和前面一样，不过加载的是查询引擎的的class，我们暂且跳过！&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;return new GraphDatabaseDependencies( null, null, new ArrayList&amp;lt;&amp;gt;(), kernelExtensions,)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerBootstrapper.start( Bootstrapper boot, String... argv )&lt;/code&gt;
```java&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;CommunityBootstrapper(AbstractNeoServer).start&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;server = createNeoServer( config, dependencies, userLogProvider );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;new CommunityNeoServer( config, dependencies, logProvider );&lt;/code&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;// 初始化很多属性&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;		protected abstract WebServer createWebServer();&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;			// 放在代码后面的属性
			private final Dependencies dependencyResolver = new Dependencies( new Supplier&lt;DependencyResolver&gt;()
    		{
    		    @Override
    		    public DependencyResolver get()
    		    {
    		        Database db = dependencyResolver.resolveDependency( Database.class );
    		        return db.getGraph().getDependencyResolver();
    		    }
    		} );
			// 构造方法
    		public AbstractNeoServer( Config config, Database.Factory dbFactory,
    		        GraphDatabaseFacadeFactory.Dependencies dependencies, LogProvider logProvider )
    		{
    		    this.logProvider = logProvider;
    		    // 初始化很多东西
    		}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    2. `AbstractNeoServer.start();`

        1. `init()`

            1. `this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );`

                1. `lambda$lifecycleManagingDatabase$0:47, LifecycleManagingDatabase (org.neo4j.server.database)`
                这里的 java8 lamabda表达式有点不懂，总之就是这个 dbFactory.newDatabase( config, dependencies ) 执行的是这段代码：
                 `( config, dependencies ) -&amp;gt; new LifecycleManagingDatabase( config, graphDbFactory, dependencies );`

                2. `dependencyResolver.satisfyDependency(LifecycleManagingDatabase )`
                这里的 satisfyDependency 方法有点奇怪，总之就是将 LifecycleManagingDatabase 的所有父类添加到一个临时变量，好像啥也没做。

                3. `life.add(LifecycleManagingDatabase)`
                奇怪的代码，后续我们专门讲解这个 life 的实现，这是注释：
                Add a new Lifecycle instance. It will immediately be transitioned to the state of this LifeSupport.
                将传入的dependency 新建为一个LifecycleInstance，add到 instances中。

                LifecycleInstance newInstance = new LifecycleInstance( instance );
                private volatile List&amp;lt;LifecycleInstance&amp;gt; instances = new ArrayList&amp;lt;&amp;gt;();

                4. `this.database = LifecycleManagingDatabase`

            2. 新建其他的，非内核部分我们忽略。


            this.authManagerSupplier = dependencyResolver.provideDependency( AuthManager.class );
    		this.userManagerSupplier = dependencyResolver.provideDependency( UserManagerSupplier.class );
    		this.sslPolicyFactorySupplier = dependencyResolver.provideDependency( SslPolicyLoader.class );
    		this.webServer = createWebServer();


            3. createServerModules()


            return Arrays.asList(
            new DBMSModule( webServer, getConfig() ),
            new RESTApiModule( webServer, getConfig(), getDependencyResolver(), logProvider ),
            new ManagementApiModule( webServer, getConfig() ),
            new ThirdPartyJAXRSModule( webServer, getConfig(), logProvider, this ),
            new ConsoleModule( webServer, getConfig() ),
            new Neo4jBrowserModule( webServer ),
            createAuthorizationModule(),
            new SecurityRulesModule( webServer, getConfig(), logProvider ) );


            4.创建 ServerComponentsLifecycleAdapter


            serverComponents = new ServerComponentsLifecycleAdapter();
            life.add( serverComponents );

            this.initialized = true;


        2. life.start();
        debug进入：`LifeSupport`

            1. init();
                1. status = changedStatus( this, status, LifecycleStatus.INITIALIZING );

                2. for ( LifecycleInstance instance : instances ) instance.init();
                    这时候有两个instance，分别是上面我们new出来的  new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter();

                    1. LifecycleInstance.init()
                    还好两个代码里面什么都没做，不然再F5进去，我要奔溃了。。。

                3. status = changedStatus( this, status, LifecycleStatus.STOPPED );

            2. for ( LifecycleInstance instance : instances ) instance.start();
                这时候有两个instance，分别是上面我们new出来的  new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter();

                    1. `LifecycleInstance.start() `

                    2. `LifecycleManagingDatabase.start()`


                        log.info( &amp;quot;Starting...&amp;quot; );
    					this.graph = dbFactory.newGraphDatabase( config, dependencies );
    					if ( !isInTestMode() )
    					{
    					    preLoadCypherCompiler();
    					}
    					log.info( &amp;quot;Started.&amp;quot; );



    					1. this.graph = dbFactory.newGraphDatabase( config, dependencies );
    					这里又是lambda表达式：
    					new GraphDatabaseFacadeFactory,

    					File storeDir = config.get( GraphDatabaseSettings.database_path );
                        return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
                               .newFacade( storeDir, config, dependencies );

                        主要的核心代码已经找到了：new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );
                        接下来我们主要调试这一段。

                    3. `ServerComponentsLifecycleAdapter.start()`
                        这里主要是和web，cypher有关，我们暂时忽略。
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;

## 2.调试 GraphDatabaseFacadeFactory.newFacade
上面我们已经调试到了 最后的部分，也是高潮部分。

newFacade 方法：
1. `initFacade( storeDir, config, dependencies, new GraphDatabaseFacade() );`

```java
    1.`new GraphDatabaseFacade()`
    初始化相关数据

    2.`GraphDatabaseFacade initFacade( File storeDir, Config config, final Dependencies dependencies, final GraphDatabaseFacade graphDatabaseFacade )`

    	1. `PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );`

        	1. `new PlatformModule( storeDir, config, databaseInfo, dependencies, graphDatabaseFacade );`
            这一部分代码很长很关键的感觉，这里是内核相关，先跳过，回头看。下一章节 TODO

            2. EditionModule edition = editionFactory.apply( platform );
            
            这里和上一个PlatformModule干的事情一样。下一章节 TODO

        2. `final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );`

            1. new DataSourceModule( platformModule, editionModule, queryEngine );
            和上面的 PlatformModule 一样，一大堆的新建。。。最后 life.add( platformModule.kernelExtensions ) 新建DataSource
        3. `ClassicCoreSPI spi = new ClassicCoreSPI( platform, dataSource, msgLog, coreAPIAvailabilityGuard );`
        
        4. `platform.life.start();`
 
            1. init();
            2. for ( LifecycleInstance instance : instances ) instance.start();
                这里的instance ：
           		
           		
           		0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;
		 		1 = {LifeSupport$LifecycleInstance@3730} &amp;quot;org.neo4j.kernel.impl.util.Neo4jJobScheduler@2667f029: STARTED&amp;quot;
		 		2 = {LifeSupport$LifecycleInstance@3635} &amp;quot;org.neo4j.udc.UsageData@67a20f67: STARTED&amp;quot;
		 		3 = {LifeSupport$LifecycleInstance@3658} &amp;quot;org.neo4j.kernel.impl.logging.StoreLogService@57c758ac: STARTED&amp;quot;
		 		4 = {LifeSupport$LifecycleInstance@3681} &amp;quot;org.neo4j.kernel.internal.locker.StoreLockerLifecycleAdapter@a9cd3b1: STARTED&amp;quot;
		 		5 = {LifeSupport$LifecycleInstance@3731} &amp;quot;org.neo4j.kernel.impl.pagecache.PageCacheLifecycle@13e39c73: STOPPED&amp;quot;
		 		6 = {LifeSupport$LifecycleInstance@3732} &amp;quot;org.neo4j.kernel.info.DiagnosticsManager@64cd705f: STOPPED&amp;quot;
		 		7 = {LifeSupport$LifecycleInstance@3733} &amp;quot;org.neo4j.kernel.impl.transaction.state.DataSourceManager@548d708a: STOPPED&amp;quot;
		 		8 = {LifeSupport$LifecycleInstance@3734} &amp;quot;org.neo4j.kernel.impl.util.watcher.DefaultFileSystemWatcherService@4b013c76: STOPPED&amp;quot;
		 		9 = {LifeSupport$LifecycleInstance@3735} &amp;quot;org.neo4j.kernel.impl.core.DelegatingPropertyKeyTokenHolder@53fb3dab: STOPPED&amp;quot;
		 		10 = {LifeSupport$LifecycleInstance@3736} &amp;quot;org.neo4j.kernel.impl.core.DelegatingLabelTokenHolder@cb0755b: STOPPED&amp;quot;
		 		11 = {LifeSupport$LifecycleInstance@3737} &amp;quot;org.neo4j.kernel.impl.core.DelegatingRelationshipTypeTokenHolder@33065d67: STOPPED&amp;quot;
		 		12 = {LifeSupport$LifecycleInstance@3738} &amp;quot;org.neo4j.kernel.internal.DefaultKernelData@30: STOPPED&amp;quot;
		 		13 = {LifeSupport$LifecycleInstance@3739} &amp;quot;org.neo4j.kernel.impl.core.ThreadToStatementContextBridge@7bba5817: STOPPED&amp;quot;
		 		14 = {LifeSupport$LifecycleInstance@3740} &amp;quot;org.neo4j.kernel.extension.KernelExtensions@25df00a0: STOPPED&amp;quot;
		 		15 = {LifeSupport$LifecycleInstance@3741} &amp;quot;org.neo4j.kernel.impl.proc.Procedures@6cc4cdb9: STOPPED&amp;quot;
		 		16 = {LifeSupport$LifecycleInstance@3742} &amp;quot;org.neo4j.server.security.auth.BasicAuthManager@47c81abf: STOPPED&amp;quot;
		 		17 = {LifeSupport$LifecycleInstance@3743} &amp;quot;org.neo4j.kernel.impl.cache.MonitorGc@30b6ffe0: STOPPED&amp;quot;
		 		18 = {LifeSupport$LifecycleInstance@3744} &amp;quot;org.neo4j.kernel.impl.pagecache.PublishPageCacheTracerMetricsAfterStart@2415fc55: STOPPED&amp;quot;
		 		19 = {LifeSupport$LifecycleInstance@3745} &amp;quot;org.neo4j.kernel.DatabaseAvailability@1890516e: STOPPED&amp;quot;
		 		20 = {LifeSupport$LifecycleInstance@3746} &amp;quot;org.neo4j.kernel.impl.factory.DataSourceModule$StartupWaiter@16c069df: STOPPED&amp;quot;
		 		21 = {LifeSupport$LifecycleInstance@3747} &amp;quot;org.neo4j.kernel.internal.KernelEventHandlers@2bec854f: STOPPED&amp;quot;
           	   
               每个instance的start方法具体是怎样的，我们稍后细看，这里跳过 TODO

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-学习neo4j-server的设计模式&#34;&gt;3.学习neo4j server的设计模式&lt;/h2&gt;

&lt;p&gt;上面我们调试了一遍启动过程，整个个过程可以多来几次，每一遍加深对neo4j的理解。
调试之前我们学习一下 LifeSupport 这个类的设计和使用。&lt;/p&gt;

&lt;p&gt;LifeSupport继承自Lifecycle，源码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Lifecycle interface for kernel components. Init is called first,
 * followed by start,
 * and then any number of stop-start sequences,
 * and finally stop and shutdown.
 *
 * As a stop-start cycle could be due to change of configuration, please perform anything that depends on config
 * in start().
 *
 * Implementations can throw any exception. Caller must handle this properly.
 *
 * The primary purpose of init in a component is to set up structure: instantiate dependent objects,
 * register handlers/listeners, etc.
 * Only in start should the component actually do anything with this structure.
 * Stop reverses whatever was done in start, and shutdown finally clears any set-up structure, if necessary.
 */
public interface Lifecycle
{
    void init() throws Throwable;

    void start() throws Throwable;

    void stop() throws Throwable;

    void shutdown() throws Throwable;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注释很清楚，万一看不懂百度翻译一下就明白。注意这里：init只是set up structure——初始化依赖的对象，注册处理器/监听器。只有start方法执行后才会用这个structure TOTDO，是不是看源码可以跳过init&lt;/p&gt;

&lt;p&gt;按F4发现有很多的实现类&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;PaxosClusterMemberAvailability (org.neo4j.cluster.member.paxos)
DefaultKernelData (org.neo4j.kernel.internal)
LifecycleAdapter (org.neo4j.kernel.lifecycle)
NeoStoreDataSource (org.neo4j.kernel)
TransactionPropagator (org.neo4j.kernel.ha.transaction)
ShellServerKernelExtension (org.neo4j.shell.impl)
OnlineBackupKernelExtension (org.neo4j.backup)
DummyExtension (org.neo4j.kernel)
LifeSupport (org.neo4j.kernel.lifecycle)
HighAvailabilityModeSwitcher (org.neo4j.kernel.ha.cluster.modeswitch)
KernelEventHandlers (org.neo4j.kernel.internal)
RecordStorageEngine (org.neo4j.kernel.impl.storageengine.impl.recordstorage)
JmxKernelExtension (org.neo4j.jmx.impl)
ExecutorLifecycleAdapter (org.neo4j.cluster)
KernelExtensions (org.neo4j.kernel.extension)
RecoveryCleanupWorkCollector (org.neo4j.index.internal.gbptree)
IndexImplementation (org.neo4j.kernel.spi.explicitindex)
NetworkReceiver (org.neo4j.cluster.com)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们重点看看 LifeSupport ，我们分析发现 LifeSupport 也是一个 Lifecycle，而且有一个 LifecycleInstance 的数组 instances ，&lt;/p&gt;

&lt;p&gt;LifecycleInstance 也是继承自 Lifecycle。所以实际上 LifeSupport 就是一堆 Lifecycle 放在了一起，进行了一个类似装饰模式而已。&lt;/p&gt;

&lt;p&gt;LifeSupport的init,start,stop,shutdown方法，分别是循环instances执行init,start,stop,shutdown方法。&lt;/p&gt;

&lt;p&gt;经过上面的调试，我们发现neo4j基本上就是一个一个这样的 LifeSupport 组成的。&lt;/p&gt;

&lt;h3 id=&#34;1-第一次使用&#34;&gt;(1). 第一次使用&lt;/h3&gt;

&lt;p&gt;我们第一次遇到 LifeSupport是 在： CommunityBootstrapper.start() 时候，先创建 CommunityNeoServer，调用它的 start，start 前先是init方法。遇到了两个代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );
serverComponents = new ServerComponentsLifecycleAdapter();
life.add( serverComponents );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的 life 就是 AbstractNeoServer(CommunityNeoServer) LifeSupport，是父类的成员变量，新建 CommunityNeoServer 的时候初始化的。然后在init方法中给他添加了两个 Lifecycle 的实现对象。&lt;/p&gt;

&lt;p&gt;AbstractNeoServer(CommunityNeoServer)执行完了init方法，就执行 life 的start方法，实际上执行的还是 new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter() 的start。&lt;/p&gt;

&lt;p&gt;总结：
CommunityNeoServer 中的 出现的 LifeSupport 为：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;new LifecycleManagingDatabase( config, graphDbFactory, dependencies )
这里的 graphDbFactory 是 CommunityNeoServer 的一个匿名内部类接口的实现类，dependencies就是包含了 kernelExtensions 等内容的东西。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;new ServerComponentsLifecycleAdapter()&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-第二次使用&#34;&gt;(2). 第二次使用&lt;/h3&gt;

&lt;p&gt;我们后面还有一次用到了 LifeSupport 。就是执行life的start时候，需要上面的 LifecycleManagingDatabase 的 start 方法。里面最重要的就是 dbFactory.newGraphDatabase( config, dependencies );&lt;/p&gt;

&lt;p&gt;这个 dbFactory 我们已经说了是 CommunityNeoServer 的一个匿名内部类接口的实现类 COMMUNITY_FACTORY， 最终执行方法返回：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;TODO 这里出现了 DatabaseInfo.COMMUNITY ，如果我们想使用企业版的功能，肯定需要在这里修改源码。还有 CommunityEditionModule ，
创建的实例只能用于社区版，所以是否可以猜想，企业版就是比社区版多了几个 LifeSupport 而已&lt;/p&gt;

&lt;p&gt;然后调用 GraphDatabaseFacadeFactory的newFacade方法，&lt;code&gt;return initFacade( storeDir, config, dependencies, new GraphDatabaseFacade() );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里 new GraphDatabaseFacade(),然后初始化，实际上就是初始化一个数据库了。&lt;/p&gt;

&lt;p&gt;然后创建一个 platform ，经过一堆复杂处理后，调用 platform 的 life 的start方法。也就是我们关心的 LifeSupport 。在查看之前，我们需要知道创建这个 platform 干了啥。&lt;/p&gt;

&lt;p&gt;打开PlatformModule的构造方法，太复杂了。。。。，但是先别泄气，我们先抓 LifeSupport 吧，搞定了这个再看别的。&lt;/p&gt;

&lt;p&gt;前面几行 F6 跳过，然后直接看：&lt;code&gt;life = dependencies.satisfyDependency( createLife() );&lt;/code&gt;
这个 createLife 方法就是new了一个 LifeSupport，然后F6跳过几行，直接看：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 createFileSystemAbstraction 就是 new DefaultFileSystemAbstraction，然后添加到 life，这时候 life 的 size 已经是1了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;jobScheduler = life.add( dependencies.satisfyDependency( createJobScheduler() ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里 createJobScheduler 就是 Neo4jJobScheduler。这时候 life 的 size 已经是2了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;dependencies.satisfyDependency( life.add( new UsageData( jobScheduler ) ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里 new UsageData ,这时候 life 的 size 已经是3了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;life.add( dependencies.satisfyDependency( new StoreLockerLifecycleAdapter( createStoreLocker() ) ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里的 createStoreLocker 就是 new GlobalStoreLocker( fileSystem, storeDir );&lt;/p&gt;

&lt;p&gt;然后 new StoreLockerLifecycleAdapter，这时候 life 的 size 已经是5了。我很好奇为啥突然加了两个。多了一个 StoreLogservice&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看：
&lt;code&gt;pageCache = dependencies.satisfyDependency( createPageCache( fileSystem, config, logging, tracers ) );life.add( new PageCacheLifecycle( pageCache ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后 new PageCacheLifecycle( pageCache ) 这时候 life 的 size 已经是6了。&lt;/p&gt;

&lt;p&gt;继续查看：&lt;code&gt;diagnosticsManager = life.add( dependencies.satisfyDependency( new DiagnosticsManager( logging.getInternalLog( DiagnosticsManager.class ) ) ) );&lt;/code&gt;
这里 new DiagnosticsManager( logging.getInternalLog( DiagnosticsManager.class ) )  ，这时候 life 的 size 已经是7了。&lt;/p&gt;

&lt;p&gt;一直到 createPlatform 运行完，life一共有7个 LifeSupport。然后调用：&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;直接进入 CommunityEditionModule 的构造方法&lt;/p&gt;

&lt;p&gt;直接F6: &lt;code&gt;LifeSupport life = platformModule.life;life.add( platformModule.dataSourceManager );&lt;/code&gt;
这里添加了 dataSourceManager，实际上是个 DAtaSourceManager。这时候 life 的 size 已经是8了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;life.add( watcherService );
propertyKeyTokenHolder = life.add( dependencies.satisfyDependency( new DelegatingPropertyKeyTokenHolder(
createPropertyKeyCreator( config, dataSourceManager, idGeneratorFactory ) ) ) );
labelTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingLabelTokenHolder( createLabelIdCreator( config,
dataSourceManager, idGeneratorFactory ) ) ));
relationshipTypeTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingRelationshipTypeTokenHolder(
createRelationshipTypeCreator( config, dataSourceManager, idGeneratorFactory ) ) ));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时候 life 的 size 已经是12了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;dependencies.satisfyDependency(createKernelData( fileSystem, pageCache, storeDir, config, graphDatabaseFacade, life ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个方法运行完成后，life一共有12个 LifeSupport。&lt;/p&gt;

&lt;p&gt;然后是：&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;
这里我们只抓取和life有关的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;LifeSupport life = platformModule.life;
threadToTransactionBridge = deps.satisfyDependency( life.add( new ThreadToStatementContextBridge() ) );
life.add( platformModule.kernelExtensions );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
life.add( new MonitorGc( config, logging.getInternalLog( MonitorGc.class ) ) );

life.add( new PublishPageCacheTracerMetricsAfterStart( platformModule.tracers.pageCursorTracerSupplier ) );

life.add( new DatabaseAvailability( platformModule.availabilityGuard, platformModule.transactionMonitor,
        config.get( GraphDatabaseSettings.shutdown_transaction_end_timeout ).toMillis() ) );

life.add( new StartupWaiter( platformModule.availabilityGuard, editionModule.transactionStartTimeout ) );

// Kernel event handlers should be the very last, i.e. very first to receive shutdown events
life.add( kernelEventHandlers );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里life的size已经是22 。&lt;/p&gt;

&lt;p&gt;然后会调用platform.life.start().就会循环调用上面的所有的 LifeSupport 的start方法。&lt;/p&gt;

&lt;p&gt;所以实际上，整个代码的运行就是一个个的 lifeSupport 的运行，&lt;/p&gt;

&lt;h2 id=&#34;4-理解lifesupport后再次调试代码&#34;&gt;4.理解LifeSupport后再次调试代码&lt;/h2&gt;

&lt;p&gt;这次调试就好多了，我们可以着重看重要的代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;1. `server = createNeoServer( config, dependencies, userLogProvider );`

    1. `this( config, lifecycleManagingDatabase( COMMUNITY_FACTORY ), dependencies, logProvider );`

        1.
        
        COMMUNITY_FACTORY = ( config, dependencies ) -&amp;gt;
    	{
    	    File storeDir = config.get( GraphDatabaseSettings.database_path );
    	    return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
    	            .newFacade( storeDir, config, dependencies );
    	};
        

2. `server.start();`

    1. `init`

        1. `this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );`

            1. `new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );`

                1. `life.add(GraphDatabaseFacadeFactory)`

            2. `this.webServer = createWebServer();`

                1. `new JettyWebServer()`

            3. `createServerModules()`

            4. `serverComponents = new ServerComponentsLifecycleAdapter();`

    2. `life.start();`

        1. for ( LifecycleInstance instance : instances ) start()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面两个 Lifecycle start 分开看。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;LifecycleManagingDatabase.start()&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;this.graph = dbFactory.newGraphDatabase( config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )&lt;/code&gt; 这里的lambda类似scala的匿名函数，钩子方法。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;newFacade( File storeDir, Config config, final Dependencies dependencies )&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;new GraphDatabaseFacade()&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;initFacade( File storeDir, Config config, final Dependencies dependencies,final GraphDatabaseFacade graphDatabaseFacade )&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;
这里就是上面我们省略的部分，&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;
start的过程启动了所有的 LifeCycle&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerComponentsLifecycleAdapter.start()&lt;/code&gt;
后续的程序&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接下来我们就是一个一个分析&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这四段代码，前三段主要是新建 LifeCycle，最后一个是start是和我们整个neo4j的集群联系最紧密的。为了提高效率，我们可以将上面22个LifeCycle一个一个看。方法很简单，以第一个&lt;code&gt;0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;&lt;/code&gt;为例，我们只需要找到新建和添加到lifeCycle的地方，打断点，然后在他的init和start方法上面打断点。
我们找到新建的调用栈，应该是 LifecycleManagingDatabase.start() -&amp;gt; &amp;hellip; -&amp;gt; new PlatformModule()，然后找到对应的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后找到 FileSystemLifecycleAdapter 的 init和start方法，好像都是空的，然后打上断点进行调试。&lt;/p&gt;

&lt;p&gt;另外对于我们关心的每一部分，实际上都是在这一块进行初始化和启动，一共就三个地方：PlatformModule，EditionModule，DataSourceModule。&lt;/p&gt;

&lt;p&gt;例如我们要找neo4j的存储，可以在这三个类中寻找，我大概感觉是：PlatformModule 中新建的 dataSourceManager，在 CommunityEditionModule 中add到life中取得，&lt;/p&gt;

&lt;p&gt;以及在 DataSourceModule 中的  new NeoStoreDataSource()  ，然后 dataSourceManager.register(NeoStoreDataSource)。仔细研究发现 dataSourceManager 也是一个LifeCycle，也有start方法，而他的instances包括了 NeoStoreDataSource，而 NeoStoreDataSource 也是一个LifeCycle，它的 instances是 start 方法中添加的。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析3-LifeCycle查看</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-datasourcemanager%E6%9F%A5%E7%9C%8B/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-datasourcemanager%E6%9F%A5%E7%9C%8B/</guid>
      
        <description>

&lt;h2 id=&#34;一-复习&#34;&gt;一、复习&lt;/h2&gt;

&lt;p&gt;上一篇我们说到，接下来我们就是一个一个分析 Lifecycle 的init和start方法，首先是 &lt;code&gt;GraphDatabaseFacadeFactory.initFacade&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这四段代码，前三段主要是新建 LifeCycle，最后一个是start是和我们整个neo4j的集群联系最紧密的。为了提高效率，我们可以将上面22个LifeCycle一个一个看。方法很简单，以第一个&lt;code&gt;0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;&lt;/code&gt;为例，我们只需要找到新建和添加到lifeCycle的地方，打断点，然后在他的init和start方法上面打断点。&lt;/p&gt;

&lt;p&gt;我们找到新建的调用栈，应该是 LifecycleManagingDatabase.start() -&amp;gt; &amp;hellip; -&amp;gt; new PlatformModule()，然后找到对应的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后找到 FileSystemLifecycleAdapter 的 init和start方法，好像都是空的，然后打上断点进行调试。&lt;/p&gt;

&lt;p&gt;另外对于我们关心的每一部分，实际上都是在这一块进行初始化和启动，一共就三个地方：PlatformModule，EditionModule，DataSourceModule。&lt;/p&gt;

&lt;p&gt;例如我们要找neo4j的存储，可以在这三个类中寻找，我大概感觉是：PlatformModule 中新建的 dataSourceManager，在 CommunityEditionModule 中add到life中取得，&lt;/p&gt;

&lt;p&gt;以及在 DataSourceModule 中的  new NeoStoreDataSource()  ，然后 dataSourceManager.register(NeoStoreDataSource)。仔细研究发现 dataSourceManager 也是一个LifeCycle，也有start方法，而他的instances包括了 NeoStoreDataSource，而 NeoStoreDataSource 也是一个LifeCycle，它的 instances是 start 方法中添加的。&lt;/p&gt;

&lt;h2 id=&#34;二-datasourcemanager-预览&#34;&gt;二、DataSourceManager 预览&lt;/h2&gt;

&lt;p&gt;从上面的分析我们看出，一共22个LifeCycle，DataSourceManager 是最复杂的，我们就从它开始。
在 PlatformModule 的构造方法新建了 dataSourceManager。并且在后面调用 start&lt;/p&gt;

&lt;h3 id=&#34;1-准备工作&#34;&gt;1.准备工作&lt;/h3&gt;

&lt;p&gt;在DataSourceManager类的init和start方法打上断点，然后在 PlatformModule 的构造方法打上断点，在 CommunityEditionModule 上打断点，在 DataSourceModule打上断点。&lt;/p&gt;

&lt;p&gt;另外我们的代码反复用到了 Dependencies 这个类，我们先大概知道一下它的方法，他有个 parent 属性，一个 resolveDependency 方法和一个 satisfyDependency 方法，&lt;/p&gt;

&lt;p&gt;satisfyDependency方法是将一个类的所有父类放进一个map中，resolveDependency方法是调用 parent的resolveDependency，实际上是 DataSourceManager中的dependencies，这里可以暂时忽略。&lt;/p&gt;

&lt;h3 id=&#34;2-开始调试&#34;&gt;2.开始调试&lt;/h3&gt;

&lt;p&gt;先定位到 PlatformModule 的断点 this.dataSourceManager = new DataSourceManager();新建只是初始化几个属性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private LifeSupport life = new LifeSupport();
    private final Listeners&amp;lt;Listener&amp;gt; dsRegistrationListeners = new Listeners&amp;lt;&amp;gt;();
    private NeoStoreDataSource dataSource;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后到 CommunityEditionModule 中，life.add( platformModule.dataSourceManager );将 dataSourceManager 添加到 LifeCycle 中。然后&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;propertyKeyTokenHolder = life.add( dependencies.satisfyDependency( new DelegatingPropertyKeyTokenHolder(
        createPropertyKeyCreator( config, dataSourceManager, idGeneratorFactory ) ) ) );
labelTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingLabelTokenHolder( createLabelIdCreator( config,
        dataSourceManager, idGeneratorFactory ) ) ));
relationshipTypeTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingRelationshipTypeTokenHolder(
        createRelationshipTypeCreator( config, dataSourceManager, idGeneratorFactory ) ) ));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这几步用到了 dataSourceManager ，但是具体干啥了暂且不知道，看名字应该是属性标签和关系等存储相关，先跳过。&lt;/p&gt;

&lt;p&gt;然后是 DataSourceModule 的 dataSourceManager.register( neoStoreDataSource );这里我们需要先看看 neoStoreDataSource 是啥。 打断点到 neoStoreDataSource = deps.satisfyDependency( new NeoStoreDataSource())，然后继续看看。&lt;/p&gt;

&lt;p&gt;进入 NeoStoreDataSource 的构造方法，NeoStoreDataSource 也是 LifeCycle 的一个实现类，有start方法，它的构造方法好像就是做了很多赋值。&lt;/p&gt;

&lt;p&gt;然后是 dataSourceManager.register( neoStoreDataSource )，实际上也就是赋值 this.dataSource = dataSource;&lt;/p&gt;

&lt;p&gt;然后接下来是 ClassicCoreSPI spi = new ClassicCoreSPI( platform, dataSource, msgLog, coreAPIAvailabilityGuard );官方文档显示 ClassicCoreSPI 是 surface-layer-of-the-database&lt;/p&gt;

&lt;p&gt;然后是 graphDatabaseFacade.init()&lt;/p&gt;

&lt;p&gt;然后进入到了关键的 platform.life.start(); 我们知道这里的life的start方法会遍历 life 的 instances 调用init和start，其中就包括我们进行要调试的 DataSourceManager 。&lt;/p&gt;

&lt;h3 id=&#34;3-datasourcemanager的start方法&#34;&gt;3.DataSourceManager的start方法。&lt;/h3&gt;

&lt;p&gt;我们已经在 DataSourceManager 中打好断点，我们已经知道他也是一个 Lifecycle ，先进入init方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void init() throws Throwable
    {
        life = new LifeSupport();
        life.add( dataSource ); // 这个DataSource是 NeoStoreDataSource
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后是start方法：其实就是 life.start(),它的life里面只有 NeoStoreDataSource 一个 instance ，然后会调用它的init和start方法，然后进入 init和start，init是空的，我们在start调试。信息量比较大，做好准备。&lt;/p&gt;

&lt;p&gt;第一步是 life = new LifeSupport();&lt;/p&gt;

&lt;p&gt;第二步是 life.add( recoveryCleanupWorkCollector );&lt;/p&gt;

&lt;p&gt;然后 life.add( indexConfigStore ) 和 life.add( Lifecycles.multiple( indexProviders.values() ) );&lt;/p&gt;

&lt;p&gt;然后是 storageEngine = buildStorageEngine()， buildRecovery(), final NeoStoreKernelModule kernelModule = buildKernel(),&lt;/p&gt;

&lt;p&gt;然后是 life.start();这里的life工有13个instance：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;instances = {ArrayList@5669}  size = 13
 0 = {LifeSupport$LifecycleInstance@5673} &amp;quot;org.neo4j.index.internal.gbptree.GroupingRecoveryCleanupWorkCollector@3b0c9195: NONE&amp;quot;
 1 = {LifeSupport$LifecycleInstance@5674} &amp;quot;org.neo4j.kernel.impl.index.IndexConfigStore@5cdd09b1: NONE&amp;quot;
 2 = {LifeSupport$LifecycleInstance@5675} &amp;quot;org.neo4j.kernel.lifecycle.Lifecycles$CombinedLifecycle@681a8b4e: NONE&amp;quot;
 3 = {LifeSupport$LifecycleInstance@5676} &amp;quot;org.neo4j.kernel.impl.storageengine.impl.recordstorage.RecordStorageEngine@305f7627: NONE&amp;quot;
 4 = {LifeSupport$LifecycleInstance@5677} &amp;quot;org.neo4j.kernel.impl.transaction.log.files.TransactionLogFiles@1bc715b8: NONE&amp;quot;
 5 = {LifeSupport$LifecycleInstance@5678} &amp;quot;org.neo4j.kernel.impl.transaction.log.BatchingTransactionAppender@24bdb479: NONE&amp;quot;
 6 = {LifeSupport$LifecycleInstance@5679} &amp;quot;org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointerImpl@7e3f95fe: NONE&amp;quot;
 7 = {LifeSupport$LifecycleInstance@5680} &amp;quot;org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointScheduler@34625ccd: NONE&amp;quot;
 8 = {LifeSupport$LifecycleInstance@5681} &amp;quot;org.neo4j.kernel.recovery.Recovery@39dcf4b0: NONE&amp;quot;
 9 = {LifeSupport$LifecycleInstance@5682} &amp;quot;org.neo4j.kernel.impl.api.KernelTransactions@21005f6c: NONE&amp;quot;
 10 = {LifeSupport$LifecycleInstance@5683} &amp;quot;org.neo4j.kernel.impl.api.KernelTransactionMonitorScheduler@32f0fba8: NONE&amp;quot;
 11 = {LifeSupport$LifecycleInstance@5684} &amp;quot;org.neo4j.kernel.impl.api.Kernel@545de5a4: NONE&amp;quot;
 12 = {LifeSupport$LifecycleInstance@5685} &amp;quot;org.neo4j.kernel.NeoStoreDataSource$2@2c1b9e4b: NONE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这12个LifeCycle什么时候加进来的我们后面有时间再看吧，我们接下来又要跳进 LifeCycle 的的init和start方法，这13个 LifeCycle 先看哪一个呢？我们发现最后一个好像是他自己的内部类？我们后面再看吧。&lt;/p&gt;

&lt;p&gt;我们先看和存储有关的 &lt;code&gt;3 = {LifeSupport$LifecycleInstance@5676} &amp;quot;org.neo4j.kernel.impl.storageengine.impl.recordstorage.RecordStorageEngine@305f7627: NONE&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;打好断点进入，这次终于没有 instance 了，感觉快进入了盗梦空间啊，直接看init：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void init() throws Throwable
{
    indexingService.init();
    labelScanStore.init();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IndexingService 的init方法，你可以选择跳进去，但是我不想跳进去了，不然进了但梦空间挑不出来。。。以后再看吧，姑且认为这个类和索引有关。&lt;/p&gt;

&lt;p&gt;NativeLabelScanStore 的init，我也先不跳进去了。&lt;/p&gt;

&lt;p&gt;再看start：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void start() throws Throwable
{
    neoStores.makeStoreOk();

    propertyKeyTokenHolder.setInitialTokens(
            neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
    relationshipTypeTokenHolder.setInitialTokens(
            neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
    labelTokenHolder.setInitialTokens(
            neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );

    neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
    loadSchemaCache();
    indexingService.start();
    labelScanStore.start();
    idController.start();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;neoStores.makeStoreOk(); 这个初始化就是读取本地存储，还是要重点查看一下：TODO&lt;/p&gt;

&lt;p&gt;然后是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;propertyKeyTokenHolder.setInitialTokens(
        neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
relationshipTypeTokenHolder.setInitialTokens(
        neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
labelTokenHolder.setInitialTokens(
        neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这几段代码都可以直接用调试的估值功能直接看出具体的值。&lt;/p&gt;

&lt;p&gt;然后是：neoStores.rebuildCountStoreIfNeeded(); 跳进去： getCounts().start();&lt;/p&gt;

&lt;p&gt;然后是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
loadSchemaCache();
indexingService.start();
labelScanStore.start();
idController.start();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后面再细看吧。&lt;/p&gt;

&lt;h2 id=&#34;三-datasourcemanager-剖析&#34;&gt;三、dataSourceManager 剖析&lt;/h2&gt;

&lt;p&gt;上面我们已经看出了，AbstractNeoServer 包含两个 LifeCycle ，其中一个是 LifecycleManagingDatabase ，&lt;/p&gt;

&lt;p&gt;LifecycleManagingDatabase  包含 22个 LifeCycle，其中一个是 dataSourceManager ，&lt;/p&gt;

&lt;p&gt;dataSourceManager 只包含一个 LifeCycle NeoStoreDataSource ，&lt;/p&gt;

&lt;p&gt;NeoStoreDataSource 里面有 13 个 LifeCycle ， 其中有和存储有关的 RecordStorageEngine 。
它的构造方法中有一句：neoStores = factory.openAllNeoStores( true ); 实际上会创建各种store，
相关的 store 和构造方法可以看：org.neo4j.kernel.impl.store.StoreType，以 NodeStore 为例，会先新建，然后 init。&lt;/p&gt;

&lt;p&gt;RecordStorageEngine 中有和存储相关的很多属性和方法。分别在构造方法赋值，init和start方法进行初始化和启动工作。&lt;/p&gt;

&lt;p&gt;这就是整个盗梦空间的五层梦，接下来我们只能从最深的一层反着往回查看了。&lt;/p&gt;

&lt;h3 id=&#34;1-recordstorageengine-分析&#34;&gt;1. RecordStorageEngine 分析&lt;/h3&gt;

&lt;p&gt;首先它的父类是 StorageEngine ： A StorageEngine provides the functionality to durably store data, and read it back.负责持久化和读数据，里面的抽象方法注释可以好好阅读。&lt;/p&gt;

&lt;h4 id=&#34;1-storageengine-预览&#34;&gt;(1). StorageEngine 预览&lt;/h4&gt;

&lt;p&gt;storeReadLayer() , return an interface for accessing data previously applied to this storage. 返回读取之前放进storage的数据的接口。&lt;/p&gt;

&lt;p&gt;allocateCommandCreationContext(), 保存需要多次执行的命令的上下文&lt;/p&gt;

&lt;p&gt;createCommands(),返回一系列在当前的事务状态下进行改变的&lt;code&gt;StorageCommand&lt;/code&gt;命令，CommandsToApply 命令可以通过调用apply方法放进存储中。&lt;/p&gt;

&lt;p&gt;apply()，执行一系列的命令到存储，&lt;/p&gt;

&lt;p&gt;其他的暂时忽略。&lt;/p&gt;

&lt;h4 id=&#34;2-recordstorageengine-属性查看&#34;&gt;(2). RecordStorageEngine 属性查看&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final StoreReadLayer storeLayer;
private final IndexingService indexingService;
private final NeoStores neoStores;
private final PropertyKeyTokenHolder propertyKeyTokenHolder;
private final RelationshipTypeTokenHolder relationshipTypeTokenHolder;
private final LabelTokenHolder labelTokenHolder;
private final DatabaseHealth databaseHealth;
private final IndexConfigStore indexConfigStore;
private final SchemaCache schemaCache;
private final IntegrityValidator integrityValidator;
private final CacheAccessBackDoor cacheAccess;
private final LabelScanStore labelScanStore;
private final SchemaIndexProviderMap schemaIndexProviderMap;
private final ExplicitIndexApplierLookup explicitIndexApplierLookup;
private final SchemaState schemaState;
private final SchemaStorage schemaStorage;
private final ConstraintSemantics constraintSemantics;
private final IdOrderingQueue explicitIndexTransactionOrdering;
private final LockService lockService;
private final WorkSync&amp;lt;Supplier&amp;lt;LabelScanWriter&amp;gt;,LabelUpdateWork&amp;gt; labelScanStoreSync;
private final CommandReaderFactory commandReaderFactory;
private final WorkSync&amp;lt;IndexingUpdateService,IndexUpdatesWork&amp;gt; indexUpdatesSync;
private final IndexStoreView indexStoreView;
private final ExplicitIndexProviderLookup explicitIndexProviderLookup;
private final PropertyPhysicalToLogicalConverter indexUpdatesConverter;
private final Supplier&amp;lt;StorageStatement&amp;gt; storeStatementSupplier;
private final IdController idController;
private final int denseNodeThreshold;
private final int recordIdBatchSize;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些field赋值是在 NeoStoreDataSource#buildStorageEngine ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private StorageEngine buildStorageEngine(
            PropertyKeyTokenHolder propertyKeyTokenHolder, LabelTokenHolder labelTokens,
            RelationshipTypeTokenHolder relationshipTypeTokens,
            ExplicitIndexProviderLookup explicitIndexProviderLookup, IndexConfigStore indexConfigStore,
            SchemaState schemaState, SynchronizedArrayIdOrderingQueue explicitIndexTransactionOrdering, OperationalMode operationalMode )
    {
        RecordStorageEngine storageEngine =
                new RecordStorageEngine( storeDir, config, pageCache, fs, logProvider, propertyKeyTokenHolder,
                        labelTokens, relationshipTypeTokens, schemaState, constraintSemantics, scheduler,
                        tokenNameLookup, lockService, schemaIndexProviderMap, indexingServiceMonitor, databaseHealth,
                        explicitIndexProviderLookup, indexConfigStore,
                        explicitIndexTransactionOrdering, idGeneratorFactory, idController, monitors, recoveryCleanupWorkCollector,
                        operationalMode );

        // We pretend that the storage engine abstract hides all details within it. Whereas that&#39;s mostly
        // true it&#39;s not entirely true for the time being. As long as we need this call below, which
        // makes available one or more internal things to the outside world, there are leaks to plug.
        storageEngine.satisfyDependencies( dependencies );

        return life.add( storageEngine );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调试得到初始值：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;storeDir = {File@1774} &amp;quot;/Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db&amp;quot;
config = {Config@1362} &amp;quot;dbms.connector.bolt.enabled=true, dbms.connector.http.enabled=true, dbms.connector.https.enabled=true, dbms.connectors.default_listen_address=localhost, dbms.directories.import=import, dbms.jvm.additional=-Dunsupported.dbms.udc.source=tarball, dbms.security.auth_enabled=true, dbms.tx_log.rotation.retention_policy=1 days, dbms.windows_service_name=neo4j, unsupported.dbms.block_size.array_properties=120, unsupported.dbms.block_size.labels=56, unsupported.dbms.block_size.strings=120, unsupported.dbms.directories.neo4j_home=/Users/dengziming/opt/soft/neo4j-community-3.2.6, unsupported.dbms.edition=community&amp;quot;
pageCache = {MuninnPageCache@1773} &amp;quot;MuninnPageCache[ \n Page[ id = 0, address = 4516331520, filePageId = 0, swapperId = 1, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 1, address = 4516339712, filePageId = 0, swapperId = 2, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 2, address = 4516347904, filePageId = 0, swapperId = 3, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 3, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 4, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 5, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 6, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 7&amp;quot;
fs = {DefaultFileSystemAbstraction@1772} 
logProvider = {FormattedLogProvider@3221} 
propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506} 
labelTokens = {DelegatingLabelTokenHolder@2495} 
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480} 
schemaState = {DatabaseSchemaState@3478} 
constraintSemantics = {StandardConstraintSemantics@2499} 
scheduler = {Neo4jJobScheduler@1778} 
tokenNameLookup = {NonTransactionalTokenNameLookup@2487} 
lockService = {ReentrantLockService@3222} 
indexProviderMap = {DefaultSchemaIndexProviderMap@3483} 
indexingServiceMonitor = {$Proxy16@3223} &amp;quot;null&amp;quot;
databaseHealth = {DatabaseHealth@2485} 
explicitIndexProviderLookup = {NeoStoreDataSource$1@3226} 
indexConfigStore = {IndexConfigStore@3473} 
explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479} 
idGeneratorFactory = {BufferingIdGeneratorFactory@2494} 
idController = {BufferedIdController@2493} 
monitors = {Monitors@2498} 
recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501} 
operationalMode = {OperationalMode@2489} &amp;quot;single&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后构造方法走完了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;storeDir = {File@1774} &amp;quot;/Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db&amp;quot;
config = {Config@1362} &amp;quot;dbms.connector.bolt.enabled=true, dbms.connector.http.enabled=true, dbms.connector.https.enabled=true, dbms.connectors.default_listen_address=localhost, dbms.directories.import=import, dbms.jvm.additional=-Dunsupported.dbms.udc.source=tarball, dbms.security.auth_enabled=true, dbms.tx_log.rotation.retention_policy=1 days, dbms.windows_service_name=neo4j, unsupported.dbms.block_size.array_properties=120, unsupported.dbms.block_size.labels=56, unsupported.dbms.block_size.strings=120, unsupported.dbms.directories.neo4j_home=/Users/dengziming/opt/soft/neo4j-community-3.2.6, unsupported.dbms.edition=community&amp;quot;
pageCache = {MuninnPageCache@1773} Method threw &#39;java.lang.OutOfMemoryError&#39; exception. Cannot evaluate org.neo4j.io.pagecache.impl.muninn.MuninnPageCache.toString()
fs = {DefaultFileSystemAbstraction@1772} 
logProvider = {FormattedLogProvider@3221} 
propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506} 
labelTokens = {DelegatingLabelTokenHolder@2495} 
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480} 
schemaState = {DatabaseSchemaState@3478} 
constraintSemantics = {StandardConstraintSemantics@2499} 
scheduler = {Neo4jJobScheduler@1778} 
tokenNameLookup = {NonTransactionalTokenNameLookup@2487} 
lockService = {ReentrantLockService@3222} 
indexProviderMap = {DefaultSchemaIndexProviderMap@3483} 
indexingServiceMonitor = {$Proxy16@3223} &amp;quot;null&amp;quot;
databaseHealth = {DatabaseHealth@2485} 
explicitIndexProviderLookup = {NeoStoreDataSource$1@3226} 
indexConfigStore = {IndexConfigStore@3473} 
explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479} 
idGeneratorFactory = {BufferingIdGeneratorFactory@2494} 
idController = {BufferedIdController@2493} 
monitors = {Monitors@2498} 
recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501} 
operationalMode = {OperationalMode@2489} &amp;quot;single&amp;quot;
factory = {StoreFactory@3550} 
neoStoreIndexStoreView = {NeoStoreIndexStoreView@3785} 
readOnly = {Boolean@3786} &amp;quot;false&amp;quot;
neoStores = {NeoStores@3549} 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后会调用 init 和 start 方法。&lt;/p&gt;

&lt;h4 id=&#34;3-recordstorageengine-属性分析&#34;&gt;(3). RecordStorageEngine 属性分析&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;storeDir&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;File类型，一开始启动参数设置的路径&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Config&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;配置&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;pageCache = {MuninnPageCache@1773}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;pageCache = {MuninnPageCache@1773} &amp;ldquo;MuninnPageCache[ \n Page[ id = 0, address = 4516331520, filePageId = 0, swapperId = 1, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 1, address = 4516339712, filePageId = 0, swapperId = 2, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 2, address = 4516347904, filePageId = 0, swapperId = 3, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 3, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 4, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 5, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 6, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 7&amp;rdquo;&lt;/p&gt;

&lt;p&gt;通过一个 re-usable cursor 来缓存和读取 cache 的内容，可以通过运行 MuninnPageCacheTest 的单元测试查看功能。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;fs = {DefaultFileSystemAbstraction@1772}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基于java的NIO 文件系统进行一个封装，。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;logProvider = {FormattedLogProvider@3221}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;进行日志打印&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;TokenHolder&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506}
labelTokens = {DelegatingLabelTokenHolder@2495}
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480}
后面的 cacheAccess storeLayer 会用到这三个 。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;schemaState = {DatabaseSchemaState@3478}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;存储一些状态，例如 cypher 的执行计划&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;constraintSemantics = {StandardConstraintSemantics@2499}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;里面的方法都是抛异常。
schemaCache 和后面的 txStateVisitor 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;scheduler = {Neo4jJobScheduler@1778}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;里面是一个 synchronizedSet ，用于放任务。
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;tokenNameLookup = {NonTransactionalTokenNameLookup@2487}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;包含了上面的三个 TokenHolder
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;lockService = {ReentrantLockService@3222}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一个读写锁，通过不区分读写实现同步
indexStoreView 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexProviderMap = {DefaultSchemaIndexProviderMap@3483}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;提供索引
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexingServiceMonitor = {$Proxy16@3223} &amp;ldquo;null&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;databaseHealth = {DatabaseHealth@2485}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;集群健康状态&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;explicitIndexProviderLookup = {NeoStoreDataSource$1@3226}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;貌似是查找索引用的。NeoStoreDataSource$1 是啥意思还没搞懂。。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexConfigStore = {IndexConfigStore@3473}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;索引属性&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;和上面两个合作，&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;idGeneratorFactory = {BufferingIdGeneratorFactory@2494}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;封装 IdGenerator&lt;/p&gt;

&lt;p&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;idController = {BufferedIdController@2493}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BufferedIdController safely free and reuse ids.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;monitors = {Monitors@2498}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;监控&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;略&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;operationalMode = {OperationalMode@2489} &amp;ldquo;single&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;略&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;factory = {StoreFactory@3550}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    {
        this.config = config;
        this.idGeneratorFactory = idGeneratorFactory;
        this.fileSystemAbstraction = fileSystemAbstraction;
        this.recordFormats = recordFormats;
        this.openOptions = openOptions;
        new RecordFormatPropertyConfigurator( recordFormats, config ).configure();

        this.logProvider = logProvider;
        this.neoStoreFileName = new File( storeDir, storeName );
        this.pageCache = pageCache;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;存储工厂实现，也可以用来创建空工厂。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;neoStoreIndexStoreView = {NeoStoreIndexStoreView@3785}&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;neoStores = {NeoStores@3549}&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;neoStores = factory.openAllNeoStores( true );&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,
                fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-recordstorageengine-init和start&#34;&gt;(3). RecordStorageEngine init和start&lt;/h4&gt;

&lt;p&gt;上面我们已经大概明白了每个类的作用，首先我们：&lt;code&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后是： &lt;code&gt;neoStores = factory.openAllNeoStores( true );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后是从 neoStores 出发，新建一系列和存储有关的属性。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;indexUpdatesConverter = new PropertyPhysicalToLogicalConverter( neoStores.getPropertyStore() );
schemaStorage = new SchemaStorage( neoStores.getSchemaStore() );
NeoStoreIndexStoreView neoStoreIndexStoreView = new NeoStoreIndexStoreView( lockService, neoStores );
indexStoreView = new DynamicIndexStoreView( neoStoreIndexStoreView, labelScanStore, lockService, neoStores, logProvider );
schemaIndexProviderMap = indexProviderMap;
indexingService = IndexingServiceFactory.createIndexingService( config, scheduler, schemaIndexProviderMap,
        indexStoreView, tokenNameLookup,
        Iterators.asList( new SchemaStorage( neoStores.getSchemaStore() ).indexesGetAll() ), logProvider,
        indexingServiceMonitor, schemaState );

integrityValidator = new IntegrityValidator( neoStores, indexingService );
storeStatementSupplier = storeStatementSupplier( neoStores );
            storeLayer = new StorageLayer(
                    propertyKeyTokenHolder, labelTokens, relationshipTypeTokens,
                    schemaStorage, neoStores, indexingService,
                    storeStatementSupplier, schemaCache );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构造方法完了就是init和start&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void init() throws Throwable
{
    indexingService.init(); -- 所以服务
    labelScanStore.init();  -- Label存储
}

@Override
public void start() throws Throwable
{
    neoStores.makeStoreOk();

    propertyKeyTokenHolder.setInitialTokens(
            neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
    relationshipTypeTokenHolder.setInitialTokens(
            neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
    labelTokenHolder.setInitialTokens(
            neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );

    neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
    loadSchemaCache();
    indexingService.start();
    labelScanStore.start();
    idController.start();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一步一步看：
1. indexingService.init();&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// Each index has an {@link org.neo4j.kernel.impl.store.record.IndexRule}
// 遍历每一个 IndexRule ，
IndexProxy indexProxy;

long indexId = indexRule.getId();
IndexDescriptor descriptor = indexRule.getIndexDescriptor();
SchemaIndexProvider.Descriptor providerDescriptor = indexRule.getProviderDescriptor();
SchemaIndexProvider provider = providerMap.apply( providerDescriptor );
InternalIndexState initialState = provider.getInitialState( indexId, descriptor );
indexStates.computeIfAbsent( initialState, internalIndexState -&amp;gt; new ArrayList&amp;lt;&amp;gt;() )
.add( new IndexLogRecord( indexId, descriptor ) );

log.debug( indexStateInfo( &amp;quot;init&amp;quot;, indexId, initialState, descriptor ) );
switch ( initialState )
{
case ONLINE:
    indexProxy =
    indexProxyCreator.createOnlineIndexProxy( indexId, descriptor, providerDescriptor );
    break;
case POPULATING:
    // The database was shut down during population, or a crash has occurred, or some other sad thing.
    indexProxy = indexProxyCreator.createRecoveringIndexProxy( descriptor, providerDescriptor );
    break;
case FAILED:
    IndexPopulationFailure failure = failure( provider.getPopulationFailure( indexId ) );
    indexProxy = indexProxyCreator
            .createFailedIndexProxy( indexId, descriptor, providerDescriptor, failure );
    break;
default:
    throw new IllegalArgumentException( &amp;quot;&amp;quot; + initialState );
}
indexMap.putIndexProxy( indexId, indexProxy );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于我的数据库没有建索引，所以这里就不调试了，接下来建了索引再说。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;labelScanStore.init();&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过 GBPTree 实现&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;-- which is implemented using {@link GBPTree}
@link GBPTree 是一种算法，减少树结构合并时候的冲突。
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;indexingService.start();&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;labelScanStore.start();&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;idController.start();&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-recordstorageengine-分析&#34;&gt;2. RecordStorageEngine 分析&lt;/h3&gt;

&lt;p&gt;上一节我们已经大概看了 RecordStorageEngine ，他只是 NeoStoreDataSource 的 13个梦中的一个而已，我们还要醒来继续做剩下的12个梦。
我看了一下 先不看了，剩下的12个重要性稍微低一点。我们先看我们最感兴趣的。&lt;/p&gt;

&lt;p&gt;PageCache&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析4-读文件</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-%E8%AF%BB%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-%E8%AF%BB%E6%96%87%E4%BB%B6/</guid>
      
        <description>

&lt;h2 id=&#34;一-复习&#34;&gt;一、复习&lt;/h2&gt;

&lt;p&gt;上一篇我们已经大概看了 RecordStorageEngine ，他只是 NeoStoreDataSource 的 13个梦中的一个而已，我们还要醒来继续做剩下的12个梦。&lt;/p&gt;

&lt;p&gt;然而我们可以先看看如何读数据，写数据的。第一是找到java类 &lt;code&gt;PhysicalLogCommandReaderV3_0_2&lt;/code&gt;。我们可以看到里面有很多读文件处理的方法，主要是&lt;code&gt;neostore.transaction.db.0&lt;/code&gt;这个文件，好像是日志文件。&lt;/p&gt;

&lt;p&gt;然后我们在 NodeStore 类的构造方法打断点。可以找到整个调用的栈帧：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;new RecordStorageEngine()
neoStores = factory.openAllNeoStores( true );
return openNeoStores( createStoreIfNotExists, StoreType.values() );
return new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
for ( StoreType type : storeTypes ) getOrCreateStore( type );
store = openStore( storeType );
Object store = type.open( this );
return neoStores.createNodeStore( getStoreName() );
return initialize( new NodeStore( storeFile, config, idGeneratorFactory, pageCache, logProvider,(DynamicArrayStore) getOrCreateStore( StoreType.NODE_LABEL ), recordFormats, openOptions ) );
new CommonAbstractStore()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同理，我们还可以在 RelationshipStore PropertyStore TokenStore AbstractDynamicStore 等store中打上断点，了解调用栈。所有的存储文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;CommonAbstractStore (org.neo4j.kernel.impl.store)
RelationshipStore (org.neo4j.kernel.impl.store)
RecordingRelationshipStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
MyStore in CommonAbstractStoreBehaviourTest (org.neo4j.kernel.impl.store)
MetaDataStore (org.neo4j.kernel.impl.store)
AbstractDynamicStore (org.neo4j.kernel.impl.store)
DynamicArrayStore (org.neo4j.kernel.impl.store)
SchemaStore (org.neo4j.kernel.impl.store)
DynamicStringStore (org.neo4j.kernel.impl.store)
Anonymous in newTestableDynamicStore() in AbstractDynamicStoreTest (org.neo4j.kernel.impl.store)
NodeStore (org.neo4j.kernel.impl.store)
RecordingNodeStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
RelationshipGroupStore (org.neo4j.kernel.impl.store)
TokenStore (org.neo4j.kernel.impl.store)
LabelTokenStore (org.neo4j.kernel.impl.store)
UnusedLabelTokenStore in LabelTokenStoreTest (org.neo4j.kernel.impl.store)
PropertyKeyTokenStore (org.neo4j.kernel.impl.store)
RelationshipTypeTokenStore (org.neo4j.kernel.impl.store)
TheStore in CommonAbstractStoreTest (org.neo4j.kernel.impl.store)
PropertyStore (org.neo4j.kernel.impl.store)
RecordingPropertyStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对应20种存储格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;AbstractBaseRecord (org.neo4j.kernel.impl.store.record)
PropertyRecord (org.neo4j.kernel.impl.store.record)
IntRecord in CommonAbstractStoreBehaviourTest (org.neo4j.kernel.impl.store)
TheRecord in CommonAbstractStoreTest (org.neo4j.kernel.impl.store)
MyRecord in BaseHighLimitRecordFormatTest (org.neo4j.kernel.impl.store.format.highlimit)
MetaDataRecord (org.neo4j.kernel.impl.store.record)
SchemaRecord (org.neo4j.kernel.impl.store.record)
DynamicRecord (org.neo4j.kernel.impl.store.record)
IndexEntry (org.neo4j.consistency.store.synthetic)
PrimitiveRecord (org.neo4j.kernel.impl.store.record)
NodeRecord (org.neo4j.kernel.impl.store.record)
NeoStoreRecord (org.neo4j.kernel.impl.store.record)
RelationshipRecord (org.neo4j.kernel.impl.store.record)
LabelScanDocument (org.neo4j.consistency.store.synthetic)
RelationshipGroupRecord (org.neo4j.kernel.impl.store.record)
RelationshipGroupCursor (org.neo4j.kernel.impl.newapi)
TokenRecord (org.neo4j.kernel.impl.store.record)
LabelTokenRecord (org.neo4j.kernel.impl.store.record)
PropertyKeyTokenRecord (org.neo4j.kernel.impl.store.record)
RelationshipTypeTokenRecord (org.neo4j.kernel.impl.store.record)
CountsEntry (org.neo4j.consistency.store.synthetic)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 StoreFactory 中可以找到对应的关系。&lt;/p&gt;

&lt;h2 id=&#34;二-id文件&#34;&gt;二、Id文件&lt;/h2&gt;

&lt;p&gt;打开代码 CommonAbstractStore ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Opens the {@link IdGenerator} used by this store.
 * &amp;lt;p&amp;gt;
 * Note: This method may be called both while the store has the store file mapped in the
 * page cache, and while the store file is not mapped. Implementers must therefore
 * map their own temporary PagedFile for the store file, and do their file IO through that,
 * if they need to access the data in the store file.
 */
void openIdGenerator()
{
    idGenerator = idGeneratorFactory.open( getIdFileName(), getIdType(), () -&amp;gt; scanForHighId(), recordFormat.getMaxId() );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IdGenerator 的功能是分配id，每一种存储格式都有自己的id，所以在 CommonAbstractStore 中都有这个属性。idGenerator负责分配和释放id，所以它里面要有最大的id，已经已经释放的id。&lt;/p&gt;

&lt;p&gt;最大的id可以用到下一次分配id，已经释放的也可以用于分配。进一步了解功能可以在 IdGeneratorImplTest 中调试。我们可以用二进制文件编辑器打开&lt;code&gt;neostore.nodestore.db.id&lt;/code&gt;看看。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0000 0000 0000 0000 0b00 0000 0000 0000
0000 0000 0000 0000 0100 0000 0000 0000
0200 0000 0000 0000 0300 0000 0000 0000
0400 0000 0000 0000 0500 0000 0000 0000
06
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里一共有 65 bytes ，第1bytes是文件头，然后8 bytes是最大的id，这里是 &lt;code&gt;00 0000 0000 0000 0b&lt;/code&gt; ，然后每8Bytes就是一个释放的id，这里是从0到6。&lt;/p&gt;

&lt;p&gt;IdGeneratorImpl 的构造方法会有一个 IdContainer ，可以分配id，可以去 IdContainerTest 的 testNextId 调试 中查看功能。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try
{
    IdGeneratorImpl.createGenerator( fs, idGeneratorFile(), 0, false );
    IdGenerator idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 3, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    for ( long i = 0; i &amp;lt; 7; i++ )
    {
        assertEquals( i, idGenerator.nextId() );
    }
    idGenerator.freeId( 1 );
    idGenerator.freeId( 3 );
    idGenerator.freeId( 5 );
    assertEquals( 7L, idGenerator.nextId() );
    idGenerator.freeId( 6 );
    closeIdGenerator( idGenerator );
    idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 5, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    idGenerator.freeId( 2 );
    idGenerator.freeId( 4 );
    assertEquals( 1L, idGenerator.nextId() );
    idGenerator.freeId( 1 );
    assertEquals( 3L, idGenerator.nextId() );
    idGenerator.freeId( 3 );
    assertEquals( 5L, idGenerator.nextId() );
    idGenerator.freeId( 5 );
    assertEquals( 6L, idGenerator.nextId() );
    idGenerator.freeId( 6 );
    assertEquals( 8L, idGenerator.nextId() );
    idGenerator.freeId( 8 );
    assertEquals( 9L, idGenerator.nextId() );
    idGenerator.freeId( 9 );
    closeIdGenerator( idGenerator );
    idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 3, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    assertEquals( 6L, idGenerator.nextId() );
    assertEquals( 8L, idGenerator.nextId() );
    assertEquals( 9L, idGenerator.nextId() );
    assertEquals( 1L, idGenerator.nextId() );
    assertEquals( 3L, idGenerator.nextId() );
    assertEquals( 5L, idGenerator.nextId() );
    assertEquals( 2L, idGenerator.nextId() );
    assertEquals( 4L, idGenerator.nextId() );
    assertEquals( 10L, idGenerator.nextId() );
    assertEquals( 11L, idGenerator.nextId() );
    closeIdGenerator( idGenerator );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;三-文件读写api&#34;&gt;三、文件读写API&lt;/h2&gt;

&lt;p&gt;ne4j有 专用的API ，neo4j的文件有它自己的特点，不能直接使用java的API，需要定义自己的API，在 org.neo4j.io.pagecache 下。我们需要了解一下。从package-info看起。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;The purpose of a page cache is to cache data from files on a storage device, and keep the most often used data in
memory where access is fast. This duplicates the most popular data from the file, into memory. Assuming that not all
data can fit in memory (even though it sometimes can), the least used data will then be pushed out of memory, when
we need data that is not already in the cache. This is called eviction, and choosing what to evict is the
responsibility of the eviction algorithm that runs inside the page cache implementation.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pagecache的功能是从文件或者存储设备缓存数据，将最常用的放在访问最快的内存。我们最少用的数据会不在内存，当我们需要的时候，这个过程是  eviction ，选择哪个 eviction 是算法最重要的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A file must first be &amp;quot;mapped&amp;quot; into the page cache, before the page cache can cache the contents of the files. When
you no longer have an immediate use for the contents of the file, it can be &amp;quot;unmapped.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文件要被 map 到cache中才能使用。&lt;/p&gt;

&lt;p&gt;通过 org.neo4j.io.pagecache.PageCache#map(java.io.File, int, java.nio.file.OpenOption&amp;hellip;) 方法将得到一个 {@link org.neo4j.io.pagecache.PagedFile} 对象。&lt;/p&gt;

&lt;p&gt;一旦一个文件被映射到页面缓存，它就不再被直接通过文件系统访问，因为页面缓存将保持内存的变化，认为它正在管理唯一权威的副本。&lt;/p&gt;

&lt;p&gt;一个文件被map多次，返回的是同一个 PageCache，对应的 reference counter +1，&lt;/p&gt;

&lt;p&gt;Unmapping decrements the reference counter, discarding the PagedFile from the cache if the counter reaches zero.&lt;/p&gt;

&lt;p&gt;If the last reference was unmapped, then all dirty pages for that file will be flushed before the file is discarded from the cache。&lt;/p&gt;

&lt;p&gt;page 是一堆data的集合，可以是 file, or the memory allocated for the page cache。We refer to these two types of pages as &amp;ldquo;file pages&amp;rdquo; and &amp;ldquo;cache pages&amp;rdquo; respectively.&lt;/p&gt;

&lt;p&gt;Pages are the unit of what data is popular or not, and the unit of moving data into memory, and out to storage.&lt;/p&gt;

&lt;p&gt;When a cache page is holding the contents of a file page, the two are said to be &amp;ldquo;bound&amp;rdquo; to one another.&lt;/p&gt;

&lt;p&gt;每个 PagedFile 对象都有一个 translation table，逻辑上存储了page file到cache里，类似 Maps 结构，key是pageid，value是page内容。&lt;/p&gt;

&lt;p&gt;几个类的逻辑视图如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;*     +---------------[ PageCache ]-----------------------------------+
 *     |                                                               |
 *     |  * PageSwapperFactory{ FileSystemAbstraction }                |
 *     |  * evictionThread                                             |
 *     |  * a large collection of Page objects:                        |
 *     |                                                               |
 *     |  +---------------[ Page ]----------------------------------+  |
 *     |  |                                                         |  |
 *     |  |  * usageCounter                                         |  |
 *     |  |  * some kind of read/write lock                         |  |
 *     |  |  * a cache page sized buffer                            |  |
 *     |  |  * binding metadata{ filePageId, PageSwapper }          |  |
 *     |  |                                                         |  |
 *     |  +---------------------------------------------------------+  |
 *     |                                                               |
 *     |  * linked list of mapped PagedFile instances:                 |
 *     |                                                               |
 *     |  +--------------[ PagedFile ]------------------------------+  |
 *     |  |                                                         |  |
 *     |  |  * referenceCounter                                     |  |
 *     |  |  * PageSwapper{ StoreChannel, filePageSize }            |  |
 *     |  |  * PageCursor freelists                                 |  |
 *     |  |  * translation table:                                   |  |
 *     |  |                                                         |  |
 *     |  |  +--------------[ translation table ]----------------+  |  |
 *     |  |  |                                                   |  |  |
 *     |  |  |  A translation table is basically a map from      |  |  |
 *     |  |  |  file page ids to Page objects. It is updated     |  |  |
 *     |  |  |  concurrently by page faulters and the eviction   |  |  |
 *     |  |  |  thread.                                          |  |  |
 *     |  |  |                                                   |  |  |
 *     |  |  +---------------------------------------------------+  |  |
 *     |  +---------------------------------------------------------+  |
 *     +---------------------------------------------------------------+
 *
 *     +--------------[ PageCursor ]-----------------------------------+
 *     |                                                               |
 *     |  * currentPage: Page                                          |
 *     |  * page lock metadata                                         |
 *     |                                                               |
 *     +---------------------------------------------------------------+
 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里有几个重要的类，我们需要大概了解一下用法，第一个是 PageCache ，可以查看 MuninnPageCacheTest 类的测试方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try ( MuninnPageCache pageCache = createPageCache( fs, 2, blockCacheFlush( tracer ), cursorTracerSupplier );
         PagedFile pagedFile = pageCache.map( file( &amp;quot;a&amp;quot; ), 8 ) )
   {
       try ( PageCursor cursor = pagedFile.io( 0, PF_SHARED_READ_LOCK ) )
       {
           assertTrue( cursor.next() );
       }
       cursorTracer.reportEvents();
       assertNotNull( cursorTracer.observe( Fault.class ) );
       assertEquals( 1, cursorTracer.faults() );
       assertEquals( 1, tracer.faults() );

       long clockArm = pageCache.evictPages( 1, 1, tracer.beginPageEvictions( 1 ) );
       assertThat( clockArm, is( 1L ) );
       assertNotNull( tracer.observe( Evict.class ) );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出，第一步是创建 pageCache，第二步是 pageCache 的 map 方法得到 pagedFile，然后调用 io 方法得到 PageCursor ，然后cusor是一个迭代器。&lt;/p&gt;

&lt;h2 id=&#34;四-commonabstractstore-格式&#34;&gt;四、CommonAbstractStore 格式&lt;/h2&gt;

&lt;p&gt;这个是一个存储格式的基本实现类，我们现在任何一个Store上面打断点，然后在 CommonAbstractStore 中打断点，开始调试即可。以 NodeStore 为例，在构造方法打断点，在 CommonAbstractStore 的 checkAndLoadStorage 打断点。&lt;/p&gt;

&lt;p&gt;我们找到了调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;neoStores = factory.openAllNeoStores( true );
return openNeoStores( createStoreIfNotExists, StoreType.values() );
new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
getOrCreateStore( type );
store = openStore( storeType );
Object store = type.open( this );
return neoStores.createDynamicArrayStore( getStoreName(), IdType.NODE_LABELS, GraphDatabaseSettings.label_block_size );

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 checkAndLoadStorage 方法上停下来，此时的storeType是 &lt;code&gt;NODE_LABEL&lt;/code&gt; ，也就是节点的Label,：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// /Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db/neostore.nodestore.db.labels
try ( PagedFile pagedFile = pageCache.map( storageFileName, pageSize, ANY_PAGE_SIZE ) ) 

extractHeaderRecord( pagedFile );
createStore( pageSize );
loadStorage( filePageSize );
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;四-abstractdynamicstore-文件格式&#34;&gt;四、AbstractDynamicStore 文件格式&lt;/h2&gt;

&lt;p&gt;neo4j 中对于字符串等变长值的保存策略是用一组定长的 block 来保存，block之间用单向链表链接。&lt;/p&gt;

&lt;p&gt;例如 neostore.propertystore.db.arrays 和 neostore.propertystore.db.strings 类 AbstractDynamicStore 实现了该功能，文件结构在 DynamicRecordFormat 中有解释。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static final int RECORD_HEADER_SIZE = 1/*header byte*/ + 3/*# of bytes*/ + 8/*max size of next reference*/;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
  </channel>
</rss>