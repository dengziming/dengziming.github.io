<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据分析师之旅</title>
    <link>https://dengziming.github.io/</link>
    <description>Recent content on 数据分析师之旅</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 20 Aug 2017 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="https://dengziming.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://dengziming.github.io/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>https://dengziming.github.io/about/</guid>
      
        <description>&lt;p&gt;Hugo is a static site engine written in Go.&lt;/p&gt;

&lt;p&gt;It makes use of a variety of open source projects including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cobra&#34;&gt;Cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;Viper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/jWalterWeatherman&#34;&gt;J Walter Weatherman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cast&#34;&gt;Cast&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Java内存区域与内存溢出异常</title>
      <link>https://dengziming.github.io/post/java/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/</guid>
      
        <description>

&lt;h2 id=&#34;一-概述&#34;&gt;一、概述&lt;/h2&gt;

&lt;p&gt;我们的代码运行过程中的，虚拟机管理着内存的分配和使用。我们今天先了解内存区域，使我们深入了解JVM的第一步。&lt;/p&gt;

&lt;h2 id=&#34;二-运行时数据区域&#34;&gt;二、运行时数据区域&lt;/h2&gt;

&lt;p&gt;根据java虚拟机规范，虚拟机内存区域结构大概如图，我们详细介绍每个区域：
&lt;img src=&#34;./_image/2018-04-16-22-37-47.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-程序计数器&#34;&gt;1.程序计数器&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;我们简单想象有个helloworld程序运行。代码最终是一步一步解释为机器码，所以有一个程序计数器，记录当前的代码执行位置，也就是行号。&lt;/li&gt;
&lt;li&gt;假如有两个线程执行helloworld，那每个线程执行到第几行都需要各自保存，每个线程都有独立的计数器。&lt;/li&gt;
&lt;li&gt;如果是循环打印，字节码需要改变程序计数器的值取到下一条指令。&lt;/li&gt;
&lt;li&gt;如果是java方法，计数器指向的是代码位置，如果是native方法，计数器为空。&lt;/li&gt;
&lt;li&gt;程序计数器是唯一一个没有 outofmermoryError情况的区域。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-java虚拟机栈&#34;&gt;2. java虚拟机栈&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;和程序计数器一样，java虚拟机栈也是线程私有。&lt;/li&gt;
&lt;li&gt;我们debug代码的时候，debugger会显示某个正在运行的线程，然后自上而下一次为每个方法对应的栈帧，每个栈帧保存局部变量等，每个方法执行结束，就有一个栈帧入栈到出栈：
&lt;img src=&#34;./_image/2018-04-16-22-48-02.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;局部变量表存储的是各自基本数据类型（8种）和引用。64位的long和double占用两个变量空间，其余的是一个，一般来说，局部变量表的大小是固定的。&lt;/li&gt;
&lt;li&gt;栈有两种异常，Stack OverflowError 和 outofmermoryError，前者是方法调用栈太多，例如递归，后者是内存不够。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;3-本地方法栈&#34;&gt;3.本地方法栈&lt;/h3&gt;

&lt;p&gt;和栈类似，主要负责本地方法，实现上很自由，有的直接和栈合二为一。也有两种异常。&lt;/p&gt;

&lt;h3 id=&#34;4-java-堆&#34;&gt;4.java 堆&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;内存最大，线程共享，作用就是存放实例（几乎所有的实例，但是技术发展导致没这么绝对）。&lt;/li&gt;
&lt;li&gt;垃圾回收采用分带收集，所以堆包括了新生代、老年代。还可以细分为：eden、from survivor、to survivor。&lt;/li&gt;
&lt;li&gt;可能也有线程私有的内存缓冲区，只是为了更好分配和回收。&lt;/li&gt;
&lt;li&gt;只要逻辑上连续即可，无需物理连续。大小可以调节（-Xmx和-Xms）&lt;/li&gt;
&lt;li&gt;无法扩展并且没有内存分配示例，会有OutOfmermoryError。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;5-方法区&#34;&gt;5.方法区&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;我们运行了一个helloworld方法，对应的主类和常量、静态变量、编译后的代码都需要放在方法去，逻辑上和堆的一个部分。&lt;/li&gt;
&lt;li&gt;基本上不需要垃圾回收，所以有人叫他永久带，实际上只是一开始的JVM将它放在了永久代的而已。但是从1.7开始，已经把原本放在永久代的字符串常量池移出, 放在堆中。&lt;/li&gt;
&lt;li&gt;方法去无法满足内训分配需求，也会有OutOfmermoryError，但是从1.7开始，不在这样。&lt;/li&gt;
&lt;li&gt;类的元数据, 字符串池, 类的静态变量将会从永久代移除, 放入Java heap或者native memory.其中建议JVM的实现中将类的元数据放入 native memory, 将字符串池和类的静态变量放入java堆中. 这样可以加载多少类的元数据就不在由MaxPermSize控制, 而由系统的实际可用空间来控制.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;6-运行时常量池&#34;&gt;6. 运行时常量池&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;是方法区的一部分，.class 文件中除了有类的版本、字段、方法等信息，还有常量池，用于存放编译器的自变量和符号引用。这部分在加载后会进入方法去的运行时常量池。&lt;/li&gt;
&lt;li&gt;.class文件的每一部分格式都很严格。但是常量池很宽松。&lt;/li&gt;
&lt;li&gt;java语言并不要求一定要常量只能在编译时候产生，运行期间也可以将新的常量放入常量池。这种特性用的最多的是String的intern()方法。&lt;/li&gt;
&lt;li&gt;也会有OutOfmermoryError。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;7-直接内存&#34;&gt;7. 直接内存&lt;/h3&gt;

&lt;p&gt;这部分是由于java的NIO引起的&lt;/p&gt;

&lt;h2 id=&#34;三-hotspot对象探秘&#34;&gt;三、Hotspot对象探秘&lt;/h2&gt;

&lt;h3 id=&#34;1-对象的创建&#34;&gt;1.对象的创建&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;从写代码看，对象的创建（例如克隆，反序列化）只是一个new关键字，然后我们调试可以看到其实还执行了 初始化的&lt;init&gt;方法。&lt;/li&gt;
&lt;li&gt;从虚拟机角度看，首先是检查对应的引用能否在常量池中定位到一个类的符号引用，并检查是否已经加载解析和初始化过，如果没有，就要开始加载。&lt;/li&gt;
&lt;li&gt;类的加载我们以后讨论，加载完后需要分配内存。对象大小在加载完成后就已经完全确定了，如果java堆内存是绝对规整的，那么需要维护一个指针指向当前分配到的位置。如果不连续需要维护一个空闲列表。&lt;/li&gt;
&lt;li&gt;分配内存可能是多线程的，有安全问题。要么加锁，要么给每个内存一个预先分配的小内存，成为本地分配缓存。&lt;/li&gt;
&lt;li&gt;内存分配完成后需要初始化为0值，然后进行元数据设置，例如是那个类的实例，GC代等。&lt;/li&gt;
&lt;li&gt;这时候对象创建才刚刚开始，执行 &lt;init&gt;方法。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-对象的内存布局&#34;&gt;2.对象的内存布局&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;对象在内存中的存储布局可以分为3部分，对象头，实例数据、对象填充。对象头第一部分存储运行时数据，第二部分是类型指针。运行时数据hash码、分带年龄等。类型指针指向类元数据，数组还要记录数组长度。&lt;/li&gt;
&lt;li&gt;第二部分为实例数据，就是代码里面定义的数据内容&lt;/li&gt;
&lt;li&gt;第三部分没什么含义，仅仅是占位符。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;3-对象的访问&#34;&gt;3.对象的访问&lt;/h3&gt;

&lt;p&gt;1.对象的访问有两种方式，第一种是句柄。java堆会有一块专门的内存作为句柄池，栈存储的是句柄地址，句柄包含了对象示例数据（堆）和类型数据（方法区）各自的指针。
2. 第二中方法是指针访问，栈存储的直接是对象地址，堆的对象布局必须考虑如何放置访问类型数据。
3. 句柄最大的好处是对象改变时不需要改变栈的地址，使用直接内存好处是访问速度快，节省时间。&lt;/p&gt;

&lt;h2 id=&#34;四-实战-outofmermoryerror&#34;&gt;四、实战 OutOfmermoryError&lt;/h2&gt;

&lt;p&gt;除了程序计数器，都会有OutOfMermoryError异常，我们实战一下，在IDEA编写代码，并学习几个参数。&lt;/p&gt;

&lt;h3 id=&#34;1-堆溢出&#34;&gt;1.堆溢出&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 17/04/2018.
 * VM ARGS: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError
 */
public class HeapOOM {
    static class OOMObject{}
    public static void main(String[] args) {
        List&amp;lt;OOMObject&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        while (true){list.add(new OOMObject());}
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VM ARGS:  -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError
马上报错：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;java.lang.OutOfMemoryError: Java heap space
Dumping heap to java_pid98722.hprof ...
Heap dump file created [27798040 bytes in 0.363 secs]
Exception in thread &amp;quot;main&amp;quot; java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3210)
	at java.util.Arrays.copyOf(Arrays.java:3181)
	at java.util.ArrayList.grow(ArrayList.java:261)
	at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235)
	at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227)
	at java.util.ArrayList.add(ArrayList.java:458)
	at io.github.dengziming.session2.HeapOOM.main(HeapOOM.java:21)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如何查看对文件和分析，我们后续有内容。简单分析两点：
1. 如果是内存泄露，通过GC工具查看泄露对象的GC引用链，定位代码位置
2. 如果内存溢出，可以考虑调大参数。 -Xmx -Xms&lt;/p&gt;

&lt;h3 id=&#34;2-虚拟机栈和本地方法溢出&#34;&gt;2.虚拟机栈和本地方法溢出&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 18/04/2018.
 * VM ARGS -Xss128k
 */
public class JavaVMStackSOF {

    private int stackLenth = 1;
    public void stackLeak(){
        stackLenth ++;
        stackLeak();
    }

    public static void main(String[] args) {
        JavaVMStackSOF oom = new JavaVMStackSOF();
        try{
            oom.stackLeak();
        }catch (Exception e){
            System.out.println(&amp;quot;stackLenth: &amp;quot; + oom.stackLenth);
            throw e;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Exception in thread &amp;ldquo;main&amp;rdquo; java.lang.StackOverflowError
结果表明，单线程下，无论是栈帧太大还是栈容量太小，内存无法分配的时候，都是Stack Overflow，如果多线程到不太一样。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 18/04/2018.
 * VM ARGS: -Xss20M
 */
public class JavaVMStackOOM {
    private void dontStop(){
        while (true){}
    }
    public void stackLeakByStack(){
        while (true){
            Thread thread = new Thread() {
                @Override
                public void run() {
                    dontStop();
                }
            };
            thread.start();
        }
    }

    public static void main(String[] args) {
        JavaVMStackOOM oom = new JavaVMStackOOM();
        oom.stackLeakByStack();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行完电脑卡死了，算了。这个内存越大反而容易耗尽资源，因为机器内存是固定的，减少容量可以获得更多的线程数。
注意：这时候通过减少内存解决内存溢出的方法，没有经验是不知道的。&lt;/p&gt;

&lt;h3 id=&#34;3-方法区和运行时常量池溢出&#34;&gt;3. 方法区和运行时常量池溢出&lt;/h3&gt;

&lt;p&gt;String.intern() 的含义是返回在代表常量池中这个字符串的对象。如果没有，就将这个字符串放进常量池，并返回引用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 18/04/2018.
 * 
 * vm args: -XX:PermSize=10M -XX:MaxPermSize=10M
 */
public class RuntimeConstantPoolOOM {

    public static void main(String[] args) {

        List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        int i=0;
        while(true){
            list.add(String.valueOf(i++).intern());
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不好意思这个方法没有达到效果：
Java HotSpot&amp;trade; 64-Bit Server VM warning: ignoring option PermSize=10M; support was removed in 8.0
Java HotSpot&amp;trade; 64-Bit Server VM warning: ignoring option MaxPermSize=10M; support was removed in 8.0
jdk1.7 已经把原本放在永久代的字符串常量池移出, 放在堆中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    public static void main(String[] args) {

        while(true){
            Enhancer enhancer = new Enhancer();
            enhancer.setSupperClass(OOMObject.class);
            enhancer.setUserCache(false);
            enhancer.setCallBack(new MethodInterceptor(){
                public Object intercept(Object obj , Method method , Object []args , MethodProxy proxy)throw Throwable{
                    return proxy.invokeSuper(obj , args);
                }
            });
            enhancer.create();
        }
    }
    static class OOMObject{

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个也是一样。因为类的元数据, 字符串池, 类的静态变量从永久代移除, 放入Java heap或者native memory.其中建议JVM的实现中将类的元数据放入 native memory, 将字符串池和类的静态变量放入java堆中.&lt;/p&gt;

&lt;p&gt;String.intern() 在1.6和1.7有不同的实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class RuntimeConstantPoolOOM2 {

    public static void main(String[] args) {

        String str1 = new StringBuilder().append(&amp;quot;计算机&amp;quot;).append(&amp;quot;软件&amp;quot;).toString();
        System.out.println(str1.intern() == str1);

        String str2 = new StringBuilder().append(&amp;quot;ja&amp;quot;).append(&amp;quot;va&amp;quot;).toString();
        System.out.println(str2.intern() == str2);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.6输出为false和false
1.7输出为true和false
原因是：1.6 的 intern返回在永久代的实例，如果是第一次遇到，会先复制到永久代。1.7不会复制到永久代，只是记录首次出现的实例的引用。
所以1.6的时候两个intern返回的是永久代的引用而不是字符串，1.7的时候 java 这个串已经出现过了。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>垃圾收集器和内存分配策略</title>
      <link>https://dengziming.github.io/post/java/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B9%9F%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B9%9F%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</guid>
      
        <description>

&lt;h2 id=&#34;一-概述&#34;&gt;一、概述&lt;/h2&gt;

&lt;p&gt;前面我们已经知道，栈的内存是固定的，栈帧多大都是已知。而堆就不一样了。&lt;/p&gt;

&lt;h2 id=&#34;二-判断对象存活状态&#34;&gt;二、判断对象存活状态&lt;/h2&gt;

&lt;p&gt;垃圾回收的第一件事就是判断对象是否还活着，是否可以回收。&lt;/p&gt;

&lt;h3 id=&#34;1-引用计数法&#34;&gt;1.引用计数法&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;给对象添加一个引用计数器，被引用时加一，失效时减一，计数器为0就不能被使用了。这种方法无法解决相互引用问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class ReferenceCountingGC {
    public Object instance = null;
    private static final int _1M = 1024 * 1024;
    //很大的内存
    private byte[] bigSize = new byte[2 * _1M];

    public static void main(String[] args) {
        testGC();
    }

    public static void testGC() {

        ReferenceCountingGC obj1 = new ReferenceCountingGC();
        ReferenceCountingGC obj2 = new ReferenceCountingGC();
        obj1.instance = obj2;
        obj2.instance = obj1;

        obj1 = null;
        obj2 = null;

        System.gc();
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的日志信息：
TODO 日志分析，gc文件查看&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;
4603k -&amp;gt; 210k

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;意味着并没有因为相互引用就不回收，说明虚拟机并不是通过引用计数实现的。&lt;/p&gt;

&lt;h3 id=&#34;2-可达性分析算法&#34;&gt;2. 可达性分析算法&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;主流语言都是通过可达性分析实现垃圾回收。就是通过一系列GCRoots作为七点，判断有没有被引用。如果一个对象到GCRoots没有引用链，用图论的语言就是不可达，那么可以回收。&lt;/li&gt;
&lt;li&gt;java的GCRoots包括 虚拟机栈（栈帧的本地变量表）引用的对象。、方法区中类静态属性引用的对象、方法区中常量引用的对象，本地方法（native方法）引用的对象。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;3-理解引用&#34;&gt;3.理解引用&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;引用实际上很重要，上面的两张方法都是通过引用来判断。如果reference类型的数据中存储的数值代表另一个内存的起始地址，就称这块内存代表一个引用。&lt;/li&gt;
&lt;li&gt;一个对象在这种定义下只有引用和被引用两种关系。所以这个定义太过狭隘。&lt;/li&gt;
&lt;li&gt;jdk1.2后java对引用的概念进行了扩充。分为强引用、软引用、弱引用、虚引用。&lt;/li&gt;
&lt;li&gt;四种引用相关的只是可以查询资料。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;4-最后的判断&#34;&gt;4.最后的判断&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;即使判断为不可达对象，也只是处于“缓刑”阶段。要彻底宣告死亡还得经过两次判断。第一次标记后进行筛选，筛选条件是该对象是否有必要执行finalize方法，当对象没有覆盖finalize方法或者已经被调用过，将会被标记为没必要执行。&lt;/li&gt;
&lt;li&gt;如果被标记为有必要执行，会被放在一个F-Queue中，稍后放在一个虚拟机级别的线程中执行这个finalize，但是不会等待它执行。&lt;/li&gt;
&lt;li&gt;finalize是对象拯救自己最后的机会，只要把自己引用到某个对象即可。但是每个对象的finalize只会调用一次，所以下面的代码拯救自己一次。第二次失败了。&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class FinalizeEscapeGC {

    public static FinalizeEscapeGC SAVE_HOOK = null;

    public void isAlive(){
        System.out.println(&amp;quot;yes , i am alive&amp;quot;);
    }

    @Override
    protected void finalize() throws Throwable {
        super.finalize();
        System.out.println(&amp;quot;finalize method executed&amp;quot;);
        FinalizeEscapeGC.SAVE_HOOK = this;
    }

    public static void main(String[] args) throws Exception {
        SAVE_HOOK = new FinalizeEscapeGC();

        // 对象第一次成功拯救自己
        SAVE_HOOK = null;
        System.gc();

        //finalize 优先级低，等待执行
        Thread.sleep(1000);

        if (null != SAVE_HOOK) {
            SAVE_HOOK.isAlive();
        }else {
            System.out.println(&amp;quot;no, i am dead&amp;quot;);
        }

        //对象第二次拯救自己
        SAVE_HOOK = null;
        System.gc();
        //finalize 优先级低，等待执行
        Thread.sleep(1000);

        if (null != SAVE_HOOK) {
            SAVE_HOOK.isAlive();
        }else {
            System.out.println(&amp;quot;no, i am dead&amp;quot;);
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种方式太不推荐了。&lt;/p&gt;

&lt;h3 id=&#34;5-回收方法区&#34;&gt;5.回收方法区&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;很多人认为方法去是没有垃圾回收的，其实只是方法区垃圾回收效率低。&lt;/li&gt;
&lt;li&gt;永久代的垃圾回收主要是两部分，一部分是常量，另一部分是无用的类。废弃常量和堆的回收很类似，但是判断一个类是否是无用的类，就比较麻烦。&lt;/li&gt;
&lt;li&gt;无用的类判断条件是：所有实例都被回收了，ClassLoader被回收了，无法在任何地方通过反射得到该类的方法。&lt;/li&gt;
&lt;li&gt;在大量使用反射、动态代理、CGlib等技术的地方，频繁自定义classLoader的地方都要虚拟机具备类卸载的功能，保证永久代不溢出。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;三-垃圾回收算法&#34;&gt;三、垃圾回收算法&lt;/h2&gt;

&lt;h3 id=&#34;1-标记-清楚&#34;&gt;1.标记-清楚&lt;/h3&gt;

&lt;p&gt;对需要回收的对象标记，然后回收。标记和清除效率都不高，而且容易产生碎片。&lt;/p&gt;

&lt;h3 id=&#34;2-复制算法&#34;&gt;2.复制算法&lt;/h3&gt;

&lt;p&gt;将空间分为相同的两块，每次回收后移动到另一边。存活率较高时效率低，另外浪费一半空间&lt;/p&gt;

&lt;h3 id=&#34;3-标记-整理&#34;&gt;3.标记-整理&lt;/h3&gt;

&lt;p&gt;标记然后移动。&lt;/p&gt;

&lt;h3 id=&#34;4-分代回收&#34;&gt;4.分代回收&lt;/h3&gt;

&lt;p&gt;对不同对象用不同方法。&lt;/p&gt;

&lt;h2 id=&#34;四-算法实现&#34;&gt;四、算法实现&lt;/h2&gt;

&lt;p&gt;TODO&lt;/p&gt;

&lt;h2 id=&#34;五-常见垃圾收集器&#34;&gt;五、常见垃圾收集器&lt;/h2&gt;

&lt;h3 id=&#34;1-todo&#34;&gt;1.TODO&lt;/h3&gt;

&lt;h3 id=&#34;2-阅读gc日志&#34;&gt;2.阅读GC日志&lt;/h3&gt;

&lt;p&gt;gc 参数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;JVM的GC日志的主要参数包括如下几个：

-XX:+PrintGC 输出GC日志

-XX:+PrintGCDetails 输出GC的详细日志

-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）

-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）

-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息

-Xloggc:../logs/gc.log 日志文件的输出路径
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;日志：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.756: [Full GC (System) 0.756: [CMS: 0K-&amp;gt;1696K(204800K), 0.0347096 secs] 11488K-&amp;gt;1696K(252608K), [CMS Perm : 10328K-&amp;gt;10320K(131072K)], 0.0347949 secs] [Times: user=0.06 sys=0.00, real=0.05 secs]  
5.617: [GC 5.617: [ParNew: 43296K-&amp;gt;7006K(47808K), 0.0136826 secs] 44992K-&amp;gt;8702K(252608K), 0.0137904 secs] [Times: user=0.03 sys=0.00, real=0.02 secs]  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解释如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;5.617（时间戳）: [GC（Young GC） 5.617（时间戳）: [ParNew（使用ParNew作为年轻代的垃圾回收器）: 43296K（年轻代垃圾回收前的大小）-&amp;gt;7006K（年轻代垃圾回收以后的大小）(47808K)（年轻代的总大小）, 0.0136826 secs（回收时间）] 44992K（堆区垃圾回收前的大小）-&amp;gt;8702K（堆区垃圾回收后的大小）(252608K)（堆区总大小）, 0.0137904 secs（回收时间）] [Times: user=0.03（Young GC用户耗时） sys=0.00（Young GC系统耗时）, real=0.02 secs（Young GC实际耗时）]  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个是时间戳，然后是GC或者FullGC代表垃圾回收类型。然后中括号括起来的是年轻代垃圾回收，第一个是垃圾回收器，例如：DefNew，PSYoungGen等，然后是年轻代的容量变化和总用量。中括号外的是堆的总容量。
后面三个是时间，分别是user,sys,real。分别是用户态CPU时间、内核态CPU时间、墙钟时间，墙钟时间包含各种非运算的等待耗时，例如IO阻塞，CPU时间则不包含这些世界，当计算机是多核这些世界会累加，所以看到real或者sys超过real也正常。&lt;/p&gt;

&lt;h3 id=&#34;3-垃圾收集器参数&#34;&gt;3.垃圾收集器参数&lt;/h3&gt;
</description>
      
    </item>
    
    <item>
      <title>spark-天池o2o竞赛</title>
      <link>https://dengziming.github.io/post/project/tianchi/%E5%A4%A9%E6%B1%A0o2o%E7%AB%9E%E8%B5%9B/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/project/tianchi/%E5%A4%A9%E6%B1%A0o2o%E7%AB%9E%E8%B5%9B/</guid>
      
        <description>

&lt;h1 id=&#34;优惠券敏感人群分析&#34;&gt;优惠券敏感人群分析&lt;/h1&gt;

&lt;p&gt;源代码地址放在Reward处。&lt;/p&gt;

&lt;p&gt;互联网给我们老百姓带来的最直接的福利要从补贴开始说起，从滴滴快的烧钱大战，美团饿了么的外卖红包，补贴的硝烟似乎从未停止。补贴不仅仅是发发优惠券那么简单的事，补贴是一门纯技术活。告别了快速占领市场时粗犷的烧钱方式，进入成熟期互联网公司大都开始了精细化运营，如何把补贴用在最需要的用户身上，如何在降低补贴的同时带来更多用户和订单量的提升，毕竟商业变现是每个公司必须面对的问题，实现盈利就要降低成本和提高收入。这一次，将让我们一起来探讨下高频产品外卖行业的高效补贴方式。
如何选定筛选优惠敏感度的指标，来发现优惠敏感用户，一般认为是下单意愿强弱受优惠和价格高低影响大的用户，而运营要做的就是根据用户的消费水平，历史补贴情况，及主动寻找优惠行为等分析来确定如何通过补贴提高用户下单率。主动获取优惠维度筛选，比如有以下几个行为：分享渠道领取优惠券、参加商家满减凑单活动、具有拆单行为的用户、高频点折扣菜、从banner活动落地页获得优惠。综合考虑用户的历史订单补贴率、历史单均价以及主动获取优惠行为，初步确定这些指标后，即可以制定初版探索方案验证这些指标是否能带来提升，然后再进入数据分析挖掘阶段寻找最佳阈值。
我们这次通过完成天池大数据竞赛的一个赛题，来更加深入理解这个问题。我们的目标很简单，就是通过已有的数据分析出用户接下来的是否会使用优惠券。&lt;/p&gt;

&lt;h2 id=&#34;一-赛题背景&#34;&gt;一、赛题背景&lt;/h2&gt;

&lt;p&gt;O2O（Online to Offline）消费
O2O：是指将线下的商务机会与互联网结合，让互联网成为线下交易的平台
以优惠券盘活老用户或吸引新客户进店消费是O2O的一种重要营销方式&lt;/p&gt;

&lt;h3 id=&#34;1-赛题目标&#34;&gt;1.赛题目标&lt;/h3&gt;

&lt;p&gt;个性化投放优惠券，提高核销率
通过分析建模，精准预测用户是否会在规定时间内使用相应优惠券
已知：用户在2016年1月1日至2016年6月30日之间真实线上线下消费行为
预测：用户在2016年7月领取优惠券后15天以内的使用情况
评价标准：优惠券核销预测的平均AUC（ROC曲线下面积）。即对每个优惠券coupon_id单独计算核销预测的AUC值，再对所有优惠券的AUC值求平均作为最终的评价标准。 关于AUC的含义与具体计算方法，可参考维基百科&lt;/p&gt;

&lt;h3 id=&#34;2-数据简介&#34;&gt;2.数据简介&lt;/h3&gt;

&lt;p&gt;一共四个表格，前两个表格是数据，第三个是用来预测的数据，第四个是提交的文件格式。：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Table 1: 用户线下消费和优惠券领取行为，ccf_offline_stage1_train.csv
Table 2: 用户线上点击/消费和优惠券领取行为，ccf_online_stage1_train
Table 3：用户O2O线下优惠券使用预测样本，ccf_offline_stage1_test_revised.csv
Table 4：选手提交文件字段，其中user_id,coupon_id和date_received均来自Table 3,而Probability为预测值
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TABLE 1： 用户线下消费和优惠券领取行为
&lt;img src=&#34;../images/2018-03-21-17-40-02.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Table 2: 用户线上点击/消费和优惠券领取行为
&lt;img src=&#34;../images/2018-03-21-17-40-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Table 3：用户O2O线下优惠券使用预测样本
&lt;img src=&#34;../images/2018-03-21-17-41-12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Table 4选手提交文件字段
其中user_id,coupon_id和date_received均来自Table 3,而Probability为预测值
&lt;img src=&#34;../images/2018-03-21-17-41-25.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;二-初步分析和项目设计&#34;&gt;二、初步分析和项目设计&lt;/h2&gt;

&lt;h3 id=&#34;1-认识数据&#34;&gt;1.认识数据&lt;/h3&gt;

&lt;h4 id=&#34;table1-分析结构&#34;&gt;TABLE1 分析结构&lt;/h4&gt;

&lt;p&gt;数据采样：
&lt;img src=&#34;../images/2018-03-22-14-11-46.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;特点：
– 标题：用户线下消费和优惠券领取行为
– 场景：线下
– 行为：消费、优惠券领取
– 数据：优惠券领取、使用情况，消费情况，用户常活动地点与最近门店距离
分析1：用户行为有三种情况
– 领了优惠券 &amp;amp;&amp;amp; 未消费 =&amp;gt; 负样本 （Date=null &amp;amp; Coupon_id != null）
– 没领优惠券 &amp;amp;&amp;amp; 已消费（Date!=null &amp;amp; Coupon_id = null）
– 领了优惠券 &amp;amp;&amp;amp; 已消费（Date!=null &amp;amp; Coupon_id != null）
– 总结：本数据作为刻画用户特点的主要依据较为合理
分析2：优惠率
– 总结：有可能用户会根据优惠率来决定是否进行消费
分析3：距离
– 离用户近的门店可能会总领取优惠券，但不一定会使用。
– 离用户远的门店如果有优惠券，则可能会为了很大的优惠率专程去使用。
总结
– 本数据集主要刻画线下用户特征。&lt;/p&gt;

&lt;h4 id=&#34;table-2-分析&#34;&gt;TABLE 2 分析&lt;/h4&gt;

&lt;p&gt;数据采样：
&lt;img src=&#34;../images/2018-03-22-14-12-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;特点：
– 标题：用户线上点击/消费和优惠券领取行为
– 场景：线上
– 行为：点击、消费、优惠券领取
– 数据：用户是否点击。购买。领取优惠券。
分析1：用户行为有三种情况
– 领了优惠券 &amp;amp;&amp;amp; 未消费 = 负样本（Date=null &amp;amp; Coupon_id != null）
– 没领优惠券 &amp;amp;&amp;amp; 已消费 （Date!=null &amp;amp; Coupon_id = null）
– 领了优惠券 &amp;amp;&amp;amp; 已消费 （Date!=null &amp;amp; Coupon_id != null）
分析2：用户点击、消费、优惠券情况
– 用户点击了 &amp;amp;&amp;amp; 没领优惠券 &amp;amp;&amp;amp; 未消费 =&amp;gt; 负样本
– 用户点击了 &amp;amp;&amp;amp; 领了优惠券 &amp;amp;&amp;amp; 未消费
– 用户点击了 &amp;amp;&amp;amp; 领了优惠券 &amp;amp;&amp;amp; 已消费
– 用户点击了 &amp;amp;&amp;amp; 没领优惠券 &amp;amp;&amp;amp; 已消费
– 用户没点击
总结
– 本数据集主要刻画线上用户特征。&lt;/p&gt;

&lt;p&gt;然后大家可以针对数据做一些统计然后将数据进行可视化展示，不过网络上已经有人做好了统计，我们直接从网络上面下载过了，下面是基本的一些指标：
&lt;img src=&#34;../images/2018-03-22-14-16-35.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2018-03-22-14-17-00.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2018-03-22-14-24-18.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2018-03-22-14-24-33.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-项目设计&#34;&gt;2.项目设计&lt;/h3&gt;

&lt;p&gt;提供数据的区间是2016-01-01~2016-06-30，预测七月份用户领券使用情况，即用或者不用，转化为二分类问题，然后通过分类算法预测结果。首先就是特征工程，其中涉及对数据集合的划分，包括提取特征的区间和训练数据区间。接着就是从特征区间中提取特征，包括用户特征、商户特征、优惠券特征、用户商户组合特征、用户优惠券组合特征。然后使用GBDT、RandomForest、LR进行基于rank的分类模型融合，模型完成以后我们需要进行验证。&lt;/p&gt;

&lt;h3 id=&#34;3-数据预览和简单实现&#34;&gt;3.数据预览和简单实现&lt;/h3&gt;

&lt;p&gt;为了更加深入理解项目目标，我们通过python脚本一步一步理解一下数据，同时熟悉一下python相关的API的使用，对数据进行简单的统计。&lt;/p&gt;

&lt;h4 id=&#34;1-分析正负数据样本&#34;&gt;1. 分析正负数据样本&lt;/h4&gt;

&lt;p&gt;新建一个python脚本&lt;code&gt;tianchi_1.py&lt;/code&gt;，
加上下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;

data = pd.read_csv(path_to_offline)

print(data.head())
print(data.shape[0])
print(data.shape[1])

# 最终发现数据有：1754884行

# 我们发现 其中有很多Coupon_id为null的数据。我们做的是优惠券使用预测，可是这些数据都没有用优惠劵，所以，首先将这些数据挑选出来。

# 不为空的数据
data1 = data[data[&#39;coupon_id&#39;] != &amp;quot;null&amp;quot;]
print(data1.head())
print(data1.shape)

# 为空的数据
data2 = data[data[&#39;coupon_id&#39;] == &amp;quot;null&amp;quot;]
print(data2.head())
print(data2.shape)

# 最终发现null数据有：701602行，不为空的：1053282行，保存为.csv备用


# 这两段代码保存数据
data1.to_csv(&#39;ccf_offline_stage1_train_NoNull.csv&#39;,index=False,header=True)
data2.to_csv(&#39;ccf_offline_stage1_train_Null.csv&#39;,index=False,header=True)
print &amp;quot;检查数据&amp;quot;

# 首先检查没有优惠券的数据
data = data2

test = data[data[&#39;date&#39;] == &amp;quot;null&amp;quot;]
print(test.head())
print(&amp;quot;没有优惠券的数据中，没有消费的条数为：&amp;quot;)
print(test.shape[0])

# 这里打印出来发现没有消费的条数为0？
# 阿里提供数据的时候提供的都是消费数据，因为没有领取优惠劵，也没有实际消费的，在阿里不会能留下数据给我们！

# 所以，我们在预测的时候，如果没有领取优惠券，可以直接预测为消费！ 当然数据里面没有这种情况。


# 再看优惠券不为空的数据集合
data = data1

test1 = data[data[&#39;date&#39;] == &amp;quot;null&amp;quot;]
print(test1.head())
print(&amp;quot;有优惠券的数据中，没有消费的条数为：&amp;quot;)
print(test1.shape[0])
test1.to_csv(&#39;ccf_offline_stage1_train_N.csv&#39;, index=False, header=True)


test2 = data[data[&#39;date&#39;] != &amp;quot;null&amp;quot;]
print(test2.head())
print(&amp;quot;有优惠券的数据中，并且消费的条数为：&amp;quot;)
print(test2.shape[0])
test2.to_csv(&#39;ccf_offline_stage1_train_P.csv&#39;, index=False, header=True)

# 正样本：75382个 负样本 977900个
# 那么平均的使用率为75382/1053282=0.071569
print (test2.shape[0] * 1.0 / (test1.shape[0] + test2.shape[0]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相关代码的含义我们已经解释清楚了，只需要大家根据注释一步一步运行即可。另外最后运行完成后会在当前代码下生成四份数据，作为接下来的数据实验样本。&lt;/p&gt;

&lt;h4 id=&#34;2-简单进行topn分析&#34;&gt;2. 简单进行topN分析&lt;/h4&gt;

&lt;p&gt;重新新建一个python文件&lt;code&gt;tianchi_2.py&lt;/code&gt;，添加下面的代码，一步一步运行查看。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;

data = pd.read_csv(path_to_offline)

# 输出排名前列和后列的商户ID ，发现了两级分化严重啊，小店铺真的可怜，看来不一定做生意就能赚钱啊。
d1 = data[&#39;merchant_id&#39;]
print(d1.value_counts())

# 输出排名前列和后列的用户ID ，发现用户层两级分化更严重啊，土豪的日志就是买买买，但是穷人们。。。
d1 = data[&#39;user_id&#39;]
print(d1.value_counts())

# 直观感觉土豪估计以后还是会买买买，穷人基本上不会买了。中间层才有数据分析和挖掘的价值。

# 同理我们统计一下线上的店铺信息
print &amp;quot;统计线下信息&amp;quot;
data = pd.read_csv(path_to_online)

# 线上线下就是不一样，线上交易明显量更多
d1 = data[&#39;merchant_id&#39;]
print(d1.value_counts())

# 输出排名前列和后列的用户ID ，发现线上用户消费更多，线上土豪的更土豪了
d1 = data[&#39;user_id&#39;]
print(d1.value_counts())
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-特征工程&#34;&gt;3.特征工程&lt;/h4&gt;

&lt;p&gt;然后可以用一个简单的模型运行一下，思路很简单，就是先提取特征和正负例样本，生成模型，然后对数据进行预测。我们直接用下面的几个特征：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#用户相关特征：
#FUser1 线下领取优惠券后消费次数
#FUser2 线下消费总次数
#商户相关特征：
#FMer1 线下总领取优惠券次数
#FMer2 线下总领取优惠券后消费次数
#FMer3 线下总消费次数
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先我们提取用户特征，新建python文件&lt;code&gt;tianchi_3.py&lt;/code&gt;，添加下面的代码，提取用户的两个特征，保存到文件中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;

OffTrain = pd.read_csv(path_to_offline, low_memory=False)

# 头文件信息，输出：user_id,merchant_id,coupon_id,discount_rate,distance,date_received,date
print OffTrain.head()

# 把其中出现的所有的用户ID都统计出来
FUser = OffTrain[[&#39;user_id&#39;]]
print(&amp;quot;FUser.shape=&amp;quot;, FUser.shape)

# 去重，总共有539438个独立用户
FUser.drop_duplicates(inplace=True)
OffTrainUser = FUser.shape[0]
print(&amp;quot;OffTrainUser=&amp;quot;, OffTrainUser)
FUser = FUser.reset_index(drop=True)

# 读取正样本，总共75382个正样本
OffTrainP = pd.read_csv(&#39;ccf_offline_stage1_train_P.csv&#39;)
OffTrainPNumber = OffTrainP.shape[0]
print(&amp;quot;OffTrainPNumber=&amp;quot;, OffTrainPNumber)
OffTrainPperUser = OffTrainPNumber * 1.0 / OffTrainUser
# 每个独立用户可能购买的几率是13.974173%
print(&amp;quot;OffTrainPperUser=&amp;quot;, OffTrainPperUser)

# 寻找同样的ID在P样本中出现的次数


# 得到userid列
t = OffTrainP[[&#39;user_id&#39;]]
# 添加 Feature1，线下消费总次数
t[&#39;FUser1&#39;] = 1
# 对数据进行求和，得到每个userid的购买次数
t = t.groupby(&#39;user_id&#39;).agg(&#39;sum&#39;).reset_index()
# join操作
FUser = pd.merge(FUser, t, on=[&#39;user_id&#39;], how=&#39;left&#39;)
print(FUser.head(5))

# 把所有NaN填充为0
FUser = FUser.fillna(0)
print(FUser.head(5))

t = OffTrain[OffTrain[&#39;date&#39;] != &amp;quot;null&amp;quot;]
t = t[[&#39;user_id&#39;]]
# 添加特征2，领取优惠券后消费的次数
t[&#39;FUser2&#39;] = 1
# 求和
t = t.groupby(&#39;user_id&#39;).agg(&#39;sum&#39;).reset_index()

# join
FUser = pd.merge(FUser, t, on=[&#39;user_id&#39;], how=&#39;left&#39;)
FUser = FUser.fillna(0)
print(FUser.head(5))

print(FUser.FUser2.describe())
FUser.to_csv(&#39;FUser.csv&#39;, index=False, header=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行完后会生成用户特征文件：FUser.csv。
然后我们提取商户特征，新建python文件&lt;code&gt;tianchi_4.py&lt;/code&gt;，添加下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;

OffTrain = pd.read_csv(path_to_offline, low_memory=False)

# 头文件信息，输出：user_id,merchant_id,coupon_id,discount_rate,distance,date_received,date
print OffTrain.head()

# 把线下商户ID都提取出来
FMer = OffTrain[[&#39;merchant_id&#39;]]
print(&amp;quot;FMer.shape=%s&amp;quot;, FMer.shape)
# 去掉重复的
FMer.drop_duplicates(inplace=True)
print(&amp;quot;FMer.shape=&amp;quot;, FMer.shape)
# 重新建立索引
FMer = FMer.reset_index(drop=True)
t = OffTrain[OffTrain[&#39;coupon_id&#39;] != &amp;quot;null&amp;quot;]  # 取出所有有领取优惠券的部分
# print(t.shape)
t = t[[&#39;merchant_id&#39;]]
t[&#39;FMer1&#39;] = 1  # 特征1
t = t.groupby(&#39;merchant_id&#39;).agg(&#39;sum&#39;).reset_index()  # 求和
# print(t.head())
FMer = pd.merge(FMer, t, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
FMer = FMer.fillna(0)
print(FMer.head())
# FMer2 线下总领取优惠券后消费次数
t = OffTrain[OffTrain[&#39;coupon_id&#39;] != &amp;quot;null&amp;quot;]  # 取出所有有领取优惠券的部分
print(t.shape)
t = t[t[&#39;date&#39;] != &#39;null&#39;]
print(t.shape)
t = t[[&#39;merchant_id&#39;]]
t[&#39;FMer2&#39;] = 1  # 特征2
t = t.groupby(&#39;merchant_id&#39;).agg(&#39;sum&#39;).reset_index()  # 求和
# print(t.head())
FMer = pd.merge(FMer, t, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
FMer = FMer.fillna(0)
print(FMer.head())
# FMer3 线下总消费次数
t = OffTrain[OffTrain[&#39;date&#39;] != &amp;quot;null&amp;quot;]  # 取出所有有消费的部分
print(t.shape)
t = t[[&#39;merchant_id&#39;]]
t[&#39;FMer3&#39;] = 1  # 特征3
t = t.groupby(&#39;merchant_id&#39;).agg(&#39;sum&#39;).reset_index()  # 求和
# print(t.head())
FMer = pd.merge(FMer, t, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
FMer = FMer.fillna(0)
print(FMer.head())
FMer.to_csv(&#39;FMer.csv&#39;, index=False, header=True)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实和之前的是相似的,运行完成后会生成你的&lt;code&gt;FMer.csv&lt;/code&gt;文件。&lt;/p&gt;

&lt;h4 id=&#34;4-建模预测&#34;&gt;4.建模预测&lt;/h4&gt;

&lt;p&gt;我们选择使用python的随机森林模型进行建模预测。新建&lt;code&gt;tianchi_5.py&lt;/code&gt;,添加下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd
import numpy as np
import time
from sklearn.ensemble import RandomForestRegressor

path_to_offline = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;
path_to_test = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_offline_stage1_test_revised.csv&amp;quot;
path_to_offline_train_N = &#39;ccf_offline_stage1_train_N.csv&#39;
path_to_offline_train_P = &#39;ccf_offline_stage1_train_P.csv&#39;
path_to_FMer = &amp;quot;FMer.csv&amp;quot;
path_to_FUser = &amp;quot;FUser.csv&amp;quot;
path_to_Result = &amp;quot;sample_submission20180401.csv&amp;quot;

OffTrain = pd.read_csv(path_to_offline, low_memory=False)

# 头文件信息，输出：user_id,merchant_id,coupon_id,discount_rate,distance,date_received,date
print OffTrain.head()

# 读取特征文件
FMer = pd.read_csv(path_to_FMer)  # 商户特征
FUser = pd.read_csv(path_to_FUser)  # 用户特征

# 读取样本数据
OffTrainN = pd.read_csv(path_to_offline_train_N)
OffTrainP = pd.read_csv(path_to_offline_train_P)

# 加入FLag区分P和N
OffTrainN[&#39;Flag&#39;] = 0
OffTrainP[&#39;Flag&#39;] = 1

# 负样本建立特征列
print(&amp;quot;OffTrainN&amp;quot;, OffTrainN.shape)
# 和特征join，添加特征
OffTrainN = pd.merge(OffTrainN, FUser, on=[&#39;user_id&#39;], how=&#39;left&#39;)
print OffTrainN.head()
OffTrainN = pd.merge(OffTrainN, FMer, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)

print(OffTrainN.shape)
print (OffTrainN.head())

# 正样本建立特征列
print(&amp;quot;OffTrainP&amp;quot;, OffTrainP.shape)
# 和特征join，添加特征

OffTrainP = pd.merge(OffTrainP, FUser, on=[&#39;user_id&#39;], how=&#39;left&#39;)
OffTrainP = pd.merge(OffTrainP, FMer, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)

print(OffTrainP.shape)
OffTrainP.head()

# 生成Flag数组
OffTrainFlagP = OffTrainP[&#39;Flag&#39;].values
print(&amp;quot;OffTrainFlagP&amp;quot;, OffTrainFlagP)
print(OffTrainFlagP.shape)
OffTrainFlagN = OffTrainN[&#39;Flag&#39;].values
print(&amp;quot;OffTrainFlagN&amp;quot;, OffTrainFlagN)
print(OffTrainFlagN.shape)

# 合并Flag
OffTrainFlag = np.append(OffTrainFlagP, OffTrainFlagN)
print(&amp;quot;OffTrainFlag&amp;quot;, OffTrainFlag)
print(OffTrainFlag.shape[0])

# 生成特征数组
OffTrainFeatureP = OffTrainP[[&#39;FUser1&#39;, &#39;FUser2&#39;, &#39;FMer1&#39;, &#39;FMer2&#39;, &#39;FMer3&#39;]].values
print(&amp;quot;OffTrainFeatureP&amp;quot;, OffTrainFeatureP)
print(OffTrainFeatureP.shape)
OffTrainFeatureN = OffTrainN[[&#39;FUser1&#39;, &#39;FUser2&#39;, &#39;FMer1&#39;, &#39;FMer2&#39;, &#39;FMer3&#39;]].values
print(&amp;quot;OffTrainFeatureN&amp;quot;, OffTrainFeatureN)
print(OffTrainFeatureN.shape)

# 合并特征
OffTrainFeature = np.append(OffTrainFeatureP, OffTrainFeatureN, axis=0)
print(&amp;quot;OffTrainFeature&amp;quot;, OffTrainFeature)
print(OffTrainFeature.shape)

&#39;&#39;&#39;训练模型&#39;&#39;&#39;
print &amp;quot;开始计算模型&amp;quot;
# 使用模型
rf = RandomForestRegressor()  # 这里使用了默认的参数设置
rf.fit(OffTrainFeature, OffTrainFlag)  # 进行模型的训练

# 使用模型预估
temp = rf.predict(OffTrainFeature)
start = time.time()
err = 0
for i in range(OffTrainFeature.shape[0]):
    t = temp[i] - OffTrainFlag[i]
    if (t &amp;gt; 0.5) | (t &amp;lt; -0.5):
        err += 1
err = err * 1.0 / OffTrainFeature.shape[0]
end = time.time()
print (&amp;quot;建模时间：&amp;quot;)
print(end - start)
print (&amp;quot;模型在测试数据上的精度：&amp;quot;)
print(1 - err)

# 读取测试集
Test = pd.read_csv(path_to_test)

Test = pd.merge(Test, FUser, on=[&#39;user_id&#39;], how=&#39;left&#39;)
Test = pd.merge(Test, FMer, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
Test[&#39;Flag&#39;] = 0.0
print(Test.shape)
print(Test.head())
Test = Test.fillna(0)
TestFeature = Test[[&#39;FUser1&#39;, &#39;FUser2&#39;, &#39;FMer1&#39;, &#39;FMer2&#39;, &#39;FMer3&#39;]].values
print(TestFeature.shape)
print(TestFeature)
start = time.time()
temp = rf.predict(TestFeature)
end = time.time()
print(end - start)
Test[&#39;Flag&#39;] = temp
Test.head()
Test.to_csv(path_to_Result, columns=[&#39;user_id&#39;, &#39;coupon_id&#39;, &#39;date_received&#39;, &#39;Flag&#39;],
            index=False, header=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里我们的结果数据就产生了，最后我们计算了模型在测试数据上的精度为：0.958539118679，还算比较高，当然在实际提交到天池官网精度只是略大于0.5而已。&lt;/p&gt;

&lt;h2 id=&#34;三-开发环境搭建&#34;&gt;三、开发环境搭建&lt;/h2&gt;

&lt;p&gt;我们使用spark进行数据分析，实际上你可以将表格保存到hive上面，使用hive进行数据的清洗，但是我们为了避免遇到很多环境的问题，直接使用spark读取文件，进行数据清洗即可。&lt;/p&gt;

&lt;h3 id=&#34;1-新建项目&#34;&gt;1.新建项目&lt;/h3&gt;

&lt;p&gt;我们以前新建项目都是打开IDEA，新建一个maven项目&lt;code&gt;hongya-coupon-analyze&lt;/code&gt;，选择scala的archetype，填好GroupId和ArtificialId：
&lt;img src=&#34;../images/2018-04-14-20-36-09.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后配置maven地址等，这个步骤以及做过很多遍，这里就不截图了。&lt;/p&gt;

&lt;p&gt;然后我们可能要新建一些模块，由于模块类型我们没定，所以暂时可以放在下一步中完成。
注意在pom文件添加多环境配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;profiles&amp;gt;
    &amp;lt;profile&amp;gt;
      &amp;lt;!-- 本地开发环境 --&amp;gt;
      &amp;lt;id&amp;gt;dev&amp;lt;/id&amp;gt;
      &amp;lt;properties&amp;gt;
        &amp;lt;package.environment&amp;gt;dev&amp;lt;/package.environment&amp;gt;
        &amp;lt;spark.scope&amp;gt;compile&amp;lt;/spark.scope&amp;gt;
      &amp;lt;/properties&amp;gt;
      &amp;lt;activation&amp;gt;
        &amp;lt;activeByDefault&amp;gt;true&amp;lt;/activeByDefault&amp;gt;
      &amp;lt;/activation&amp;gt;
    &amp;lt;/profile&amp;gt;
    &amp;lt;profile&amp;gt;
      &amp;lt;!-- 测试环境 --&amp;gt;
      &amp;lt;id&amp;gt;test&amp;lt;/id&amp;gt;
      &amp;lt;properties&amp;gt;
        &amp;lt;package.environment&amp;gt;test&amp;lt;/package.environment&amp;gt;
        &amp;lt;spark.scope&amp;gt;provided&amp;lt;/spark.scope&amp;gt;
      &amp;lt;/properties&amp;gt;
    &amp;lt;/profile&amp;gt;
    &amp;lt;profile&amp;gt;
      &amp;lt;!-- 生产环境 --&amp;gt;
      &amp;lt;id&amp;gt;prod&amp;lt;/id&amp;gt;
      &amp;lt;properties&amp;gt;
        &amp;lt;package.environment&amp;gt;prod&amp;lt;/package.environment&amp;gt;
        &amp;lt;spark.scope&amp;gt;provided&amp;lt;/spark.scope&amp;gt;
      &amp;lt;/properties&amp;gt;
    &amp;lt;/profile&amp;gt;
  &amp;lt;/profiles&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-加入依赖&#34;&gt;2.加入依赖&lt;/h3&gt;

&lt;p&gt;我们这次的开发需要使用到的依赖是spark-core和spark-mllib，开发也有可能用到其他的库，到时候再加入即可，我们完整的pom文件的依赖可以参考项目。我们删掉项目新建完成后自带的测试scala文件和依赖。&lt;/p&gt;

&lt;h2 id=&#34;三-项目开发&#34;&gt;三、项目开发&lt;/h2&gt;

&lt;p&gt;项目开发按照上面的步骤进行。&lt;/p&gt;

&lt;h3 id=&#34;1-数据清洗部分开发&#34;&gt;1.数据清洗部分开发&lt;/h3&gt;

&lt;p&gt;由于我们是多环境下工作，我们需要解析配置文件，首先新建一个&lt;code&gt;Settings&lt;/code&gt;类，用来解析配置，路径为 &lt;code&gt;com.hongya.bigdata.coupon.util&lt;/code&gt;,相关代码可以参考以前的代码，其实就是读取配置：
&lt;img src=&#34;../images/2018-04-15-08-44-16.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们通过读取数据进行ETL操作，在&lt;code&gt;com.hongya.bigdata.coupon.etl&lt;/code&gt;包下新建DataEtl类，然后添加数据ETL的代码，代码主要是读取数据，将消费和未消费的数据取出分别保存，相关代码可以查看我们给的源码：
&lt;img src=&#34;../images/2018-04-15-09-18-00.jpg&#34; alt=&#34;&#34; /&gt;
然后我们在&lt;code&gt;src/main/resources&lt;/code&gt;下面新建dev文件夹，添加config.properties文件。添加Etl需要的三个文件路径，分别是输入的offline数据路径，正负例样本路径：
&lt;img src=&#34;../images/2018-04-15-09-30-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后打开idea自带的终端，输打包命令：&lt;code&gt;mvn clean install -P dev&lt;/code&gt;
&lt;img src=&#34;../images/2018-04-15-09-25-43.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;稍等编译完成就可以点击&lt;code&gt;DataEtl&lt;/code&gt;类的运行：
&lt;img src=&#34;../images/2018-04-15-09-26-46.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;运行完成后你会在你配置的路径下面看到输出文件：
&lt;img src=&#34;../images/2018-04-15-09-35-44.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-特征工程部分代码&#34;&gt;2.特征工程部分代码&lt;/h3&gt;

&lt;p&gt;我们首先要取到数据进行特征提取。类似前面的逻辑，首先在&lt;code&gt;com.hongya.bigdata.coupon.feature&lt;/code&gt;包下面新建&lt;code&gt;UserFeature&lt;/code&gt;类，添加提取用户特征的代码：
&lt;img src=&#34;../images/2018-04-15-09-40-45.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;代码详情可以查看源码，注意我们使用了一个sql语句提取用户特征：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.user_id,
    b.FUser1,
    c.FUser2
from
    (select distinct user_id from train_P ) a
left join
    (select user_id,sum(1) as FUser1 from train_P group by user_id) b
on
    a.user_id = b.user_id
left join
    (select user_id,sum(1) as FUser2 from train_P where date&amp;lt;&amp;gt;&#39;null&#39; group by user_id) c
on
    a.user_id = c.user_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个sql的含义大家自己理解，我们可以使用更加复杂的sql提取更多特征。
然后我们在配置文件配置用户特征的保存路径：
&lt;img src=&#34;../images/2018-04-15-09-42-11.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;点击运行代码：
&lt;img src=&#34;../images/2018-04-15-09-42-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;运行完成后可以看到我们配置的目录下有用户特征文件:
&lt;img src=&#34;../images/2018-04-15-09-52-19.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;同理新建MerchantFeature文件：
&lt;img src=&#34;../images/2018-04-15-09-55-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意我们获得特征的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.merchant_id,
    b.FMer1,
    c.FMer2,
    d.FMer3
from
    (select distinct merchant_id from train ) a
left join
    (select merchant_id,sum(1) as FMer1 from train where coupon_id&amp;lt;&amp;gt;&#39;null&#39; group by merchant_id) b
on
    a.merchant_id = b.merchant_id
left join
    (select merchant_id,sum(1) as FMer2 from train where coupon_id&amp;lt;&amp;gt;&#39;null&#39; and date&amp;lt;&amp;gt;&#39;null&#39; group by merchant_id) c
on
    a.merchant_id = c.merchant_id
left join
    (select merchant_id,sum(1) as FMer3 from train where date&amp;lt;&amp;gt;&#39;null&#39; group by merchant_id) d
on
    a.merchant_id = d.merchant_id

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加merchant配置：
&lt;img src=&#34;../images/2018-04-15-09-58-27.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后点击运行，完成后会有FMer文件夹生成，数据有空值，这需要我们后续处理的时候进行进一步填值：
&lt;img src=&#34;../images/2018-04-15-09-59-36.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-建模预测&#34;&gt;3.建模预测&lt;/h3&gt;

&lt;p&gt;新建模型计算的代码，读取数据进行预测，相关代码可以参考源码：
&lt;img src=&#34;../images/2018-04-15-12-29-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意我们使用了sql语句将数据变成我们模型的入口格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.user_id,
    a.merchant_id,
    coalesce(b.FUser1,0) as FUser1,
    coalesce(b.FUser2,0) as FUser2,
    coalesce(c.FMer1,0) as FMer1,
    coalesce(c.FMer2,0) as FMer2,
    coalesce(c.FMer3,0) as FMer3,
    a.label as label
from
    (
    select
        user_id ,
        merchant_id,
        1 as label
    from
        train_P
    union all
    select
        user_id ,
        merchant_id,
        0 as label
    from
        train_N
    ) a
left join
    FUser b
on
    a.user_id = b.user_id
left join
    FMer c
on
    a.merchant_id = c.merchant_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外我们使用类似的sql将需要提交的数据变成我们模型的输入格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.user_id,
    a.merchant_id,
    a.coupon_id,
    a.date_received,
    coalesce(b.FUser1,0) as FUser1,
    coalesce(b.FUser2,0) as FUser2,
    coalesce(c.FMer1,0) as FMer1,
    coalesce(c.FMer2,0) as FMer2,
    coalesce(c.FMer3,0) as FMer3
from
    (
    select
        user_id ,
        merchant_id,
        coupon_id,
        date_received
    from
        testData
    ) a
left join
    FUser b
on
    a.user_id = b.user_id
left join
    FMer c
on
    a.merchant_id = c.merchant_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们将原始数据分成两部分分别进行模型计算和测试，最后用模型计算天池提供的数据，生成提交文件。整个过程需要一定的时间，完成后会生产提交文件的文件，放在我们配置的文件中。&lt;/p&gt;

&lt;h2 id=&#34;四-集群部署&#34;&gt;四、集群部署&lt;/h2&gt;

&lt;h3 id=&#34;1-生产环境配置&#34;&gt;1.生产环境配置&lt;/h3&gt;

&lt;p&gt;我们前面配置了开发环境，现在改为生产环境即可，在resources下新建prod文件夹，和dev一样：
&lt;img src=&#34;../images/2018-04-15-12-42-48.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后将config.properties的配置也改一下即可，注意修改相应的配置为你的机器配置。然后启动项目即可:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;env=prod
# 配置输入路径
path_to_offline = hdfs://node1:8020/hongya/day10/input/ccf_offline_stage1_train.csv
path_to_online = hdfs://node1:8020/hongya/day10/input/cf_online_stage1_train.csv
path_to_test = hdfs://node1:8020/hongya/day10/input/ccf_offline_stage1_test_revised.csv
path_to_offline_train_N = hdfs://node1:8020/hongya/day10/output/ccf_offline_stage1_train_N
path_to_offline_train_P = hdfs://node1:8020/hongya/day10/output/ccf_offline_stage1_train_P
path_to_FMer = hdfs://node1:8020/hongya/day10/output/FMer
path_to_FUser = hdfs://node1:8020/hongya/day10/FUser
path_to_Result = hdfs://node1:8020/hongya/day10/output/sample_submission20180401
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们打包，执行命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn clean install -P prod
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打完包以后可以看到 &lt;code&gt;hongya-broker-analyze/order-handle/target&lt;/code&gt; 目录下有两个jar包，其中比较大一点的就是完整的jar，小一点的是我们代码编译后的输出。然后我们复制这个大一点的jar到集群环境下，提交相应的任务即可，一共三个任务：
&lt;img src=&#34;../images/2018-04-15-12-44-47.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-启动&#34;&gt;2.启动&lt;/h3&gt;

&lt;p&gt;我们将jar包和生产环境下的config.properties拷贝到集群环境下，再将原始的数据上传到hdfs上面，然后提交任务。
ETL任务的启动命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.etl.DataEtl \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_etl \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以在浏览器访问yarn的的8088端口查看应用程序了。执行完成后，可以用hadoop命令查看对应的路径上面的文件。&lt;/p&gt;

&lt;p&gt;第二个任务,提取商户特征：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.feature.MerchantFeature \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_merchant_feature \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第三个任务，提取用户特征：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.feature.UserFeature \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_user_feature \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第四个任务，新建模型并生成结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.model.Model \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_user_feature \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然这几个任务你可以放在一个shell脚本中，一次性提交。&lt;/p&gt;

&lt;h3 id=&#34;3-查看结果数据&#34;&gt;3.查看结果数据&lt;/h3&gt;

&lt;p&gt;结果保存在我们配置的&lt;code&gt;path_to_Result&lt;/code&gt;中，我们通过hadoop命令即可查看，为了验证准确率，我们可以提交到天池的官网上面进行验证，相关步骤可以查看天池官网，经过验证了我们的模型准确率只有59%左右，基本上就比随机猜好一点点，这也是因为我们对数据的建模比较粗糙，大家可以提取更多的特征进行分析。&lt;/p&gt;

&lt;h2 id=&#34;五-实验总结&#34;&gt;五、实验总结&lt;/h2&gt;

&lt;h3 id=&#34;1-注意事项&#34;&gt;1.注意事项&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;测试环境下的开发过程比较需要一步一步来，数据量可能比较大，大家可以自己从文件中截取一千行作为测试数据；&lt;/li&gt;
&lt;li&gt;使用python进行数据分析的过程是我们从数据清洗、特征工程、建模、预测的完整步骤，大家需要一步一步亲自动手才行，最好多操作几遍；&lt;/li&gt;
&lt;li&gt;使用spark和python进行分析的过程大家可以对比，python是动态语言，所以在类型操作更加方便，python代码更加简介。但是spark实际上也不复杂，而且我们使用的是低版本的spark风格，实际上高版本的spark直接基于DataFrame代码就很简洁了。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-心得体会&#34;&gt;2.心得体会&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;数据分析大部分时间都是特征工程，建模时间是很少的，建模最复杂的是调参；&lt;/li&gt;
&lt;li&gt;spark机器学习库和python的机器学习操作代码是很类似的， 所以大家只要掌握了一种工具，再学习另外一种就很简单了；&lt;/li&gt;
&lt;li&gt;本次实验体验了一次天池大数据竞赛的题目，对于数据分析项目有了更加深入的理解，以后能后快速上手类似的数据分析项目。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;源码地址：&lt;code&gt;https://github.com/dengziming/hongya-coupon-analyze&lt;/code&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>hadoop网站日志分析项目架构</title>
      <link>https://dengziming.github.io/post/project/hadoop/hadoop/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/project/hadoop/hadoop/</guid>
      
        <description>

&lt;p&gt;项目简介：大数据涉及到的业务很多很复杂，从一开始的项目架构，再到后台的网站搭建，以及数据的收集，数据的分析，数据的迁移，业务开发，后台运维，等等。我们没办法一个实验将所有的过程都学习到。本次试验我们将会将重点放在项目架构上，后面的项目我们将重点放在每一部分的实现上。通过本次实验，你将能了解到一个大数据架构师工作的基本步骤，虽然本次实验我们也有复杂的代码分析过程，但是大家没有必要将自己的重点放在代码上面，大家应该更加站在架构师的角度，专注于整个项目每一部分的连接，每个部分具体实现的细节，大家可以不必太深入，我们后期会有专门的实验放在这上面。
有关代码我们已经实现并且提供，大家直接打开，然后阅读熟悉每部分的意义即可。
本次项目我们是架构一个日志分析，我们的要完成的任务包括后台和前端的实现，网站的搭建，nginx反向代理的搭建，etl数据清洗程序，数据分析，数据报表的实现。&lt;/p&gt;

&lt;h2 id=&#34;一-业务分析和需求文档&#34;&gt;一、业务分析和需求文档&lt;/h2&gt;

&lt;h3 id=&#34;1-业务分析概述&#34;&gt;1.业务分析概述&lt;/h3&gt;

&lt;p&gt;本次试验我们主要是分析类似淘宝等购物网站上的点击流，从而进行展示分析。在本次项目中我们分别从七个大的角度来进行分析，分别为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;用户基本信息分析模块、浏览器信息分析模块、地域信息分析模块、用户浏览深度分析模块、外链数据分析模块、订单分析模块以及事件分析模块。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意几个概念:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;用户/访客：表示同一个浏览器代表的用户。唯一标示用户
会员：表示网站的一个正常的会员用户。
会话：一段时间内的连续操作，就是一个会话中的所有操作。
Pv：访问页面的数量
在本次项目中，所有的计数都是去重过的。比如：活跃用户/访客，计算uuid的去重后的个数。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们分析数据的需求文档和最终的展示结果大概如下。&lt;/p&gt;

&lt;h3 id=&#34;2-用户基本信息分析模块&#34;&gt;2.用户基本信息分析模块&lt;/h3&gt;

&lt;p&gt;用户基本信息分析模块主要是从用户/访客和会员两个主要角度分析浏览相关信息，包括但不限于新增用户，活跃用户，总用户，新增会员，活跃会员，总会员以及会话分析等。下面就各个不同的用户信息角度来进行分析：&lt;/p&gt;

&lt;h4 id=&#34;1-用户分析&#34;&gt;(1).用户分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析新增用户、活跃用户以及总用户的相关信息。
新访客:老访客(活跃访客中) =  1:7~10
&lt;img src=&#34;../images/2017-06-20-21-21-54.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-会员分析&#34;&gt;(2).会员分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析新增会员、活跃会员以及总会员的相关信息。
&lt;img src=&#34;../images/2017-06-20-21-22-26.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-会话分析&#34;&gt;(3).会话分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析会话个数、会话长度和平均会话长度相关的信息。
&lt;img src=&#34;../images/2017-06-20-21-23-17.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-hourly分析&#34;&gt;(4).Hourly分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析每天每小时的用户、会话个数以及会话长度的相关信息。
&lt;img src=&#34;../images/2017-06-20-21-24-07.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-其他模块分析&#34;&gt;3.其他模块分析&lt;/h3&gt;

&lt;p&gt;在用户模块的基础上，我们可以添加其他的六个模块分析，我们本次试验先不展示所有的模块，只是作简单介绍，例如地域分布模块：
&lt;img src=&#34;../images/2017-06-20-21-25-43.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面分析的业务需求大家可能不太懂，没关系，注意在下面的项目中，时不时回头看看我们的需求，就能明白了。&lt;/p&gt;

&lt;h2 id=&#34;二-开发环境搭建&#34;&gt;二、开发环境搭建&lt;/h2&gt;

&lt;p&gt;为了方便管理，我们以后按照管理，尽量使用maven构建java和scala项目。另外我们的软件安装在D盘的&lt;code&gt;soft&lt;/code&gt;目录下，我们的开发项目放在D盘的&lt;code&gt;workspace&lt;/code&gt;目录下。&lt;/p&gt;

&lt;h3 id=&#34;1-下载安装软件&#34;&gt;1.下载安装软件&lt;/h3&gt;

&lt;p&gt;分别在&lt;code&gt;http://tomcat.apache.org&lt;/code&gt;和&lt;code&gt;http://maven.apache.org&lt;/code&gt;下载tomcat和maven，解压后放在D盘的soft目录，然后配置环境变量，需要配置的环境变量包括 &lt;code&gt;MAVEN_HOME&lt;/code&gt;和&lt;code&gt;TOMCAT_HOME&lt;/code&gt;，并且将他们的bin目录添加到&lt;code&gt;PATH&lt;/code&gt;中。安装配置完成后，在命令行输入start-up和mvn命令，检查是否安装正确。
确保无误后，我们的开发环境使用IDEA，安装好IDEA，打开，配置maven的目录，如下图的方法，搜索maven，在Maven的配置填写maven的路径。
&lt;img src=&#34;../images/2017-06-20-19-07-00.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-搭建服务器&#34;&gt;2.搭建服务器&lt;/h3&gt;

&lt;h4 id=&#34;1-布置开发环境&#34;&gt;(1).布置开发环境&lt;/h4&gt;

&lt;p&gt;如果大家熟悉javaEE开发，这一段就比较简单。我们搭建服务器就是新建一个javaEE项目，然后启动，这个过程需要借助tomcat实现。首先打开IDEA，IDEA中已经配置好了maven的路径。
点击File -&amp;gt;New -&amp;gt; Project ，选择java的web application，然后下一步:
&lt;img src=&#34;../images/2017-06-20-19-09-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在下一步我们设置项目路径，我们的项目名为&lt;code&gt;taobaopayment&lt;/code&gt;，放在D盘下的workspace目录下。然后点击完成。这时候就新建了一个web项目，我们在项目的web文件下能看到一个index.jsp文件，这个文件你可以修改为自定义的内容，例如我修改为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;%@ page contentType=&amp;quot;text/html;charset=UTF-8&amp;quot; language=&amp;quot;java&amp;quot; %&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;taobaopayment&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
  支付页面
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-本地发布项目&#34;&gt;(2).本地发布项目&lt;/h4&gt;

&lt;p&gt;菜单栏选择Run -&amp;gt;Edit Configuration或者点击右上角按钮添加tomcat的发布参数，依次点击 加号 -&amp;gt;tomcat server -&amp;gt; local ，添加tomcat：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2017-06-20-19-18-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在右边的配置页面配置好名字、地址、端口：
&lt;img src=&#34;../images/2017-06-20-19-20-30.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后在deployment选项下面点击加号添加发布选项，然后设置你content名字，我们设置为 &lt;code&gt;taobaopayment&lt;/code&gt;：
&lt;img src=&#34;../images/2017-06-20-19-21-52.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;点击确定后，我们可以看到右上方和下方都出现了可以启动的三角形按钮，点击启动：
&lt;img src=&#34;../images/2017-06-20-19-25-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;启动成功后打开浏览器，输入&lt;code&gt;http://localhost:8080/taobaopayment/&lt;/code&gt;，出现我们刚刚编辑的jsp页面，剩下的操作自己实验。
&lt;img src=&#34;../images/2017-06-20-19-24-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;三-web服务器开发&#34;&gt;三、Web服务器开发&lt;/h2&gt;

&lt;p&gt;根据我们的需求文档，我们需要实现支付成功和退款页面。这里又分为两部分，一是前端的页面传来的请求数据，这部分代码使用JavaScript编写，另一方面是后台的服务器发送过来的代码，通过Java语言编写。&lt;/p&gt;

&lt;h3 id=&#34;1-后端开发&#34;&gt;1.后端开发&lt;/h3&gt;

&lt;h4 id=&#34;1-程序后台事件分析&#34;&gt;(1).程序后台事件分析&lt;/h4&gt;

&lt;p&gt;本项目中在程序后台会有chargeSuccess事件，本事件的主要作用是发送订单成功的信息给nginx服务器。发送格式同pc端发送方式， 也是访问同一个url来进行数据的传输。格式为:
&lt;code&gt;http://hongyahuayu.com/index.jpg?query1=spark&lt;/code&gt;
当会员最终支付成功的时候触发chargeSuccess该事件，该事件需要程序主动调用，然后向后台发送数据：
&lt;code&gt;u_mid=maomao&amp;amp;c_time=1449142044528&amp;amp;oid=orderid_1&amp;amp;ver=1&amp;amp;en=e_cs&amp;amp;pl=jdk&amp;amp;sdk=java&lt;/code&gt;，其中 &lt;code&gt;u_mid&lt;/code&gt;和&lt;code&gt;oid&lt;/code&gt;代表用户id和订单id。
前面我们分析了后端的业务，如果你不太懂，我们尅简单地说，后端程序的工作流如下：
&lt;img src=&#34;../images/2017-06-20-21-52-16.jpg&#34; alt=&#34;&#34; /&gt;
简单说，后端就是要设计方法，当&lt;code&gt;chargeSuccess&lt;/code&gt;触发的时候，我们给后台发送数据。&lt;/p&gt;

&lt;h4 id=&#34;2-后端程序开发&#34;&gt;(2).后端程序开发&lt;/h4&gt;

&lt;p&gt;程序开发有一定难度，另外由于我们本次试验的重点是后面的数据分析，这一块不作太高的要求，大家能够理解即可，核心代码如下，其余代码可以在项目中查看：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;	public static boolean onChargeSuccess(String orderId, String memberId) {
		try {
			if (isEmpty(orderId) || isEmpty(memberId)) {
				// 订单id或者memberid为空
				log.log(Level.WARNING, &amp;quot;订单id和会员id不能为空&amp;quot;);
				return false;
			}
			// 代码执行到这儿，表示订单id和会员id都不为空。
			Map&amp;lt;String, String&amp;gt; data = new HashMap&amp;lt;String, String&amp;gt;();
			data.put(&amp;quot;u_mid&amp;quot;, memberId);
			data.put(&amp;quot;oid&amp;quot;, orderId);
			data.put(&amp;quot;c_time&amp;quot;, String.valueOf(System.currentTimeMillis()));
			data.put(&amp;quot;ver&amp;quot;, version);
			data.put(&amp;quot;en&amp;quot;, &amp;quot;e_cs&amp;quot;);
			data.put(&amp;quot;pl&amp;quot;, platformName);
			data.put(&amp;quot;sdk&amp;quot;, sdkName);
			// 创建url
			String url = buildUrl(data);
			// 发送url&amp;amp;将url加入到队列
			SendDataMonitor.addSendUrl(url);
			return true;
		} catch (Throwable e) {
			log.log(Level.WARNING, &amp;quot;发送数据异常&amp;quot;, e);
		}
		return false;
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;注意事项&lt;/em&gt;&lt;/strong&gt; 修改代码这里url地址为自己服务器的地址：
&lt;img src=&#34;../images/2017-06-20-23-42-54.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-前端开发&#34;&gt;2.前端开发&lt;/h3&gt;

&lt;h4 id=&#34;1-前端事件分析&#34;&gt;(1).前端事件分析&lt;/h4&gt;

&lt;p&gt;前面我们说后端的事件主要是chargeSuccess，前端的时间处理就更复杂了。针对我们最终的不同分析模块，我们需要不同的数据，接下来分别从各个模块分析，每个模块需要的数据。
1. 用户基本信息就是用户的浏览行为信息分析，也就是我们只需要pageview事件就可以了；
2. 浏览器信息分析以及地域信息分析其实就是在用户基本信息分析的基础上添加浏览器和地域这个维度信息，其中浏览器信息我们可以通过浏览器的window.navigator.userAgent来进行分析，地域信息可以通过nginx服务器来收集用户的ip地址来进行分析，也就是说pageview事件也可以满足这两个模块的分析。
3. 外链数据分析以及用户浏览深度分析我们可以在pageview事件中添加访问页面的当前url和前一个页面的url来进行处理分析，也就是说pageview事件也可以满足这两个模块的分析。
4. 订单信息分析要求pc端发送一个订单产生的事件，那么对应这个模块的分析，我们需要一个新的事件chargeRequest。对于事件分析我们也需要一个pc端发送一个新的事件数据，我们可以定义为event。
我们要分析的模块包括：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;用户基本信息分析
浏览器信息分析
地域信息分析
外链数据分析
用户浏览深度分析
订单信息分析
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们处理的事件包括：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pageview事件
chargeRequest事件
launch事件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一，Launch事件。当用户第一次访问网站的时候触发该事件，不提供对外调用的接口，只实现该事件的数据收集。
第二，Pageview事件，当用户访问页面/刷新页面的时候触发该事件。该事件会自动调用，也可以让程序员手动调用。
第三，chargeRequest事件。当用户下订单的时候触发该事件，该事件需要程序主动调用。
每次都会发送对应的数据，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;u_sd=8E9559B3-DA35-44E1-AC98-85EB37D1F263&amp;amp;c_time=1449139048231&amp;amp;oid=orderid123&amp;amp;on=%E4%BA%A7%E5%93%81%E5%90%8D%E7%A7%B0&amp;amp;cua=1000&amp;amp;cut=%E4%BA%BA%E6%B0%91%E5%B8%81&amp;amp;pt=%E6%B7%98%E5%AE%9D&amp;amp;ver=1&amp;amp;en=e_cr&amp;amp;pl=website&amp;amp;sdk=js&amp;amp;b_rst=1920*1080&amp;amp;u_ud=12BF4079-223E-4A57-AC60-C1A04D8F7A2F&amp;amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%206.1%3B%20WOW64)%20AppleWebKit%2F537.1%20(KHTML%2C%20like%20Gecko)%20Chrome%2F21.0.1180.77%20Safari%2F537.1&amp;amp;l=zh-CN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个url的字段比较多，字段词典如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;参数名称	类型	描述
en	string	事件名称, eg: e_pv
ver	string	版本号, eg: 0.0.1
pl	string	平台, eg: website
sdk	string	Sdk类型, eg: js
b_rst	string	浏览器分辨率，eg: 1800*678
b_iev	string	浏览器信息useragent
u_ud	string	用户/访客唯一标识符
l	string	客户端语言
u_mid	string	会员id，和业务系统一致
u_sd	string	会话id
c_time	string	客户端时间
p_url	string	当前页面的url
p_ref	string	上一个页面的url
tt	string	当前页面的标题
ca	string	Event事件的Category名称
ac	string	Event事件的action名称
kv_*	string	Event事件的自定义属性
du	string	Event事件的持续时间
oid	string	订单id
on	string	订单名称
cua	string	支付金额
cut	string	支付货币类型
pt	string	支付方式
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-前端程序开发&#34;&gt;(2).前端程序开发&lt;/h4&gt;

&lt;p&gt;前面我们简单实现了后端开发，现在前端的JavaScript代码实现可能就更复杂了，对大家来说难度略大，但是还好这不是我们的重点，我大概展示几个函数：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;onPageView: function() {
				// 触发page view事件
				if (this.preCallApi()) {
					var time = new Date().getTime();
					var pageviewEvent = {};
					pageviewEvent[this.columns.eventName] = this.keys.pageView;
					pageviewEvent[this.columns.currentUrl] = window.location.href; // 设置当前url
					pageviewEvent[this.columns.referrerUrl] = document.referrer; // 设置前一个页面的url
					pageviewEvent[this.columns.title] = document.title; // 设置title
					this.setCommonColumns(pageviewEvent); // 设置公用columns
					this.sendDataToServer(this.parseParam(pageviewEvent)); // 最终发送编码后的数据ss
					this.updatePreVisitTime(time);
				}
			},

			onChargeRequest: function(orderId, name, currencyAmount, currencyType, paymentType) {
				// 触发订单产生事件
				if (this.preCallApi()) {
					if (!orderId || !currencyType || !paymentType) {
						this.log(&amp;quot;订单id、货币类型以及支付方式不能为空&amp;quot;);
						return ;
					}

					if (typeof(currencyAmount) == &amp;quot;number&amp;quot;) {
						// 金额必须是数字
						var time = new Date().getTime();
						var chargeRequestEvent = {};
						chargeRequestEvent[this.columns.eventName] = this.keys.chargeRequestEvent;
						chargeRequestEvent[this.columns.orderId] = orderId;
						chargeRequestEvent[this.columns.orderName] = name;
						chargeRequestEvent[this.columns.currencyAmount] = currencyAmount;
						chargeRequestEvent[this.columns.currencyType] = currencyType;
						chargeRequestEvent[this.columns.paymentType] = paymentType;
						this.setCommonColumns(chargeRequestEvent); // 设置公用columns
						this.sendDataToServer(this.parseParam(chargeRequestEvent)); // 最终发送编码后的数据ss
						this.updatePreVisitTime(time);
					} else {
						this.log(&amp;quot;订单金额必须是数字&amp;quot;);
						return ;
					}	
				}
			},
			
			onEventDuration: function(category, action, map, duration) {
				// 触发event事件
				if (this.preCallApi()) {
					if (category &amp;amp;&amp;amp; action) {
						var time = new Date().getTime();
						var event = {};
						event[this.columns.eventName] = this.keys.eventDurationEvent;
						event[this.columns.category] = category;
						event[this.columns.action] = action;
						if (map) {
							for (var k in map){
								if (k &amp;amp;&amp;amp; map[k]) {
									event[this.columns.kv + k] = map[k];
								}
							}
						}
						if (duration) {
							event[this.columns.duration] = duration;
						}
						this.setCommonColumns(event); // 设置公用columns
						this.sendDataToServer(this.parseParam(event)); // 最终发送编码后的数据ss
						this.updatePreVisitTime(time);
					} else {
						this.log(&amp;quot;category和action不能为空&amp;quot;);
					}
				}
			}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;完整的代码，如果有兴趣自己可以详细研究，
*** 注意事项 ***，发布的时候一定要将代码中的url改为你的服务器的url：
&lt;img src=&#34;../images/2017-06-20-23-05-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-项目发布&#34;&gt;3.项目发布&lt;/h3&gt;

&lt;h4 id=&#34;1-本地项目发布&#34;&gt;(1).本地项目发布&lt;/h4&gt;

&lt;p&gt;前面我们已经简单的实现了后台和前端的代码，首先我们在本地启动服务，方法和前面一样，只是我们将自己的代码添加进去了，点击启动按钮。
&lt;img src=&#34;../images/2017-06-20-22-14-58.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后去浏览器访问 &lt;code&gt;http://localhost:8080/taobaopayment/demo4.jsp&lt;/code&gt;，然后点击跳转按钮测试
&lt;img src=&#34;../images/2017-06-20-22-16-22.jpg&#34; alt=&#34;&#34; /&gt;
截止现在我们的后台项目基本完成，这里面的代码比较难，大家可以根据情况查看，不用花太多的精力。&lt;/p&gt;

&lt;h4 id=&#34;2-发布到linux的tomcat上&#34;&gt;(2).发布到linux的tomcat上&lt;/h4&gt;

&lt;p&gt;我们的项目不可能放在本地运行，需要放到Linux的集群环境才能正常运行。首先打开Xshell，连上linux节点。
第一步，在Linux上安装tomcat。
安装的过程很简单，首先要安装java配置JAVA相关环境变量，然后在tomcat的官网下载tomcat的tar.gz包，解压，然后配置tomcat相关环境变量。启动tomcat的命令是tomcat安装目录下面的bin下面的&lt;code&gt;startup.sh&lt;/code&gt;，执行就能启动tomcat，然后访问节点的8080端口，如图：
&lt;img src=&#34;../images/2017-06-20-22-27-11.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第二步，将项目打成war包。
类似以前打jar包，点开project structure -&amp;gt; artificts，添加一个artifict，名字为taobaopayment，type选择 Web Application:Archive，设置好对应的输出目录output idrectory，一般默认即可，然后点击确定&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2017-06-20-22-28-57.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;设置好后，点击build -&amp;gt; build artifacts，构建war包
&lt;img src=&#34;../images/2017-06-20-22-32-33.jpg&#34; alt=&#34;&#34; /&gt;
构建结束后，进入刚刚设置的输出目录，你将会在刚刚设置的目录下看到一个war包。&lt;/p&gt;

&lt;p&gt;通过xshell的xftp工具，将打出来的war包拷贝放在linux的tomcat安装目录的webapps目录下：
&lt;img src=&#34;../images/2017-06-20-22-35-41.jpg&#34; alt=&#34;&#34; /&gt;
然后tomcat会自动解压war包，我们就可以在浏览器访问刚刚发布的项目了：
&lt;img src=&#34;../images/2017-06-20-22-39-45.jpg&#34; alt=&#34;&#34; /&gt;
到这里我们的整个后端项目就发布成功了。&lt;/p&gt;

&lt;h2 id=&#34;四-数据分析系统开发&#34;&gt;四、数据分析系统开发&lt;/h2&gt;

&lt;p&gt;本次我们的重心是整个系统的搭建，这部分的开发过程比较复杂，大家酌情进行学习，代码我们已经写好，大家只要稍作理解。细节和逻辑我们后续的实验还会讲解。&lt;/p&gt;

&lt;h3 id=&#34;1-需求回顾&#34;&gt;1.需求回顾&lt;/h3&gt;

&lt;p&gt;之前我们已经做过需求分析，这时候大家再回头看看我们一开始的需求设计，我们是要完成几个关键指标的设计分析。假设我们已经配置好了tomcat和nginx，那么我们知道每次用有浏览等行为时，我们的服务器就会给我们的设置的url发送数据，然后nginx就会收到我们发送的数据。接下来就是分析nginx收集到的数据。&lt;/p&gt;

&lt;p&gt;随便选取一条数据查看：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;192.168.126.1^A1458731952.690^A192.168.126.11^A/log.gif?en=e_pv&amp;amp;p_url=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;p_ref=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;tt=%E6%B5%8B%E8%AF%95%E9%A1%B5%E9%9D%A21&amp;amp;ver=1&amp;amp;pl=website&amp;amp;sdk=js&amp;amp;u_ud=EAB36BC9-0347-4D33-8579-AA8C331D001A&amp;amp;u_mid=laoxiao&amp;amp;u_sd=2D24B8A2-B2EF-450C-8C86-4F8B0F3E2785&amp;amp;c_time=1458731943823&amp;amp;l=zh-CN&amp;amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A45.0)%20Gecko%2F20100101%20Firefox%2F45.0&amp;amp;b_rst=1366*768
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这条数据提取了很多来自url的query信息，通过^A隔开，我们需要编写代码分析这种数据。&lt;/p&gt;

&lt;h3 id=&#34;2-etl处理&#34;&gt;2.ETL处理&lt;/h3&gt;

&lt;h4 id=&#34;1-定义工具类&#34;&gt;(1).定义工具类&lt;/h4&gt;

&lt;p&gt;本次试验的工具类主要是从一个url中抽取KPI信息，我们前面的业务需要的信息包括了地址、浏览器、操作系统等，根据我们的分析，所以我们需要使用IP地址解析等工具。解析url的工具类我们放在&lt;code&gt;com.hongya.etl.util&lt;/code&gt;下面，大家自己认真分析。&lt;/p&gt;

&lt;h4 id=&#34;2-定义相关常量类&#34;&gt;(2).定义相关常量类&lt;/h4&gt;

&lt;p&gt;我们的数据分析是有时间段的，我们分析的结果放进hbase中的表中，表名、字段名、时间范围等都是需要用到的常量，我们放在&lt;code&gt;com.hongya.common&lt;/code&gt;下面，大家可以查看。&lt;/p&gt;

&lt;h4 id=&#34;3-业务代码&#34;&gt;(3).业务代码&lt;/h4&gt;

&lt;p&gt;我们的数据字段含义在前面已经讲过了，现在我们需要将数据解析后放进hbase中。ETL过程就是简单的字符串处理，只需要一个Mapper程序即可完成。相应的代码在&lt;code&gt;com.hongya.etl.mr.ald&lt;/code&gt;中，大家可以查看。&lt;/p&gt;

&lt;h4 id=&#34;4-本地测试运行&#34;&gt;(4).本地测试运行&lt;/h4&gt;

&lt;p&gt;然后我们在本地新建一个文件，将上面哪一行测试数据放进去：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;192.168.126.1^A1458731952.690^A192.168.126.11^A/log.gif?en=e_pv&amp;amp;p_url=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;p_ref=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;tt=%E6%B5%8B%E8%AF%95%E9%A1%B5%E9%9D%A21&amp;amp;ver=1&amp;amp;pl=website&amp;amp;sdk=js&amp;amp;u_ud=EAB36BC9-0347-4D33-8579-AA8C331D001A&amp;amp;u_mid=laoxiao&amp;amp;u_sd=2D24B8A2-B2EF-450C-8C86-4F8B0F3E2785&amp;amp;c_time=1458731943823&amp;amp;l=zh-CN&amp;amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A45.0)%20Gecko%2F20100101%20Firefox%2F45.0&amp;amp;b_rst=1366*768
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们将&lt;code&gt;com.hongya.etl.mr.ald.AnalyserLogDataRunner&lt;/code&gt;中的&lt;code&gt;setJobInputPaths&lt;/code&gt;方法的路径改为刚刚添加的文件的路径，并且在&lt;code&gt;setConf&lt;/code&gt;方法设置一下zookeeper地址，并且启动zookeeper，就可以点击运行，在本地观察结果。
&lt;img src=&#34;../images/2017-06-21-01-16-19.jpg&#34; alt=&#34;&#34; /&gt;
如图我们可以看出ETL后将这一行数据转化为了Hbase的一条Put，这里一直运行不结束是因为我没有启动Hbase，所以一直没法写进去，发布项目的时候是需要启动的。
这个Mapper读取数据格式上面有，而写出的数据格式是Hbase的Put。不知道大家是否记得Hbase的javaAPI，我们介绍过Put的使用。最后我们每一条记录将会放进Hbase的表格中，例如上面的示例数据最后会解析为一条Put数据，我们可以看出它的rowKey是带着日期的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rowKey 1458731952690_84973288
cf: info ,key:tt value:测试页面1
cf: info ,key:country value:unknown
cf: info ,key:ver value:1
cf: info ,key:u_mid value:laoxiao
cf: info ,key:os value:Windows
cf: info ,key:city value:unknown
cf: info ,key:ip value:192.168.126.1
cf: info ,key:b_rst value:1366*768
cf: info ,key:en value:e_pv
cf: info ,key:c_time value:1458731943823
cf: info ,key:l value:zh-CN
cf: info ,key:u_sd value:2D24B8A2-B2EF-450C-8C86-4F8B0F3E2785
cf: info ,key:u_ud value:EAB36BC9-0347-4D33-8579-AA8C331D001A
cf: info ,key:os_v value:Windows
cf: info ,key:p_ref value:http://localhost:8080/BIG_DATA_LOG2/demo.jsp
cf: info ,key:province value:unknown
cf: info ,key:s_time value:1458731952690
cf: info ,key:p_url value:http://localhost:8080/BIG_DATA_LOG2/demo.jsp
cf: info ,key:browser value:Firefox
cf: info ,key:sdk value:js
cf: info ,key:pl value:website
cf: info ,key:browser_v value:45.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-关键指标分析&#34;&gt;3.关键指标分析&lt;/h3&gt;

&lt;p&gt;上面的ETL完成后我们的结果数据都放在hbase的event_logs表格的info列族中，现在我们需要运行代码分析这些数据，对我们的数据进行我们前面的设计文档中的关键指标分析。&lt;/p&gt;

&lt;h4 id=&#34;1-代码结构规范&#34;&gt;(1).代码结构规范&lt;/h4&gt;

&lt;p&gt;我们的程序需要定期分析hbase的数据，我们分析的指标有很多，我们需要从hbase中提取的数据也有很多。最后分析完每个指标后我们放进mysql中，供echart做展示。
1. 首先我们分析的指标需要即KPI需要专门的类定义好，放在&lt;code&gt;com.hongya.common.KpiType&lt;/code&gt;下面。
2. 我们需要自定义Key和Value的类型，这些类型包含了需要统计的关键维度信息，作为mapreduce任务的输入输出key，我们定义好了放在&lt;code&gt;com.hongya.transformer.model.dim&lt;/code&gt;下面。
3. 我们的hadoop任务写mysql需要有专门的OutputFormat，我们放在&lt;code&gt;com.hongya.transformer.service&lt;/code&gt;下面，由于每个唯独统计任务写mysql都不一样，所以我们通过配置文件的方式传入，在&lt;code&gt;output-collector.xml&lt;/code&gt;中有相关配置。
4. 无论是读写mysql还是hbase都有配置，我们通过配置文件的方式传入，配置文件有&lt;code&gt;query-mapping.xml&lt;/code&gt;，&lt;code&gt;transfomer-env.xml&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;2-业务代码实现&#34;&gt;(2).业务代码实现&lt;/h4&gt;

&lt;p&gt;上面分析了业务，我们开始写mapreduce程序统计分析指标。
我们知道我们现在的mapreduce读取hbase的数据，然后写进mysql中，相关代码我们放在了&lt;code&gt;com.hongya.transformer.mr&lt;/code&gt;包下面。
由于时间关系，我们的业务只实现了new user指标的统计，大家可以查看&lt;code&gt;com.hongya.transformer.mr.nu&lt;/code&gt;包下的内容。
当我们的hbase中有数据时，运行&lt;code&gt;com.hongya.transformer.mr.nu.NewInstallUserRunner&lt;/code&gt;，就能看到下面的结果。
&lt;img src=&#34;../images/2017-06-21-13-10-29.jpg&#34; alt=&#34;&#34; /&gt;
如果你map完成后reduce就失败 ，没关系，是因为你的mysql还没有配置好，我们在后面会介绍的。&lt;/p&gt;

&lt;h2 id=&#34;四-数据分析系统架构&#34;&gt;四、数据分析系统架构&lt;/h2&gt;

&lt;p&gt;我们有了服务器后，接下来的任务就是对服务器的数据进行收集处理，处理后的数据进行展示。我们需要搭建一个完整的服务器，这时候首先需要一个集群，我们在云端直接使用一个节点的centos作为服务器。首先打开Xshell，连上centos节点，我们这里节点名为&lt;code&gt;node1&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;1-部署hadoop和hbase&#34;&gt;1.部署hadoop和Hbase&lt;/h3&gt;

&lt;h4 id=&#34;1-部署hadoop&#34;&gt;(1).部署hadoop&lt;/h4&gt;

&lt;p&gt;hadoop单节点安装很简单，以前讲过。直接解压后，配置&lt;code&gt;hadoop-env.sh、core-site.xml、hdfs-site.xml&lt;/code&gt;
1. hadoop-env.sh配置 JAVA_HOME
2. core-site.xml配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt; &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://localhost:8020&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/hadoop&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就能够格式化，启动：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hdfs namenode -format
start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-配置hbase&#34;&gt;(2).配置Hbase&lt;/h4&gt;

&lt;p&gt;首先安装单节点的zookeeper，安装好后启动，这个不细说：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后解压Hbase安装包.
1. 配置hbase-env.sh，配置JAVA_HOME，然后将 HBASE_MANAGES_ZK改为false
2. 配置hbase-site.xm&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://localhost:8020/hbase&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;localhost&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;复制hadoop配置
复制hadoop的 core-site.xml和hdf-site.xml到hbase的conf目录下
然后就能启动Hbase了。
启动hbase后使用hbase shell进入交互窗口，执行建表语句：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;create &#39;event_logs&#39; ,&#39;info&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果执行成功了就可以开始下一步了。&lt;/p&gt;

&lt;h3 id=&#34;2-部署nginx服务&#34;&gt;2.部署nginx服务&lt;/h3&gt;

&lt;p&gt;前面我们将项目发布到tomcat上面了。正常情况下我们需要通过nginx进行负载均衡，同时收集url的请求日志。
我们可以安装nginx，也可以安装淘宝开源的tengine，比一般nginx多一些功能，而且淘宝上有中文文档。&lt;/p&gt;

&lt;h4 id=&#34;1-nginx安装&#34;&gt;(1).nginx安装&lt;/h4&gt;

&lt;p&gt;步骤如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1.安装GCC编译器等工具：
yum install -y gcc gcc-c++ autoconf automake libtool make openssl openssl-devel pcre pcre-devel
2.下载安装Nginx:
wget http://nginx.org/download/nginx-1.6.3.tar.gz
注：这里也可以下载tengine压缩包，比一般nginx多一些功能
tar -zxvf nginx-1.6.3.tar.gz 
cd nginx-1.6.3/  
./configure --prefix=/usr/local/nginx
--sbin-path=/usr/local/nginx/sbin/nginx
--conf-path=/usr/local/nginx/conf/nginx.conf
--pid-path=/usr/local/nginx/logs/nginx.pid \
--with-http_ssl_module \
--with-http_stub_status_module \
--with-http_gzip_static_module \ 
make &amp;amp;&amp;amp; make install 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果正常的话，就安装好了，然后启动nginx服务即可。记住启动之前需要先关闭之前的tomcat，因为他们两个的端口冲突了。启动命令是就是nginx，启动以后，如果不修改配置，我们可以直接打开浏览器访问8080端口，出现这样就算是成功了。
&lt;img src=&#34;../images/2017-06-21-15-52-28.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-nginx配置&#34;&gt;(2).nginx配置&lt;/h4&gt;

&lt;p&gt;现在我们已经安装了nginx，我们要配置nginx的反向代理，让他替我们监听我们的需要监听的端口。上面我们安装的时候已经配置了配置文件的路径：&lt;code&gt;/usr/local/nginx/conf/nginx.conf&lt;/code&gt;。现在我们修改他的内容。
我们让它监听80端口，这样我们给80端口发送的数据就可以被nginx收集然后我们后期处理：
我们只需要添加下面的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log_format my_format &#39;$remote_addr^A$msec^A$http_host^A$request_uri&#39;;

location = /log.gif {
   root html;
   ## 配置日志文件保存位置
   access_log /opt/data/access.log my_format;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改后的nginx.conf内容大概是这样的，其实就是添加了一行log_format，然后修改了端口信息：
&lt;img src=&#34;../images/2017-06-21-16-06-08.jpg&#34; alt=&#34;&#34; /&gt;
然后我们通过命令让配置文件生效： sudo nginx -s reload&lt;/p&gt;

&lt;h4 id=&#34;3-测试nginx收集日志&#34;&gt;(3).测试nginx收集日志&lt;/h4&gt;

&lt;p&gt;这时候我们可以启动我们之前的web项目，启动之前记得修改代码的url为刚刚配置的地址格式：
&lt;img src=&#34;../images/2017-06-21-16-11-05.jpg&#34; alt=&#34;&#34; /&gt;
然后我们发布运行项目，或者打war包放在tomcat里面，然后启动tomcat。在浏览器输入：&lt;code&gt;http://localhost:8080/taobaopayment/demo4.jsp&lt;/code&gt; 模拟用户点击。如果你发现浏览器一直处于刷新状态，可能你需要换一个浏览器：
&lt;img src=&#34;../images/2017-06-21-16-14-49.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;你还可以运行我们的Test类，来模拟后台的数据，报错没关系，只需要手动点击停止程序：
&lt;img src=&#34;../images/2017-06-21-16-16-11.jpg&#34; alt=&#34;&#34; /&gt;
然后我们查看刚刚配置的文件，已经有了几条记录，是刚刚我们发送的，而且都是我们配置的格式：
&lt;img src=&#34;../images/2017-06-21-16-25-15.jpg&#34; alt=&#34;&#34; /&gt;
到这里就恭喜，我们的gninx基本完成。&lt;/p&gt;

&lt;h3 id=&#34;3-日志收集系统&#34;&gt;3.日志收集系统&lt;/h3&gt;

&lt;p&gt;日志手机一般有两种方式，shell实现和flume实现。
shell命令前面大家都熟悉过，flume使用在前面的SparkStreaming实验也使用过，我们不介绍过多，简单回顾一下即可。
首先安装好flume，配置JAVA_HOME和HADOOP_HOME，然后新建或者复制一个配置文件，log.cfg ，添加下面的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 配置三个组件的名字
agent.sources = r1
agent.channels = c1
agent.sinks = k1

# For each one of the sources, the type is defined
agent.sources.r1.type = exec
## 这里配置你刚刚手机日志的文件
agent.sources.r1.command = tail -F /Users/dengziming/opt/data/hongya/taobaopayment/access.log
agent.sources.r1.port = 44444

# The channel can be defined as follows.
agent.channels.c1.type = memory
agent.channels.c1.capacity = 1000
agent.channels.c1.transactionCapacity = 1000

# Each sink&#39;s type must be defined
agent.sinks.k1.type = hdfs
agent.sinks.k1.hdfs.path = hdfs://localhost:8020/flume/events/%Y-%m-%d/%H%M/
agent.sinks.k1.hdfs.filePrefix = events-
agent.sinks.k1.hdfs.round = true
agent.sinks.k1.hdfs.roundValue = 10
agent.sinks.k1.hdfs.roundUnit = minute
agent.sinks.k1.hdfs.useLocalTimeStamp = true

#Specify the channel the sink should use
agent.sources.r1.channels = c1
agent.sinks.k1.channel = c1
agent.channels.memoryChannel.capacity = 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置好后适用命令启动：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/flume-ng agent --conf conf --conf-file conf/log.cfg --name agent -D flume.root.logger=INFO,console
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会收集我们刚刚nginx的日志到hadoop的 &lt;code&gt;/flume/events/%Y-%m-%d/%H%M/&lt;/code&gt; 路径下
恭喜你，马上就要进入数据分析部分&lt;/p&gt;

&lt;h3 id=&#34;4-提交数据分析任务&#34;&gt;4.提交数据分析任务&lt;/h3&gt;

&lt;p&gt;现在我们要开始运行程序，分析数据了。&lt;/p&gt;

&lt;h4 id=&#34;1-启动zookeeper-hadoop-hbase&#34;&gt;(1).启动zookeeper、hadoop、hbase&lt;/h4&gt;

&lt;p&gt;启动命令就不说了，然后记得之前我们已经在hbase中创建了表格：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;create &#39;event_logs&#39; ,&#39;info&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../images/2017-06-21-16-45-52.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-运行etl任务&#34;&gt;(2).运行ETL任务&lt;/h4&gt;

&lt;p&gt;我们的etl的任务是 &lt;code&gt;com.hongya.etl.mr.ald.AnalyserLogDataRunner&lt;/code&gt;，打开这段代码，我们修改几个路径和配置，因为是测试，我们把数据放在本地运行。修改的主要是zookeeper地址和我们刚刚的日志路径：
&lt;img src=&#34;../images/2017-06-21-16-41-30.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后运行程序：
&lt;img src=&#34;../images/2017-06-21-16-46-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后我们可以根据日志看到打印的rowKey，我们可以在hbase中查看这些rowKey
&lt;img src=&#34;../images/2017-06-21-16-48-51.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-创建mysql表格&#34;&gt;(3).创建mysql表格&lt;/h4&gt;

&lt;p&gt;我们的etl完成后数据放在hbase中，然后我们需要进行统计分析，结果放在mysql，首先是建立mysql表格，我们的表格统一放在数据库report下面，首先建库，然后按照下面的语句依次建表：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;DROP TABLE IF EXISTS `stats_user`;
CREATE TABLE `stats_user` (
  `date_dimension_id` int(11) NOT NULL,
  `platform_dimension_id` int(11) NOT NULL,
  `active_users` int(11) DEFAULT &#39;0&#39; COMMENT &#39;活跃用户数&#39;,
  `new_install_users` int(11) DEFAULT &#39;0&#39; COMMENT &#39;新增用户数&#39;,
  `total_install_users` int(11) DEFAULT &#39;0&#39; COMMENT &#39;总用户数&#39;,
  `sessions` int(11) DEFAULT &#39;0&#39; COMMENT &#39;会话个数&#39;,
  `sessions_length` int(11) DEFAULT &#39;0&#39; COMMENT &#39;会话长度&#39;,
  `total_members` int(11) unsigned DEFAULT &#39;0&#39; COMMENT &#39;总会员数&#39;,
  `active_members` int(11) unsigned DEFAULT &#39;0&#39; COMMENT &#39;活跃会员数&#39;,
  `new_members` int(11) unsigned DEFAULT &#39;0&#39; COMMENT &#39;新增会员数&#39;,
  `created` date DEFAULT NULL,
  PRIMARY KEY (`platform_dimension_id`,`date_dimension_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT COMMENT=&#39;统计用户基本信息的统计表&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这只是一个表格，由于我们的表格太多，这里不展示，我们会将所有数据库的建表语句放在文件中，大家可以参考，最终如图：
&lt;img src=&#34;../images/2017-06-21-16-55-12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-运行统计任务&#34;&gt;(4).运行统计任务&lt;/h4&gt;

&lt;p&gt;新用户点击分析任务放在&lt;code&gt;com.hongya.transformer.mr.nu.NewInstallUserRunner&lt;/code&gt;中，大家可以查看代码，然后我们修改一下配置，主要是mysql的用户名密码，在DimensionConverterImpl中，另外我们还有查看核对 src/transformer-env.xml 下的内容：
如图，修改用户名密码为你的mysql设置：
&lt;img src=&#34;../images/2017-06-21-16-58-32.jpg&#34; alt=&#34;&#34; /&gt;
修改zookeeper地址和运行的起始日期，你可以设置的小一点：
&lt;img src=&#34;../images/2017-06-21-16-57-33.jpg&#34; alt=&#34;&#34; /&gt;
然后我们点击运行，我们就可以根据日志看到map和reduce执行的过程:
&lt;img src=&#34;../images/2017-06-21-17-02-13.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;执行完成后，我们查看我们刚刚的mysql的report库的stats_device_browser和stats_user表格：
&lt;img src=&#34;../images/2017-06-21-17-03-45.jpg&#34; alt=&#34;&#34; /&gt;
当然我们还可以查看dimension_browser等其他表格。
程序执行成功。&lt;/p&gt;

&lt;h3 id=&#34;4-数据转移系统&#34;&gt;4.数据转移系统&lt;/h3&gt;

&lt;p&gt;数据转移系统我们使用sqoop，由于我们的部分mapreduce任务每次运行的结果都放在hadoop或者Hbase上面，我们可能需要手动将关键指标转移到关系型数据库，然后编写代码进行展示。但是在这里，我们都写进了mysql，就暂时不适用sqoop了，也是为了减轻大家的负担。&lt;/p&gt;

&lt;h3 id=&#34;5-数据展示&#34;&gt;5.数据展示&lt;/h3&gt;

&lt;p&gt;数据展示我们使用 jquery + Echart吧。真正项目的echart展示部分一般不需要我们管，会有专门的前端高手负责，所以我们就简单的做一下吧。以浏览器维度为例，我们直接写sql语句&lt;code&gt;select name,count(*) from dimension_browser group by browser_name&lt;/code&gt;，将结果文件写到echart的option属性中：
&lt;img src=&#34;../images/2017-06-21-20-20-50.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后重新再浏览器段查看吧：
&lt;img src=&#34;../images/2017-06-21-20-21-47.jpg&#34; alt=&#34;&#34; /&gt;
当然我这是一种不可取的做法，因为这种方式显然是不符合企业生产环境的。真正的生产环境肯定是通过后台和数据库交互，通过ajax将数据传给前端展示，我们做的很敷衍，是因为这不是我们的重点。&lt;/p&gt;

&lt;h3 id=&#34;6-项目发布&#34;&gt;6.项目发布&lt;/h3&gt;

&lt;p&gt;这上面的所有步骤都完成了，就可以发布项目了，我们需要一套任务调度系统。azkaban是目前来说用的比较多的任务调度系统，我们推荐大家课后了解一下azkaban的安装使用。这里我们没法演示了。&lt;/p&gt;

&lt;h2 id=&#34;项目上线&#34;&gt;项目上线&lt;/h2&gt;

&lt;h3 id=&#34;1-基本步骤&#34;&gt;1.基本步骤&lt;/h3&gt;

&lt;p&gt;将整个项目设计好以后，就可以上线了，这里我们总结一下真实项目上线的过程。
1. 软件的安装
本地安装开发环境需要的东西，以及相关的依赖。服务器需要安装tomcat、nginx、zookeeper、hadoop、Hbase
2. 项目开发
这里的项目开发有三部分，服务端程序，日志分析程序，前端展示程序，其中日志分析程序我们只完成了new user 开发，剩下的业务由大家自己开发。前端展示程序我们只是简单展示，没有开发，这不是重点。
3. 搭建nginx服务器，监听80端口
nginx的安装和部署需要注意很多，安装完成后修改配置文件。
4. 启动flume，收集来自nginx的数据
flume配置完成后会收集日志文件的日志，按照时间放到hadoop上面。
5. 发布web项目
将项目打成war包，放到tomcat上，然后浏览器就可以访问，有访问时会向80端口发送数据。
6. 建表
新建hbase的表格和mysql表格
7. 定时启动hadoop任务
我们通过以前说过的方法将程序打成jar包，上传到linux，在Linux上通过&lt;code&gt;hadoop jar&lt;/code&gt;命令提交。
8. 启动展示任务
这里我们简单处理一下忽略掉。
9. 将运行和展示任务添加到定时任务进行调度
这部分比较复杂，需要专门的时间学习。&lt;/p&gt;

&lt;h3 id=&#34;2-自己动手发布程序&#34;&gt;2.自己动手发布程序&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;安装相关软件，我这里已经安装完成，大家自己检查安装。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装hadoop、zookeeper、hbase、flume并配置
这部分不详细讲解，配置方法上面都有，配置好以后启动相应集群。启动命令分别为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start-dfs.sh
start-yarn.sh
start-hbase.sh
bin/flume-ng agent -c ./conf -f ./conf/log.cfg -n agent 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至少有这些java进程：
&lt;img src=&#34;../images/2017-06-21-21-38-57.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装nginx，启动nginx服务，修改nginx的配置文件，监听80端口，并且收集格式为： /log.gif 的url。
可以在浏览器访问linux的80端口：
&lt;img src=&#34;../images/2017-06-21-21-40-36.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;项目打war包，放到tomcat中。
打包之前，修改代码的url为你的linux节点加上log.gif
&lt;img src=&#34;../images/2017-06-21-21-57-51.jpg&#34; alt=&#34;&#34; /&gt;
然后打成war包，名字为：&lt;code&gt;taobaopayment.war&lt;/code&gt;，放在tomcat的webapps目录下，使员工startup.sh 启动tomcat，访问8080端口，然后访&lt;code&gt;http://node1:8080/taobaopayment/demo4.jsp&lt;/code&gt;：
如果这里一直在刷新，那么需要换一个浏览器：
&lt;img src=&#34;../images/2017-06-21-22-06-20.jpg&#34; alt=&#34;&#34; /&gt;
比如我用Safari浏览器，不断点击，产生数据：
&lt;img src=&#34;../images/2017-06-21-22-07-45.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建hbase和mysql表格
hbase创建event_logs表格，info列族，
mysql建表语句文件里有。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;执行mapreduce的ETL任务
你可以选择打jar包，或者在本地执行，执行的主类是：&lt;code&gt;com.hongya.etl.mr.ald.AnalyserLogDataRunner&lt;/code&gt;
需要修改zookeeper配置和输入路径，如果在集群上运行，这个输入路径是前面配置的flume手机日志的路径。
&lt;img src=&#34;../images/2017-06-21-22-12-59.jpg&#34; alt=&#34;&#34; /&gt;
执行完成后，可以去hbase查看数据。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;运行分析程序
分析程序基于我们刚刚的结果，主类为：&lt;code&gt;com.hongya.transformer.mr.nu.NewInstallUserRunner&lt;/code&gt;，运行之前需要在&lt;code&gt;DimensionConverterImpl&lt;/code&gt;类中设置mysql的连接信息。
&lt;img src=&#34;../images/2017-06-21-22-16-00.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;查看mysql数据库的结果，并展示
查看mysql的结果：
&lt;img src=&#34;../images/2017-06-21-22-16-54.jpg&#34; alt=&#34;&#34; /&gt;
数据展示模块，需要使用Echart，脱离了我们的实验主题，我们简单模拟，访问浏览器的：&lt;code&gt;http://node1:8080/taobaopayment/showUser.jsp&lt;/code&gt;和&lt;code&gt;http://node1:8080/taobaopayment/showBrowser.jsp&lt;/code&gt;
&lt;img src=&#34;../images/2017-06-21-22-18-47.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>JavaNIO</title>
      <link>https://dengziming.github.io/post/java/javanio/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/javanio/</guid>
      
        <description>

&lt;p&gt;// 参考资料
&lt;a href=&#34;http://tutorials.jenkov.com/java-nio/nio-vs-io.html#main-differences-between-java-nio-and-io&#34;&gt;http://tutorials.jenkov.com/java-nio/nio-vs-io.html#main-differences-between-java-nio-and-io&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-io和nio有什么区别&#34;&gt;一、IO和NIO有什么区别&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Stream Oriented vs. Buffer Oriented&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Blocking vs. Non-blocking IO&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;IO是阻塞的，一旦调用了 read() or write()，线程就堵住了，NIO非阻塞。&lt;/p&gt;

&lt;h2 id=&#34;二-channels-and-buffers&#34;&gt;二、Channels and Buffers&lt;/h2&gt;

&lt;p&gt;Typically, all IO in NIO starts with a Channel.
A Channel is a bit like a stream. From the Channel data can be read into a Buffer.
Data can also be written from a Buffer into a Channel.&lt;/p&gt;

&lt;p&gt;There are several Channel and Buffer types. Here is a list of the primary Channel implementations in Java NIO:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FileChannel
DatagramChannel
SocketChannel
ServerSocketChannel
As you can see, these channels cover UDP + TCP network IO, and file IO.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is a list of the core Buffer implementations in Java NIO:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer
CharBuffer
DoubleBuffer
FloatBuffer
IntBuffer
LongBuffer
ShortBuffer
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;1-channel&#34;&gt;1. Channel&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;RandomAccessFile aFile = new RandomAccessFile(&amp;quot;data/nio-data.txt&amp;quot;, &amp;quot;rw&amp;quot;);
    FileChannel inChannel = aFile.getChannel();

    ByteBuffer buf = ByteBuffer.allocate(48);

    int bytesRead = inChannel.read(buf);
    while (bytesRead != -1) {

      System.out.println(&amp;quot;Read &amp;quot; + bytesRead);
      buf.flip();

      while(buf.hasRemaining()){
          System.out.print((char) buf.get());
      }

      buf.clear();
      bytesRead = inChannel.read(buf);
    }
    aFile.close();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the buf.flip() call. First you read into a Buffer. Then you flip it. Then you read out of it.&lt;/p&gt;

&lt;h3 id=&#34;2-buffer&#34;&gt;2.Buffer&lt;/h3&gt;

&lt;p&gt;Java NIO Buffers are used when interacting with NIO Channels. As you know, data is read from channels into buffers, and written from buffers into channels.&lt;/p&gt;

&lt;p&gt;A buffer is essentially a block of memory into which you can write data, which you can then later read again.
This memory block is wrapped in a NIO Buffer object, which provides a set of methods that makes it easier to work with the memory block.&lt;/p&gt;

&lt;p&gt;Using a Buffer to read and write data typically follows this little 4-step process:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. Write data into the Buffer
2. Call buffer.flip()
3. Read data out of the Buffer
4. Call buffer.clear() or buffer.compact()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When you write data into a buffer, the buffer keeps track of how much data you have written.
Once you need to read the data, you need to switch the buffer from writing mode into reading mode using the flip() method call.
In reading mode the buffer lets you read all the data written into the buffer.&lt;/p&gt;

&lt;p&gt;Once you have read all the data, you need to clear the buffer, to make it ready for writing again.
You can do this in two ways: By calling clear() or by calling compact(). The clear() method clears the whole buffer.
The compact() method only clears the data which you have already read.
Any unread data is moved to the beginning of the buffer, and data will now be written into the buffer after the unread data.&lt;/p&gt;

&lt;p&gt;above had given a simple Buffer usage example, with the write, flip, read and clear operations maked in bold.&lt;/p&gt;

&lt;h3 id=&#34;3-buffer-capacity-position-and-limit&#34;&gt;3. Buffer Capacity, Position and Limit&lt;/h3&gt;

&lt;p&gt;A Buffer has three properties you need to be familiar with, in order to understand how a Buffer works. These are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;capacity
position
limit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The meaning of position and limit depends on whether the Buffer is in read or write mode. Capacity always means the same, no matter the buffer mode.&lt;/p&gt;

&lt;p&gt;position and limit依赖于模式，而capacity在两种模式下都是一样的。&lt;/p&gt;

&lt;p&gt;Being a memory block, a Buffer has a certain fixed size, also called its &amp;ldquo;capacity&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;When you write data into the Buffer, you do so at a certain position. Initially the position is 0.
When a byte, long etc. has been written into the Buffer the position is advanced to point to the next cell in the buffer to insert data into.
Position can maximally become capacity - 1.&lt;/p&gt;

&lt;p&gt;When you read data from a Buffer you also do so from a given position.
 When you flip a Buffer from writing mode to reading mode, the position is reset back to 0.
As you read data from the Buffer you do so from position, and position is advanced to next position to read.&lt;/p&gt;

&lt;p&gt;In write mode the limit of a Buffer is the limit of how much data you can write into the buffer. In write mode the limit = capacity&lt;/p&gt;

&lt;p&gt;When flipping the Buffer into read mode, limit means the limit of how much data you can read from the data.
Therefore, when flipping a Buffer into read mode, limit is set to write position of the write mode.&lt;/p&gt;

&lt;h3 id=&#34;4-buffer-types&#34;&gt;4. Buffer Types&lt;/h3&gt;

&lt;p&gt;Java NIO comes with the following Buffer types:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer
MappedByteBuffer
CharBuffer
DoubleBuffer
FloatBuffer
IntBuffer
LongBuffer
ShortBuffer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, these Buffer types represent different data types. In other words, they let you work with the bytes in the buffer as char, short, int, long, float or double instead.&lt;/p&gt;

&lt;p&gt;The MappedByteBuffer is a bit special, and will be covered in its own text.&lt;/p&gt;

&lt;h3 id=&#34;5-allocating-a-buffer&#34;&gt;5. Allocating a Buffer&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer buf = ByteBuffer.allocate(48);

CharBuffer buf = CharBuffer.allocate(1024);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;6-writing-data-to-a-buffer&#34;&gt;6. Writing Data to a Buffer&lt;/h3&gt;

&lt;p&gt;You can write data into a Buffer in two ways:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Write data from a Channel into a Buffer
int bytesRead = inChannel.read(buf); //read into buffer.
//
Write data into the Buffer yourself, via the buffer&#39;s put() methods.
buf.put(127);    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;7-flip&#34;&gt;7. flip&lt;/h3&gt;

&lt;p&gt;The flip() method switches a Buffer from writing mode to reading mode.
Calling flip() sets the position back to 0, and sets the limit to where position just was.&lt;/p&gt;

&lt;h3 id=&#34;8-reading-data-from-a-buffer&#34;&gt;8. Reading Data from a Buffer&lt;/h3&gt;

&lt;p&gt;There are two ways you can read data from a Buffer.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Read data from the buffer into a channel.
//read from buffer into channel.
int bytesWritten = inChannel.write(buf);

Read data from the buffer yourself, using one of the get() methods.
byte aByte = buf.get();    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;9-rewind&#34;&gt;9. rewind&lt;/h3&gt;

&lt;p&gt;The Buffer.rewind() sets the position back to 0, so you can reread all the data in the buffer.&lt;/p&gt;

&lt;p&gt;The limit remains untouched, thus still marking how many elements (bytes, chars etc.) that can be read from the Buffer.&lt;/p&gt;

&lt;h3 id=&#34;10-clear-and-compact&#34;&gt;10. clear() and compact()&lt;/h3&gt;

&lt;p&gt;Once you are done reading data out of the Buffer you have to make the Buffer ready for writing again. You can do so either by calling clear() or by calling compact().&lt;/p&gt;

&lt;p&gt;If you call clear() the position is set back to 0 and the limit to capacity. In other words, the Buffer is cleared.
The data in the Buffer is not cleared. Only the markers telling where you can write data into the Buffer are.&lt;/p&gt;

&lt;p&gt;compact() copies all unread data to the beginning of the Buffer. Then it sets position to right after the last unread element.
The limit property is still set to capacity, just like clear() does. Now the Buffer is ready for writing, but you will not overwrite the unread data.&lt;/p&gt;

&lt;h3 id=&#34;11-mark-and-reset&#34;&gt;11. mark() and reset()&lt;/h3&gt;

&lt;p&gt;You can mark a given position in a Buffer by calling the Buffer.mark() method. You can then later reset the position back to the marked position by calling the Buffer.reset() method. Here is an example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;buffer.mark();

//call buffer.get() a couple of times, e.g. during parsing.

buffer.reset();  //set position back to mark.    
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;五-java-nio-scatter-gather&#34;&gt;五、Java NIO Scatter / Gather&lt;/h2&gt;

&lt;p&gt;javaNIO自带了Scatter/gather的支持，用于从Channel读数据和写数据。&lt;/p&gt;

&lt;p&gt;scattering read from a channel：从channel读数据到不止一个Buffer，所以会 &amp;ldquo;scatters&amp;rdquo; the data from the channel into multiple buffers.&lt;/p&gt;

&lt;p&gt;gathering write to a channel: 从多个 buffer 写到一个Channel，多疑 &amp;ldquo;gathers&amp;rdquo; the data from multiple buffers into one channel。&lt;/p&gt;

&lt;h3 id=&#34;1-scattering-reads&#34;&gt;1. Scattering Reads&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ByteBuffer header = ByteBuffer.allocate(128);
ByteBuffer body   = ByteBuffer.allocate(1024);

ByteBuffer[] bufferArray = { header, body };

channel.read(bufferArray);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public static void scatter() throws Exception {

        RandomAccessFile aFile = new RandomAccessFile(&amp;quot;src/main/resources/data/nio-data.txt&amp;quot;, &amp;quot;rw&amp;quot;);

        FileChannel inChannel = aFile.getChannel();


        ByteBuffer header = ByteBuffer.allocate(128);
        ByteBuffer body   = ByteBuffer.allocate(1028);

        ByteBuffer[] bufferArray = { header, body };

        long bytesRead = inChannel.read(bufferArray);

        System.out.println(&amp;quot;Read &amp;quot; + bytesRead);
        header.flip();
        body.flip();

        while(header.hasRemaining()){
            System.out.print((char) header.get());
        }
        while(body.hasRemaining()){
            System.out.print((char) body.get());
        }

        header.clear();
        body.clear();


        aFile.close();

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The fact that scattering reads fill up one buffer before moving on to the next, means that it is not suited for dynamically sized message parts.&lt;/p&gt;

&lt;h3 id=&#34;2-gathering-writes&#34;&gt;2. Gathering Writes&lt;/h3&gt;

&lt;p&gt;Here is a code example that shows how to perform a gathering write:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer header = ByteBuffer.allocate(128);
ByteBuffer body   = ByteBuffer.allocate(1024);

//write data into buffers

ByteBuffer[] bufferArray = { header, body };

channel.write(bufferArray);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行下面的代码，会得到一个文件，里面是 header+body&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void gather() throws Exception {

        RandomAccessFile aFile = new RandomAccessFile(&amp;quot;src/main/resources/data/nio-in.txt&amp;quot;, &amp;quot;rw&amp;quot;);

        FileChannel inChannel = aFile.getChannel();

        ByteBuffer header = ByteBuffer.allocate(12);

        header.put(&amp;quot;header&amp;quot;.getBytes());
        header.put(&amp;quot;body&amp;quot;.getBytes());
        ByteBuffer body   = ByteBuffer.allocate(120);

        ByteBuffer[] bufferArray = { header, body };

        header.flip();
        body.flip();
        inChannel.write(bufferArray);

        inChannel.force(true);
        inChannel.close();
        header.clear();
        body.clear();

        aFile.close();

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;四-java-nio-channel-to-channel-transfers&#34;&gt;四、Java NIO Channel to Channel Transfers&lt;/h2&gt;

&lt;p&gt;channel的传输工具，类似IOUtils&lt;/p&gt;

&lt;h3 id=&#34;1&#34;&gt;1.&lt;/h3&gt;

&lt;p&gt;The FileChannel.transferFrom() method transfers data from a source channel into the FileChannel. Here is a simple example: transferFrom()&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
RandomAccessFile fromFile = new RandomAccessFile(&amp;quot;fromFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      fromChannel = fromFile.getChannel();

RandomAccessFile toFile = new RandomAccessFile(&amp;quot;toFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      toChannel = toFile.getChannel();

long position = 0;
long count    = fromChannel.size();

toChannel.transferFrom(fromChannel, position, count);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The parameters position and count, tell where in the destination file to start writing (position), and how many bytes to transfer maximally (count). If the source channel has fewer than count bytes, less is transfered.&lt;/p&gt;

&lt;p&gt;Additionally, some SocketChannel implementations may transfer only the data the SocketChannel has ready in its internal buffer here and now - even if the SocketChannel may later have more data available. Thus, it may not transfer the entire data requested (count) from the SocketChannel into FileChannel.&lt;/p&gt;

&lt;h3 id=&#34;2&#34;&gt;2.&lt;/h3&gt;

&lt;p&gt;The transferTo() method transfer from a FileChannel into some other channel. Here is a simple example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;RandomAccessFile fromFile = new RandomAccessFile(&amp;quot;fromFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      fromChannel = fromFile.getChannel();

RandomAccessFile toFile = new RandomAccessFile(&amp;quot;toFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      toChannel = toFile.getChannel();

long position = 0;
long count    = fromChannel.size();

fromChannel.transferTo(position, count, toChannel);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice how similar the example is to the previous. The only real difference is the which FileChannel object the method is called on. The rest is the same.&lt;/p&gt;

&lt;p&gt;The issue with SocketChannel is also present with the transferTo() method. The SocketChannel implementation may only transfer bytes from the FileChannel until the send buffer is full, and then stop.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tutorials.jenkov.com/java-nio/selectors.html&#34;&gt;http://tutorials.jenkov.com/java-nio/selectors.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;四-selectors&#34;&gt;四、Selectors&lt;/h2&gt;

&lt;p&gt;NIO&amp;rsquo;s Selectors 允许一个 a single thread 去 monitor multiple channels of input。
你可以注册 multiple channels with a selector，然后用一个线程去 &amp;ldquo;select&amp;rdquo; the channels that have input available for processing,
或者 or select the channels that are ready for writing。
This selector mechanism makes it easy for a single thread to manage multiple channels.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析1-下载编译启动</title>
      <link>https://dengziming.github.io/post/titan/first/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/first/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph了&lt;/p&gt;

&lt;h2 id=&#34;一-下载编译&#34;&gt;一、下载编译&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j企业版分析</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E4%BC%81%E4%B8%9A%E7%89%88%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E4%BC%81%E4%B8%9A%E7%89%88%E5%88%86%E6%9E%90/</guid>
      
        <description>&lt;p&gt;阅读neo4j源码是为了改造，所以研究一下企业版的源码。OpenEnterpriseNeoServer 和 CommunityNeoServer 稍微对比一下。&lt;/p&gt;

&lt;p&gt;CommunityNeoServer&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;protected static final GraphFactory COMMUNITY_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
                .newFacade( storeDir, config, dependencies );
    };

    public CommunityNeoServer( Config config, GraphDatabaseFacadeFactory.Dependencies dependencies,
            LogProvider logProvider )
    {
        this( config, lifecycleManagingDatabase( COMMUNITY_FACTORY ), dependencies, logProvider );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OpenEnterpriseNeoServer&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    protected static Database.Factory createDbFactory( Config config )
    {
        final Mode mode = config.get( EnterpriseEditionSettings.mode );

        switch ( mode )
        {
        case HA:
            return lifecycleManagingDatabase( HA_FACTORY );
        case ARBITER:
            // Should never reach here because this mode is handled separately by the scripts.
            throw new IllegalArgumentException( &amp;quot;The server cannot be started in ARBITER mode.&amp;quot; );
        case CORE:
            return lifecycleManagingDatabase( CORE_FACTORY );
        case READ_REPLICA:
            return lifecycleManagingDatabase( READ_REPLICA_FACTORY );
        default:
            return lifecycleManagingDatabase( ENTERPRISE_FACTORY );
        }
    }
    
    private static final GraphFactory HA_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new HighlyAvailableGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory ENTERPRISE_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new EnterpriseGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory CORE_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new CoreGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory READ_REPLICA_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new ReadReplicaGraphDatabase( storeDir, config, dependencies );
    };
    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终不一样的还是启动的 server的不一样而已。最终是在 PlatformModule EditionModule DataSourceModule 三个类负责的 中不一样的。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j存储结构分析</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</guid>
      
        <description>

&lt;h2 id=&#34;1-修改配置&#34;&gt;1.修改配置&lt;/h2&gt;

&lt;p&gt;待完成&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j导数据</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E5%AF%BC%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E5%AF%BC%E6%95%B0%E6%8D%AE/</guid>
      
        <description>

&lt;h2 id=&#34;1-修改配置&#34;&gt;1.修改配置&lt;/h2&gt;

&lt;p&gt;dbms.security.allow_csv_import_from_file_urls=true
&amp;ndash; load csv 命令&lt;/p&gt;

&lt;p&gt;dbms.directories.import=import&lt;/p&gt;

&lt;p&gt;restart neo4j&lt;/p&gt;

&lt;h3 id=&#34;2-导入数据方法1&#34;&gt;2.导入数据方法1&lt;/h3&gt;

&lt;p&gt;load csv with headers from &amp;ldquo;file:///path/to/file&amp;rdquo; as row
create (:Employee {employeeId:toInt(row.id),first_name:row,first_name,title:row.title });&lt;/p&gt;

&lt;h3 id=&#34;3-导入数据方法2&#34;&gt;3. 导入数据方法2&lt;/h3&gt;

&lt;p&gt;dbms.directories.import=/var/lib/neo4j/import/&lt;/p&gt;

&lt;p&gt;注释：&lt;/p&gt;

&lt;h1 id=&#34;dbms-security-allow-csv-import-from-file-urls-true&#34;&gt;dbms.security.allow_csv_import_from_file_urls=true&lt;/h1&gt;

&lt;p&gt;将文件放入 ：/var/lib/neo4j/import/  文件夹下，直接输入文件名即可：&lt;/p&gt;

&lt;p&gt;load csv with headers from &amp;ldquo;file:///filename&amp;rdquo; as row
create (:Employee {employeeId:toInt(row.id),first_name:row,first_name,title:row.title });&lt;/p&gt;

&lt;h3 id=&#34;4-初始化导数据&#34;&gt;4.初始化导数据&lt;/h3&gt;

&lt;p&gt;新建每个节点和关系的header文件和数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# vertex header
phone:ID(PHONE),isblack,ismedia,iscuishou
# edge header
:START_ID(USERID),:END_ID(PHONE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后导数据：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;neo4j-import \
 --into /data/neo4j/graph/all20180417.db \
 --skip-duplicate-nodes true \
 --skip-bad-relationships true \
 --ignore-extra-columns true \
 --ignore-empty-strings true \
 --bad-tolerance 10000000 \
  --processors 56 \
 --id-type string \
 --max-memory 170G \
--nodes:LBS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_lbs.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_lbs.txt&amp;quot;  \
--nodes:IDCARD &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_idcard.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_idcard.txt&amp;quot;  \
--nodes:GNHID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_gnhid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_gnhid.txt&amp;quot;  \
--nodes:QQ &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_qq.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_qq.txt&amp;quot;  \
--nodes:WEIXIN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_weixin.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_weixin.txt&amp;quot;  \
--nodes:EMAIL &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_email.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_email.txt&amp;quot;  \
--nodes:DEVICETOKEN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_devicetoken.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_devicetoken.txt&amp;quot;  \
--nodes:COMPANY &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_company.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_company.txt&amp;quot;  \
--nodes:IP &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_ip.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_ip.txt&amp;quot;  \
--nodes:ORDERID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_orderid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_orderid.txt&amp;quot;  \
--nodes:USERID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_userid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_userid.txt&amp;quot;  \
--nodes:PHONE &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_phone.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_phone.txt&amp;quot;  \
--nodes:WIFI &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_wifi.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_wifi.txt&amp;quot;  \
--relationships:USERID_PHONE_EMG &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_phone_emg.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_phone_emg.txt&amp;quot;  \
--relationships:USERID_PHONE_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_phone_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_phone_loan.txt&amp;quot;  \
--relationships:USERID_COMPANY_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_company_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_company_loan.txt&amp;quot;  \
--relationships:USERID_LBS_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_lbs_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_lbs_loan.txt&amp;quot;  \
--relationships:USERID_DEVICETOKEN_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_devicetoken_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_devicetoken_loan.txt&amp;quot;  \
--relationships:USERID_LBS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_lbs.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_lbs.txt&amp;quot;  \
--relationships:USERID_COMPANY_GJJ &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_company_gjj.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_company_gjj.txt&amp;quot;  \
--relationships:USERID_IDCARD &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_idcard.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_idcard.txt&amp;quot;  \
--relationships:USERID_COMPANY_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_company_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_company_gnh_users.txt&amp;quot;  \
--relationships:USERID_GNHID_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_gnhid_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_gnhid_users.txt&amp;quot;  \
--relationships:USERID_IP_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_ip_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_ip_gnh_users.txt&amp;quot;  \
--relationships:USERID_PHONE_GNH_EMG_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_gnh_emg_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_gnh_emg_users.txt&amp;quot;  \
--relationships:USERID_QQ_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_qq_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_qq_gnh_users.txt&amp;quot;  \
--relationships:ORDERID_IP_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_orderid_ip_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_orderid_ip_gnh_users.txt&amp;quot;  \
--relationships:USERID_ORDERID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_orderid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_orderid.txt&amp;quot; \
--relationships:USERID_DEVICETOKEN_RISKBRAIN_UMID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_devicetoken_riskbrain_umid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_devicetoken_riskbrain_umid.txt&amp;quot; \
--relationships:USERID_DEVICETOKEN_USER_DEVICES &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_devicetoken_t_user_devices.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_devicetoken_t_user_devices.txt&amp;quot; \
--relationships:USERID_DEVICETOKEN_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_devicetoken_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_devicetoken_user_event.txt&amp;quot; \
--relationships:USERID_COMPANY_USER_INFO_EXT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_company_user_info_ext.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_company_user_info_ext.txt&amp;quot; \
--relationships:USERID_IP_CUSTINFO &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_ip_custinfo.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_ip_custinfo.txt&amp;quot; \
--relationships:USERID_IP_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_ip_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_ip_user_event.txt&amp;quot; \
--relationships:USERID_EMAIL_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_email_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_email_user_event.txt&amp;quot; \
--relationships:USERID_EMAIL_EXTMAIL_USER_MAILACCOUNT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_email_user_mailaccount.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_email_user_mailaccount.txt&amp;quot; \
--relationships:USERID_QQ_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_qq_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_qq_user_event.txt&amp;quot; \
--relationships:USERID_WEIXIN_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_weixin_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_weixin_user_event.txt&amp;quot; \
--relationships:USERID_PHONE_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_user_event.txt&amp;quot; \
--relationships:USERID_PHONE_CUSTINFO &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_custinfo.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_custinfo.txt&amp;quot; \
--relationships:USERID_PHONE_USERCENTER &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_usercenter.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_usercenter.txt&amp;quot; \
--relationships:USERID_PHONE_USER_EMG_CONTACT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_user_emg_contact.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_user_emg_contact.txt&amp;quot; \
--relationships:USERID_PHONE_TEL &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_phone_tel.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_phone_tel.txt&amp;quot; \
--relationships:USERID_PHONE_CONTACT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_contact.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_contact.txt&amp;quot; \
--relationships:PHONE_PHONE_TEL &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_phone_phone_tel.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_phone_phone_tel.txt&amp;quot; \
--relationships:PHONE_PHONE_CONTACT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_phone_phone_contact.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_phone_phone_contact.txt&amp;quot; \
--relationships:USERID_WIFI &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_wifi.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_wifi.txt&amp;quot; \
--relationships:ORDERID_WIFI &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_orderid_wifi.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_orderid_wifi.txt&amp;quot; \
          &amp;gt; /data/neo4j/graph/all20180417.log 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析1-编译打包启动</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E5%90%AF%E5%8A%A8/</guid>
      
        <description>

&lt;h2 id=&#34;1-打包&#34;&gt;1.打包&lt;/h2&gt;

&lt;h3 id=&#34;1-打包community&#34;&gt;1.打包community&lt;/h3&gt;

&lt;p&gt;进入community,neo4j-graphdb-api，
注释掉common的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.revapi&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;revapi-maven-plugin&amp;lt;/artifactId&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;里面好像涉及到了版本检查，如果某个类的最新发布版本已经没有这个方法，打包会失败，反正对打包有影响，不删除可能会失败。&lt;/p&gt;

&lt;p&gt;还可能要在主项目的pom里面注释掉：&lt;code&gt;maven-checkstyle-plugin&lt;/code&gt;，代码风格检查可能会通不过。
然后用maven命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests package install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-打包企业版&#34;&gt;2.打包企业版&lt;/h3&gt;

&lt;p&gt;进入enterprise,ha目录
进入management,注释掉 &lt;groupId&gt;org.revapi&lt;/groupId&gt;
还有其他问题，比如java文件没有license，这里不一一列举。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests package install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-打包完整的tar包&#34;&gt;3. 打包完整的tar包&lt;/h3&gt;

&lt;p&gt;进入项目路径&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn clean install -Dmaven.test.skip=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要注意两个参数的异同点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
-DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。

-Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打包的输出文件：packaging/standalone/target/neo4j-community-3.4.0-SNAPSHOT-unix.tar.gz，这个就是我们的neo4j包。解压后，放到一个目录。一方面你可以选择执行 bin/neo4j start 启动neo4j，我们要分析源码，自然会是在本地启动。&lt;/p&gt;

&lt;h2 id=&#34;二-运行&#34;&gt;二、运行&lt;/h2&gt;

&lt;h3 id=&#34;1-启动&#34;&gt;1.启动&lt;/h3&gt;

&lt;p&gt;我们在IDEA中，找到入口类：org.neo4j.server.CommunityEntryPoint，点击运行，然后会报错，我们需要添加运行参数：&lt;/p&gt;

&lt;p&gt;-server &amp;ndash;home-dir=~/neo4j-community-3.2.6 &amp;ndash;config-dir=~/neo4j-community-3.2.6/conf&lt;/p&gt;

&lt;p&gt;这里的参数是刚刚解压的neo4j目录和配置文件。然后运行成功，访问 &lt;a href=&#34;http://localhost:7474/browser/，会发现有问题。&#34;&gt;http://localhost:7474/browser/，会发现有问题。&lt;/a&gt;
通过调试前端的js代码，我们发现版本有问题，这里我们稍作修改，找到 org.neo4j.kernel.internal.Version。最后的代码注释掉，换成我们的版本，也就是将Version.class.getPackage().getImplementationVersion() 换成 3.4，然后就可以运行成功了。
打开7474端口，写cypher语言，查看。&lt;/p&gt;

&lt;h3 id=&#34;2-打断点调试&#34;&gt;2.打断点调试&lt;/h3&gt;

&lt;p&gt;既然是源码分析，我们的办法就是先看，然后打断点调试，查看调用栈，但是由于是多线程，其实还是很有难度的，容易跟丢，后续我们慢慢来吧。&lt;/p&gt;

&lt;h3 id=&#34;3-代码结构查看&#34;&gt;3.代码结构查看&lt;/h3&gt;

&lt;p&gt;看源码之前我们先大概过一下代码结构。我们主要看 community 模块的结构，里面有很多子模块。&lt;/p&gt;

&lt;p&gt;我们可以大概根据名字猜测 ：io模块是用来处理读写数据的，kernel模块是我们需要着重查看的。bolt是处理bolt连接的，server是整个项目启动的。codegen是动态生成代码的。我们要从内核部分开始看。&lt;/p&gt;

&lt;h3 id=&#34;4-架构了解&#34;&gt;4.架构了解&lt;/h3&gt;

&lt;p&gt;The node records contain only a pointer to their first property and their first relationship (in what is oftentermed the _relationship chain). From here, we can follow the (doubly) linked-list of relationships until we find the one we’re interested in, the LIKES relationship from Node 1 to Node 2 in this case. Once we’ve found the relationship record of interest, we can simply read its properties if there are any via the same singly-linked list structure as node properties, or we can examine the node records that it relates via its start node and end node IDs. These IDs, multiplied by the node record size, of course give the immediate offset of both nodes in the node store file.&lt;/p&gt;

&lt;p&gt;这段话来自&lt;Graph Databases&gt;(作者：IanRobinson) 一书。描述了neo4j的存储方式。详情可以查阅其他资料。&lt;/p&gt;

&lt;h3 id=&#34;5-源码查看&#34;&gt;5.源码查看&lt;/h3&gt;

&lt;p&gt;参考下一篇&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析2-启动源码跟踪</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E8%B7%9F%E8%B8%AA/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E8%B7%9F%E8%B8%AA/</guid>
      
        <description>

&lt;h2 id=&#34;1-第一遍调试&#34;&gt;1.第一遍调试&lt;/h2&gt;

&lt;p&gt;第一遍就是打断点，然后查看调用栈，忽略过多的线程。&lt;/p&gt;

&lt;p&gt;找到 CommunityEntryPoint，打一个断点，调试,不断F5进入，F6单步执行，F跳出。
1. &lt;code&gt;new CommunityBootstrapper(),ServerBootstrapper.start(boot,args)&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerBootstrapper&lt;/code&gt; 中的初始化关键代码： &lt;code&gt;private GraphDatabaseDependencies dependencies = GraphDatabaseDependencies.newDependencies()&lt;/code&gt;; 这个dependencies貌似来头很大。F5进入
&lt;code&gt;public static GraphDatabaseDependencies newDependencies()&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;KernelExtensionFactory factory : Service.load( KernelExtensionFactory.class)&lt;/code&gt;
这段代码似乎跳不进去，反正最后得到了7个:&lt;/p&gt;

&lt;p&gt;0 = {LuceneKernelExtensionFactory@675} &amp;ldquo;KernelExtension:LuceneKernelExtensionFactory[lucene]&amp;rdquo;
1 = {LuceneSchemaIndexProviderFactory@679} &amp;ldquo;KernelExtension:LuceneSchemaIndexProviderFactory[lucene]&amp;rdquo;
2 = {NativeLuceneFusionSchemaIndexProviderFactory@680} &amp;ldquo;KernelExtension:NativeLuceneFusionSchemaIndexProviderFactory[lucene+native]&amp;rdquo;
3 = {BoltKernelExtension@681} &amp;ldquo;KernelExtension:BoltKernelExtension[bolt-server]&amp;rdquo;
4 = {ShellServerExtensionFactory@682} &amp;ldquo;KernelExtension:ShellServerExtensionFactory[shell]&amp;rdquo;
5 = {UdcKernelExtensionFactory@683} &amp;ldquo;KernelExtension:UdcKernelExtensionFactory[kernel udc]&amp;rdquo;
6 = {JmxExtensionFactory@684} &amp;ldquo;KernelExtension:JmxExtensionFactory[kernel jmx]&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;List&amp;lt;QueryEngineProvider&amp;gt; queryEngineProviders = asList( Service.load( QueryEngineProvider.class ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这段代码和前面一样，不过加载的是查询引擎的的class，我们暂且跳过！&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;return new GraphDatabaseDependencies( null, null, new ArrayList&amp;lt;&amp;gt;(), kernelExtensions,)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerBootstrapper.start( Bootstrapper boot, String... argv )&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;CommunityBootstrapper(AbstractNeoServer).start&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;server = createNeoServer( config, dependencies, userLogProvider );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;new CommunityNeoServer( config, dependencies, logProvider );&lt;/code&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 初始化很多属性

protected abstract WebServer createWebServer();

// 放在代码后面的属性
private final Dependencies dependencyResolver = new Dependencies( new Supplier&amp;lt;DependencyResolver&amp;gt;()
{
    @Override
    public DependencyResolver get()
    {
        Database db = dependencyResolver.resolveDependency( Database.class );
        return db.getGraph().getDependencyResolver();
    }
} );
// 构造方法
public AbstractNeoServer( Config config, Database.Factory dbFactory,
        GraphDatabaseFacadeFactory.Dependencies dependencies, LogProvider logProvider )
{
    this.logProvider = logProvider;
    // 初始化很多东西
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;AbstractNeoServer.start();&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;init()&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;lambda$lifecycleManagingDatabase$0:47, LifecycleManagingDatabase (org.neo4j.server.database)&lt;/code&gt;
这里的 java8 lamabda表达式有点不懂，总之就是这个 dbFactory.newDatabase( config, dependencies ) 执行的是这段代码：
&lt;code&gt;( config, dependencies ) -&amp;gt; new LifecycleManagingDatabase( config, graphDbFactory, dependencies );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;dependencyResolver.satisfyDependency(LifecycleManagingDatabase )&lt;/code&gt;
这里的 satisfyDependency 方法有点奇怪，总之就是将 LifecycleManagingDatabase 的所有父类添加到一个临时变量，好像啥也没做。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;life.add(LifecycleManagingDatabase)&lt;/code&gt;
奇怪的代码，后续我们专门讲解这个 life 的实现，这是注释：
Add a new Lifecycle instance. It will immediately be transitioned to the state of this LifeSupport.
将传入的dependency 新建为一个LifecycleInstance，add到 instances中。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LifecycleInstance newInstance = new LifecycleInstance( instance );
private volatile List&amp;lt;LifecycleInstance&amp;gt; instances = new ArrayList&amp;lt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;this.database = LifecycleManagingDatabase&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新建其他的，非内核部分我们忽略。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.authManagerSupplier = dependencyResolver.provideDependency( AuthManager.class );
this.userManagerSupplier = dependencyResolver.provideDependency( UserManagerSupplier.class );
this.sslPolicyFactorySupplier = dependencyResolver.provideDependency( SslPolicyLoader.class );
this.webServer = createWebServer();
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;createServerModules()
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;return Arrays.asList(
new DBMSModule( webServer, getConfig() ),
new RESTApiModule( webServer, getConfig(), getDependencyResolver(), logProvider ),
new ManagementApiModule( webServer, getConfig() ),
new ThirdPartyJAXRSModule( webServer, getConfig(), logProvider, this ),
new ConsoleModule( webServer, getConfig() ),
new Neo4jBrowserModule( webServer ),
createAuthorizationModule(),
new SecurityRulesModule( webServer, getConfig(), logProvider ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;4.创建 ServerComponentsLifecycleAdapter&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;serverComponents = new ServerComponentsLifecycleAdapter();
life.add( serverComponents );

this.initialized = true;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;life.start();
debug进入：&lt;code&gt;LifeSupport&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;init();&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;status = changedStatus( this, status, LifecycleStatus.INITIALIZING );&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;for ( LifecycleInstance instance : instances ) instance.init();
这时候有两个instance，分别是上面我们new出来的  new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter();&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;LifecycleInstance.init()
还好两个代码里面什么都没做，不然再F5进去，我要奔溃了。。。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;status = changedStatus( this, status, LifecycleStatus.STOPPED );&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;for ( LifecycleInstance instance : instances ) instance.start();
这时候有两个instance，分别是上面我们new出来的  new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter();&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. `LifecycleInstance.start() `

2. `LifecycleManagingDatabase.start()`

    ```java
    log.info( &amp;quot;Starting...&amp;quot; );
    this.graph = dbFactory.newGraphDatabase( config, dependencies );
    if ( !isInTestMode() )
    {
        preLoadCypherCompiler();
    }
    log.info( &amp;quot;Started.&amp;quot; );

    ```

    1. this.graph = dbFactory.newGraphDatabase( config, dependencies );
    这里又是lambda表达式：
    new GraphDatabaseFacadeFactory,
    ```java
    File storeDir = config.get( GraphDatabaseSettings.database_path );
    return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
           .newFacade( storeDir, config, dependencies );
    ```
    主要的核心代码已经找到了：new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );
    接下来我们主要调试这一段。

3. `ServerComponentsLifecycleAdapter.start()`
    这里主要是和web，cypher有关，我们暂时忽略。
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;2-调试-graphdatabasefacadefactory-newfacade&#34;&gt;2.调试 GraphDatabaseFacadeFactory.newFacade&lt;/h2&gt;

&lt;p&gt;上面我们已经调试到了 最后的部分，也是高潮部分。&lt;/p&gt;

&lt;p&gt;newFacade 方法：
1. &lt;code&gt;initFacade( storeDir, config, dependencies, new GraphDatabaseFacade() );&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1.`new GraphDatabaseFacade()`
初始化相关数据

2.`GraphDatabaseFacade initFacade( File storeDir, Config config, final Dependencies dependencies, final GraphDatabaseFacade graphDatabaseFacade )`

    1. `PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );`

        1. `new PlatformModule( storeDir, config, databaseInfo, dependencies, graphDatabaseFacade );`
        这一部分代码很长很关键的感觉，这里是内核相关，先跳过，回头看。下一章节 TODO

        2. EditionModule edition = editionFactory.apply( platform );

        这里和上一个PlatformModule干的事情一样。下一章节 TODO

    2. `final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );`

        1. new DataSourceModule( platformModule, editionModule, queryEngine );
        和上面的 PlatformModule 一样，一大堆的新建。。。最后 life.add( platformModule.kernelExtensions ) 新建DataSource
    3. `ClassicCoreSPI spi = new ClassicCoreSPI( platform, dataSource, msgLog, coreAPIAvailabilityGuard );`

    4. `platform.life.start();`

        1. init();
        2. for ( LifecycleInstance instance : instances ) instance.start();
            这里的instance ：

            ```java
            0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;
            1 = {LifeSupport$LifecycleInstance@3730} &amp;quot;org.neo4j.kernel.impl.util.Neo4jJobScheduler@2667f029: STARTED&amp;quot;
            2 = {LifeSupport$LifecycleInstance@3635} &amp;quot;org.neo4j.udc.UsageData@67a20f67: STARTED&amp;quot;
            3 = {LifeSupport$LifecycleInstance@3658} &amp;quot;org.neo4j.kernel.impl.logging.StoreLogService@57c758ac: STARTED&amp;quot;
            4 = {LifeSupport$LifecycleInstance@3681} &amp;quot;org.neo4j.kernel.internal.locker.StoreLockerLifecycleAdapter@a9cd3b1: STARTED&amp;quot;
            5 = {LifeSupport$LifecycleInstance@3731} &amp;quot;org.neo4j.kernel.impl.pagecache.PageCacheLifecycle@13e39c73: STOPPED&amp;quot;
            6 = {LifeSupport$LifecycleInstance@3732} &amp;quot;org.neo4j.kernel.info.DiagnosticsManager@64cd705f: STOPPED&amp;quot;
            7 = {LifeSupport$LifecycleInstance@3733} &amp;quot;org.neo4j.kernel.impl.transaction.state.DataSourceManager@548d708a: STOPPED&amp;quot;
            8 = {LifeSupport$LifecycleInstance@3734} &amp;quot;org.neo4j.kernel.impl.util.watcher.DefaultFileSystemWatcherService@4b013c76: STOPPED&amp;quot;
            9 = {LifeSupport$LifecycleInstance@3735} &amp;quot;org.neo4j.kernel.impl.core.DelegatingPropertyKeyTokenHolder@53fb3dab: STOPPED&amp;quot;
            10 = {LifeSupport$LifecycleInstance@3736} &amp;quot;org.neo4j.kernel.impl.core.DelegatingLabelTokenHolder@cb0755b: STOPPED&amp;quot;
            11 = {LifeSupport$LifecycleInstance@3737} &amp;quot;org.neo4j.kernel.impl.core.DelegatingRelationshipTypeTokenHolder@33065d67: STOPPED&amp;quot;
            12 = {LifeSupport$LifecycleInstance@3738} &amp;quot;org.neo4j.kernel.internal.DefaultKernelData@30: STOPPED&amp;quot;
            13 = {LifeSupport$LifecycleInstance@3739} &amp;quot;org.neo4j.kernel.impl.core.ThreadToStatementContextBridge@7bba5817: STOPPED&amp;quot;
            14 = {LifeSupport$LifecycleInstance@3740} &amp;quot;org.neo4j.kernel.extension.KernelExtensions@25df00a0: STOPPED&amp;quot;
            15 = {LifeSupport$LifecycleInstance@3741} &amp;quot;org.neo4j.kernel.impl.proc.Procedures@6cc4cdb9: STOPPED&amp;quot;
            16 = {LifeSupport$LifecycleInstance@3742} &amp;quot;org.neo4j.server.security.auth.BasicAuthManager@47c81abf: STOPPED&amp;quot;
            17 = {LifeSupport$LifecycleInstance@3743} &amp;quot;org.neo4j.kernel.impl.cache.MonitorGc@30b6ffe0: STOPPED&amp;quot;
            18 = {LifeSupport$LifecycleInstance@3744} &amp;quot;org.neo4j.kernel.impl.pagecache.PublishPageCacheTracerMetricsAfterStart@2415fc55: STOPPED&amp;quot;
            19 = {LifeSupport$LifecycleInstance@3745} &amp;quot;org.neo4j.kernel.DatabaseAvailability@1890516e: STOPPED&amp;quot;
            20 = {LifeSupport$LifecycleInstance@3746} &amp;quot;org.neo4j.kernel.impl.factory.DataSourceModule$StartupWaiter@16c069df: STOPPED&amp;quot;
            21 = {LifeSupport$LifecycleInstance@3747} &amp;quot;org.neo4j.kernel.internal.KernelEventHandlers@2bec854f: STOPPED&amp;quot;
           ```
           每个instance的start方法具体是怎样的，我们稍后细看，这里跳过 TODO
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-学习neo4j-server的设计模式&#34;&gt;3.学习neo4j server的设计模式&lt;/h2&gt;

&lt;p&gt;上面我们调试了一遍启动过程，整个个过程可以多来几次，每一遍加深对neo4j的理解。
调试之前我们学习一下 LifeSupport 这个类的设计和使用。&lt;/p&gt;

&lt;p&gt;LifeSupport继承自Lifecycle，源码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Lifecycle interface for kernel components. Init is called first,
 * followed by start,
 * and then any number of stop-start sequences,
 * and finally stop and shutdown.
 *
 * As a stop-start cycle could be due to change of configuration, please perform anything that depends on config
 * in start().
 *
 * Implementations can throw any exception. Caller must handle this properly.
 *
 * The primary purpose of init in a component is to set up structure: instantiate dependent objects,
 * register handlers/listeners, etc.
 * Only in start should the component actually do anything with this structure.
 * Stop reverses whatever was done in start, and shutdown finally clears any set-up structure, if necessary.
 */
public interface Lifecycle
{
    void init() throws Throwable;

    void start() throws Throwable;

    void stop() throws Throwable;

    void shutdown() throws Throwable;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注释很清楚，万一看不懂百度翻译一下就明白。注意这里：init只是set up structure——初始化依赖的对象，注册处理器/监听器。只有start方法执行后才会用这个structure TOTDO，是不是看源码可以跳过init&lt;/p&gt;

&lt;p&gt;按F4发现有很多的实现类&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;PaxosClusterMemberAvailability (org.neo4j.cluster.member.paxos)
DefaultKernelData (org.neo4j.kernel.internal)
LifecycleAdapter (org.neo4j.kernel.lifecycle)
NeoStoreDataSource (org.neo4j.kernel)
TransactionPropagator (org.neo4j.kernel.ha.transaction)
ShellServerKernelExtension (org.neo4j.shell.impl)
OnlineBackupKernelExtension (org.neo4j.backup)
DummyExtension (org.neo4j.kernel)
LifeSupport (org.neo4j.kernel.lifecycle)
HighAvailabilityModeSwitcher (org.neo4j.kernel.ha.cluster.modeswitch)
KernelEventHandlers (org.neo4j.kernel.internal)
RecordStorageEngine (org.neo4j.kernel.impl.storageengine.impl.recordstorage)
JmxKernelExtension (org.neo4j.jmx.impl)
ExecutorLifecycleAdapter (org.neo4j.cluster)
KernelExtensions (org.neo4j.kernel.extension)
RecoveryCleanupWorkCollector (org.neo4j.index.internal.gbptree)
IndexImplementation (org.neo4j.kernel.spi.explicitindex)
NetworkReceiver (org.neo4j.cluster.com)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们重点看看 LifeSupport ，我们分析发现 LifeSupport 也是一个 Lifecycle，而且有一个 LifecycleInstance 的数组 instances ，
LifecycleInstance 也是继承自 Lifecycle。所以实际上 LifeSupport 就是一堆 Lifecycle 放在了一起，进行了一个类似装饰模式而已。
LifeSupport的init,start,stop,shutdown方法，分别是循环instances执行init,start,stop,shutdown方法。&lt;/p&gt;

&lt;p&gt;经过上面的调试，我们发现neo4j基本上就是一个一个这样的 LifeSupport 组成的。&lt;/p&gt;

&lt;h3 id=&#34;1-第一次使用&#34;&gt;(1). 第一次使用&lt;/h3&gt;

&lt;p&gt;我们第一次遇到 LifeSupport是 在： CommunityBootstrapper.start() 时候，先创建 CommunityNeoServer，调用它的 start，start 前先是init方法。遇到了两个代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );
serverComponents = new ServerComponentsLifecycleAdapter();
life.add( serverComponents );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的 life 就是 AbstractNeoServer(CommunityNeoServer) LifeSupport，是父类的成员变量，新建 CommunityNeoServer 的时候初始化的。然后在init方法中给他添加了两个 Lifecycle 的实现对象。
AbstractNeoServer(CommunityNeoServer)执行完了init方法，就执行 life 的start方法，实际上执行的还是 new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter() 的start。&lt;/p&gt;

&lt;p&gt;总结：
CommunityNeoServer 中的 出现的 LifeSupport 为：
1. new LifecycleManagingDatabase( config, graphDbFactory, dependencies )
 这里的 graphDbFactory 是 CommunityNeoServer 的一个匿名内部类接口的实现类，dependencies就是包含了 kernelExtensions 等内容的东西。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;new ServerComponentsLifecycleAdapter()&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-第二次使用&#34;&gt;(2). 第二次使用&lt;/h3&gt;

&lt;p&gt;我们后面还有一次用到了 LifeSupport 。就是执行life的start时候，需要上面的 LifecycleManagingDatabase 的 start 方法。里面最重要的就是 dbFactory.newGraphDatabase( config, dependencies );
这个 dbFactory 我们已经说了是 CommunityNeoServer 的一个匿名内部类接口的实现类 COMMUNITY_FACTORY， 最终执行方法返回：
&lt;code&gt;return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;TODO 这里出现了 DatabaseInfo.COMMUNITY ，如果我们想使用企业版的功能，肯定需要在这里修改源码。还有 CommunityEditionModule ，
创建的实例只能用于社区版，所以是否可以猜想，企业版就是比社区版多了几个 LifeSupport 而已&lt;/p&gt;

&lt;p&gt;然后调用 GraphDatabaseFacadeFactory的newFacade方法，&lt;code&gt;return initFacade( storeDir, config, dependencies, new GraphDatabaseFacade() );&lt;/code&gt;
这里 new GraphDatabaseFacade(),然后初始化，实际上就是初始化一个数据库了。
然后创建一个 platform ，经过一堆复杂处理后，调用 platform 的 life 的start方法。也就是我们关心的 LifeSupport 。在查看之前，我们需要知道创建这个 platform 干了啥。&lt;/p&gt;

&lt;p&gt;打开PlatformModule的构造方法，太复杂了。。。。，但是先别泄气，我们先抓 LifeSupport 吧，搞定了这个再看别的。&lt;/p&gt;

&lt;p&gt;前面几行 F6 跳过，然后直接看：&lt;code&gt;life = dependencies.satisfyDependency( createLife() );&lt;/code&gt;
这个 createLife 方法就是new了一个 LifeSupport，然后F6跳过几行，直接看：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 createFileSystemAbstraction 就是 new DefaultFileSystemAbstraction，然后添加到 life，这时候 life 的 size 已经是1了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;jobScheduler = life.add( dependencies.satisfyDependency( createJobScheduler() ) );&lt;/code&gt;
这里 createJobScheduler 就是 Neo4jJobScheduler。这时候 life 的 size 已经是2了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;dependencies.satisfyDependency( life.add( new UsageData( jobScheduler ) ) );&lt;/code&gt;
这里 new UsageData ,这时候 life 的 size 已经是3了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;life.add( dependencies.satisfyDependency( new StoreLockerLifecycleAdapter( createStoreLocker() ) ) );&lt;/code&gt;
这里的 createStoreLocker 就是 new GlobalStoreLocker( fileSystem, storeDir );
然后 new StoreLockerLifecycleAdapter，这时候 life 的 size 已经是5了。我很好奇为啥突然加了两个。多了一个 StoreLogservice&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看：
&lt;code&gt;pageCache = dependencies.satisfyDependency( createPageCache( fileSystem, config, logging, tracers ) );life.add( new PageCacheLifecycle( pageCache ) );&lt;/code&gt;
然后 new PageCacheLifecycle( pageCache ) 这时候 life 的 size 已经是6了。&lt;/p&gt;

&lt;p&gt;继续查看：&lt;code&gt;diagnosticsManager = life.add( dependencies.satisfyDependency( new DiagnosticsManager( logging.getInternalLog( DiagnosticsManager.class ) ) ) );&lt;/code&gt;
这里 new DiagnosticsManager( logging.getInternalLog( DiagnosticsManager.class ) )  ，这时候 life 的 size 已经是7了。&lt;/p&gt;

&lt;p&gt;一直到 createPlatform 运行完，life一共有7个 LifeSupport。然后调用：&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;直接进入 CommunityEditionModule 的构造方法&lt;/p&gt;

&lt;p&gt;直接F6: &lt;code&gt;LifeSupport life = platformModule.life;life.add( platformModule.dataSourceManager );&lt;/code&gt;
这里添加了 dataSourceManager，实际上是个 DAtaSourceManager。这时候 life 的 size 已经是8了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;life.add( watcherService );
propertyKeyTokenHolder = life.add( dependencies.satisfyDependency( new DelegatingPropertyKeyTokenHolder(
createPropertyKeyCreator( config, dataSourceManager, idGeneratorFactory ) ) ) );
labelTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingLabelTokenHolder( createLabelIdCreator( config,
dataSourceManager, idGeneratorFactory ) ) ));
relationshipTypeTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingRelationshipTypeTokenHolder(
createRelationshipTypeCreator( config, dataSourceManager, idGeneratorFactory ) ) ));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时候 life 的 size 已经是12了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;dependencies.satisfyDependency(createKernelData( fileSystem, pageCache, storeDir, config, graphDatabaseFacade, life ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个方法运行完成后，life一共有12个 LifeSupport。&lt;/p&gt;

&lt;p&gt;然后是：&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;
这里我们只抓取和life有关的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;LifeSupport life = platformModule.life;
threadToTransactionBridge = deps.satisfyDependency( life.add( new ThreadToStatementContextBridge() ) );
life.add( platformModule.kernelExtensions );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
life.add( new MonitorGc( config, logging.getInternalLog( MonitorGc.class ) ) );

life.add( new PublishPageCacheTracerMetricsAfterStart( platformModule.tracers.pageCursorTracerSupplier ) );

life.add( new DatabaseAvailability( platformModule.availabilityGuard, platformModule.transactionMonitor,
        config.get( GraphDatabaseSettings.shutdown_transaction_end_timeout ).toMillis() ) );

life.add( new StartupWaiter( platformModule.availabilityGuard, editionModule.transactionStartTimeout ) );

// Kernel event handlers should be the very last, i.e. very first to receive shutdown events
life.add( kernelEventHandlers );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里life的size已经是22 。
然后会调用platform.life.start().就会循环调用上面的所有的 LifeSupport 的start方法。
所以实际上，整个代码的运行就是一个个的 lifeSupport 的运行，&lt;/p&gt;

&lt;h2 id=&#34;4-理解lifesupport后再次调试代码&#34;&gt;4.理解LifeSupport后再次调试代码&lt;/h2&gt;

&lt;p&gt;这次调试就好多了，我们可以着重看重要的代码&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;server = createNeoServer( config, dependencies, userLogProvider );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;this( config, lifecycleManagingDatabase( COMMUNITY_FACTORY ), dependencies, logProvider );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;1.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;COMMUNITY_FACTORY = ( config, dependencies ) -&amp;gt;
{
    File storeDir = config.get( GraphDatabaseSettings.database_path );
    return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
            .newFacade( storeDir, config, dependencies );
};
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;server.start();&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;init&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;life.add(GraphDatabaseFacadeFactory)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;this.webServer = createWebServer();&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;new JettyWebServer()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;createServerModules()&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;serverComponents = new ServerComponentsLifecycleAdapter();&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;life.start();&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;for ( LifecycleInstance instance : instances ) start()&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上面两个 Lifecycle start 分开看。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;LifecycleManagingDatabase.start()&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;this.graph = dbFactory.newGraphDatabase( config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )&lt;/code&gt; 这里的lambda类似scala的匿名函数，钩子方法。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;newFacade( File storeDir, Config config, final Dependencies dependencies )&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;new GraphDatabaseFacade()&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;initFacade( File storeDir, Config config, final Dependencies dependencies,final GraphDatabaseFacade graphDatabaseFacade )&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;
这里就是上面我们省略的部分，&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;
start的过程启动了所有的 LifeCycle&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerComponentsLifecycleAdapter.start()&lt;/code&gt;
后续的程序&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接下来我们就是一个一个分析&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这四段代码，前三段主要是新建 LifeCycle，最后一个是start是和我们整个neo4j的集群联系最紧密的。为了提高效率，我们可以将上面22个LifeCycle一个一个看。方法很简单，以第一个&lt;code&gt;0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;&lt;/code&gt;为例，我们只需要找到新建和添加到lifeCycle的地方，打断点，然后在他的init和start方法上面打断点。
我们找到新建的调用栈，应该是 LifecycleManagingDatabase.start() -&amp;gt; &amp;hellip; -&amp;gt; new PlatformModule()，然后找到对应的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后找到 FileSystemLifecycleAdapter 的 init和start方法，好像都是空的，然后打上断点进行调试。&lt;/p&gt;

&lt;p&gt;另外对于我们关心的每一部分，实际上都是在这一块进行初始化和启动，一共就三个地方：PlatformModule，EditionModule，DataSourceModule。
例如我们要找neo4j的存储，可以在这三个类中寻找，我大概感觉是：PlatformModule 中新建的 dataSourceManager，在 CommunityEditionModule 中add到life中取得，
以及在 DataSourceModule 中的  new NeoStoreDataSource()  ，然后 dataSourceManager.register(NeoStoreDataSource)。仔细研究发现 dataSourceManager 也是一个LifeCycle，也有start方法，而他的instances包括了 NeoStoreDataSource，而 NeoStoreDataSource 也是一个LifeCycle，它的 instances是 start 方法中添加的。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析3-LifeCycle查看</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-datasourcemanager%E6%9F%A5%E7%9C%8B/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-datasourcemanager%E6%9F%A5%E7%9C%8B/</guid>
      
        <description>

&lt;h2 id=&#34;一-复习&#34;&gt;一、复习&lt;/h2&gt;

&lt;p&gt;上一篇我们说到，接下来我们就是一个一个分析 Lifecycle 的init和start方法&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这四段代码，前三段主要是新建 LifeCycle，最后一个是start是和我们整个neo4j的集群联系最紧密的。为了提高效率，我们可以将上面22个LifeCycle一个一个看。方法很简单，以第一个&lt;code&gt;0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;&lt;/code&gt;为例，我们只需要找到新建和添加到lifeCycle的地方，打断点，然后在他的init和start方法上面打断点。
我们找到新建的调用栈，应该是 LifecycleManagingDatabase.start() -&amp;gt; &amp;hellip; -&amp;gt; new PlatformModule()，然后找到对应的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后找到 FileSystemLifecycleAdapter 的 init和start方法，好像都是空的，然后打上断点进行调试。&lt;/p&gt;

&lt;p&gt;另外对于我们关心的每一部分，实际上都是在这一块进行初始化和启动，一共就三个地方：PlatformModule，EditionModule，DataSourceModule。
例如我们要找neo4j的存储，可以在这三个类中寻找，我大概感觉是：PlatformModule 中新建的 dataSourceManager，在 CommunityEditionModule 中add到life中取得，
以及在 DataSourceModule 中的  new NeoStoreDataSource()  ，然后 dataSourceManager.register(NeoStoreDataSource)。仔细研究发现 dataSourceManager 也是一个LifeCycle，也有start方法，而他的instances包括了 NeoStoreDataSource，而 NeoStoreDataSource 也是一个LifeCycle，它的 instances是 start 方法中添加的。&lt;/p&gt;

&lt;h2 id=&#34;二-datasourcemanager-预览&#34;&gt;二、DataSourceManager 预览&lt;/h2&gt;

&lt;p&gt;从上面的分析我们看出，一共22个LifeCycle，DataSourceManager 是最复杂的，我们就从它开始。&lt;/p&gt;

&lt;h3 id=&#34;1-准备工作&#34;&gt;1.准备工作&lt;/h3&gt;

&lt;p&gt;在DataSourceManager类的init和start方法打上断点，然后在 PlatformModule 的构造方法打上断点，在 CommunityEditionModule 上打断点，在 DataSourceModule打上断点。&lt;/p&gt;

&lt;p&gt;另外我们的代码反复用到了 Dependencies 这个类，我们先大概知道一下它的方法，他有个 parent 属性，一个 resolveDependency 方法和一个 satisfyDependency 方法，
satisfyDependency方法是将一个类的所有父类放进一个map中，resolveDependency方法是调用 parent的resolveDependency，实际上是 DataSourceManager中的dependencies，这里可以暂时忽略。&lt;/p&gt;

&lt;h3 id=&#34;2-开始调试&#34;&gt;2.开始调试&lt;/h3&gt;

&lt;p&gt;先定位到 PlatformModule 的断点 this.dataSourceManager = new DataSourceManager();新建只是初始化几个属性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private LifeSupport life = new LifeSupport();
    private final Listeners&amp;lt;Listener&amp;gt; dsRegistrationListeners = new Listeners&amp;lt;&amp;gt;();
    private NeoStoreDataSource dataSource;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后到 CommunityEditionModule 中，life.add( platformModule.dataSourceManager );将 dataSourceManager 添加到 LifeCycle 中。然后&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;propertyKeyTokenHolder = life.add( dependencies.satisfyDependency( new DelegatingPropertyKeyTokenHolder(
        createPropertyKeyCreator( config, dataSourceManager, idGeneratorFactory ) ) ) );
labelTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingLabelTokenHolder( createLabelIdCreator( config,
        dataSourceManager, idGeneratorFactory ) ) ));
relationshipTypeTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingRelationshipTypeTokenHolder(
        createRelationshipTypeCreator( config, dataSourceManager, idGeneratorFactory ) ) ));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这几步用到了 dataSourceManager ，但是具体干啥了暂且不知道，先跳过。&lt;/p&gt;

&lt;p&gt;然后是 DataSourceModule 的 dataSourceManager.register( neoStoreDataSource );这里我们需要先看看 neoStoreDataSource 是啥。 打断点到 neoStoreDataSource = deps.satisfyDependency( new NeoStoreDataSource())，然后继续看看。
进入 NeoStoreDataSource 的构造方法，NeoStoreDataSource 也是 LifeCycle 的一个实现类，有start方法，它的构造方法好像就是做了很多赋值。
然后是 dataSourceManager.register( neoStoreDataSource )，实际上也就是赋值 this.dataSource = dataSource;
然后接下来是 ClassicCoreSPI spi = new ClassicCoreSPI( platform, dataSource, msgLog, coreAPIAvailabilityGuard );官方文档显示 ClassicCoreSPI 是 surface-layer-of-the-database
然后是 graphDatabaseFacade.init()
然后进入到了关键的 platform.life.start(); 我们知道这里的life的start方法会遍历 life 的 instances 调用init和start，其中就包括我们进行要调试的 DataSourceManager 。&lt;/p&gt;

&lt;h3 id=&#34;3-datasourcemanager的start方法&#34;&gt;3.DataSourceManager的start方法。&lt;/h3&gt;

&lt;p&gt;我们已经在 DataSourceManager 中打好断点，我们已经知道他也是一个 Lifecycle ，先进入init方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void init() throws Throwable
    {
        life = new LifeSupport();
        life.add( dataSource ); // 这个DataSource是 NeoStoreDataSource
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后是start方法：其实就是 life.start(),它的life里面只有 NeoStoreDataSource 一个 instance ，然后会调用它的init和start方法，然后进入 init和start，init是空的，我们在start调试。信息量比较大，做好准备。
第一步是 life = new LifeSupport();
第二步是 life.add( recoveryCleanupWorkCollector );
然后 life.add( indexConfigStore ) 和 life.add( Lifecycles.multiple( indexProviders.values() ) );
然后是 storageEngine = buildStorageEngine()， buildRecovery(), final NeoStoreKernelModule kernelModule = buildKernel(),
然后是 life.start();这里的life工有13个instance：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;instances = {ArrayList@5669}  size = 13
 0 = {LifeSupport$LifecycleInstance@5673} &amp;quot;org.neo4j.index.internal.gbptree.GroupingRecoveryCleanupWorkCollector@3b0c9195: NONE&amp;quot;
 1 = {LifeSupport$LifecycleInstance@5674} &amp;quot;org.neo4j.kernel.impl.index.IndexConfigStore@5cdd09b1: NONE&amp;quot;
 2 = {LifeSupport$LifecycleInstance@5675} &amp;quot;org.neo4j.kernel.lifecycle.Lifecycles$CombinedLifecycle@681a8b4e: NONE&amp;quot;
 3 = {LifeSupport$LifecycleInstance@5676} &amp;quot;org.neo4j.kernel.impl.storageengine.impl.recordstorage.RecordStorageEngine@305f7627: NONE&amp;quot;
 4 = {LifeSupport$LifecycleInstance@5677} &amp;quot;org.neo4j.kernel.impl.transaction.log.files.TransactionLogFiles@1bc715b8: NONE&amp;quot;
 5 = {LifeSupport$LifecycleInstance@5678} &amp;quot;org.neo4j.kernel.impl.transaction.log.BatchingTransactionAppender@24bdb479: NONE&amp;quot;
 6 = {LifeSupport$LifecycleInstance@5679} &amp;quot;org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointerImpl@7e3f95fe: NONE&amp;quot;
 7 = {LifeSupport$LifecycleInstance@5680} &amp;quot;org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointScheduler@34625ccd: NONE&amp;quot;
 8 = {LifeSupport$LifecycleInstance@5681} &amp;quot;org.neo4j.kernel.recovery.Recovery@39dcf4b0: NONE&amp;quot;
 9 = {LifeSupport$LifecycleInstance@5682} &amp;quot;org.neo4j.kernel.impl.api.KernelTransactions@21005f6c: NONE&amp;quot;
 10 = {LifeSupport$LifecycleInstance@5683} &amp;quot;org.neo4j.kernel.impl.api.KernelTransactionMonitorScheduler@32f0fba8: NONE&amp;quot;
 11 = {LifeSupport$LifecycleInstance@5684} &amp;quot;org.neo4j.kernel.impl.api.Kernel@545de5a4: NONE&amp;quot;
 12 = {LifeSupport$LifecycleInstance@5685} &amp;quot;org.neo4j.kernel.NeoStoreDataSource$2@2c1b9e4b: NONE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这12个LifeCycle什么时候加进来的我们后面有时间再看吧，我们接下来又要跳进 LifeCycle 的的init和start方法，这13个 LifeCycle 先看哪一个呢？我们发现最后一个好像是他自己？这岂不是会无限调用 start 了？我们后面再看吧。
我们先看和存储有关的 &lt;code&gt;3 = {LifeSupport$LifecycleInstance@5676} &amp;quot;org.neo4j.kernel.impl.storageengine.impl.recordstorage.RecordStorageEngine@305f7627: NONE&amp;quot;&lt;/code&gt;
打好断点进入，这次终于没有 instance 了，感觉快进入了盗梦空间啊，直接看init：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void init() throws Throwable
{
    indexingService.init();
    labelScanStore.init();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IndexingService的init方法，你可以选择跳进去，但是我不想跳进去了，不然进了但梦空间挑不出来。。。以后再看吧，姑且认为这个类和索引有关。
NativeLabelScanStore的init，我也先不跳进去了。&lt;/p&gt;

&lt;p&gt;再看start：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void start() throws Throwable
{
    neoStores.makeStoreOk();

    propertyKeyTokenHolder.setInitialTokens(
            neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
    relationshipTypeTokenHolder.setInitialTokens(
            neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
    labelTokenHolder.setInitialTokens(
            neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );

    neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
    loadSchemaCache();
    indexingService.start();
    labelScanStore.start();
    idController.start();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;neoStores.makeStoreOk(); 这个初始化就是读取本地存储，还是要重点查看一下：TODO
然后是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;propertyKeyTokenHolder.setInitialTokens(
        neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
relationshipTypeTokenHolder.setInitialTokens(
        neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
labelTokenHolder.setInitialTokens(
        neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这几段代码都可以直接用调试的估值功能直接看出具体的值。
然后是：neoStores.rebuildCountStoreIfNeeded(); 跳进去： getCounts().start();
然后是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
loadSchemaCache();
indexingService.start();
labelScanStore.start();
idController.start();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后面再细看吧。&lt;/p&gt;

&lt;h2 id=&#34;三-datasourcemanager-剖析&#34;&gt;三、dataSourceManager 剖析&lt;/h2&gt;

&lt;p&gt;上面我们已经看出了，AbstractNeoServer 包含两个 LifeCycle ，其中一个是 LifecycleManagingDatabase ，
LifecycleManagingDatabase  包含 22个 LifeCycle，其中一个是 dataSourceManager ，
dataSourceManager 只包含一个 LifeCycle NeoStoreDataSource ，
NeoStoreDataSource 里面有 13 个 LifeCycle ， 其中有和存储有关的 RecordStorageEngine 。
RecordStorageEngine 中有和存储相关的很多属性和方法。分别在构造方法赋值，init和start方法进行初始化和启动工作。
这就是整个盗梦空间的五层梦，接下来我们只能从最深的一层反着往回查看了。&lt;/p&gt;

&lt;h3 id=&#34;1-recordstorageengine-分析&#34;&gt;1. RecordStorageEngine 分析&lt;/h3&gt;

&lt;p&gt;首先它的父类是 StorageEngine ： A StorageEngine provides the functionality to durably store data, and read it back.负责持久化和读数据，里面的抽象方法注释可以好好阅读。&lt;/p&gt;

&lt;h4 id=&#34;1-storageengine-预览&#34;&gt;(1). StorageEngine 预览&lt;/h4&gt;

&lt;p&gt;storeReadLayer() , return an interface for accessing data previously applied to this storage. 返回读取之前放进storage的数据的接口。
allocateCommandCreationContext(), 保存需要多次执行的命令的上下文
createCommands(),返回一系列在当前的事务状态下进行改变的&lt;code&gt;StorageCommand&lt;/code&gt;命令，CommandsToApply 命令可以通过调用apply方法放进存储中。
apply()，执行一系列的命令到存储，
其他的暂时忽略。&lt;/p&gt;

&lt;h4 id=&#34;2-recordstorageengine-属性查看&#34;&gt;(2). RecordStorageEngine 属性查看&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final StoreReadLayer storeLayer;
private final IndexingService indexingService;
private final NeoStores neoStores;
private final PropertyKeyTokenHolder propertyKeyTokenHolder;
private final RelationshipTypeTokenHolder relationshipTypeTokenHolder;
private final LabelTokenHolder labelTokenHolder;
private final DatabaseHealth databaseHealth;
private final IndexConfigStore indexConfigStore;
private final SchemaCache schemaCache;
private final IntegrityValidator integrityValidator;
private final CacheAccessBackDoor cacheAccess;
private final LabelScanStore labelScanStore;
private final SchemaIndexProviderMap schemaIndexProviderMap;
private final ExplicitIndexApplierLookup explicitIndexApplierLookup;
private final SchemaState schemaState;
private final SchemaStorage schemaStorage;
private final ConstraintSemantics constraintSemantics;
private final IdOrderingQueue explicitIndexTransactionOrdering;
private final LockService lockService;
private final WorkSync&amp;lt;Supplier&amp;lt;LabelScanWriter&amp;gt;,LabelUpdateWork&amp;gt; labelScanStoreSync;
private final CommandReaderFactory commandReaderFactory;
private final WorkSync&amp;lt;IndexingUpdateService,IndexUpdatesWork&amp;gt; indexUpdatesSync;
private final IndexStoreView indexStoreView;
private final ExplicitIndexProviderLookup explicitIndexProviderLookup;
private final PropertyPhysicalToLogicalConverter indexUpdatesConverter;
private final Supplier&amp;lt;StorageStatement&amp;gt; storeStatementSupplier;
private final IdController idController;
private final int denseNodeThreshold;
private final int recordIdBatchSize;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些field赋值是在 NeoStoreDataSource#buildStorageEngine ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private StorageEngine buildStorageEngine(
            PropertyKeyTokenHolder propertyKeyTokenHolder, LabelTokenHolder labelTokens,
            RelationshipTypeTokenHolder relationshipTypeTokens,
            ExplicitIndexProviderLookup explicitIndexProviderLookup, IndexConfigStore indexConfigStore,
            SchemaState schemaState, SynchronizedArrayIdOrderingQueue explicitIndexTransactionOrdering, OperationalMode operationalMode )
    {
        RecordStorageEngine storageEngine =
                new RecordStorageEngine( storeDir, config, pageCache, fs, logProvider, propertyKeyTokenHolder,
                        labelTokens, relationshipTypeTokens, schemaState, constraintSemantics, scheduler,
                        tokenNameLookup, lockService, schemaIndexProviderMap, indexingServiceMonitor, databaseHealth,
                        explicitIndexProviderLookup, indexConfigStore,
                        explicitIndexTransactionOrdering, idGeneratorFactory, idController, monitors, recoveryCleanupWorkCollector,
                        operationalMode );

        // We pretend that the storage engine abstract hides all details within it. Whereas that&#39;s mostly
        // true it&#39;s not entirely true for the time being. As long as we need this call below, which
        // makes available one or more internal things to the outside world, there are leaks to plug.
        storageEngine.satisfyDependencies( dependencies );

        return life.add( storageEngine );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调试得到初始值：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;storeDir = {File@1774} &amp;quot;/Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db&amp;quot;
config = {Config@1362} &amp;quot;dbms.connector.bolt.enabled=true, dbms.connector.http.enabled=true, dbms.connector.https.enabled=true, dbms.connectors.default_listen_address=localhost, dbms.directories.import=import, dbms.jvm.additional=-Dunsupported.dbms.udc.source=tarball, dbms.security.auth_enabled=true, dbms.tx_log.rotation.retention_policy=1 days, dbms.windows_service_name=neo4j, unsupported.dbms.block_size.array_properties=120, unsupported.dbms.block_size.labels=56, unsupported.dbms.block_size.strings=120, unsupported.dbms.directories.neo4j_home=/Users/dengziming/opt/soft/neo4j-community-3.2.6, unsupported.dbms.edition=community&amp;quot;
pageCache = {MuninnPageCache@1773} &amp;quot;MuninnPageCache[ \n Page[ id = 0, address = 4516331520, filePageId = 0, swapperId = 1, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 1, address = 4516339712, filePageId = 0, swapperId = 2, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 2, address = 4516347904, filePageId = 0, swapperId = 3, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 3, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 4, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 5, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 6, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 7&amp;quot;
fs = {DefaultFileSystemAbstraction@1772} 
logProvider = {FormattedLogProvider@3221} 
propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506} 
labelTokens = {DelegatingLabelTokenHolder@2495} 
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480} 
schemaState = {DatabaseSchemaState@3478} 
constraintSemantics = {StandardConstraintSemantics@2499} 
scheduler = {Neo4jJobScheduler@1778} 
tokenNameLookup = {NonTransactionalTokenNameLookup@2487} 
lockService = {ReentrantLockService@3222} 
indexProviderMap = {DefaultSchemaIndexProviderMap@3483} 
indexingServiceMonitor = {$Proxy16@3223} &amp;quot;null&amp;quot;
databaseHealth = {DatabaseHealth@2485} 
explicitIndexProviderLookup = {NeoStoreDataSource$1@3226} 
indexConfigStore = {IndexConfigStore@3473} 
explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479} 
idGeneratorFactory = {BufferingIdGeneratorFactory@2494} 
idController = {BufferedIdController@2493} 
monitors = {Monitors@2498} 
recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501} 
operationalMode = {OperationalMode@2489} &amp;quot;single&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后构造方法走完了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;storeDir = {File@1774} &amp;quot;/Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db&amp;quot;
config = {Config@1362} &amp;quot;dbms.connector.bolt.enabled=true, dbms.connector.http.enabled=true, dbms.connector.https.enabled=true, dbms.connectors.default_listen_address=localhost, dbms.directories.import=import, dbms.jvm.additional=-Dunsupported.dbms.udc.source=tarball, dbms.security.auth_enabled=true, dbms.tx_log.rotation.retention_policy=1 days, dbms.windows_service_name=neo4j, unsupported.dbms.block_size.array_properties=120, unsupported.dbms.block_size.labels=56, unsupported.dbms.block_size.strings=120, unsupported.dbms.directories.neo4j_home=/Users/dengziming/opt/soft/neo4j-community-3.2.6, unsupported.dbms.edition=community&amp;quot;
pageCache = {MuninnPageCache@1773} Method threw &#39;java.lang.OutOfMemoryError&#39; exception. Cannot evaluate org.neo4j.io.pagecache.impl.muninn.MuninnPageCache.toString()
fs = {DefaultFileSystemAbstraction@1772} 
logProvider = {FormattedLogProvider@3221} 
propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506} 
labelTokens = {DelegatingLabelTokenHolder@2495} 
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480} 
schemaState = {DatabaseSchemaState@3478} 
constraintSemantics = {StandardConstraintSemantics@2499} 
scheduler = {Neo4jJobScheduler@1778} 
tokenNameLookup = {NonTransactionalTokenNameLookup@2487} 
lockService = {ReentrantLockService@3222} 
indexProviderMap = {DefaultSchemaIndexProviderMap@3483} 
indexingServiceMonitor = {$Proxy16@3223} &amp;quot;null&amp;quot;
databaseHealth = {DatabaseHealth@2485} 
explicitIndexProviderLookup = {NeoStoreDataSource$1@3226} 
indexConfigStore = {IndexConfigStore@3473} 
explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479} 
idGeneratorFactory = {BufferingIdGeneratorFactory@2494} 
idController = {BufferedIdController@2493} 
monitors = {Monitors@2498} 
recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501} 
operationalMode = {OperationalMode@2489} &amp;quot;single&amp;quot;
factory = {StoreFactory@3550} 
neoStoreIndexStoreView = {NeoStoreIndexStoreView@3785} 
readOnly = {Boolean@3786} &amp;quot;false&amp;quot;
neoStores = {NeoStores@3549} 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后会调用 init 和 start 方法。&lt;/p&gt;

&lt;h4 id=&#34;3-recordstorageengine-属性分析&#34;&gt;(3). RecordStorageEngine 属性分析&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;storeDir&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;File类型，一开始启动参数设置的路径&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Config&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;配置&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;pageCache = {MuninnPageCache@1773}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;pageCache = {MuninnPageCache@1773} &amp;ldquo;MuninnPageCache[ \n Page[ id = 0, address = 4516331520, filePageId = 0, swapperId = 1, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 1, address = 4516339712, filePageId = 0, swapperId = 2, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 2, address = 4516347904, filePageId = 0, swapperId = 3, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 3, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 4, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 5, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 6, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 7&amp;rdquo;
通过一个 re-usable cursor 来缓存和读取 cache 的内容，可以通过运行 MuninnPageCacheTest 的单元测试查看功能。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;fs = {DefaultFileSystemAbstraction@1772}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基于java的NIO 文件系统进行一个封装，。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;logProvider = {FormattedLogProvider@3221}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;进行日志打印&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;TokenHolder&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506}
labelTokens = {DelegatingLabelTokenHolder@2495}
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480}
后面的 cacheAccess storeLayer 会用到这三个 。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;schemaState = {DatabaseSchemaState@3478}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;存储一些状态，例如 cypher 的执行计划&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;constraintSemantics = {StandardConstraintSemantics@2499}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;里面的方法都是抛异常。
schemaCache 和后面的 txStateVisitor 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;scheduler = {Neo4jJobScheduler@1778}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;里面是一个 synchronizedSet ，用于放任务。
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;tokenNameLookup = {NonTransactionalTokenNameLookup@2487}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;包含了上面的三个 TokenHolder
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;lockService = {ReentrantLockService@3222}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一个读写锁，通过不区分读写实现同步
indexStoreView 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexProviderMap = {DefaultSchemaIndexProviderMap@3483}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;提供索引
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexingServiceMonitor = {$Proxy16@3223} &amp;ldquo;null&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;databaseHealth = {DatabaseHealth@2485}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;集群健康状态&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;explicitIndexProviderLookup = {NeoStoreDataSource$1@3226}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;貌似是查找索引用的。NeoStoreDataSource$1 是啥意思还没搞懂。。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexConfigStore = {IndexConfigStore@3473}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;索引属性&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;和上面两个合作，&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;idGeneratorFactory = {BufferingIdGeneratorFactory@2494}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;封装 IdGenerator&lt;/p&gt;

&lt;p&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;idController = {BufferedIdController@2493}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BufferedIdController safely free and reuse ids.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;monitors = {Monitors@2498}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;监控&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;略&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;operationalMode = {OperationalMode@2489} &amp;ldquo;single&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;略&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;factory = {StoreFactory@3550}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    {
        this.config = config;
        this.idGeneratorFactory = idGeneratorFactory;
        this.fileSystemAbstraction = fileSystemAbstraction;
        this.recordFormats = recordFormats;
        this.openOptions = openOptions;
        new RecordFormatPropertyConfigurator( recordFormats, config ).configure();

        this.logProvider = logProvider;
        this.neoStoreFileName = new File( storeDir, storeName );
        this.pageCache = pageCache;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;存储工厂实现，也可以用来创建空工厂。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;neoStoreIndexStoreView = {NeoStoreIndexStoreView@3785}&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;neoStores = {NeoStores@3549}&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;neoStores = factory.openAllNeoStores( true );&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,
                fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-recordstorageengine-init和start&#34;&gt;(3). RecordStorageEngine init和start&lt;/h4&gt;

&lt;p&gt;上面我们已经大概明白了每个类的作用，首先我们：&lt;code&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后是： &lt;code&gt;neoStores = factory.openAllNeoStores( true );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后是从 neoStores 出发，新建一系列和存储有关的属性。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;indexUpdatesConverter = new PropertyPhysicalToLogicalConverter( neoStores.getPropertyStore() );
schemaStorage = new SchemaStorage( neoStores.getSchemaStore() );
NeoStoreIndexStoreView neoStoreIndexStoreView = new NeoStoreIndexStoreView( lockService, neoStores );
indexStoreView = new DynamicIndexStoreView( neoStoreIndexStoreView, labelScanStore, lockService, neoStores, logProvider );
schemaIndexProviderMap = indexProviderMap;
indexingService = IndexingServiceFactory.createIndexingService( config, scheduler, schemaIndexProviderMap,
        indexStoreView, tokenNameLookup,
        Iterators.asList( new SchemaStorage( neoStores.getSchemaStore() ).indexesGetAll() ), logProvider,
        indexingServiceMonitor, schemaState );

integrityValidator = new IntegrityValidator( neoStores, indexingService );
storeStatementSupplier = storeStatementSupplier( neoStores );
            storeLayer = new StorageLayer(
                    propertyKeyTokenHolder, labelTokens, relationshipTypeTokens,
                    schemaStorage, neoStores, indexingService,
                    storeStatementSupplier, schemaCache );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构造方法完了就是init和start&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void init() throws Throwable
{
    indexingService.init(); -- 所以服务
    labelScanStore.init();  -- Label存储
}

@Override
public void start() throws Throwable
{
    neoStores.makeStoreOk();

    propertyKeyTokenHolder.setInitialTokens(
            neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
    relationshipTypeTokenHolder.setInitialTokens(
            neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
    labelTokenHolder.setInitialTokens(
            neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );

    neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
    loadSchemaCache();
    indexingService.start();
    labelScanStore.start();
    idController.start();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一步一步看：
1. indexingService.init();&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// Each index has an {@link org.neo4j.kernel.impl.store.record.IndexRule}
// 遍历每一个 IndexRule ，
IndexProxy indexProxy;

long indexId = indexRule.getId();
IndexDescriptor descriptor = indexRule.getIndexDescriptor();
SchemaIndexProvider.Descriptor providerDescriptor = indexRule.getProviderDescriptor();
SchemaIndexProvider provider = providerMap.apply( providerDescriptor );
InternalIndexState initialState = provider.getInitialState( indexId, descriptor );
indexStates.computeIfAbsent( initialState, internalIndexState -&amp;gt; new ArrayList&amp;lt;&amp;gt;() )
.add( new IndexLogRecord( indexId, descriptor ) );

log.debug( indexStateInfo( &amp;quot;init&amp;quot;, indexId, initialState, descriptor ) );
switch ( initialState )
{
case ONLINE:
    indexProxy =
    indexProxyCreator.createOnlineIndexProxy( indexId, descriptor, providerDescriptor );
    break;
case POPULATING:
    // The database was shut down during population, or a crash has occurred, or some other sad thing.
    indexProxy = indexProxyCreator.createRecoveringIndexProxy( descriptor, providerDescriptor );
    break;
case FAILED:
    IndexPopulationFailure failure = failure( provider.getPopulationFailure( indexId ) );
    indexProxy = indexProxyCreator
            .createFailedIndexProxy( indexId, descriptor, providerDescriptor, failure );
    break;
default:
    throw new IllegalArgumentException( &amp;quot;&amp;quot; + initialState );
}
indexMap.putIndexProxy( indexId, indexProxy );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于我的数据库没有建索引，所以这里就不调试了，接下来建了索引再说。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;labelScanStore.init();&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过 GBPTree 实现&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;-- which is implemented using {@link GBPTree}
@link GBPTree 是一种算法，减少树结构合并时候的冲突。
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;indexingService.start();&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;labelScanStore.start();&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;idController.start();&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-recordstorageengine-分析&#34;&gt;2. RecordStorageEngine 分析&lt;/h3&gt;

&lt;p&gt;上一节我们已经大概看了 RecordStorageEngine ，他只是 NeoStoreDataSource 的 13个梦中的一个而已，我们还要醒来继续做剩下的12个梦。
我看了一下 先不看了，剩下的12个重要性稍微低一点。我们先看我们最感兴趣的。&lt;/p&gt;

&lt;p&gt;PageCache&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析3-LifeCycle查看</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-%E8%AF%BB%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-%E8%AF%BB%E6%96%87%E4%BB%B6/</guid>
      
        <description>

&lt;h2 id=&#34;一-复习&#34;&gt;一、复习&lt;/h2&gt;

&lt;p&gt;上一篇我们已经大概看了 RecordStorageEngine ，他只是 NeoStoreDataSource 的 13个梦中的一个而已，我们还要醒来继续做剩下的12个梦。&lt;/p&gt;

&lt;p&gt;然而我们可以先看看如何读数据，写数据的。第一是找到java类 &lt;code&gt;PhysicalLogCommandReaderV3_0_2&lt;/code&gt;。我们可以看到里面有很多读文件处理的方法，主要是&lt;code&gt;neostore.transaction.db.0&lt;/code&gt;这个文件，好像是日志文件。&lt;/p&gt;

&lt;p&gt;然后我们在 NodeStore 类的构造方法打断点。可以找到整个调用的栈帧：
new RecordStorageEngine()
neoStores = factory.openAllNeoStores( true );
return openNeoStores( createStoreIfNotExists, StoreType.values() );
return new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
for ( StoreType type : storeTypes ) getOrCreateStore( type );
store = openStore( storeType );
Object store = type.open( this );
return neoStores.createNodeStore( getStoreName() );
return initialize( new NodeStore( storeFile, config, idGeneratorFactory, pageCache, logProvider,(DynamicArrayStore) getOrCreateStore( StoreType.NODE_LABEL ), recordFormats, openOptions ) );
new CommonAbstractStore()&lt;/p&gt;

&lt;p&gt;同理，我们还可以在 RelationshipStore PropertyStore TokenStore AbstractDynamicStore 等store中打上断点，了解调用栈。所有的存储文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;CommonAbstractStore (org.neo4j.kernel.impl.store)
RelationshipStore (org.neo4j.kernel.impl.store)
RecordingRelationshipStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
MyStore in CommonAbstractStoreBehaviourTest (org.neo4j.kernel.impl.store)
MetaDataStore (org.neo4j.kernel.impl.store)
AbstractDynamicStore (org.neo4j.kernel.impl.store)
DynamicArrayStore (org.neo4j.kernel.impl.store)
SchemaStore (org.neo4j.kernel.impl.store)
DynamicStringStore (org.neo4j.kernel.impl.store)
Anonymous in newTestableDynamicStore() in AbstractDynamicStoreTest (org.neo4j.kernel.impl.store)
NodeStore (org.neo4j.kernel.impl.store)
RecordingNodeStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
RelationshipGroupStore (org.neo4j.kernel.impl.store)
TokenStore (org.neo4j.kernel.impl.store)
LabelTokenStore (org.neo4j.kernel.impl.store)
UnusedLabelTokenStore in LabelTokenStoreTest (org.neo4j.kernel.impl.store)
PropertyKeyTokenStore (org.neo4j.kernel.impl.store)
RelationshipTypeTokenStore (org.neo4j.kernel.impl.store)
TheStore in CommonAbstractStoreTest (org.neo4j.kernel.impl.store)
PropertyStore (org.neo4j.kernel.impl.store)
RecordingPropertyStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对应20种存储格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;AbstractBaseRecord (org.neo4j.kernel.impl.store.record)
PropertyRecord (org.neo4j.kernel.impl.store.record)
IntRecord in CommonAbstractStoreBehaviourTest (org.neo4j.kernel.impl.store)
TheRecord in CommonAbstractStoreTest (org.neo4j.kernel.impl.store)
MyRecord in BaseHighLimitRecordFormatTest (org.neo4j.kernel.impl.store.format.highlimit)
MetaDataRecord (org.neo4j.kernel.impl.store.record)
SchemaRecord (org.neo4j.kernel.impl.store.record)
DynamicRecord (org.neo4j.kernel.impl.store.record)
IndexEntry (org.neo4j.consistency.store.synthetic)
PrimitiveRecord (org.neo4j.kernel.impl.store.record)
NodeRecord (org.neo4j.kernel.impl.store.record)
NeoStoreRecord (org.neo4j.kernel.impl.store.record)
RelationshipRecord (org.neo4j.kernel.impl.store.record)
LabelScanDocument (org.neo4j.consistency.store.synthetic)
RelationshipGroupRecord (org.neo4j.kernel.impl.store.record)
RelationshipGroupCursor (org.neo4j.kernel.impl.newapi)
TokenRecord (org.neo4j.kernel.impl.store.record)
LabelTokenRecord (org.neo4j.kernel.impl.store.record)
PropertyKeyTokenRecord (org.neo4j.kernel.impl.store.record)
RelationshipTypeTokenRecord (org.neo4j.kernel.impl.store.record)
CountsEntry (org.neo4j.consistency.store.synthetic)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 StoreFactory 中可以找到对应的关系。&lt;/p&gt;

&lt;h2 id=&#34;二-id文件&#34;&gt;二、Id文件&lt;/h2&gt;

&lt;p&gt;打开代码 CommonAbstractStore ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Opens the {@link IdGenerator} used by this store.
 * &amp;lt;p&amp;gt;
 * Note: This method may be called both while the store has the store file mapped in the
 * page cache, and while the store file is not mapped. Implementers must therefore
 * map their own temporary PagedFile for the store file, and do their file IO through that,
 * if they need to access the data in the store file.
 */
void openIdGenerator()
{
    idGenerator = idGeneratorFactory.open( getIdFileName(), getIdType(), () -&amp;gt; scanForHighId(), recordFormat.getMaxId() );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IdGenerator 的功能是分配id，每一种存储格式都有自己的id，所以在 CommonAbstractStore 中都有这个属性。idGenerator负责分配和释放id，所以它里面要有最大的id，已经已经释放的id。
最大的id可以用到下一次分配id，已经释放的也可以用于分配。进一步了解功能可以在 IdGeneratorImplTest 中调试。我们可以用二进制文件编辑器打开&lt;code&gt;neostore.nodestore.db.id&lt;/code&gt;看看。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0000 0000 0000 0000 0b00 0000 0000 0000
0000 0000 0000 0000 0100 0000 0000 0000
0200 0000 0000 0000 0300 0000 0000 0000
0400 0000 0000 0000 0500 0000 0000 0000
06
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里一共有 65 bytes ，第1bytes是文件头，然后8 bytes是最大的id，这里是 &lt;code&gt;00 0000 0000 0000 0b&lt;/code&gt; ，然后每8Bytes就是一个释放的id，这里是从0到6。&lt;/p&gt;

&lt;p&gt;IdGeneratorImpl 的构造方法会有一个 IdContainer ，可以分配id，可以去 IdContainerTest 的 testNextId 调试 中查看功能。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try
{
    IdGeneratorImpl.createGenerator( fs, idGeneratorFile(), 0, false );
    IdGenerator idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 3, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    for ( long i = 0; i &amp;lt; 7; i++ )
    {
        assertEquals( i, idGenerator.nextId() );
    }
    idGenerator.freeId( 1 );
    idGenerator.freeId( 3 );
    idGenerator.freeId( 5 );
    assertEquals( 7L, idGenerator.nextId() );
    idGenerator.freeId( 6 );
    closeIdGenerator( idGenerator );
    idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 5, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    idGenerator.freeId( 2 );
    idGenerator.freeId( 4 );
    assertEquals( 1L, idGenerator.nextId() );
    idGenerator.freeId( 1 );
    assertEquals( 3L, idGenerator.nextId() );
    idGenerator.freeId( 3 );
    assertEquals( 5L, idGenerator.nextId() );
    idGenerator.freeId( 5 );
    assertEquals( 6L, idGenerator.nextId() );
    idGenerator.freeId( 6 );
    assertEquals( 8L, idGenerator.nextId() );
    idGenerator.freeId( 8 );
    assertEquals( 9L, idGenerator.nextId() );
    idGenerator.freeId( 9 );
    closeIdGenerator( idGenerator );
    idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 3, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    assertEquals( 6L, idGenerator.nextId() );
    assertEquals( 8L, idGenerator.nextId() );
    assertEquals( 9L, idGenerator.nextId() );
    assertEquals( 1L, idGenerator.nextId() );
    assertEquals( 3L, idGenerator.nextId() );
    assertEquals( 5L, idGenerator.nextId() );
    assertEquals( 2L, idGenerator.nextId() );
    assertEquals( 4L, idGenerator.nextId() );
    assertEquals( 10L, idGenerator.nextId() );
    assertEquals( 11L, idGenerator.nextId() );
    closeIdGenerator( idGenerator );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;三-文件读写api&#34;&gt;三、文件读写API&lt;/h2&gt;

&lt;p&gt;ne4j有 专用的API ，neo4j的文件有它自己的特点，不能直接使用java的API，需要定义自己的API，在 org.neo4j.io.pagecache 下。我们需要了解一下。从package-info看起。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;The purpose of a page cache is to cache data from files on a storage device, and keep the most often used data in
memory where access is fast. This duplicates the most popular data from the file, into memory. Assuming that not all
data can fit in memory (even though it sometimes can), the least used data will then be pushed out of memory, when
we need data that is not already in the cache. This is called eviction, and choosing what to evict is the
responsibility of the eviction algorithm that runs inside the page cache implementation.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pagecache的功能是从文件或者存储设备缓存数据，将最常用的放在访问最快的内存。我们最少用的数据会不在内存，当我们需要的时候，这个过程是  eviction ，选择哪个 eviction 是算法最重要的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A file must first be &amp;quot;mapped&amp;quot; into the page cache, before the page cache can cache the contents of the files. When
you no longer have an immediate use for the contents of the file, it can be &amp;quot;unmapped.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文件要被 map 到cache中才能使用。&lt;/p&gt;

&lt;p&gt;通过 org.neo4j.io.pagecache.PageCache#map(java.io.File, int, java.nio.file.OpenOption&amp;hellip;) 方法将得到一个 {@link org.neo4j.io.pagecache.PagedFile} 对象。&lt;/p&gt;

&lt;p&gt;一旦一个文件被映射到页面缓存，它就不再被直接通过文件系统访问，因为页面缓存将保持内存的变化，认为它正在管理唯一权威的副本。&lt;/p&gt;

&lt;p&gt;一个文件被map多次，返回的是同一个 PageCache，对应的 reference counter +1，
Unmapping decrements the reference counter, discarding the PagedFile from the cache if the counter reaches zero.
If the last reference was unmapped, then all dirty pages for that file will be flushed before the file is discarded from the cache。&lt;/p&gt;

&lt;p&gt;page 是一堆data的集合，可以是 file, or the memory allocated for the page cache。We refer to these two types of pages as &amp;ldquo;file pages&amp;rdquo; and &amp;ldquo;cache pages&amp;rdquo; respectively.&lt;/p&gt;

&lt;p&gt;Pages are the unit of what data is popular or not, and the unit of moving data into memory, and out to storage.&lt;/p&gt;

&lt;p&gt;When a cache page is holding the contents of a file page, the two are said to be &amp;ldquo;bound&amp;rdquo; to one another.&lt;/p&gt;

&lt;p&gt;每个 PagedFile 对象都有一个 translation table，逻辑上存储了page file到cache里，类似 Maps 结构，key是pageid，value是page内容。&lt;/p&gt;

&lt;p&gt;几个类的逻辑视图如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;*     +---------------[ PageCache ]-----------------------------------+
 *     |                                                               |
 *     |  * PageSwapperFactory{ FileSystemAbstraction }                |
 *     |  * evictionThread                                             |
 *     |  * a large collection of Page objects:                        |
 *     |                                                               |
 *     |  +---------------[ Page ]----------------------------------+  |
 *     |  |                                                         |  |
 *     |  |  * usageCounter                                         |  |
 *     |  |  * some kind of read/write lock                         |  |
 *     |  |  * a cache page sized buffer                            |  |
 *     |  |  * binding metadata{ filePageId, PageSwapper }          |  |
 *     |  |                                                         |  |
 *     |  +---------------------------------------------------------+  |
 *     |                                                               |
 *     |  * linked list of mapped PagedFile instances:                 |
 *     |                                                               |
 *     |  +--------------[ PagedFile ]------------------------------+  |
 *     |  |                                                         |  |
 *     |  |  * referenceCounter                                     |  |
 *     |  |  * PageSwapper{ StoreChannel, filePageSize }            |  |
 *     |  |  * PageCursor freelists                                 |  |
 *     |  |  * translation table:                                   |  |
 *     |  |                                                         |  |
 *     |  |  +--------------[ translation table ]----------------+  |  |
 *     |  |  |                                                   |  |  |
 *     |  |  |  A translation table is basically a map from      |  |  |
 *     |  |  |  file page ids to Page objects. It is updated     |  |  |
 *     |  |  |  concurrently by page faulters and the eviction   |  |  |
 *     |  |  |  thread.                                          |  |  |
 *     |  |  |                                                   |  |  |
 *     |  |  +---------------------------------------------------+  |  |
 *     |  +---------------------------------------------------------+  |
 *     +---------------------------------------------------------------+
 *
 *     +--------------[ PageCursor ]-----------------------------------+
 *     |                                                               |
 *     |  * currentPage: Page                                          |
 *     |  * page lock metadata                                         |
 *     |                                                               |
 *     +---------------------------------------------------------------+
 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里有几个重要的类，我们需要大概了解一下用法，第一个是 PageCache ，可以查看 MuninnPageCacheTest 类的测试方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try ( MuninnPageCache pageCache = createPageCache( fs, 2, blockCacheFlush( tracer ), cursorTracerSupplier );
         PagedFile pagedFile = pageCache.map( file( &amp;quot;a&amp;quot; ), 8 ) )
   {
       try ( PageCursor cursor = pagedFile.io( 0, PF_SHARED_READ_LOCK ) )
       {
           assertTrue( cursor.next() );
       }
       cursorTracer.reportEvents();
       assertNotNull( cursorTracer.observe( Fault.class ) );
       assertEquals( 1, cursorTracer.faults() );
       assertEquals( 1, tracer.faults() );

       long clockArm = pageCache.evictPages( 1, 1, tracer.beginPageEvictions( 1 ) );
       assertThat( clockArm, is( 1L ) );
       assertNotNull( tracer.observe( Evict.class ) );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出，第一步是创建 pageCache，第二步是 pageCache 的 map 方法得到 pagedFile，然后调用 io 方法得到 PageCursor ，然后cusor是一个迭代器。&lt;/p&gt;

&lt;h2 id=&#34;四-commonabstractstore-格式&#34;&gt;四、CommonAbstractStore 格式&lt;/h2&gt;

&lt;p&gt;这个是一个存储格式的基本实现类，我们现在任何一个Store上面打断点，然后在 CommonAbstractStore 中打断点，开始调试即可。以 NodeStore 为例，在构造方法打断点，在 CommonAbstractStore 的 checkAndLoadStorage 打断点。
我们找到了调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;neoStores = factory.openAllNeoStores( true );
return openNeoStores( createStoreIfNotExists, StoreType.values() );
new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
getOrCreateStore( type );
store = openStore( storeType );
Object store = type.open( this );
return neoStores.createDynamicArrayStore( getStoreName(), IdType.NODE_LABELS, GraphDatabaseSettings.label_block_size );

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 checkAndLoadStorage 方法上停下来，此时的storeType是 &lt;code&gt;NODE_LABEL&lt;/code&gt; ，也就是节点的Label,：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// /Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db/neostore.nodestore.db.labels
try ( PagedFile pagedFile = pageCache.map( storageFileName, pageSize, ANY_PAGE_SIZE ) ) 

extractHeaderRecord( pagedFile );
createStore( pageSize );
loadStorage( filePageSize );
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;四-abstractdynamicstore-文件格式&#34;&gt;四、AbstractDynamicStore 文件格式&lt;/h2&gt;

&lt;p&gt;neo4j 中对于字符串等变长值的保存策略是用一组定长的 block 来保存，block之间用单向链表链接。
例如 neostore.propertystore.db.arrays 和 neostore.propertystore.db.strings 类 AbstractDynamicStore 实现了该功能，文件结构在 DynamicRecordFormat 中有解释。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static final int RECORD_HEADER_SIZE = 1/*header byte*/ + 3/*# of bytes*/ + 8/*max size of next reference*/;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>如何在github.io搭建Hugo博客</title>
      <link>https://dengziming.github.io/post/java/first/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/first/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>常用maven命令</title>
      <link>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/maven%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/maven%E5%91%BD%E4%BB%A4/</guid>
      
        <description>

&lt;h2 id=&#34;插件&#34;&gt;插件&lt;/h2&gt;

&lt;h3 id=&#34;1&#34;&gt;1.&lt;/h3&gt;

&lt;p&gt;版本兼容检查&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.revapi&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;revapi-maven-plugin&amp;lt;/artifactId&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代码风格检查&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;maven-checkstyle-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-常见异常&#34;&gt;2.常见异常&lt;/h3&gt;

&lt;p&gt;cached in local repository &amp;hellip;
这个原因可能是上一次更新失败，会有一个update文件放在本地，去repository对应目录删除即可。&lt;/p&gt;

&lt;p&gt;can&amp;rsquo;t find jar in alimaven， 这个原因是仓库可能没这个jar，可是换一个仓库。
例如换成开源中国的仓库，但是可能又有新的错误，最好是使用 -rf 从某一个重新开始打包 &lt;code&gt;mvn clean install -DskipTests=true -rf :janusgraph-es&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;3&#34;&gt;3.&lt;/h3&gt;
</description>
      
    </item>
    
    <item>
      <title>常用sql写法</title>
      <link>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/sql/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/sql/</guid>
      
        <description>

&lt;h2 id=&#34;sql语法&#34;&gt;sql语法&lt;/h2&gt;

&lt;p&gt;每个语言的语法不一样，大致类似。&lt;/p&gt;

&lt;h3 id=&#34;1-调优经验&#34;&gt;1. 调优经验&lt;/h3&gt;

&lt;p&gt;可以先explain，分析一下。然后再运行。&lt;/p&gt;

&lt;p&gt;join可能会导致数据倾斜的情况：&lt;/p&gt;

&lt;p&gt;join的key是不均匀的，
join的key有很多事空值，这时候可以分为两部分进行union&lt;/p&gt;

&lt;p&gt;多表join：
一般是前面的stage一起执行，最后有一个stage。
如果发现很慢，数据也没有倾斜，可能是某些表的key重复，导致join会有笛卡尔积操作，得到很多数据所以慢，可以根据业务进行过滤。&lt;/p&gt;

&lt;h2 id=&#34;常用sql&#34;&gt;常用sql&lt;/h2&gt;

&lt;h3 id=&#34;1-不等值join&#34;&gt;1.不等值join&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;
cache table b as select * from location ;

select
    a.ip,
    b.city
from
    b
RIGHT JOIN
    fin_kg.kg_v2_v_ip a
ON
    a.ip &amp;gt;= b.ip_start
AND
    a.ip &amp;lt;= b.ip_end

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CACHE TABLE chuanxiao AS SELECT id,name,regs FROM vdm_fin.chuanxiao_20180417;

insert overwrite table kg_v2_e_userid_gang
select
    b.id,
    b.name,
    a.phone,
    a.contact_phone,
    a.contact_name
from
     a
right join
    chuanxiao b
on
    a.contact_name regexp regexp_replace(b.regs,&amp;quot;%&amp;quot;,&amp;quot;.*&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改null存储为&amp;rdquo;,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;ROW FORMAT DELIMITED
      FIELDS TERMINATED BY &#39;,&#39;
      LINES TERMINATED BY &#39;\n&#39;
      NULL DEFINED AS &#39;&#39;
     stored as textfile;
     
alter table fin_kg.kg_v2_e_phone_gang_bak SET SERDEPROPERTIES (&#39;serialization.null.format&#39;=&#39;&#39;); 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-分位点&#34;&gt;2.分位点&lt;/h3&gt;

&lt;p&gt;percentile
percentile_approx
percentile_rank&lt;/p&gt;

&lt;h3 id=&#34;3-保留小数&#34;&gt;3.保留小数&lt;/h3&gt;

&lt;p&gt;printf&lt;/p&gt;

&lt;h3 id=&#34;4-手动刷新impala元数据&#34;&gt;4. 手动刷新impala元数据&lt;/h3&gt;

&lt;p&gt;invalidate metadata [tablename]&lt;/p&gt;

&lt;h3 id=&#34;5-键值对&#34;&gt;5.键值对&lt;/h3&gt;

&lt;p&gt;str_to_map(concat_ws(&amp;lsquo;,&amp;rsquo;,collect_set(concat_ws(&amp;rsquo;:&amp;lsquo;, ctime_month, cast(final_score as string) )))) as time2score&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>常用正则表达式</title>
      <link>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/%E5%B8%B8%E7%94%A8%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/%E5%B8%B8%E7%94%A8%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</guid>
      
        <description>

&lt;h2 id=&#34;正则语法&#34;&gt;正则语法&lt;/h2&gt;

&lt;p&gt;每个语言的语法不一样，大致类似。&lt;/p&gt;

&lt;h3 id=&#34;1&#34;&gt;1.&lt;/h3&gt;

&lt;h2 id=&#34;常用正则&#34;&gt;常用正则&lt;/h2&gt;

&lt;h3 id=&#34;1-nginx匹配&#34;&gt;1.nginx匹配&lt;/h3&gt;

&lt;p&gt;([^\s]+) - ([.+])&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 
&#39;([^\\s]+) - (\\[.+\\])&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注释：
\转义，这里加上sql转义是两个转义。
括号括起来是一个字符集
. 代表任意字符，+代表至少一次（*为任意次，？为最多一次）&lt;/p&gt;

&lt;h3 id=&#34;2-字符串分割&#34;&gt;2.字符串分割&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT split(&#39;%180%霖易%|%180%商城%|%霖易商城%&#39;,&#39;\\|&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;|代表或，如果分割需要转义。&lt;/p&gt;

&lt;h3 id=&#34;3-特殊字符替换&#34;&gt;3.特殊字符替换&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT   regexp_replace(&#39;(名字)。|得到的sssa》《？&#39;,&#39;\\(.*?\\)|[^(a-zA-Z0-9\\u2E80-\\u9FFF)]|[\\( \\)《》。，〈〉、⼂\\⼁]|\\s+|,|&amp;quot;|\&#39;&#39;,&#39;&#39;) as contact_name

-- 得到的sssa
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>虚拟机性能监控工具</title>
      <link>https://dengziming.github.io/post/java/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/</guid>
      
        <description>

&lt;p&gt;定位问题知识、经验是关键，工具也是必要的，但是要注意工具知识工具，对知识的封装，不可能包治百病。
java的bin目录下处理java和javac是常用工具，但是还有一些其他的工具。jdk官方说的是这些不一定可靠，但是实际上这些最可靠了。&lt;/p&gt;

&lt;h2 id=&#34;一-介绍&#34;&gt;一、介绍&lt;/h2&gt;
</description>
      
    </item>
    
  </channel>
</rss>