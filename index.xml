<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据分析师之旅</title>
    <link>https://dengziming.github.io/</link>
    <description>Recent content on 数据分析师之旅</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 20 Aug 2017 21:38:52 +0800</lastBuildDate>
    
        <atom:link href="https://dengziming.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://dengziming.github.io/about/</link>
      <pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate>
      
      <guid>https://dengziming.github.io/about/</guid>
      
        <description>&lt;p&gt;Hugo is a static site engine written in Go.&lt;/p&gt;

&lt;p&gt;It makes use of a variety of open source projects including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cobra&#34;&gt;Cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;Viper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/jWalterWeatherman&#34;&gt;J Walter Weatherman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spf13/cast&#34;&gt;Cast&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learn more and contribute on &lt;a href=&#34;https://github.com/gohugoio&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>tinkerpop源码解析2-简单例子debug</title>
      <link>https://dengziming.github.io/post/tinkerpop/first/</link>
      <pubDate>Tue, 30 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/tinkerpop/first/</guid>
      
        <description>

&lt;p&gt;tinkerpop 源码是JanusGraph 源码解析的第一步，我们需要大概有个了解。&lt;/p&gt;

&lt;h2 id=&#34;demo-编写&#34;&gt;demo 编写&lt;/h2&gt;

&lt;p&gt;我们可以直接复制来自 tinkerpop 官方的源码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {

    TinkerGraph graph = TinkerGraph.open();
    GraphTraversalSource g = graph.traversal();

    Vertex v = g.addV().property(&amp;quot;name&amp;quot;,&amp;quot;marko&amp;quot;).property(&amp;quot;nam&amp;quot;,&amp;quot;marko a. rodriguez&amp;quot;).next();

    GraphTraversal&amp;lt;Vertex, Long&amp;gt; name = g.V(v).properties(&amp;quot;name&amp;quot;).count();
    v.property(list, &amp;quot;name&amp;quot;, &amp;quot;m. a. rodriguez&amp;quot;);
    g.V(v).properties(&amp;quot;name&amp;quot;).count();
    g.V(v).properties();
    g.V(v).properties(&amp;quot;name&amp;quot;);
    g.V(v).properties(&amp;quot;name&amp;quot;).hasValue(&amp;quot;marko&amp;quot;);
    g.V(v).properties(&amp;quot;name&amp;quot;).hasValue(&amp;quot;marko&amp;quot;).property(&amp;quot;acl&amp;quot;,&amp;quot;private&amp;quot;); //
    g.V(v).properties(&amp;quot;name&amp;quot;).hasValue(&amp;quot;marko a. rodriguez&amp;quot;);
    g.V(v).properties(&amp;quot;name&amp;quot;).hasValue(&amp;quot;marko a. rodriguez&amp;quot;).property(&amp;quot;acl&amp;quot;,&amp;quot;public&amp;quot;);
    g.V(v).properties(&amp;quot;name&amp;quot;).has(&amp;quot;acl&amp;quot;,&amp;quot;public&amp;quot;).value();
    g.V(v).properties(&amp;quot;name&amp;quot;).has(&amp;quot;acl&amp;quot;,&amp;quot;public&amp;quot;).drop(); //4\
    g.V(v).properties(&amp;quot;name&amp;quot;).has(&amp;quot;acl&amp;quot;,&amp;quot;public&amp;quot;).value();
    g.V(v).properties(&amp;quot;name&amp;quot;).has(&amp;quot;acl&amp;quot;,&amp;quot;private&amp;quot;).value();
    g.V(v).properties();
    g.V(v).properties().properties(); //5\
    g.V(v).properties().property(&amp;quot;date&amp;quot;,2014) ;//6\
    g.V(v).properties().property(&amp;quot;creator&amp;quot;,&amp;quot;stephen&amp;quot;);
    g.V(v).properties().properties();
    g.V(v).properties(&amp;quot;name&amp;quot;).valueMap();
    g.V(v).property(&amp;quot;name&amp;quot;,&amp;quot;okram&amp;quot;); //7\
    g.V(v).properties(&amp;quot;name&amp;quot;);
    g.V(v).values(&amp;quot;name&amp;quot;); //8
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后从第一行开始 打断点，debug。首先注意 TinkerGraph 是一个很简单的图数据库，超级简单。&lt;/p&gt;

&lt;h2 id=&#34;tinkergraph&#34;&gt;TinkerGraph&lt;/h2&gt;

&lt;p&gt;TinkerGraph.open() 方法会新建一个 TinkerGraph：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private TinkerGraph(final Configuration configuration) {
    this.configuration = configuration;
    vertexIdManager = selectIdManager(configuration, GREMLIN_TINKERGRAPH_VERTEX_ID_MANAGER, Vertex.class);
    edgeIdManager = selectIdManager(configuration, GREMLIN_TINKERGRAPH_EDGE_ID_MANAGER, Edge.class);
    vertexPropertyIdManager = selectIdManager(configuration, GREMLIN_TINKERGRAPH_VERTEX_PROPERTY_ID_MANAGER, VertexProperty.class);
    defaultVertexPropertyCardinality = VertexProperty.Cardinality.valueOf(
            configuration.getString(GREMLIN_TINKERGRAPH_DEFAULT_VERTEX_PROPERTY_CARDINALITY, VertexProperty.Cardinality.single.name()));

    graphLocation = configuration.getString(GREMLIN_TINKERGRAPH_GRAPH_LOCATION, null);
    graphFormat = configuration.getString(GREMLIN_TINKERGRAPH_GRAPH_FORMAT, null);

    if ((graphLocation != null &amp;amp;&amp;amp; null == graphFormat) || (null == graphLocation &amp;amp;&amp;amp; graphFormat != null))
        throw new IllegalStateException(String.format(&amp;quot;The %s and %s must both be specified if either is present&amp;quot;,
                GREMLIN_TINKERGRAPH_GRAPH_LOCATION, GREMLIN_TINKERGRAPH_GRAPH_FORMAT));

    if (graphLocation != null) loadGraph();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的 configuration 类似一个map。然后有几个 IDManager 和其他变量赋值。&lt;/p&gt;

&lt;p&gt;然后是 GraphTraversalSource g = graph.traversal(); 这一句仅仅是 return new GraphTraversalSource(this);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public GraphTraversalSource(final Graph graph) {
    this(graph, TraversalStrategies.GlobalCache.getStrategies(graph.getClass()));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时候我们取看一下几个特殊的类： Traversal&lt;S,E&gt; Traversal.Admin&lt;S, E&gt; 。 他们两个都是接口，而且 Admin 是继承自 Traversal。
Traversal 代表遍历，主要方法包括 next， asNext，iterator toList 等，可以看成一个迭代器，而 Admin 的主要方法和他没有什么关系。&lt;/p&gt;

&lt;p&gt;GraphTraversal&lt;S, E&gt; extends Traversal&lt;S, E&gt; , 新增加了很多和 gremlin 相关的方法。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janus官方实例调试解析</title>
      <link>https://dengziming.github.io/post/titan/janus%E6%B5%8B%E8%AF%95%E8%B0%83%E8%AF%95/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janus%E6%B5%8B%E8%AF%95%E8%B0%83%E8%AF%95/</guid>
      
        <description>

&lt;h2 id=&#34;开始&#34;&gt;开始&lt;/h2&gt;

&lt;p&gt;打好断点。主要类：&lt;/p&gt;

&lt;p&gt;JanusGraphFactory.build() 建造者模式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
// new GraphDatabaseConfiguration

// 创建两个 conf 对象
BasicConfiguration localBasicConfiguration = new BasicConfiguration(ROOT_NS,localConfig, BasicConfiguration.Restriction.NONE);
ModifiableConfiguration overwrite = new ModifiableConfiguration(ROOT_NS,new CommonsConfiguration(), BasicConfiguration.Restriction.NONE);

// get storeManager，根据配置反射生成。
final KeyColumnValueStoreManager storeManager = Backend.getStorageManager(localBasicConfiguration);

// conf ，需要连接数据库获得配置。
KCVSConfiguration keyColumnValueStoreConfiguration=Backend.getStandaloneGlobalConfiguration(storeManager,localBasicConfiguration);

// 后面是连接数据库进行读写和默认设置
preLoadConfiguration()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Builder.open() 新建 StandardJanusGraph,首先是静态代码和成员变量&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
// TraversalStrategies 优化策略， 需要结合 tinkerpop 的代码才能理解
static {
        TraversalStrategies graphStrategies = TraversalStrategies.GlobalCache.getStrategies(Graph.class).clone()
                .addStrategies(AdjacentVertexFilterOptimizerStrategy.instance(), JanusGraphLocalQueryOptimizerStrategy.instance(), JanusGraphStepStrategy.instance());

        //Register with cache
        TraversalStrategies.GlobalCache.registerStrategies(StandardJanusGraph.class, graphStrategies);
        TraversalStrategies.GlobalCache.registerStrategies(StandardJanusGraphTx.class, graphStrategies);
    }
    
&amp;lt;clinit&amp;gt;:641, StandardJanusGraph (org.janusgraph.graphdb.database)

// Predicate 用来判断新增的 Relation 是 schema 还是 data，可以看出 BaseRelationType 是属于 schema ，而且第一个顶点是 JanusGraphSchemaVertex
private static final Predicate&amp;lt;InternalRelation&amp;gt; SCHEMA_FILTER =
        internalRelation -&amp;gt; internalRelation.getType() instanceof BaseRelationType &amp;amp;&amp;amp; internalRelation.getVertex(0) instanceof JanusGraphSchemaVertex;
    
// NO_SCHEMA_FILTER NO_FILTER 

private final SchemaCache.StoreRetrieval typeCacheRetrieval = new SchemaCache.StoreRetrieval() {。。。}

this.backend = configuration.getBackend();

// 序列化
this.serializer = config.getSerializer();
StoreFeatures storeFeatures = backend.getStoreFeatures();
this.indexSerializer = new IndexSerializer(configuration.getConfiguration(), this.serializer,
        this.backend.getIndexInformation(), storeFeatures.isDistributed() &amp;amp;&amp;amp; storeFeatures.isKeyOrdered());
this.edgeSerializer = new EdgeSerializer(this.serializer);
this.vertexExistenceQuery = edgeSerializer.getQuery(BaseKey.VertexExists, Direction.OUT, new EdgeSerializer.TypedInterval[0]).setLimit(1);
this.queryCache = new RelationQueryCache(this.edgeSerializer);
this.schemaCache = configuration.getTypeCache(typeCacheRetrieval);
 
// management 日志管理
Log managementLog = backend.getSystemMgmtLog();
// registerReader 后，就会不断的读取日志。
managementLogger = new ManagementLogger(this, managementLog, schemaCache, this.times);
managementLog.registerReader(ReadMarker.fromNow(), managementLogger);


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Backend, 协调和配置所有后端系统&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
private final ConcurrentHashMap&amp;lt;String, Locker&amp;gt; lockers = new ConcurrentHashMap&amp;lt;&amp;gt;();

// 并发锁创建
CONSISTENT_KEY_LOCKER_CREATOR = .....// lockerStore = storeManager.openDatabase(lockerName);// 

ASTYANAX_RECIPE_LOCKER_CREATOR = 。。

indexes = getIndexes(configuration);

managementLogManager = getKCVSLogManager(MANAGEMENT_LOG);
txLogManager = getKCVSLogManager(TRANSACTION_LOG);
userLogManager = getLogManager(USER_LOG);

KeyColumnValueStore idStore = storeManager.openDatabase(config.get(IDS_STORE_NAME));
idAuthority = new ConsistentKeyIDAuthority(idStore, storeManager, config);
KeyColumnValueStore edgeStoreRaw = storeManagerLocking.openDatabase(EDGESTORE_NAME);
KeyColumnValueStore indexStoreRaw = storeManagerLocking.openDatabase(INDEXSTORE_NAME);

txLogManager.openLog(SYSTEM_TX_LOG_NAME);

txLogStore = new NoKCVSCache(storeManager.openDatabase(SYSTEM_TX_LOG_NAME));

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JanusGraphManagement management = graph.openManagement();&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;skip
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>树</title>
      <link>https://dengziming.github.io/post/algorithm/first/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/algorithm/first/</guid>
      
        <description>

&lt;h1 id=&#34;平衡二叉树&#34;&gt;平衡二叉树&lt;/h1&gt;

&lt;p&gt;平衡二叉树，就是左右最高差都不大于1的树。和二叉查找树不一样在于，在插入和删除的时候通过左旋和右旋的方式，使得树保持平衡。&lt;/p&gt;

&lt;p&gt;实现可以通过递归，注意每次左旋右旋的时候root结的改变l。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>tinkerpop查看</title>
      <link>https://dengziming.github.io/post/tinkerpop/tinkerpop%E7%9A%84step/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/tinkerpop/tinkerpop%E7%9A%84step/</guid>
      
        <description>

&lt;h2 id=&#34;一-简单调试&#34;&gt;一、简单调试&lt;/h2&gt;

&lt;p&gt;api地址： &lt;a href=&#34;http://tinkerpop.apache.org/javadocs/current/full/&#34;&gt;http://tinkerpop.apache.org/javadocs/current/full/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;第一步：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraph graph = JanusGraphFactory.open(&amp;quot;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;quot;);

GraphTraversalSource g = graph.traversal();

g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).path();

List&amp;lt;Path&amp;gt; paths = path.toList();

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们在 StandardJanusGraph 的 edgeQuery 方法打上断点。得到整个调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;org.janusgraph.graphdb.database.StandardJanusGraph.edgeQuery(StandardJanusGraph.java:436)
org.janusgraph.graphdb.database.StandardJanusGraph$1.retrieveSchemaRelations(StandardJanusGraph.java:390)
org.janusgraph.graphdb.database.cache.StandardSchemaCache.getSchemaRelations(StandardSchemaCache.java:169)
org.janusgraph.graphdb.types.vertices.JanusGraphSchemaVertex.getDefinition(JanusGraphSchemaVertex.java:80)
org.janusgraph.graphdb.types.vertices.PropertyKeyVertex.dataType(PropertyKeyVertex.java:31)
org.janusgraph.graphdb.query.QueryUtil.constraints2QNF(QueryUtil.java:178)
org.janusgraph.graphdb.query.graph.GraphCentricQueryBuilder.constructQueryWithoutProfile(GraphCentricQueryBuilder.java:239)
org.janusgraph.graphdb.query.graph.GraphCentricQueryBuilder.constructQuery(GraphCentricQueryBuilder.java:226)
org.janusgraph.graphdb.tinkerpop.optimize.JanusGraphStep.buildGraphCentricQuery(JanusGraphStep.java:149)
org.janusgraph.graphdb.tinkerpop.optimize.JanusGraphStep.lambda$null$0(JanusGraphStep.java:90)
org.janusgraph.graphdb.tinkerpop.optimize.JanusGraphStep$$Lambda$94.13001549.accept(Unknown Source:-1)
java.util.LinkedHashMap$LinkedEntrySet.forEach(LinkedHashMap.java:671)
org.janusgraph.graphdb.tinkerpop.optimize.JanusGraphStep.lambda$new$2(JanusGraphStep.java:90)
org.janusgraph.graphdb.tinkerpop.optimize.JanusGraphStep$$Lambda$81.1296612741.get(Unknown Source:-1)
org.apache.tinkerpop.gremlin.process.traversal.step.map.GraphStep.processNextStart(GraphStep.java:142)
org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.hasNext(AbstractStep.java:143)
org.apache.tinkerpop.gremlin.process.traversal.step.util.ExpandableStepIterator.next(ExpandableStepIterator.java:50)
org.apache.tinkerpop.gremlin.process.traversal.step.map.MapStep.processNextStart(MapStep.java:36)
org.apache.tinkerpop.gremlin.process.traversal.step.map.PathStep.processNextStart(PathStep.java:118)
org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:128)
org.apache.tinkerpop.gremlin.process.traversal.step.util.AbstractStep.next(AbstractStep.java:38)
org.apache.tinkerpop.gremlin.process.traversal.Traversal.fill(Traversal.java:179)
org.apache.tinkerpop.gremlin.process.traversal.Traversal.toList(Traversal.java:117)
org.janusgraph.test.dengziming.FirstTest.main(FirstTest.java:46)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一步一步看整个调用过程：&lt;/p&gt;

&lt;p&gt;进入: fill:179, Traversal (org.apache.tinkerpop.gremlin.process.traversal)&lt;/p&gt;

&lt;p&gt;fill 方法的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Step&amp;lt;?, E&amp;gt; endStep = this.asAdmin().getEndStep();
while (true) {
    final Traverser&amp;lt;E&amp;gt; traverser = endStep.next();
    TraversalHelper.addToCollection(collection, traverser.get(), traverser.bulk());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;asAdmin 得到 endStep，有点类似 spark 的 stage 拆分后得到 shuffleMapTask。然后调用 endStep.next() 得到 traverser。&lt;/p&gt;

&lt;p&gt;进入： next:128, AbstractStep (org.apache.tinkerpop.gremlin.process.traversal.step.util)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Traverser.Admin&amp;lt;E&amp;gt; traverser = this.processNextStart();
if (null != traverser.get() &amp;amp;&amp;amp; 0 != traverser.bulk())
    return this.prepareTraversalForNextStep(traverser);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入 processNextStart:118, PathStep (org.apache.tinkerpop.gremlin.process.traversal.step.map)
&lt;code&gt;return PathProcessor.processTraverserPathLabels(super.processNextStart(), this.keepLabels);&lt;/code&gt;
可以看出调用了父类的 processNextStart 方法，&lt;/p&gt;

&lt;p&gt;进入 processNextStart:36, MapStep (org.apache.tinkerpop.gremlin.process.traversal.step.map)&lt;/p&gt;

&lt;p&gt;由于是 mapStep，所以类似 spark 的 mapPartitionsRdd ，逻辑就是得到前面的 rdd，然后执行 map 方法的逻辑。
所以这里 mapStep 也是一样，得到  starts 的 next，然后调用map。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Traverser.Admin&amp;lt;S&amp;gt; traverser = this.starts.next();
return traverser.split(this.map(traverser), this);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入 next:50, ExpandableStepIterator (org.apache.tinkerpop.gremlin.process.traversal.step.util)，主要就是&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;if (this.hostStep.getPreviousStep().hasNext())
   return this.hostStep.getPreviousStep().next();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 hostStep 就是上面的 mapStep。这里有 getPreviousStep 然后 next。&lt;/p&gt;

&lt;p&gt;然后又进入到了 processNextStart:142, GraphStep (org.apache.tinkerpop.gremlin.process.traversal.step.map)，
这里的 iteratorSupplier 变量其实是在 GraphStep 的子类中赋值的，所以 get 方法得到的就是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public JanusGraphStep(final GraphStep&amp;lt;S, E&amp;gt; originalStep) {
    super(originalStep.getTraversal(), originalStep.getReturnClass(), originalStep.isStartStep(), originalStep.getIds());
    originalStep.getLabels().forEach(this::addLabel);
    this.setIteratorSupplier(() -&amp;gt; {
        if (this.ids == null) {
            return Collections.emptyIterator();
        }
        else if (this.ids.length &amp;gt; 0) {
            final Graph graph = (Graph)traversal.asAdmin().getGraph().get();
            return iteratorList((Iterator)graph.vertices(this.ids));
        }
        if (hasLocalContainers.isEmpty()) {
            hasLocalContainers.put(new ArrayList&amp;lt;&amp;gt;(), new QueryInfo(new ArrayList&amp;lt;&amp;gt;(), 0, BaseQuery.NO_LIMIT));
        }
        final JanusGraphTransaction tx = JanusGraphTraversalUtil.getTx(traversal);
        final GraphCentricQuery globalQuery = buildGlobalGraphCentricQuery(tx);

        final Multimap&amp;lt;Integer, GraphCentricQuery&amp;gt; queries = ArrayListMultimap.create();
        if (globalQuery != null &amp;amp;&amp;amp; !globalQuery.getSubQuery(0).getBackendQuery().isEmpty()) {
            queries.put(0, globalQuery);
        } else {
            hasLocalContainers.entrySet().forEach(c -&amp;gt; queries.put(c.getValue().getLowLimit(), buildGraphCentricQuery(tx, c)));
        }

        final GraphCentricQueryBuilder builder = (GraphCentricQueryBuilder) tx.query();
        final List&amp;lt;Iterator&amp;lt;E&amp;gt;&amp;gt; responses = new ArrayList&amp;lt;&amp;gt;();
        queries.entries().forEach(q -&amp;gt;  executeGraphCentryQuery(builder, responses, q));

        return new MultiDistinctOrderedIterator&amp;lt;E&amp;gt;(lowLimit, highLimit, responses, orders);
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先是 buildGraphCentricQuery&lt;/p&gt;

&lt;p&gt;然后我们可以进行其他的查询操作，例如 propertyMap 操作，会新建一个 PropertyMapStep ，它的 map 方法就是自动查询。我们差 values ，会调用 JanusGraphPropertiesStep。&lt;/p&gt;

&lt;h2 id=&#34;二-strategies&#34;&gt;二、strategies&lt;/h2&gt;

&lt;p&gt;我们知道 tinkerpop 是一个独立的项目，里面是不带任何和 janus 相关的内容，如何会有 JanusGraphStep 呢，
其实在很多地方（例如 fill:175, Traversal (org.apache.tinkerpop.gremlin.process.traversal)）会调用 this.asAdmin().applyStrategies();
会循环调用 traversalStrategy.apply(traversal)。在 apply 方法中得到了所有的 GraphStep。然后new JanusGraphStep ，并且替换掉原有的 step。&lt;/p&gt;

&lt;h2 id=&#34;三-addstep&#34;&gt;三、addStep&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析7-关系存储</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%907-%E5%85%B3%E7%B3%BB%E5%AD%98%E5%82%A8/</link>
      <pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%907-%E5%85%B3%E7%B3%BB%E5%AD%98%E5%82%A8/</guid>
      
        <description>

&lt;h1 id=&#34;基础类&#34;&gt;基础类&lt;/h1&gt;

&lt;h2 id=&#34;internalrelation-和-internalrelationtype&#34;&gt;InternalRelation 和 InternalRelationType&lt;/h2&gt;

&lt;p&gt;有关类型体系很复杂，可以使用 IDEA 的显示继承体系功能，查看类图。类图比较大，不太好看。大概描述一下：
主要是 JanusGraphElement 作为顶级类，接下来还有一个 InternalElement 作为顶级的 Internal 类。
JanusGraphElement 继承的类主要分为 JanusGraphRelation,JanusGraphVertex 两个分支，前者又分为 JanusGraphVertexProperty, JanusGraphEdge 。
InternalElement 的继承类主要分为 InternalRelation ,InternalVertex 两个分支，前者又分为 JanusGraphVertexProperty, JanusGraphEdge 。
其中 Internal 开头类总是有一个 JanusGraph 开头的类作为父类。例如 InternalRelation 继承自 JanusGraphRelation。&lt;/p&gt;

&lt;p&gt;JanusGraphVertex 比较特殊，他除了有 InternalVertex 子类以外，还有 VertexLabel 和 RelationType 两个子类。
同理 InternalVertex 的继承体系下，除了真正的实体以外，还有一个 JanusGraphSchemaVertex ，他有 VertexLabelVertex, RelationTypeVertex 两个子类，
RelationTypeVertex 又有 EdgeLabelVertex 和 PropertyKeyVertex 两个子类。还有 BaseLabel BaseKey BaseVerteLabel 等子类。&lt;/p&gt;

&lt;p&gt;这里就需要提到我们之前说的，janus 的 schema 也是以顶点的形式保存的，顶级类就是 JanusGraphSchemaVertex ，有 VertexLabelVertex, EdgeLabelVertex 和 PropertyKeyVertex 三个实现。
他们分别代表了 VertexLabel EdgeLabel PropertyKey 的 Vertex，同时我们想想，这些 Vertex 也是 janus 的元素 也是有属性的，我们岂不是还要新建三个类，保存他们的 Property Label 等？
然后他们的 Label 也是有属性的，这样下去就子子孙孙无穷尽也。所以才有了上面的 BaseLabel BaseKey BaseVerteLabel 作为终极的 Vertex。&lt;/p&gt;

&lt;p&gt;然后我们看一下 InternalRelation 和 InternalRelationType 的关系，InternalRelation 代表的就是一种关系，有 JanusGraphEdge 和 JanusGraphVertexProperty 两种，&lt;/p&gt;

&lt;p&gt;例如一个用户的性别是女，也就是给一个顶点添加一个性别 &lt;code&gt;女&lt;/code&gt; 的属性：
首先有两个顶点, a: InternalVertex (JanusGraphVertex)， 性别则是一个 b: PropertyKey (InternalRelationType) 也是一个 Vertex，
而 &lt;code&gt;女&lt;/code&gt; 则是 property 的值，实际上就是在这两个不同类型的 Vertex 之间建立一条连接。再加上一个 value 这三个组合在一起就是一个 JanusGraphVertexProperty 。&lt;/p&gt;

&lt;p&gt;再例如我们要给一个顶点的 VertexLabel 是 User：
首先有一个用户顶点，a: InternalVertex (JanusGraphVertex)，然后 User 也是一个建好的 schema，也就是顶点： VertexLabelVertex 。然后给他们之间建立一条关系，这个关系也是一个顶点 BaseLabel.VertexLabelEdge。&lt;/p&gt;

&lt;p&gt;在比如给两个用户之间添加一个 Friend 的关系。
首先有两个顶点就是用户，然后新建一个 StandardEdge，然后 这两个顶点分别和这个 StandardEdge 建立一个 EdgeLabel 为 Friend 的关系。&lt;/p&gt;

&lt;p&gt;到这里我们大概明白，其实添加 Property 就是和 和一个 PropertyKey 建立一条边，添加 Edge 就是和一个 vertex 建立一条边，添加 VertexLabel 就是和一个 VertexLabel 建立一条边。&lt;/p&gt;

&lt;p&gt;InternalRelation 就是添加的边，可以序列化存储起来，也可以读出来反序列化成 InternalRelation。 InternalRelationType 就是类型，类型也是一个顶点， 而 PropertyKey 这种类型对应的属性都是 Base开头的。&lt;/p&gt;

&lt;p&gt;##&lt;/p&gt;

&lt;h2 id=&#34;relationcache&#34;&gt;RelationCache&lt;/h2&gt;

&lt;h2 id=&#34;staticarrayentry&#34;&gt;StaticArrayEntry&lt;/h2&gt;

&lt;p&gt;类似 java.nio 的 ByteBuffer。&lt;/p&gt;

&lt;h1 id=&#34;edgeserializer&#34;&gt;EdgeSerializer&lt;/h1&gt;

&lt;h2 id=&#34;writerelation&#34;&gt;writeRelation&lt;/h2&gt;

&lt;p&gt;EdgeSerializer 类主要用来写 edgestore 库，这个库序列化方式相对比较简单，但代码还是比较多。&lt;/p&gt;

&lt;p&gt;从代码调用开始看：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (Long vertexId : mutations.keySet()) {
       Preconditions.checkArgument(vertexId &amp;gt; 0, &amp;quot;Vertex has no id: %s&amp;quot;, vertexId);
       final List&amp;lt;InternalRelation&amp;gt; edges = mutations.get(vertexId);
       final List&amp;lt;Entry&amp;gt; additions = new ArrayList&amp;lt;&amp;gt;(edges.size());
       final List&amp;lt;Entry&amp;gt; deletions = new ArrayList&amp;lt;&amp;gt;(Math.max(10, edges.size() / 10));
       for (final InternalRelation edge : edges) {
           final InternalRelationType baseType = (InternalRelationType) edge.getType();
           assert baseType.getBaseType()==null;

           for (InternalRelationType type : baseType.getRelationIndexes()) {
               if (type.getStatus()== SchemaStatus.DISABLED) continue;
               for (int pos = 0; pos &amp;lt; edge.getArity(); pos++) {
                   if (!type.isUnidirected(Direction.BOTH) &amp;amp;&amp;amp; !type.isUnidirected(EdgeDirection.fromPosition(pos)))
                       continue; //Directionality is not covered
                   if (edge.getVertex(pos).longId()==vertexId) {
                       StaticArrayEntry entry = edgeSerializer.writeRelation(edge, type, pos, tx);
                       if (edge.isRemoved()) {
                           deletions.add(entry);
                       } else {
                           Preconditions.checkArgument(edge.isNew());
                           int ttl = getTTL(edge);
                           if (ttl &amp;gt; 0) {
                               entry.setMetaData(EntryMetaData.TTL, ttl);
                           }
                           additions.add(entry);
                       }
                   }
               }
           }
       }

       StaticBuffer vertexKey = idManager.getKey(vertexId);
       mutator.mutateEdges(vertexKey, additions, deletions);
   }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是java类 StandardJanusGraph 写数据 的代码。可以看出写数据之前是需要调用 StaticArrayEntry entry = edgeSerializer.writeRelation(edge, type, pos, tx);
所以接下来我么的任务就是看看这个方法，我们先看看这几个参数的意义：&lt;/p&gt;

&lt;p&gt;InternalRelation relation, 代表一条关系，可以是 edge，也可以是 Property。
如果是edge，edge的两个顶点都会保存这条边，如果是 Property，只会有节点保存，PropertyKey 不会保存。&lt;/p&gt;

&lt;p&gt;InternalRelationType type,  可以是 Property 和 Edge&lt;/p&gt;

&lt;p&gt;int position, 通过调用部分代码，可以看出表示顶点在这个关系中的位置。例如 v1 -[e1]-&amp;gt; v2, 对于e1来讲，v1的pos是0，v2的pos是1。
TypeInspector tx 用来检测类型.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public StaticArrayEntry writeRelation(InternalRelation relation, 
										InternalRelationType type, 
										int position,
										TypeInspector tx) 
										
{
    // 判断类型
    assert type==relation.getType() || (type.getBaseType() != null
            &amp;amp;&amp;amp; type.getBaseType().equals(relation.getType()));
    // 得到方向，可以是 只有 OUT 和 IN 两种结果
    Direction dir = EdgeDirection.fromPosition(position);
    
    // isUnidirected 方法是判断是不是这个方向的。
    Preconditions.checkArgument(type.isUnidirected(Direction.BOTH) || type.isUnidirected(dir));
    
    // 得到 type 的id，注意 JanusGraph 中的schema 也是以顶点的形式存储，也有 id。
    long typeId = type.longId();
    
    // 得到 PROPERTY_DIR 或者 EDGE_OUT_DIR 或者 EDGE_IN_DIR
    DirectionID dirID = getDirID(dir, relation.isProperty() ? RelationCategory.PROPERTY : RelationCategory.EDGE);

    // 得到一个输出，实际就是 byte 数组
    DataOutput out = serializer.getDataOutput(DEFAULT_CAPACITY);
    
    // 保存 key 和 value 的临界点
    int valuePosition;
    
    // 这里调用方法写入 typeId dirID isInvisibleType ，详细内容我们后面看 TODO
    IDHandler.writeRelationType(out, typeId, dirID, type.isInvisibleType());
    
    // multiplicity 代表多元性
    Multiplicity multiplicity = type.multiplicity();

    long[] sortKey = type.getSortKey();
    // 多对多关系不允许有排序的key
    assert !multiplicity.isConstrained() || sortKey.length==0: type.name();
    
    int keyStartPos = out.getPosition();
    if (!multiplicity.isConstrained()) { // isConstrained 代表是否有限制。SINGLE 和 SET 有限制，LIST 无限制。
        // 写排序key ，这个方法后面讨论 TODO
        writeInlineTypes(sortKey, relation, out, tx, InlineType.KEY);
    }
    int keyEndPos = out.getPosition();

    long relationId = relation.longId();

    //How multiplicity is handled for edges and properties is slightly different
    if (relation.isEdge()) {  // 如果是边关系
        // 得到另一个顶点的id
        long otherVertexId = relation.getVertex((position + 1) % 2).longId();
        if (multiplicity.isConstrained()) { // 非多对多
            if (multiplicity.isUnique(dir)) { // 只有一个这种类型的边。例如每个 Person只有一个父亲节点。
                valuePosition = out.getPosition(); // 得到 position
                // 写出另一个顶点的id
                VariableLong.writePositive(out, otherVertexId);
            } else { // 可能有多个关系，例如一个Person可能有多个 儿子节点
                
                // 这时候从后往前写，这个方法后面讨论  TODO 
                VariableLong.writePositiveBackward(out, otherVertexId);
                valuePosition = out.getPosition();
            }
            // 然后写出 关系的 relationId
            VariableLong.writePositive(out, relationId);
        } else {// 多对多，我们的数据绝大部分都是这种情况
            //从后往前写 vertex 和 relationId。得到position
            VariableLong.writePositiveBackward(out, otherVertexId);
            VariableLong.writePositiveBackward(out, relationId);
            valuePosition = out.getPosition();
        }

/**
总结上面
SortKey是一种特殊的属性，JanusGraph允许在定义Edge Label时指定其中的一个或多个属性为Sort Key。
对于边的Sort Key属性，JanusGraph在存储时会将其存储在Relation Type ID的后面,其他所有字段的前面。
通过这种方式，可以保证一个节点的多条同一个类型的边，会按Sort Key属性排序存储。这对于一个节点有大量边时，对查询性能提升有帮助。

MULTIPLICITY为MULTI时的存储结构： 从后往前写 otherVertexId 和 relationId。其余放在 value 里面

MULTIPLICITY非MULTI且此方向存在多条边时的存储结构：从后往前写 otherVertexId，relationId 和其余放在 value里面

MULTIPLICITY非MULTI且此方向仅有一条边时的存储结构： 不记录relationId，otherVertexId 放在value 里面
*/

    } else { // 如果是属性关系，得到属性的 key 和 value
        assert relation.isProperty();
        Preconditions.checkArgument(relation.isProperty());
        Object value = ((JanusGraphVertexProperty) relation).value();
        Preconditions.checkNotNull(value);
        PropertyKey key = (PropertyKey) type;
        assert key.dataType().isInstance(value);

        // 没有限制，不是 LIST 类型
        if (multiplicity.isConstrained()) {
            if (multiplicity.isUnique(dir)) { //Cardinality=SINGLE
                // property 放在 value 中
                valuePosition = out.getPosition();
                writePropertyValue(out,key,value);
            } else { //Cardinality=SET
                // property 放在 key 中
                writePropertyValue(out,key,value);
                valuePosition = out.getPosition();
            }
            // 写出 relationId
            VariableLong.writePositive(out, relationId);
        } else {
            assert multiplicity.getCardinality()== Cardinality.LIST;
            // 在key中反向写出 relationId, property 放在 value 中
            VariableLong.writePositiveBackward(out, relationId);
            valuePosition = out.getPosition();
            writePropertyValue(out,key,value);
        }
    }

/** 总结上面

Cardinality为SINGLE时的存储结构

列名只存储Property Key的ID及方向。具体的Property Value值以及Property ID(relationId)，都存放在Cell的Value中。
另外，如果该Property还有额外的 Remaining properties，也会放在Value中。Remaining properties一般不使用，仅在一些特殊场景下，用于为该Property记录更多的附加信息(比如存储元数据Edge Labe的定义等)。

PropertyKeyID 及方向整个结构的详细结构在后文中描述；占用一个或多个字段，具体格式在后文描述;及采用相同的格式，具体格式在后文描述。

Candinality为LIST时的存储结构

各个部分与Cardinality为SINGLE时的结构相似，区别在于属性的ID被放在了列名中，而不是放在Value中。

Candinality为SET存储结构

各个部分与Cardinality为SINGLE时的结构相似，区别在于属性的值被放在了列名中，而不是放在Value中。

*** /


    //Write signature 
    // 得到 relationType 所有的 signature 的 PropertyKeyid，写到 value 中
    long[] signature = type.getSignature();
    writeInlineTypes(signature, relation, out, tx, InlineType.SIGNATURE);

    //Write remaining properties
    // sortKey 和 signature 是已经写过，所以排除掉
    LongSet writtenTypes = new LongHashSet(sortKey.length + signature.length);
    if (sortKey.length &amp;gt; 0 || signature.length &amp;gt; 0) {
        for (long id : sortKey) writtenTypes.add(id);
        for (long id : signature) writtenTypes.add(id);
    }
    LongArrayList remainingTypes = new LongArrayList(8);
    for (PropertyKey t : relation.getPropertyKeysDirect()) {
        if (!(t instanceof ImplicitKey) &amp;amp;&amp;amp; !writtenTypes.contains(t.longId())) {
            remainingTypes.add(t.longId());
        }
    }
    //Sort types before writing to ensure that value is always written the same way
    long[] remaining = remainingTypes.toArray();
    Arrays.sort(remaining);
    for (long tid : remaining) {
        // 剩下的 value 写到值部分。
        PropertyKey t = tx.getExistingPropertyKey(tid);
        writeInline(out, t, relation.getValueDirect(t), InlineType.NORMAL);
    }
    assert valuePosition&amp;gt;0;

    // 返回，返回的时候需要注意根据 type.getSortOrder() 的结果进行判断，如果 DESC 需要将 key 部分反过来
    return new StaticArrayEntry(type.getSortOrder() == Order.DESC ?
                                out.getStaticBufferFlipBytes(keyStartPos, keyEndPos) :
                                out.getStaticBuffer(), valuePosition);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里我们基本了解了数据的存储结构，但是细节还是没了解。比如key具体多少位，每一位是啥。接下来我们需要稍微了解一下每次写的时候对应方法的细节。
我们只需要找有变量 out 的代码部分。&lt;/p&gt;

&lt;p&gt;第一次是 &lt;code&gt;DataOutput out = serializer.getDataOutput(DEFAULT_CAPACITY)&lt;/code&gt;, 这个就是创建新的Buffer，然后是 IDHandler 写部分。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/**
 * The edge type is written as follows: [ Invisible &amp;amp;amp; System (2 bit) | Relation-Type-ID (1 bit) | Relation-Type-Count (variable) | Direction-ID (1 bit)]
 * Would only need 1 bit to store relation-type-id, but using two so we can upper bound.
 * 
 * 注释说明，edge格式： Invisible &amp;amp; System  2bit, Relation-Type-ID 1 bit, Relation-Type-Count 变化的,Direction-ID 一位。
 * 这里有个小疑问，Relation-Type-ID 也是一个 long 类型，1bit 应该没法表示。我们在代码中看
 *
 * @param out
 * @param relationTypeId
 * @param dirID
 */
public static void writeRelationType(WriteBuffer out, long relationTypeId, DirectionID dirID, boolean invisible) {
    
    // 断言判断
    assert relationTypeId &amp;gt; 0 &amp;amp;&amp;amp; (relationTypeId &amp;lt;&amp;lt; 1) &amp;gt; 0; //Check positive and no-overflow

    // 去掉 relationTypeId 的 padding，在后面补一位 dirID.getDirectionInt。
    long strippedId = (IDManager.stripEntireRelationTypePadding(relationTypeId) &amp;lt;&amp;lt; 1) + dirID.getDirectionInt();
    {
    // 这个方法就是将 id 的 Padding 部分 去掉。
    public static long stripEntireRelationTypePadding(long id) {
        Preconditions.checkArgument(isProperRelationType(id));
        return VertexIDType.UserEdgeLabel.removePadding(id);
        {
            VertexIDType.UserEdgeLabel.removePadding(id){
                id &amp;gt;&amp;gt;&amp;gt; offset();// 这个 offset() 代表 id 的padding 长度，NormalVertex 是 3，EdgeLabel 是5，UserEdgeLabel 是6
            }
        }
    }
    }
    
    //
    VariableLong.writePositiveWithPrefix(out, strippedId, dirID.getPrefix(invisible, IDManager.isSystemRelationTypeId(relationTypeId)), PREFIX_BIT_LEN);
    {
    // IDManager.isSystemRelationTypeId(relationTypeId)) 判断是否是系统关系
    // getPrefix 方法如下，其实就是得到了 上面所说的数据，
    	private int getPrefix(boolean invisible, boolean systemType) {
    	    assert !systemType || invisible; // systemType implies invisible
    	    return ((systemType?0:invisible?2:1)&amp;lt;&amp;lt;1) + getRelationType();
    	}
    
    // 整个方法就是写下 prefix strippedId 。
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;整个方法大概就清楚了，然后是 writeInlineTypes 和 writeInline ，writePropertyValue ，和上面的方法类似。
然后是 VariableLong.writePositiveBackward(out, otherVertexId); 和 VariableLong.writePositive(out, otherVertexId);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void writePositive(WriteBuffer out, final long value) {
    assert value &amp;gt;= 0;
    writeUnsigned(out, value);
    
    	/** writeUnsigned 方法 */
    	{
    	private static void writeUnsigned(WriteBuffer out, final long value) {
    	    writeUnsigned(out, unsignedBlockBitLength(value), value);
    	    
    	    /** unsignedBlockBitLength 最终是 block 的数量 * 7 */
    	    {
    	    return unsignedNumBlocks(value)*7;
    	    	/** unsignedNumBlocks 求 block 数量 */
    	    	{
    	    	     return numVariableBlocks(unsignedBitLength(value));
    	    	     {
    	    	     // 得到数据去掉所有0 的位数，如果是0有1位。也就是无符号位数
    	    	     unsignedBitLength(value){
    	    	         return (value == 0) ? 1 : Long.SIZE - Long.numberOfLeadingZeros(value);
    	    	     }
    	    	     /** 这个方法返回 位数－1 除以 7 再加一，
    	    	     简单理解 ,就是第一个bit一个 block，剩下每7bit 一个 block
    	    	     实际上是除以七进一。
    	    	      */
    	    	     numVariableBlocks{
    	    	         return (numBits - 1) / 7 + 1;
    	    	     }
    	    	     }
    	    	}
    	    }
    	    
    	    /** writeUnsigned 方法 */
    	    {
    		private static void writeUnsigned(WriteBuffer out, int offset, final long value) {
        		assert offset % 7 == 0;
        		while (offset &amp;gt; 0) { // offset 就是上面求的 block 数量 * 7
        		    offset -= 7; // 一次写 7 位。
        		    
        		    byte b = (byte) ((value &amp;gt;&amp;gt;&amp;gt; offset) &amp;amp; BIT_MASK); // 左移 offset 与 01111111 进行 `逻辑与` 操作。
        		    if (offset == 0) {
        		        b = (byte) (b | STOP_MASK);  // 如果是最后一位，再与 -128(111111...1110000000) 进行或操作,这个操作的结果会得到一个类似补码的数据
        		    }
        		    out.putByte(b);
    		    }
    		}
    	    }
    	}
    }
}
/**
综上所述, 整个写 long 的方法，首先是计算数据的 block 数，每 7 位一个block。
写出的时候，每次写一个 byte(8bit)，其中一个block 7bit，再加一个占位符(0)。最后再与 -128(111111...1110000000) 进行或操作，
例如 72 会变成 -56， 满足 72 - (-56) = 128，这应该是补码还是反码记不清了。
*/

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后是  VariableLong.writePositiveBackward(out, otherVertexId)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
/**
 * The format used is this:
 * - The first bit indicates whether this is the first block (reading backwards, this would be the stop criterion)
 * - In the first byte, the 3 bits after the first bit indicate the number of bytes written minus 3 (since 3 is
 * the minimum number of bytes written. So, if the 3 bits are 010 = 2 =&amp;gt; 5 bytes written. The value is aligned to
 * the left to ensure that this encoding is byte order preserving.
 *
 *  根据注释，第一 bit 表示是否是第一个 block （往后读需要一个停止标识），紧接着代表数据的位数。
 * 
 * @param out
 * @param value
 */
private static void writeUnsignedBackward(WriteBuffer out, final long value) {
    
    int numBytes = unsignedBackwardLength(value);
    /** unsignedBackwardLength 这个类似上面，得到最少的 bytes 数量。可以看出至少有3 bytes。*/
    {
        int bitLength = unsignedBitLength(value); // 这个上面已经看过。
        assert bitLength &amp;gt; 0 &amp;amp;&amp;amp; bitLength &amp;lt;= 64;
        return Math.max(3, 1 + (bitLength &amp;lt;= 4 ? 0 : (1 + (bitLength - 5) / 7)));
    }
    int prefixLen = numBytes - 3;
    assert prefixLen &amp;gt;= 0 &amp;amp;&amp;amp; prefixLen &amp;lt; 8; //Consumes 3 bits
    //Prepare first byte
    byte b = (byte)((prefixLen &amp;lt;&amp;lt; 4) | 0x80); //stop marker (first bit) and length
    for (int i = numBytes - 1; i &amp;gt;= 0; i--) {
        b = (byte)(b | (0x7F &amp;amp; (value &amp;gt;&amp;gt;&amp;gt; (i * 7)))); // 左移 i*7 位，和 0x7F 进行逻辑与，实际上就是取七位。
        out.putByte(b);
        b = 0;
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的对比我们看出 writePositiveBackward 和 writePositive 的差别在于 writePositiveBackward 把停止标识放在了开头，writePositive 放在结尾。&lt;/p&gt;

&lt;p&gt;看完序列化的代码我们可以大概知道存储的格式，我们整理一下。序列化的步骤在 writeRelation 中，首先写出Relation 的方向、可见性、schemaId，然后如果有sortKey写出sortKey的值，
然后判断是Edge 还是Property，根据他们的 multiplicity 处理有所不同。详情上面已经有了。最后还要写出 signature 和剩下的属性。&lt;/p&gt;

&lt;h2 id=&#34;readrelation&#34;&gt;readRelation&lt;/h2&gt;

&lt;p&gt;和 writeRelation 对应的是 readRelation，相关调用如下，主要是 readRelation 方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Returns the list of adjacent vertex ids for this query. By reading those ids
 * from the entries directly (without creating objects) we get much better performance.
 *
 * @return
 */
public VertexList vertexIds() {
    LongArrayList list = new LongArrayList();
    long previousId = 0;
    for (Long id : Iterables.transform(this,new Function&amp;lt;Entry, Long&amp;gt;() {
        @Nullable
        @Override
        public Long apply(@Nullable Entry entry) {
            return edgeSerializer.readRelation(entry,true,tx).getOtherVertexId();
        }
    })) {
        list.add(id);
        if (id&amp;gt;=previousId &amp;amp;&amp;amp; previousId&amp;gt;=0) previousId=id;
        else previousId=-1;
    }
    return new VertexLongList(tx,list,previousId&amp;gt;=0);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入方法发现核心就是一个 parseRelation 方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
@Override
public RelationCache parseRelation(Entry data, boolean excludeProperties, TypeInspector tx) {
    ReadBuffer in = data.asReadBuffer();

    LongObjectHashMap properties = excludeProperties ? null : new LongObjectHashMap(4);
    
    // 第一步，读取关系类型。就是上面的写进去的 三位prefix+typeId ，包括方向，类型，可见性
    RelationTypeParse typeAndDir = IDHandler.readRelationType(in);

    long typeId = typeAndDir.typeId;
    Direction dir = typeAndDir.dirID.getDirection();

   // 根据id 查询对应的类型
    RelationType relationType = tx.getExistingRelationType(typeId);
    InternalRelationType def = (InternalRelationType) relationType;
    Multiplicity multiplicity = def.multiplicity();
    long[] keySignature = def.getSortKey();

    long relationId;
    Object other;
    int startKeyPos = in.getPosition();
    int endKeyPos = 0;
    
    // 这里和前面写的对应， 分别读取
    if (relationType.isEdgeLabel()) {
        long otherVertexId;
        if (multiplicity.isConstrained()) {
            if (multiplicity.isUnique(dir)) { 
                otherVertexId = VariableLong.readPositive(in);
            } else {
                in.movePositionTo(data.getValuePosition());
                otherVertexId = VariableLong.readPositiveBackward(in);
                in.movePositionTo(data.getValuePosition());
            }
            relationId = VariableLong.readPositive(in);
        } else {
            in.movePositionTo(data.getValuePosition());

            relationId = VariableLong.readPositiveBackward(in);
            otherVertexId = VariableLong.readPositiveBackward(in);
            endKeyPos = in.getPosition();
            in.movePositionTo(data.getValuePosition());
        }
        other = otherVertexId;
    } else {
        assert relationType.isPropertyKey();
        PropertyKey key = (PropertyKey) relationType;

        if (multiplicity.isConstrained()) {
            other = readPropertyValue(in,key);
            relationId = VariableLong.readPositive(in);
        } else {
            in.movePositionTo(data.getValuePosition());
            relationId = VariableLong.readPositiveBackward(in);
            endKeyPos = in.getPosition();
            in.movePositionTo(data.getValuePosition());
            other = readPropertyValue(in,key);
        }
        Preconditions.checkState(other!=null,
            &amp;quot;Encountered error in deserializer [null value returned]. Check serializer compatibility.&amp;quot;);
    }
    assert other!=null;

    // 
    if (!excludeProperties &amp;amp;&amp;amp; !multiplicity.isConstrained() &amp;amp;&amp;amp; keySignature.length&amp;gt;0) {
        int currentPos = in.getPosition();
        //Read sort key which only exists if type is not unique in this direction
        assert endKeyPos&amp;gt;startKeyPos;
        int keyLength = endKeyPos-startKeyPos; //after reading the ids, we are on the last byte of the key
        in.movePositionTo(startKeyPos);
        ReadBuffer inKey = in;
        if (def.getSortOrder()== Order.DESC) inKey = in.subrange(keyLength,true);
        readInlineTypes(keySignature, properties, inKey, tx, InlineType.KEY);
        in.movePositionTo(currentPos);
    }

    if (!excludeProperties) {
        //read value signature
        readInlineTypes(def.getSignature(), properties, in, tx, InlineType.SIGNATURE);

        //Third: read rest
        while (in.hasRemaining()) {
            PropertyKey type = tx.getExistingPropertyKey(IDHandler.readInlineRelationType(in));
            Object propertyValue = readInline(in, type, InlineType.NORMAL);
            assert propertyValue != null;
            properties.put(type.longId(), propertyValue);
        }

        if (data.hasMetaData()) {
            for (Map.Entry&amp;lt;EntryMetaData,Object&amp;gt; metas : data.getMetaData().entrySet()) {
                ImplicitKey key = ImplicitKey.MetaData2ImplicitKey.get(metas.getKey());
                if (key!=null) {
                    assert metas.getValue()!=null;
                    properties.put(key.longId(),metas.getValue());
                }
            }
        }
    }

    return new RelationCache(dir, typeId, relationId, other, properties);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看出，如果你熟悉上面的readRelation，就是 反过来读一遍。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析8-底层交互</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%909-%E8%B4%A1%E7%8C%AE%E5%AF%BC%E6%95%B0%E6%8D%AE%E6%BA%90%E7%A0%81/</link>
      <pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%909-%E8%B4%A1%E7%8C%AE%E5%AF%BC%E6%95%B0%E6%8D%AE%E6%BA%90%E7%A0%81/</guid>
      
        <description>

&lt;h1 id=&#34;反向分析&#34;&gt;反向分析&lt;/h1&gt;

&lt;h2 id=&#34;cassandra-写数据-api&#34;&gt;cassandra 写数据 API&lt;/h2&gt;

&lt;p&gt;cassandra 的结构类似 bigtable ，数据实际上是多层嵌套的 map，第一个 key 是 rowkey，第二层key 是 columnFamily，第三层key 是 column，第四层(也可以忽略) 是 timestamp，然后是 value。&lt;/p&gt;

&lt;p&gt;写数据的 API 如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; CTConnection conn = null;
 try {
     conn = pool.borrowObject(keySpaceName);
     Cassandra.Client client = conn.getClient();
     if (atomicBatch) {
         client.atomic_batch_mutate(batch, consistency);
     } else {
         client.batch_mutate(batch, consistency);
     }
 } catch (Exception ex) {
     throw CassandraThriftKeyColumnValueStore.convertException(ex);
 } finally {
     pool.returnObjectUnsafe(keySpaceName, conn);
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的 batch 就是一个多层嵌套的map。&lt;code&gt;final Map&amp;lt;ByteBuffer, Map&amp;lt;String, List&amp;lt;org.apache.cassandra.thrift.Mutation&amp;gt;&amp;gt;&amp;gt; batch = new HashMap&amp;lt;&amp;gt;(size);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里看起来只有两层，第一层的 ByteBuffer 当然是 rowKey，第二层是 String 是 columnFamily。而 &lt;code&gt;List&amp;lt;org.apache.cassandra.thrift.Mutation&amp;gt;&lt;/code&gt; 很明显就是添加或者删除的 key:value。&lt;/p&gt;

&lt;h2 id=&#34;写入-cassandra-的数据格式&#34;&gt;写入 cassandra 的数据格式&lt;/h2&gt;

&lt;p&gt;上面是写 cassandra 的 API，而最终调用这段代码的位置在 &lt;code&gt;CassandraThriftStoreManager.mutateMany(Map&amp;lt;String, Map&amp;lt;StaticBuffer, KCVMutation&amp;gt;&amp;gt; mutations, StoreTransaction txh)&lt;/code&gt; 方法。&lt;/p&gt;

&lt;p&gt;我们需要了解的就是  &lt;code&gt;Map&amp;lt;String, Map&amp;lt;StaticBuffer, KCVMutation&amp;gt;&amp;gt; mutations&lt;/code&gt; 和 &lt;code&gt;Map&amp;lt;ByteBuffer, Map&amp;lt;String, List&amp;lt;org.apache.cassandra.thrift.Mutation&amp;gt;&amp;gt;&amp;gt; batch&lt;/code&gt; 的对应关系。&lt;/p&gt;

&lt;p&gt;从代码可以看出：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final Map&amp;lt;ByteBuffer, Map&amp;lt;String, List&amp;lt;org.apache.cassandra.thrift.Mutation&amp;gt;&amp;gt;&amp;gt; batch = new HashMap&amp;lt;&amp;gt;(size);

for (final Map.Entry&amp;lt;String, Map&amp;lt;StaticBuffer, KCVMutation&amp;gt;&amp;gt; keyMutation : mutations.entrySet()) {
    
    // mutations 的 key 是 columnFamily
    final String columnFamily = keyMutation.getKey(); 
    
    for (final Map.Entry&amp;lt;StaticBuffer, KCVMutation&amp;gt; mutEntry : keyMutation.getValue().entrySet()) {
        
        // mutations 的第二层 key 是 rowKey
        ByteBuffer keyBB = mutEntry.getKey().asByteBuffer();

        // Get or create the single Cassandra Mutation object responsible for this key
        // Most mutations only modify the edgeStore and indexStore
        
        final Map&amp;lt;String, List&amp;lt;org.apache.cassandra.thrift.Mutation&amp;gt;&amp;gt; cfmutation
            = batch.computeIfAbsent(keyBB, k -&amp;gt; new HashMap&amp;lt;&amp;gt;(3));

        final KCVMutation mutation = mutEntry.getValue();
        final List&amp;lt;org.apache.cassandra.thrift.Mutation&amp;gt; thriftMutation = new ArrayList&amp;lt;&amp;gt;(mutations.size());
        
        // 省略删除的代码。
        
        if (mutation.hasAdditions()) {
            
            for (final Entry ent : mutation.getAdditions()) {
                final ColumnOrSuperColumn columnOrSuperColumn = new ColumnOrSuperColumn();
                
                // mutations 的第三层 key 是 column
                final Column column = new Column(ent.getColumnAs(StaticBuffer.BB_FACTORY));
                // mutations 的 value 是 value
                column.setValue(ent.getValueAs(StaticBuffer.BB_FACTORY));

                column.setTimestamp(commitTime.getAdditionTime(times));

                final Integer ttl = (Integer) ent.getMetaData().get(EntryMetaData.TTL);
                if (null != ttl &amp;amp;&amp;amp; ttl &amp;gt; 0) {
                    column.setTtl(ttl);
                }

                columnOrSuperColumn.setColumn(column);
                org.apache.cassandra.thrift.Mutation m = new org.apache.cassandra.thrift.Mutation();
                m.setColumn_or_supercolumn(columnOrSuperColumn);
                thriftMutation.add(m);
            }
        }

        cfmutation.put(columnFamily, thriftMutation);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看出 mutateMany 方法的参数和写到 cassandra 的结果不是完全一致，主要是 rowkey 和 columnFamily 的位置是反的。&lt;/p&gt;

&lt;h2 id=&#34;传入-mutatemany-的数据&#34;&gt;传入 mutateMany 的数据&lt;/h2&gt;

&lt;p&gt;通过调试可以看出，调用 mutateMany 的地方主要是 &lt;code&gt;CacheTransation.persist&lt;/code&gt; ,而调用 persist 的就是 flushInternal 方法。相应代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 成员变量： Map&amp;lt;KCVSCache, Map&amp;lt;StaticBuffer, KCVEntryMutation&amp;gt;&amp;gt; mutations

// 新建Map，这个 map 就是上面 mutateMany 的参数，key 分别是 columnFamily 和 rowKey ，
final Map&amp;lt;String, Map&amp;lt;StaticBuffer, KCVMutation&amp;gt;&amp;gt; subMutations = new HashMap&amp;lt;&amp;gt;(mutations.size());

int numSubMutations = 0;
// 遍历 mutations
for (Map.Entry&amp;lt;KCVSCache,Map&amp;lt;StaticBuffer, KCVEntryMutation&amp;gt;&amp;gt; storeMutations : mutations.entrySet()) {
    final Map&amp;lt;StaticBuffer, KCVMutation&amp;gt; sub = new HashMap&amp;lt;&amp;gt;();
    
    // KCVSCache 的 getKey().getName() 就是 columnFamily
    subMutations.put(storeMutations.getKey().getName(),sub);
   
    // mutations 的 value
    for (Map.Entry&amp;lt;StaticBuffer,KCVEntryMutation&amp;gt; mutationsForKey : storeMutations.getValue().entrySet()) {
        if (mutationsForKey.getValue().isEmpty()) continue;
        
        // 将 mutationsForKey 放进去，这个 convert 做了啥没有具体研究，可能只是一个适配。
        sub.put(mutationsForKey.getKey(), convert(mutationsForKey.getValue()));
        numSubMutations+=mutationsForKey.getValue().getTotalMutations();
        if (numSubMutations&amp;gt;= persistChunkSize) {
            numSubMutations = persist(subMutations);
            sub.clear();
            subMutations.put(storeMutations.getKey().getName(),sub);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mutations-的构造&#34;&gt;mutations 的构造&lt;/h2&gt;

&lt;p&gt;上面我们看出了，其实基本上没复杂处理，接下来我们看看 mutations 数据哪里来的。&lt;/p&gt;

&lt;p&gt;对于 mutations 的修改操作，来自于 mutate 方法，代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 传入的是 store（包含了columnFamily） key（rowKey） additions 和 deletions
void mutate(KCVSCache store, StaticBuffer key, List&amp;lt;Entry&amp;gt; additions, List&amp;lt;Entry&amp;gt; deletions) throws BackendException {
    Preconditions.checkNotNull(store);
    if (additions.isEmpty() &amp;amp;&amp;amp; deletions.isEmpty()) return;
    
    // 构造 KCVEntryMutation
    KCVEntryMutation m = new KCVEntryMutation(additions, deletions);
    
    // 这几步就是简单的合并所以的 additions 和 deletions
    final Map&amp;lt;StaticBuffer, KCVEntryMutation&amp;gt; storeMutation = mutations.computeIfAbsent(store, k -&amp;gt; new HashMap&amp;lt;&amp;gt;());
    KCVEntryMutation existingM = storeMutation.get(key);
    
    if (existingM != null) {
        existingM.merge(m);
    } else {
        storeMutation.put(key, m);
    }

    numMutations += m.getTotalMutations();

    if (batchLoading &amp;amp;&amp;amp; numMutations &amp;gt;= persistChunkSize) {
        flushInternal();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mutate-方法参数来源&#34;&gt;mutate 方法参数来源&lt;/h2&gt;

&lt;p&gt;mutate 方法传入的是 store（包含了columnFamily） key（rowKey） additions 和 deletions，这几个参数哪里来的呢？ KCVSCache 的 mutateEntries，
mutateEdges 调用时机呢？ edgeStore.mutateEntries(key, additions, deletions, storeTx); indexStore.mutateEntries(key, additions, deletions, storeTx);
我们先以 edgeStore 为例，在 StandardJanusGraph 的 prepareCommit 方法中，调用了 mutator.mutateEdges(vertexKey, additions, deletions);
代码如下，我们删掉了部分代码，包括 索引和数据删除。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ListMultimap&amp;lt;Long, InternalRelation&amp;gt; mutations = ArrayListMultimap.create();
ListMultimap&amp;lt;InternalVertex, InternalRelation&amp;gt; mutatedProperties = ArrayListMultimap.create();
List&amp;lt;IndexSerializer.IndexUpdate&amp;gt; indexUpdates = Lists.newArrayList();


//2) Collect added edges and their index updates and acquire edge locks
// add 是 InternalRelation ，包括 VertexProperty 和 Edge，前面分析过，VertexProperty 实际上就是顶点和一个 schema 的订单建一条边，Edge 就是两个顶点建一条边。
for (InternalRelation add : Iterables.filter(addedRelations,filter)) {
    Preconditions.checkArgument(add.isNew());
    
    // getLen 返回这个 Relation 的长度，如果是 VertexProperty 是1，Edge 是需要根据方向进行判断
    for (int pos = 0; pos &amp;lt; add.getLen(); pos++) {
        // 得到对应的 vertex 
        InternalVertex vertex = add.getVertex(pos);
        if (pos == 0 || !add.isLoop()) {
        
            // mutatedProperties 的 key: InternalVertex,value:InternalRelation,mutatedProperties 是用于更新索引的，在我们这里实际上没什么用。
            if (add.isProperty()) mutatedProperties.put(vertex,add);
            // mutations 的 key ： vertexId, value ： InternalRelation
            mutations.put(vertex.longId(), add);
        }
        if (!vertex.isNew() &amp;amp;&amp;amp; acquireLock(add,pos,acquireLocks)) {
            Entry entry = edgeSerializer.writeRelation(add, pos, tx);
            mutator.acquireEdgeLock(idManager.getKey(vertex.longId()), entry.getColumn());
        }
    }
}


//5) Add relation mutations
for (Long vertexId : mutations.keySet()) {
    Preconditions.checkArgument(vertexId &amp;gt; 0, &amp;quot;Vertex has no id: %s&amp;quot;, vertexId);
    final List&amp;lt;InternalRelation&amp;gt; edges = mutations.get(vertexId);
    final List&amp;lt;Entry&amp;gt; additions = new ArrayList&amp;lt;&amp;gt;(edges.size());
    final List&amp;lt;Entry&amp;gt; deletions = new ArrayList&amp;lt;&amp;gt;(Math.max(10, edges.size() / 10));
    for (final InternalRelation edge : edges) {
        // 得到 InternalRelationType ，分为 PropertyKey 和 EdgeLabel 两类
        final InternalRelationType baseType = (InternalRelationType) edge.getType();
        assert baseType.getBaseType()==null;

        for (InternalRelationType type : baseType.getRelationIndexes()) { 
            if (type.getStatus()== SchemaStatus.DISABLED) continue;
            // getArity 和 getLen 不一样，
            for (int pos = 0; pos &amp;lt; edge.getArity(); pos++) {
                if (!type.isUnidirected(Direction.BOTH) &amp;amp;&amp;amp; !type.isUnidirected(EdgeDirection.fromPosition(pos)))
                    continue; //Directionality is not covered
                
                // 如果是起始顶点
                if (edge.getVertex(pos).longId()==vertexId) {
                
                    // 根据 edge type pos tx 得到应该序列化的 StaticArrayEntry
                    StaticArrayEntry entry = edgeSerializer.writeRelation(edge, type, pos, tx);
                    if (edge.isRemoved()) {
                        deletions.add(entry);
                    } else {
                        Preconditions.checkArgument(edge.isNew());
                        int ttl = getTTL(edge);
                        if (ttl &amp;gt; 0) {
                            entry.setMetaData(EntryMetaData.TTL, ttl);
                        }
                        additions.add(entry);
                    }
                }
            }
        }
    }

    StaticBuffer vertexKey = idManager.getKey(vertexId);
    mutator.mutateEdges(vertexKey, additions, deletions);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;edgeserializer-writerelation-到底做了什么&#34;&gt;edgeSerializer.writeRelation 到底做了什么&lt;/h2&gt;

&lt;p&gt;我们现在就想知道，数据是怎么被序列化话 entry 的，代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public StaticArrayEntry writeRelation(InternalRelation relation, InternalRelationType type, int position,
                                      TypeInspector tx) {
    assert type==relation.getType() || (type.getBaseType() != null
            &amp;amp;&amp;amp; type.getBaseType().equals(relation.getType()));
    // 得到方向，pos 是 0 就是 out，是 1 就是 in
    Direction dir = EdgeDirection.fromPosition(position);
    
    // 方向验证
    Preconditions.checkArgument(type.isUnidirected(Direction.BOTH) || type.isUnidirected(dir));
    
    // 得到 typeId， 这个 type 是 VertexLabel 或者 PropertyKey
    long typeId = type.longId();
    // 得到 dirID 
    DirectionID dirID = getDirID(dir, relation.isProperty() ? RelationCategory.PROPERTY : RelationCategory.EDGE);
    
    // 得到 一个 out
    DataOutput out = serializer.getDataOutput(DEFAULT_CAPACITY);
    // key 和 value 的分割地址。
    int valuePosition;
    
    // 写 typeId 和 dirID 
    IDHandler.writeRelationType(out, typeId, dirID, type.isInvisibleType());
    
    // 得到 multiplicity 和 sortKey
    Multiplicity multiplicity = type.multiplicity();
    long[] sortKey = type.getSortKey();
    
    assert !multiplicity.isConstrained() || sortKey.length==0: type.name();
    int keyStartPos = out.getPosition();
    if (!multiplicity.isConstrained()) {
        // 如果 multiplicity 是 没有限制，也就是为 MULTI，必须要有 sortKey，写出 sortKey。
        writeInlineTypes(sortKey, relation, out, tx, InlineType.KEY);
    }
    
    // 到这里 key 就写完了，得到 key 的 pos
    int keyEndPos = out.getPosition();

    long relationId = relation.longId();

    //How multiplicity is handled for edges and properties is slightly different
    if (relation.isEdge()) {
        // 得到另一个 vertex 的 id
        long otherVertexId = relation.getVertex((position + 1) % 2).longId();
        // 如果 multiplicity 有限制
        if (multiplicity.isConstrained()) {
            // isUnique
            if (multiplicity.isUnique(dir)) {
                // 得到 valuePosition ，写出 otherVertexId 
                valuePosition = out.getPosition();
                VariableLong.writePositive(out, otherVertexId);
            } else {
                // 反方向写 otherVertexId ,记下 valuePosition
                VariableLong.writePositiveBackward(out, otherVertexId);
                valuePosition = out.getPosition();
            }
            // 写下 relationId
            VariableLong.writePositive(out, relationId);
        } else {
            // 没有限制，反方向写出 otherVertexId 和 relationId ，记下 valuePosition
            VariableLong.writePositiveBackward(out, otherVertexId);
            VariableLong.writePositiveBackward(out, relationId);
            valuePosition = out.getPosition();
        }
    } else { // PropertyKey
        assert relation.isProperty();
        Preconditions.checkArgument(relation.isProperty());
        // 得到 property 的值。
        Object value = ((JanusGraphVertexProperty) relation).value();
        Preconditions.checkNotNull(value);
        PropertyKey key = (PropertyKey) type;
        assert key.dataType().isInstance(value);
        
        // 写出 value 得到 valuePosition
        if (multiplicity.isConstrained()) { // 没有限制的 property
            if (multiplicity.isUnique(dir)) { //Cardinality=SINGLE
                valuePosition = out.getPosition();
                writePropertyValue(out,key,value);
            } else { //Cardinality=SET
                writePropertyValue(out,key,value);
                valuePosition = out.getPosition();
            }
            VariableLong.writePositive(out, relationId);
        } else {
            assert multiplicity.getCardinality()== Cardinality.LIST;
            VariableLong.writePositiveBackward(out, relationId);
            valuePosition = out.getPosition();
            writePropertyValue(out,key,value);
        }
    }

    //Write signature
    long[] signature = type.getSignature();
    writeInlineTypes(signature, relation, out, tx, InlineType.SIGNATURE);

    //Write remaining properties
    LongSet writtenTypes = new LongHashSet(sortKey.length + signature.length);
    if (sortKey.length &amp;gt; 0 || signature.length &amp;gt; 0) {
        for (long id : sortKey) writtenTypes.add(id);
        for (long id : signature) writtenTypes.add(id);
    }
    LongArrayList remainingTypes = new LongArrayList(8);
    for (PropertyKey t : relation.getPropertyKeysDirect()) {
        if (!(t instanceof ImplicitKey) &amp;amp;&amp;amp; !writtenTypes.contains(t.longId())) {
            remainingTypes.add(t.longId());
        }
    }
    //Sort types before writing to ensure that value is always written the same way
    long[] remaining = remainingTypes.toArray();
    Arrays.sort(remaining);
    for (long tid : remaining) {
        PropertyKey t = tx.getExistingPropertyKey(tid);
        writeInline(out, t, relation.getValueDirect(t), InlineType.NORMAL);
    }
    assert valuePosition&amp;gt;0;

    return new StaticArrayEntry(type.getSortOrder() == Order.DESC ?
                                out.getStaticBufferFlipBytes(keyStartPos, keyEndPos) :
                                out.getStaticBuffer(), valuePosition);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实就是不断吧值写进去并且记录一下值的位置。&lt;/p&gt;

&lt;p&gt;我们需要了解一下 writeInline 方法以及  StaticArrayEntry VariableLong 类。&lt;/p&gt;

&lt;h3 id=&#34;staticarrayentry&#34;&gt;StaticArrayEntry&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Entry (org.janusgraph.diskstorage)
BaseStaticArrayEntry (org.janusgraph.diskstorage.util)
StaticEntry in StaticArrayEntryList (org.janusgraph.diskstorage.util)
StaticArrayEntry (org.janusgraph.diskstorage.util)
SwappingEntry in StaticArrayEntryList (org.janusgraph.diskstorage.util)
StaticArrayEntry (org.janusgraph.diskstorage.util)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Entry 代表存储在 cassandra 基本结构，有 getColumn getValuePosition getValue 等方法，
BaseStaticArrayEntry 则是利用一个 array,offset,limit,valuePosition 进行封装。&lt;/p&gt;

&lt;h3 id=&#34;variablelong&#34;&gt;VariableLong&lt;/h3&gt;

&lt;p&gt;这个提供了一个读写Long类型的数据的方法，具体后续研究。&lt;/p&gt;

&lt;h3 id=&#34;writeinline&#34;&gt;writeInline&lt;/h3&gt;

&lt;p&gt;writeInline 方法实现：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void writeInlineTypes(long[] keyIds, InternalRelation relation, DataOutput out, TypeInspector tx,
                              InlineType inlineType) {
    for (long keyId : keyIds) {
        PropertyKey t = tx.getExistingPropertyKey(keyId);
        writeInline(out, t, relation.getValueDirect(t), inlineType);
    }
}

private void writeInline(DataOutput out, PropertyKey inlineKey, Object value, InlineType inlineType) {
    assert inlineType.writeInlineKey() || !AttributeUtil.hasGenericDataType(inlineKey);

    if (inlineType.writeInlineKey()) {
        IDHandler.writeInlineRelationType(out, inlineKey.longId());
    }

    writePropertyValue(out,inlineKey,value, inlineType);
}

private void writePropertyValue(DataOutput out, PropertyKey key, Object value, InlineType inlineType) {
    if (AttributeUtil.hasGenericDataType(key)) {
        assert !inlineType.writeByteOrdered();
        out.writeClassAndObject(value);
    } else {
        assert value==null || value.getClass().equals(key.dataType());
        if (inlineType.writeByteOrdered()) out.writeObjectByteOrder(value, key.dataType());
        else out.writeObject(value, key.dataType());
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从代码我们可以看出，实际上都是对id进行的操作，所以如果知道了顶点的 id，给顶点添加边和属性，实际上不需要查询这个顶点，直接操作即可，所以这给我们导数据提供了一种思路，可以直接操作 id。&lt;/p&gt;

&lt;h2 id=&#34;writerelation-方法的参数怎么构造的&#34;&gt;writeRelation 方法的参数怎么构造的&lt;/h2&gt;

&lt;p&gt;从上面我们可以看出来 edgeSerializer.writeRelation 方法的参数是 (edge, type, pos, tx)，而 edge 来自于对 mutations 的处理，mutations 来自 add ,add 来自 addedRelations。&lt;/p&gt;

&lt;p&gt;addedRelations 进行 add 操作的步骤在 StandardJanusGraph 的 connectRelation(InternalRelation r) 方法中。connectRelation 方法有两处调用 addEdge 和 addProperty。&lt;/p&gt;

&lt;p&gt;addEdge 和 addProperty 的调用栈就比较多了。&lt;/p&gt;

&lt;h1 id=&#34;正向理清思路&#34;&gt;正向理清思路&lt;/h1&gt;

&lt;h2 id=&#34;1-janus-官网介绍&#34;&gt;1. janus 官网介绍&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.janusgraph.org/latest/schema.html&#34;&gt;https://docs.janusgraph.org/latest/schema.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;edge-label&#34;&gt;Edge Label&lt;/h3&gt;

&lt;p&gt;Multiplicity&lt;/p&gt;

&lt;p&gt;MULTI SIMPLE MANY2ONE ONE2MANY ONE2ONE 五种，每种的意义可以参考官网。默认的是 MULTI&lt;/p&gt;

&lt;h3 id=&#34;property-keys&#34;&gt;Property Keys&lt;/h3&gt;

&lt;p&gt;dataType(Class) 确定数据类型，Object.class 能够传入任何参数，但是不鼓励。&lt;/p&gt;

&lt;p&gt;Property Key Cardinality&lt;/p&gt;

&lt;p&gt;SINGLE: Allows at most one value per element for such key. In other words, the key→value mapping is unique for all elements in the graph. The property key birthDate is an example with SINGLE cardinality since each person has exactly one birth date.
LIST: Allows an arbitrary number of values per element for such key. In other words, the key is associated with a list of values allowing duplicate values. Assuming we model sensors as vertices in a graph, the property key sensorReading is an example with LIST cardinality to allow lots of (potentially duplicate) sensor readings to be recorded.
SET: Allows multiple values but no duplicate values per element for such key. In other words, the key is associated with a set of values. The property key name has SET cardinality if we want to capture all names of an individual (including nick name, maiden name, etc).&lt;/p&gt;

&lt;h3 id=&#34;relation-types&#34;&gt;Relation Types&lt;/h3&gt;

&lt;p&gt;Edge labels and property keys are jointly referred to as relation types ,must unique&lt;/p&gt;

&lt;h3 id=&#34;vertex-labels&#34;&gt;Vertex Labels&lt;/h3&gt;

&lt;p&gt;call makeVertexLabel(String).make()&lt;/p&gt;

&lt;h3 id=&#34;unidirected-edges&#34;&gt;Unidirected Edges&lt;/h3&gt;

&lt;p&gt;单向的边是只能在向外方向上遍历的边。单指向边具有较低的存储占用，但在它们支持的遍历类型中受到限制。单向的边在概念上类似于万维网中的超链接，在这个意义上，外顶点可以遍历边缘，但是顶点不知道它的存在。&lt;/p&gt;

&lt;h2 id=&#34;2-addproperty-和-addedge&#34;&gt;2. addProperty 和 addEdge&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public JanusGraphVertexProperty addProperty(VertexProperty.Cardinality cardinality, JanusGraphVertex vertex, PropertyKey key, Object value) {
    if (key.cardinality().convert()!=cardinality &amp;amp;&amp;amp; cardinality!=VertexProperty.Cardinality.single)
        throw new SchemaViolationException(&amp;quot;Key is defined for %s cardinality which conflicts with specified: %s&amp;quot;,key.cardinality(),cardinality);
    verifyWriteAccess(vertex);
    Preconditions.checkArgument(!(key instanceof ImplicitKey),&amp;quot;Cannot create a property of implicit type: %s&amp;quot;,key.name());
    vertex = ((InternalVertex) vertex).it();
    Preconditions.checkNotNull(key);
    checkPropertyConstraintForVertexOrCreatePropertyConstraint(vertex, key);
    final Object normalizedValue = verifyAttribute(key, value);
    
    // 得到 Cardinality SINGLE LIST SET ，一般是 SINGLE
    Cardinality keyCardinality = key.cardinality();
    
    // 省略部分代码
    try {
          // 省略检查
          
        StandardVertexProperty prop = new StandardVertexProperty(IDManager.getTemporaryRelationID(temporaryIds.nextID()), key, (InternalVertex) vertex, normalizedValue, ElementLifeCycle.New);
        if (config.hasAssignIDsImmediately()) graph.assignID(prop);
        connectRelation(prop);
        return prop;
    } finally {
        uniqueLock.unlock();
    }

}

public JanusGraphEdge addEdge(JanusGraphVertex outVertex, JanusGraphVertex inVertex, EdgeLabel label) {
    verifyWriteAccess(outVertex, inVertex);
    outVertex = ((InternalVertex) outVertex).it();
    inVertex = ((InternalVertex) inVertex).it();
    Preconditions.checkNotNull(label);
    checkConnectionConstraintOrCreateConnectionConstraint(outVertex, inVertex, label);
    Multiplicity multiplicity = label.multiplicity();
    TransactionLock uniqueLock = getUniquenessLock(outVertex, (InternalRelationType) label,inVertex);
    uniqueLock.lock(LOCK_TIMEOUT);
    try {
     // 省略检查
        StandardEdge edge = new StandardEdge(IDManager.getTemporaryRelationID(temporaryIds.nextID()), label, (InternalVertex) outVertex, (InternalVertex) inVertex, ElementLifeCycle.New);
        if (config.hasAssignIDsImmediately()) graph.assignID(edge);
        connectRelation(edge);
        return edge;
    } finally {
        uniqueLock.unlock();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实这两个做的最主要的就两步： new StandardEdge new StandardVertexProperty  connectRelation(edge);&lt;/p&gt;

&lt;p&gt;connectRelation 最主要的就是 addedRelations.add&amp;reg;&lt;/p&gt;

&lt;p&gt;最后在 commit 的时候，会 处理  addedRelations，代码逻辑在上面我们已经看过了。我们在简化一下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (InternalRelation add : Iterables.filter(addedRelations,filter)) {
    Preconditions.checkArgument(add.isNew());

    for (int pos = 0; pos &amp;lt; add.getLen(); pos++) {
        InternalVertex vertex = add.getVertex(pos);
        if (pos == 0 || !add.isLoop()) {
            // 添加 mutations
            mutations.put(vertex.longId(), add);
        }
    }
}

// 
for (Long vertexId : mutations.keySet()) {

    final List&amp;lt;InternalRelation&amp;gt; edges = mutations.get(vertexId);
    final List&amp;lt;Entry&amp;gt; additions = new ArrayList&amp;lt;&amp;gt;(edges.size());
    final List&amp;lt;Entry&amp;gt; deletions = new ArrayList&amp;lt;&amp;gt;(Math.max(10, edges.size() / 10));
    
    for (final InternalRelation edge : edges) {
        final InternalRelationType baseType = (InternalRelationType) edge.getType();
        assert baseType.getBaseType()==null;

        for (InternalRelationType type : baseType.getRelationIndexes()) { // getRelationIndexes 这里是得到了 RelationTypeIndex 相关的 关系
            if (type.getStatus()== SchemaStatus.DISABLED) continue;
            for (int pos = 0; pos &amp;lt; edge.getArity(); pos++) {
                if (!type.isUnidirected(Direction.BOTH) &amp;amp;&amp;amp; !type.isUnidirected(EdgeDirection.fromPosition(pos)))
                    continue; //Directionality is not covered
                if (edge.getVertex(pos).longId()==vertexId) {
                    StaticArrayEntry entry = edgeSerializer.writeRelation(edge, type, pos, tx);
                    if (edge.isRemoved()) {
                        deletions.add(entry);
                    } else {
                        Preconditions.checkArgument(edge.isNew());
                        int ttl = getTTL(edge);
                        if (ttl &amp;gt; 0) {
                            entry.setMetaData(EntryMetaData.TTL, ttl);
                        }
                        additions.add(entry);
                    }
                }
            }
        }
    }

    StaticBuffer vertexKey = idManager.getKey(vertexId);
    mutator.mutateEdges(vertexKey, additions, deletions);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mutateedges&#34;&gt;mutateEdges&lt;/h2&gt;

&lt;p&gt;会逐步调用
edgeStore.mutateEntries(key, additions, deletions, storeTx);
mutateEntries(StaticBuffer key, List&lt;Entry&gt; additions, List&lt;Entry&gt; deletions, StoreTransaction txh)
mutate&lt;/p&gt;

&lt;p&gt;mutate 会将改变都记录到 mutations 中，在 flushInternal 的时候 mutations 会变换一下记录到 subMutations ，然后调用 persist(subMutations);
紧接着调用 manager.mutateMany(subMutations, tx); 最后重构成 cfmutation，通过 cassandra 的 CTConnection 保存到 cassandra 中。&lt;/p&gt;

&lt;p&gt;这样看来，整个过程就清晰了。&lt;/p&gt;

&lt;h2 id=&#34;id-分配&#34;&gt;id 分配&lt;/h2&gt;

&lt;p&gt;StandardIDPool 进行 id 的分配，调用 graph.assignID(schemaVertex, BaseVertexLabel.DEFAULT_VERTEXLABEL) 等方法的时候，会调用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;assignID:455, StandardJanusGraph (org.janusgraph.graphdb.database)
assignID:153, VertexIDAssigner (org.janusgraph.graphdb.database.idassigner)
assignID:182, VertexIDAssigner (org.janusgraph.graphdb.database.idassigner)
assignID:308, VertexIDAssigner (org.janusgraph.graphdb.database.idassigner)
nextID:204, StandardIDPool (org.janusgraph.graphdb.database.idassigner)
nextBlock:173, StandardIDPool (org.janusgraph.graphdb.database.idassigner)
startIDBlockGetter:247, StandardIDPool (org.janusgraph.graphdb.database.idassigner)

call:288, StandardIDPool$IDBlockGetter (org.janusgraph.graphdb.database.idassigner)
getIDBlock:213, ConsistentKeyIDAuthority (org.janusgraph.diskstorage.idmanagement)
    getBlockApplication:373, ConsistentKeyIDAuthority (org.janusgraph.diskstorage.idmanagement)
idStore.mutate(partitionKey, Arrays.asList(StaticArrayEntry.of(finalTarget)), KeyColumnValueStore.NO_DELETIONS, txh);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里涉及到了很多东西，而且是在两个线程中完成的，就不太方便处理了。&lt;/p&gt;

&lt;h3 id=&#34;vertexidassigner&#34;&gt;VertexIDAssigner&lt;/h3&gt;

&lt;p&gt;首先是 VertexIDAssigner 的创建：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public VertexIDAssigner(Configuration config, IDAuthority idAuthority, StoreFeatures idAuthFeatures) {
    Preconditions.checkNotNull(idAuthority);
    this.idAuthority = idAuthority;

    int partitionBits = NumberUtil.getPowerOf2(config.get(CLUSTER_MAX_PARTITIONS));
    idManager = new IDManager(partitionBits);
    Preconditions.checkArgument(idManager.getPartitionBound() &amp;lt;= Integer.MAX_VALUE &amp;amp;&amp;amp; idManager.getPartitionBound()&amp;gt;0);
    this.partitionIdBound = (int)idManager.getPartitionBound();
    hasLocalPartitions = idAuthFeatures.hasLocalKeyPartition();

    placementStrategy = Backend.getImplementationClass(config, config.get(PLACEMENT_STRATEGY),
            REGISTERED_PLACEMENT_STRATEGIES);
    placementStrategy.injectIDManager(idManager);
    log.debug(&amp;quot;Partition IDs? [{}], Local Partitions? [{}]&amp;quot;,true,hasLocalPartitions);

    long baseBlockSize = config.get(IDS_BLOCK_SIZE);
    idAuthority.setIDBlockSizer(new SimpleVertexIDBlockSizer(baseBlockSize));

    renewTimeoutMS = config.get(IDS_RENEW_TIMEOUT);
    renewBufferPercentage = config.get(IDS_RENEW_BUFFER_PERCENTAGE);

    idPools = new ConcurrentHashMap&amp;lt;Integer, PartitionIDPool&amp;gt;(partitionIdBound);
    schemaIdPool = new StandardIDPool(idAuthority, IDManager.SCHEMA_PARTITION, PoolType.SCHEMA.getIDNamespace(),
            IDManager.getSchemaCountBound(), renewTimeoutMS, renewBufferPercentage);
    partitionVertexIdPool = new StandardIDPool(idAuthority, IDManager.PARTITIONED_VERTEX_PARTITION, PoolType.PARTITIONED_VERTEX.getIDNamespace(),
            PoolType.PARTITIONED_VERTEX.getCountBound(idManager), renewTimeoutMS, renewBufferPercentage);
    setLocalPartitions(partitionBits);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;里面主要有 idAuthority , idManager(partitionBits=5) partitionIdBound=32  placementStrategy idPools schemaIdPool partitionVertexIdPool .&lt;/p&gt;

&lt;h4 id=&#34;assignid&#34;&gt;assignID&lt;/h4&gt;

&lt;p&gt;id 有三个部分组成 [0 count suffix partitionId],count，最高位是0，然后是后缀。后缀在 IDManager 中有配置,partitionId 默认是5位.
第一部是 得到 partitionID ，分为很多种情况，例如 schema 为0，分区的为 -1，vertex 的为 placementStrategy 随机获得。例如8， Relation 通过 incident 获得。&lt;/p&gt;

&lt;p&gt;然后才是 assignID
先得到 count ，得到过程是：
通过 partition 在 idPools 得到 PartitionIDPool，如果没有，新建 PartitionIDPool ，然后在每个 PartitionIDPool 中新建 3个 StandardIDPool ，分别对应 NORMAL_VERTEX, UNMODIFIABLE_VERTEX, RELATION;
在 PartitionIDPool 中得到现在的 element 所对应的 idPool，然后调用 count = idPool.nextID()  得到count ,nextID 会调用 currentBlock 得到 id。如果当前的 currentBlock 分配完了，重新申请一个 block&lt;/p&gt;

&lt;p&gt;调用 getId 方法的时候，会有一个 uniqueIDBitWidth ，默认是 4位，然后还有一个 unique 数值是0，最后返回的是得到的count 左右4位，如果是1，就是16.
返回了 count，然后构造的 结果就是 00000 0 000010000000&lt;/p&gt;

&lt;h3 id=&#34;standardidpool&#34;&gt;StandardIDPool&lt;/h3&gt;

&lt;p&gt;构造传入了：idAuthority partition idNamespace idUpperBound renewBufferPercentage
还有一个 exec ，用来执行线程。
还有 currentBlock currentIndex renewBlockIndex 记录当前的状态。&lt;/p&gt;

&lt;p&gt;###&lt;/p&gt;

&lt;p&gt;我们从 assignID 开始看。分为两步：&lt;/p&gt;

&lt;p&gt;partitionID = placementStrategy.getPartition(element);&lt;/p&gt;

&lt;h2 id=&#34;调试一次&#34;&gt;调试一次&lt;/h2&gt;

&lt;p&gt;接下来我们可以调试一次，通过调试过每一步，熟悉每一步的内容。&lt;/p&gt;

&lt;h1 id=&#34;bulk-loading&#34;&gt;bulk loading&lt;/h1&gt;

&lt;p&gt;接下来我们要做一个导数据的工具。我们有一堆给定好的书籍，然后我们能够将数据导入到 janus 中，我们需要结合 cassandra 和 hbase 自带的 bulk loading 工具。
首先我们需要得到所有的序列化的数据，实际上就是 edge 数据，而 index 的数据我们可以后续调用 reindex。&lt;/p&gt;

&lt;h2 id=&#34;vertex-导入&#34;&gt;vertex 导入&lt;/h2&gt;

&lt;p&gt;我们可以想象一下，导入边的流程，首先要有一个表格，并且这个表格要带有表头，然后下面的就是数据。表头包括字段名和数据类型，其中第一个是主键。例如有电话的数据，表头结构为：
phone:string,name:string,relation:integer&lt;/p&gt;

&lt;p&gt;我们程序首先是验证数据，验证数据主要是重复性检验，格式检验。然后需要创建 schema。读取所有的表头，并创建好 schema。然后导入数据。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析8-索引存储</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%908-%E7%B4%A2%E5%BC%95%E5%AD%98%E5%82%A8/</link>
      <pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%908-%E7%B4%A2%E5%BC%95%E5%AD%98%E5%82%A8/</guid>
      
        <description>

&lt;p&gt;上一节我们了解了 JanusGraph 的关系存储，主要是在 EdgeSerializer 中的序列化和反序列化，我们还要这次看看 IndexSerializer 的相关类。&lt;/p&gt;

&lt;h1 id=&#34;基础类&#34;&gt;基础类&lt;/h1&gt;

&lt;h2 id=&#34;internalrelation-和-internalrelationtype&#34;&gt;InternalRelation 和 InternalRelationType&lt;/h2&gt;

&lt;p&gt;##&lt;/p&gt;

&lt;h2 id=&#34;relationcache&#34;&gt;RelationCache&lt;/h2&gt;

&lt;h2 id=&#34;staticarrayentry&#34;&gt;StaticArrayEntry&lt;/h2&gt;

&lt;p&gt;类似 java.nio 的 ByteBuffer。&lt;/p&gt;

&lt;h1 id=&#34;edgeserializer&#34;&gt;EdgeSerializer&lt;/h1&gt;

&lt;h2 id=&#34;writerelation&#34;&gt;writeRelation&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph主要类分析</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%905-%E4%B8%BB%E8%A6%81%E7%B1%BB/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%905-%E4%B8%BB%E8%A6%81%E7%B1%BB/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>resourcemanager</title>
      <link>https://dengziming.github.io/post/hadoop/hadoopha/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/hadoopha/</guid>
      
        <description>

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;h1 id=&#34;hadoopha&#34;&gt;HadoopHa&lt;/h1&gt;

&lt;p&gt;hadoop 有两个NameNode，Active NameNode和Standby NameNode，通过 DFSZKFailoverController extends ZKFailoverController 进行切换。
ZKFailoverController通过HealthMonitor线程能及时检测到NameNode的健康状况，在主NameNode故障时借助Zookeeper实现自动的主备选举和切换。
DataNode 会同时向主NameNode和备NameNode上报数据块的位置信息，但只接收来自active namenode的读写命令。&lt;/p&gt;

&lt;p&gt;为啥把监控分开?&lt;/p&gt;

&lt;p&gt;显然，我们不能在NN进程内进行心跳等信息同步，最简单的原因，一次FullGC就可以让NN挂起十几分钟，所以，必须要有一个独立的短小精悍的watchdog来专门负责监控。这也是一个松耦合的设计，便于扩展或更改。&lt;/p&gt;

&lt;p&gt;通过隔离和Quorum Journal Manager(QJM)共享存储空间实现HDFS HA&lt;/p&gt;

&lt;h1 id=&#34;dfszkfailovercontroller&#34;&gt;DFSZKFailoverController&lt;/h1&gt;

&lt;p&gt;启动代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  public static void main(String args[])
      throws Exception {
    if (DFSUtil.parseHelpArgument(args, 
        ZKFailoverController.USAGE, System.out, true)) {
      System.exit(0);
    }
    
    GenericOptionsParser parser = new GenericOptionsParser(
        new HdfsConfiguration(), args);
    DFSZKFailoverController zkfc = DFSZKFailoverController.create(
        parser.getConfiguration());
    {
        NNHAServiceTarget localTarget = new NNHAServiceTarget(
        localNNConf, nsId, nnId);
        return new DFSZKFailoverController(localNNConf, localTarget);
    }
    
    System.exit(zkfc.run(parser.getRemainingArgs()));
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;run 的步骤：
initZK();
formatZK(force, interactive);
initRPC();
initHM();
startRPC();
mainLoop();&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;initZK();
{
    elector = new ActiveStandbyElector(zkQuorum,
        zkTimeout, getParentZnode(), zkAcls, zkAuths,
        new ElectorCallbacks(), maxRetryNum);
    {
    	new ElectorCallbacks()
    	  // 临时节点ActiveStandbyElectorLock，用于标识锁
    	zkLockFilePath = znodeWorkingDir + &amp;quot;/&amp;quot; + LOCK_FILENAME;
    	// 永久节点ActiveBreadCrumb，用于存放active信息
    	zkBreadCrumbPath = znodeWorkingDir + &amp;quot;/&amp;quot; + BREADCRUMB_FILENAME;
    	this.maxRetryNum = maxRetryNum;
    	// createConnection for future API calls
    	// 创建zk连接
    	createConnection();
    	{
    	      // 不幸的是，zk的构造方法连接上zk之后，可能马上触发连接事件。
  			  // 因此如果构造zk之后注册watcher，可能不会捕获到连接事件。
  			  // 取而代之的方法是，先构造Watcher，在设置了zk的引用之前，使它阻塞所有的事件
  			  
  			  watcher = new WatcherWithClientRef();
  			  ZooKeeper zk = new ZooKeeper(zkHostPort, zkSessionTimeout, watcher);
  			  // 在watcher中设置zk的引用
  			  watcher.setZooKeeperRef(zk);
  			  // Wait for the asynchronous success/failure. This may throw an exception
  			  // if we don&#39;t connect within the session timeout.
  			  watcher.waitForZKConnectionEvent(zkSessionTimeout);
  			  
  			  for (ZKAuthInfo auth : zkAuthInfo) {
  			    zk.addAuthInfo(auth.getScheme(), auth.getAuth());
  			  }
  			  return zk;
    	      }
    	  }
    	}
}

formatZK(force, interactive);
initRPC();
{
    new ZKFCRpcServer(conf, bindAddr, this, getPolicyProvider());
    {
          this.zkfc = zkfc;
  			// 使用protocol buffer序列化
  			RPC.setProtocolEngine(conf, ZKFCProtocolPB.class,
  			    ProtobufRpcEngine.class);
  			ZKFCProtocolServerSideTranslatorPB translator =
  			    new ZKFCProtocolServerSideTranslatorPB(this);
  			BlockingService service = ZKFCProtocolService
  			    .newReflectiveBlockingService(translator);
  			// 使用hadoop rpc接口得到rpc server
  			// ZKFCProtocol是rpc协议，service是rpc协议的实现类
  			// ZKFCProtocolPB是protobuf rpc接口的一个过渡类
  			this.server = new RPC.Builder(conf).setProtocol(ZKFCProtocolPB.class)
  			    .setInstance(service).setBindAddress(bindAddr.getHostName())
  			    .setPort(bindAddr.getPort()).setNumHandlers(HANDLER_COUNT)
  			    .setVerbose(false).build();
    }
}
initHM();
startRPC();
mainLoop();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;WatcherWithClientRef 在构造zk时被注册为默认watcher，主要监听连接或者断开事件。当调用initZk之后，watcher.process会对事件进行处理，连接、断开、过期的状态类型都是EventType.None。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>yarn-api使用</title>
      <link>https://dengziming.github.io/post/hadoop/yarn-api%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/yarn-api%E4%BD%BF%E7%94%A8/</guid>
      
        <description>

&lt;p&gt;参考： &lt;a href=&#34;https://ieevee.com/tech/2015/05/05/yarn-dist-shell.html&#34;&gt;https://ieevee.com/tech/2015/05/05/yarn-dist-shell.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;distributeshell&#34;&gt;distributeshell&lt;/h1&gt;

&lt;h2 id=&#34;client解析&#34;&gt;Client解析&lt;/h2&gt;

&lt;p&gt;distShell主要有2个类组成，Client和ApplicationMaster。两个类都带有main入口。Client的主要工作是启动AM，真正要做的任务由AM来调度。 Client的简化框架如下。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args) {
    boolean result = false;
    try {
      Client client = new Client();  //1 创建Client对象
      try {
        boolean doRun = client.init(args);  //2 初始化
        if (!doRun) {
          System.exit(0);
        }
      }
      result = client.run();   //3 运行
    }
    if (result) {
      System.exit(0);
    }
    System.exit(2);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;1-创建client对象&#34;&gt;1 创建Client对象&lt;/h3&gt;

&lt;p&gt;创建时会指定本Client要用到的AM。 创建yarnClient。yarn将client与RM的交互抽象出了编程库YarnClient，用以应用程序提交、状态查询和控制等，简化应用程序。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  public Client(Configuration conf) throws Exception  {
    this(		//指定AM
      &amp;quot;org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster&amp;quot;,
      conf);
  Client(String appMasterMainClass, Configuration conf) {
    this.conf = conf;
    this.appMasterMainClass = appMasterMainClass;
    yarnClient = YarnClient.createYarnClient();		//创建yarnClient
    yarnClient.init(conf);
    opts = new Options();	//创建opts，后面解析参数的时候用
    opts.addOption(&amp;quot;appname&amp;quot;, true, &amp;quot;Application Name. Default value - DistributedShell&amp;quot;);
    opts.addOption(&amp;quot;priority&amp;quot;, true, &amp;quot;Application Priority. Default 0&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-初始化&#34;&gt;2 初始化&lt;/h3&gt;

&lt;p&gt;init会解析命令行传入的参数，例如使用的jar包、内存大小、cpu个数等。 代码里使用GnuParser解析：init时定义所有的参数opts（可以认为是一个模板），
然后将opts和实际的args传入解析后得到一个CommnadLine对象，后面查询选项直接操作该CommnadLine对象即可，如cliParser.hasOption(&amp;ldquo;help&amp;rdquo;)和cliParser.getOptionValue(&amp;ldquo;jar&amp;rdquo;)。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; public boolean init(String[] args) throws ParseException {
    CommandLine cliParser = new GnuParser().parse(opts, args);
    amMemory = Integer.parseInt(cliParser.getOptionValue(&amp;quot;master_memory&amp;quot;, &amp;quot;10&amp;quot;));
    amVCores = Integer.parseInt(cliParser.getOptionValue(&amp;quot;master_vcores&amp;quot;, &amp;quot;1&amp;quot;));
    shellCommand = cliParser.getOptionValue(&amp;quot;shell_command&amp;quot;);
    appMasterJar = cliParser.getOptionValue(&amp;quot;jar&amp;quot;);
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-运行&#34;&gt;3 运行&lt;/h3&gt;

&lt;p&gt;先启动yarnClient，会建立跟RM的RPC连接，之后就跟调用本地方法一样。通过此yarnClient查询NM个数、NM详细信息（ID/地址/Container个数等）、Queue info（其实没用到，示例里只是打印了下调试用）。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class Client {
  public boolean run() throws IOException, YarnException {
    yarnClient.start();
    YarnClusterMetrics clusterMetrics = yarnClient.getYarnClusterMetrics();
    List&amp;lt;NodeReport&amp;gt; clusterNodeReports = yarnClient.getNodeReports(
收集提交AM所需的信息。
    YarnClientApplication app = yarnClient.createApplication();	//创建app
    GetNewApplicationResponse appResponse = app.getNewApplicationResponse();
...
    ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();
    //AM需要的本地资源，如jar包、log文件
    Map&amp;lt;String, LocalResource&amp;gt; localResources = new HashMap&amp;lt;String, LocalResource&amp;gt;();

    FileSystem fs = FileSystem.get(conf);
    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),
        localResources, null);
    ...	//添加localResource

    vargs.add(Environment.JAVA_HOME.$$() + &amp;quot;/bin/java&amp;quot;);
    vargs.add(&amp;quot;-Xmx&amp;quot; + amMemory + &amp;quot;m&amp;quot;);
    vargs.add(appMasterMainClass);
...
    for (CharSequence str : vargs) {
      command.append(str).append(&amp;quot; &amp;quot;);	//重新组织命令行
    }
	//创建Container加载上下文，包含本地资源，环境变量，实际命令。
    ContainerLaunchContext amContainer = ContainerLaunchContext.newInstance(
      localResources, env, commands, null, null, null);

    Resource capability = Resource.newInstance(amMemory, amVCores);
    appContext.setResource(capability);		//请求使用的内存、cpu

    appContext.setAMContainerSpec(amContainer);
    appContext.setQueue(amQueue);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重新组织出来的commands如下：&lt;/p&gt;

&lt;p&gt;$JAVA_HOME/bin/java -Xmx10m org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster &amp;ndash;container_memory 10
提交AM（即appContext），并启动监控。 Client只关心自己提交到RM的AM是否正常运行，而AM内部的多个task，由AM管理。如果Client要查询应用程序的任务信息，需要自己设计与AM的交互。
    yarnClient.submitApplication(appContext);   //客户端提交AM到RM
    return monitorApplication(appId);
总的来说，Client做的事情比较简单，即建立与RM的连接，提交AM，监控AM运行状态。&lt;/p&gt;

&lt;p&gt;有个疑问，走读代码没有看到jar包是怎么送到NM上去的。&lt;/p&gt;

&lt;h2 id=&#34;application-master解析&#34;&gt;Application Master解析&lt;/h2&gt;

&lt;p&gt;AM简化框架如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;

      boolean doRun = appMaster.init(args);
      if (!doRun) {
        System.exit(0);
      }
      appMaster.run();
      result = appMaster.finish();
// yarn抽象了两个编程库，AMRMClient和NMClient(AM和RM都可以用)，简化AM编程。

// 1 设置RM、NM消息的异步处理方法
    AMRMClientAsync.CallbackHandler allocListener = new RMCallbackHandler();
    amRMClient = AMRMClientAsync.createAMRMClientAsync(1000, allocListener);
    amRMClient.init(conf);
    amRMClient.start();

    containerListener = createNMCallbackHandler();
    nmClientAsync = new NMClientAsyncImpl(containerListener);
    nmClientAsync.init(conf);
    nmClientAsync.start();
// 2 向RM注册
    RegisterApplicationMasterResponse response = amRMClient.registerApplicationMaster(appMasterHostname,
        appMasterRpcPort, appMasterTrackingUrl);
// 3 计算需要的Container，向RM发起请求
    // Setup ask for containers from RM
    // Send request for containers to RM
    // Until we get our fully allocated quota, we keep on polling RM for
    // containers
    // Keep looping until all the containers are launched and shell script
    // executed on them ( regardless of success/failure).
    for (int i = 0; i &amp;lt; numTotalContainersToRequest; ++i) {
      ContainerRequest containerAsk = setupContainerAskForRM();
      amRMClient.addContainerRequest(containerAsk);		//请求指定个数的Container
    }

  private ContainerRequest setupContainerAskForRM() {
    Resource capability = Resource.newInstance(containerMemory,
      containerVirtualCores);		//指定需要的memory/cpu能力
    ContainerRequest request = new ContainerRequest(capability, null, null,
        pri);


4 // RM分配Container给AM，AM启动任务RMCallbackHandler RM消息的响应，由RMCallbackHandler处理。示例中主要对前两种消息进行了处理。

  private class RMCallbackHandler implements AMRMClientAsync.CallbackHandler {
    //处理消息：Container执行完毕。在RM返回的心跳应答中携带。如果心跳应答中有已完成和新分配两种Container，先处理已完成
    public void onContainersCompleted(List&amp;lt;ContainerStatus&amp;gt; completedContainers) {
...
    //处理消息：RM新分配Container。在RM返回的心跳应答中携带
    public void onContainersAllocated(List&amp;lt;Container&amp;gt; allocatedContainers) {

    public void onShutdownRequest() {done = true;}

    //节点状态变化
    public void onNodesUpdated(List&amp;lt;NodeReport&amp;gt; updatedNodes) {}

    public float getProgress() {
onContainersAllocated收到分配的Container之后，会提交任务到NM。

    public void onContainersAllocated(List&amp;lt;Container&amp;gt; allocatedContainers) {
        LaunchContainerRunnable runnableLaunchContainer =   //创建runnable容器
            new LaunchContainerRunnable(allocatedContainer, containerListener);
        Thread launchThread = new Thread(runnableLaunchContainer);	//新建线程

        // launch and start the container on a separate thread to keep
        // the main thread unblocked
        // as all containers may not be allocated at one go.
        launchThreads.add(launchThread);
        launchThread.start();	//线程中提交Container到NM，不影响主流程

//简单分析下LaunchContainerRunnable。该类实现自Runnable，其run方法准备任务命令（本例即为date）。

  private class LaunchContainerRunnable implements Runnable {
    public LaunchContainerRunnable(
        Container lcontainer, NMCallbackHandler containerListener) {
      this.container = lcontainer;		//创建时记录待使用的Container
      this.containerListener = containerListener;
    }
    public void run() {
      vargs.add(shellCommand);		//待执行的shell命令
      vargs.add(shellArgs);			//shell命令参数
      List&amp;lt;String&amp;gt; commands = new ArrayList&amp;lt;String&amp;gt;();
      commands.add(command.toString());	//转为commands

      //根据命令、环境变量、本地资源等创建Container加载上下文
      ContainerLaunchContext ctx = ContainerLaunchContext.newInstance(
              localResources, shellEnv, commands, null, allTokens.duplicate(), null);
      containerListener.addContainer(container.getId(), container);
      //异步启动Container
      nmClientAsync.startContainerAsync(container, ctx);
// onContainersCompleted的功能比较简单，收到Container执行完毕的消息，检查其执行结果，如果执行失败，则重新发起请求，直到全部完成。

// NMCallbackHandler NM消息的响应，由NMCallbackHandler处理。

//在distShell示例里，回调句柄对NM通知过来的各种事件的处理比较简单，只是修改AM维护的Container执行完成、失败的个数。这样等到有Container执行完毕后，可以重启发起请求。失败处理和上面Container执行完毕消息的处理类似，达到了上面问题里所说的loopback效果。

  static class NMCallbackHandler
    implements NMClientAsync.CallbackHandler {

    @Override
    public void onContainerStopped(ContainerId containerId) {

    @Override
    public void onContainerStatusReceived(ContainerId containerId,

    @Override
    public void onContainerStarted(ContainerId containerId,
...
总的来说，AM做的事就是向RM/NM注册回调函数，然后请求Container；得到Container后提交任务，并跟踪这些任务的执行情况，如果失败了则重新提交，直到全部任务完成。
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;unmanagedam&#34;&gt;UnmanagedAM&lt;/h1&gt;

&lt;p&gt;distShell的Client提交AM到RM后，由RM将AM分配到某一个NM上的Container，这样给AM调试带来了困难。yarn提供了一个参数，Client可以设置为Unmanaged，提交AM后，会在客户端本地起一个单独的进程来运行AM。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class UnmanagedAMLauncher {
  public void launchAM(ApplicationAttemptId attemptId)
    //创建新进程
    Process amProc = Runtime.getRuntime().exec(amCmd, envAMList.toArray(envAM));
    try {
      int exitCode = amProc.waitFor();  //等待AM进程结束
    } finally {
      amCompleted = true;
    }

  public boolean run() throws IOException, YarnException {
      appContext.setUnmanagedAM(true);		//设置为Unmanaged
      rmClient.submitApplication(appContext);	//提交AM

      ApplicationReport appReport =		//监控AM状态，如果状态变为ACCEPTED，则跳出循环，launchAM。
          monitorApplication(appId, EnumSet.of(YarnApplicationState.ACCEPTED,
            YarnApplicationState.KILLED, YarnApplicationState.FAILED,
            YarnApplicationState.FINISHED));

      if (appReport.getYarnApplicationState() == YarnApplicationState.ACCEPTED) {
        launchAM(attemptId);
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>hdfs-client</title>
      <link>https://dengziming.github.io/post/hadoop/hdfs-client/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/hdfs-client/</guid>
      
        <description>

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;hadoop 技术内幕丛书&lt;/p&gt;

&lt;h1 id=&#34;写&#34;&gt;写&lt;/h1&gt;

&lt;h1 id=&#34;创建流&#34;&gt;创建流&lt;/h1&gt;

&lt;p&gt;简单写一个 demo 进行测试，通过打断点方法，另外发现一个问题， 在 dfsClient.namenode.create 打断点调试会报错，可能是因为动态代理卡主了 ：&lt;/p&gt;

&lt;p&gt;注意我们上传的文件 nio-data.txt 内容可以进行控制，例如我们写 600 个 a(97)，转换为 DataOutputStream 后的 byte[] 就是 600个97 ，这样调试就知道是哪个数据，600 a 是因为每个chunk的默认大小是 512&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void main(String[] args) throws IOException {

    FileSystem fs = FileSystem.get(new Configuration());
    
    Path src = new Path(&amp;quot;ideaspace/learn-jvm/src/main/resources/data/nio-data.txt&amp;quot;); //文件里面是一个 java 代码
    Path desc = new Path(&amp;quot;/tmp/&amp;quot;);
    if (fs.exists(desc)){
            fs.delete(desc,true);
        }

    fs.copyFromLocalFile(src,desc);

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过一系列的调用后进入的第一个关键方法是 ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
  public FSDataOutputStream create(final Path f, final FsPermission permission,
    final EnumSet&amp;lt;CreateFlag&amp;gt; cflags, final int bufferSize,
    final short replication, final long blockSize, final Progressable progress,
    final ChecksumOpt checksumOpt) throws IOException {
    statistics.incrementWriteOps(1);
    Path absF = fixRelativePart(f);
    return new FileSystemLinkResolver&amp;lt;FSDataOutputStream&amp;gt;() {
      @Override
      public FSDataOutputStream doCall(final Path p)
          throws IOException, UnresolvedLinkException {
        final DFSOutputStream dfsos = dfs.create(getPathName(p), permission,
                cflags, replication, blockSize, progress, bufferSize,
                checksumOpt);
        return dfs.createWrappedOutputStream(dfsos, statistics);
      }
      @Override
      public FSDataOutputStream next(final FileSystem fs, final Path p)
          throws IOException {
        return fs.create(p, permission, cflags, bufferSize,
            replication, blockSize, progress, checksumOpt);
      }
    }.resolve(this, absF);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;1-create&#34;&gt;1.create&lt;/h1&gt;

&lt;p&gt;首先是 create，然后是 dfs.createWrappedOutputStream(out, statistics);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public DFSOutputStream create(String src, 
                           FsPermission permission,
                           EnumSet&amp;lt;CreateFlag&amp;gt; flag, 
                           boolean createParent,
                           short replication,
                           long blockSize,
                           Progressable progress,
                           int buffersize,
                           ChecksumOpt checksumOpt,
                           InetSocketAddress[] favoredNodes) throws IOException {
  checkOpen();
  if (permission == null) {
    permission = FsPermission.getFileDefault();
  }
  FsPermission masked = permission.applyUMask(dfsClientConf.uMask);
  if(LOG.isDebugEnabled()) {
    LOG.debug(src + &amp;quot;: masked=&amp;quot; + masked);
  }
  String[] favoredNodeStrs = null;
  if (favoredNodes != null) {
    favoredNodeStrs = new String[favoredNodes.length];
    for (int i = 0; i &amp;lt; favoredNodes.length; i++) {
      favoredNodeStrs[i] = 
          favoredNodes[i].getHostName() + &amp;quot;:&amp;quot; 
                       + favoredNodes[i].getPort();
    }
  }
  final DFSOutputStream result = DFSOutputStream.newStreamForCreate(this,
      src, masked, flag, createParent, replication, blockSize, progress,
      buffersize, dfsClientConf.createChecksum(checksumOpt),
      favoredNodeStrs);
  beginFileLease(result.getFileId(), result);
  return result;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;两个方法比较关键：&lt;/p&gt;

&lt;p&gt;DFSOutputStream.newStreamForCreate 和 beginFileLease(result.getFileId(), result)&lt;/p&gt;

&lt;h2 id=&#34;1-newstreamforcreate-方法是第一次创建真正的-流-类是-dfsoutputstream&#34;&gt;1. newStreamForCreate 方法是第一次创建真正的 流，类是 DFSOutputStream&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static DFSOutputStream newStreamForCreate(DFSClient dfsClient, String src,
      FsPermission masked, EnumSet&amp;lt;CreateFlag&amp;gt; flag, boolean createParent,
      short replication, long blockSize, Progressable progress, int buffersize,
      DataChecksum checksum, String[] favoredNodes) throws IOException {
    ...
    while (shouldRetry) {
      shouldRetry = false;
      try {
        stat = dfsClient.namenode.create(src, masked, dfsClient.clientName,
            new EnumSetWritable&amp;lt;CreateFlag&amp;gt;(flag), createParent, replication,
            blockSize, SUPPORTED_CRYPTO_VERSIONS);
        break;
      } catch (RemoteException re) {...}
    Preconditions.checkNotNull(stat, &amp;quot;HdfsFileStatus should not be null!&amp;quot;);
    final DFSOutputStream out = new DFSOutputStream(dfsClient, src, stat,
        flag, progress, checksum, favoredNodes);
    out.start();
    return out;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;rpc
这部分没法调试，因为在远程。只能自己观看
通过 RPC 调用 NameNodeRpcServer.create -&amp;gt; namesystem.startFile -&amp;gt; startFileInt -&amp;gt; startFileInternal ，先跳过，&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;new DFSOutputStream(dfsClient, src, stat,flag, progress, checksum, favoredNodes);&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/** Construct a new output stream for creating a file. */
  private DFSOutputStream(DFSClient dfsClient, String src, HdfsFileStatus stat,
      EnumSet&amp;lt;CreateFlag&amp;gt; flag, Progressable progress,
      DataChecksum checksum, String[] favoredNodes) throws IOException {
    this(dfsClient, src, progress, stat, checksum);
    this.shouldSyncBlock = flag.contains(CreateFlag.SYNC_BLOCK);

    computePacketChunkSize(dfsClient.getConf().writePacketSize, bytesPerChecksum);

    Span traceSpan = null;
    if (Trace.isTracing()) {
      traceSpan = Trace.startSpan(this.getClass().getSimpleName()).detach();
    }
    streamer = new DataStreamer(stat, traceSpan);
    if (favoredNodes != null &amp;amp;&amp;amp; favoredNodes.length != 0) {
      streamer.setFavoredNodes(favoredNodes);
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;新建 DFSOutputStream 中有个重要的线程 DataStreamer，功能后续研究。
DFSOutputStream 中的成员变量我们可以好好看看，什么是 checksum，chunk，packet。另外它的父类 FSOutputSummer 也很重要。&lt;/p&gt;

&lt;h2 id=&#34;2-beginfilelease-这个可以暂时忽略-后面专门研究-lease&#34;&gt;2. beginFileLease 这个可以暂时忽略，后面专门研究 lease&lt;/h2&gt;

&lt;p&gt;dfs.createWrappedOutputStream(dfsos, statistics) 对上面创建的流就行一个 包装&lt;/p&gt;

&lt;p&gt;返回 return new HdfsDataOutputStream(dfsos, statistics, startPos);&lt;/p&gt;

&lt;p&gt;至此创建流的过程就完成了。我们大概回顾一下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;DistributedFileSystem.create(final Path f, final FsPermission permission,
final EnumSet&amp;lt;CreateFlag&amp;gt; cflags, final int bufferSize,
    final short replication, final long blockSize, final Progressable progress,
    final ChecksumOpt checksumOpt)
{
    // 1. 
    DFSOutputStream dfsos = DfsClient.create(getPathName(p), permission,
                cflags, replication, blockSize, progress, bufferSize,
                checksumOpt)
    {
        // 1. 
        DFSOutputStream.newStreamForCreate(this,
        	src, masked, flag, createParent, replication, blockSize, progress,
        	buffersize, dfsClientConf.createChecksum(checksumOpt),
        	favoredNodeStrs);
        {
            // 1.
            stat = dfsClient.namenode.create(src, masked, dfsClient.clientName,
                new EnumSetWritable&amp;lt;CreateFlag&amp;gt;(flag), createParent, replication,
                blockSize, SUPPORTED_CRYPTO_VERSIONS);
            {
                // RPC
            }
            // 2.
            final DFSOutputStream out = new DFSOutputStream(dfsClient, src, stat,
            flag, progress, checksum, favoredNodes);
            {
                // 
                class DataStreamer
                class Patket
                streamer = new DataStreamer(stat, traceSpan);
            }
            
        }
        // 2.
        beginFileLease(result.getFileId(), result);
    }
                
    // 2. 
    return dfs.createWrappedOutputStream(dfsos, statistics);
    {
        return new HdfsDataOutputStream(dfsos, statistics, startPos);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先是 DistributedFileSystem 创建，然后调用 DfsClient 的 create ，DfsClient需要创建流和lease，创建流 由 DFSOutputStream 完成，
DFSOutputStream 需要分别和namenode、datanode通信。DFSOutputStream 内部有 Packet 和 DataStreamer，继承自 FSOutputSummer ，FSOutputSummer 完成了write的真正逻辑&lt;/p&gt;

&lt;h1 id=&#34;2-out-write-buf-0-bytesread&#34;&gt;2. out.write(buf, 0, bytesRead)&lt;/h1&gt;

&lt;p&gt;创建完成后就是写数据，HdfsDataOutputStream 写数据比较复杂，先写到缓存，然后发送。需要做 checksum 检验，然后做成一个 chuck，然后将多个 chuck 合成一个 Packet，然后发送 Packet。&lt;/p&gt;

&lt;p&gt;FSDataOutputStream.out.write(byte[])
调用过程：
out.write(bytes) -&amp;gt; FilterOutputStream.write -&amp;gt; DataOutputStream.write -&amp;gt; out.write(byte[], off, len) -&amp;gt; FSOutputSummer.write(byte b[], int off, int len)&lt;/p&gt;

&lt;p&gt;FSOutputSummer.write&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public synchronized void write(byte b[], int off, int len)
      throws IOException {
    
    checkClosed();
    
    if (off &amp;lt; 0 || len &amp;lt; 0 || off &amp;gt; b.length - len) {
      throw new ArrayIndexOutOfBoundsException();
    }
    // 循环调用 write ，每次写入 #write1() 长度
    for (int n=0;n&amp;lt;len;n+=write1(b, off+n, len-n)) {
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 byte b[] 就是我们的数据流，通过断点我们可以看到是600个97，也就是600个a。&lt;/p&gt;

&lt;p&gt;write1，这里有几个比较核心的内容，如果写入长度比较大，直接写入流，如果写入比较少，先写到 Buffer，到达一定长度再统一进行写到流。这么做是为了减少拷贝&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private int write1(byte b[], int off, int len) throws IOException {
  
  // 写入长度大于本地buf的长度时，直接写入本地buf的长度。
  if(count==0 &amp;amp;&amp;amp; len&amp;gt;=buf.length) {
    // local buffer is empty and user buffer size &amp;gt;= local buffer size, so
    // simply checksum the user buffer and send it directly to the underlying
    // stream
    final int length = buf.length;
    writeChecksumChunks(b, off, length);
    return length;
  }
  // 当len小于本地buf的长度时，先写入buf，当buf写满之后，flushBuffer
  // copy user data to local buffer
  
  int bytesToCopy = buf.length-count; // 这个 count 代表以及复制的数据长度，第一次是 0
  bytesToCopy = (len&amp;lt;bytesToCopy) ? len : bytesToCopy;  // 这时候就是要复制的数据长度，600
  System.arraycopy(b, off, buf, count, bytesToCopy);
  count += bytesToCopy;
  if (count == buf.length) {
    // local buffer is full
    flushBuffer();
  } 
  return bytesToCopy;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，写入数据大的话，直接调用 writeChecksumChunks 将buf长度大小的数据生成 chunksum ，
（chunksum 是检查数据完整性的，相关知识可以查看计算机网络。）并写入 packet中。如果写入数据比较少，直接放进 buffer，等待buffer比较大，再统一flush&lt;/p&gt;

&lt;p&gt;数据写完了关闭流的时候会再调用一次 fulshBuffer ,会调用 writeChecksumChunks&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void writeChecksumChunks(byte b[], int off, int len)
throws IOException {
  // 计算checksum
  sum.calculateChunkedSums(b, off, len, checksum, 0);
  for (int i = 0; i &amp;lt; len; i += sum.getBytesPerChecksum()) {
    int chunkLen = Math.min(sum.getBytesPerChecksum(), len - i);
    int ckOffset = i / sum.getBytesPerChecksum() * getChecksumSize();
    // 一个chunk一个chunk的写入packet
    writeChunk(b, off + i, chunkLen, checksum, ckOffset, getChecksumSize());
  }

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sum.calculateChunkedSums 计算校验值，计算完以后b还是 600个97，off和len分别是 0和600，checksum是一个36位的数组，
但是只有前八位有值：0 = 111,1 = 50,2 = -90,3 = 31,4 = -99,5 = 97,6 = -69,7 = 102。因为每512位生成4个校验码。现在是600位，需要8个。
然后写出 chunk，chunk的长度为： 512，所以这里会调用两次 writeChunk。&lt;/p&gt;

&lt;p&gt;writeChunk 先将 chunk 写入 currentPacket 中，当currentPacket写满之后调用 waitAndQueueCurrentPacket，
将packet放入dataQueue队列，等待DataStreamer线程将packet写入pipeline中，整个block发送完毕之后将发送一个空的packet。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;writeChunk{}
currentPacket.writeChecksum(checksum, ckoff, cklen);
currentPacket.writeData(b, offset, len);
currentPacket.numChunks++;
bytesCurBlock += len;
waitAndQueueCurrentPacket()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们把这段代码跑两遍以后，去看看生成的Packet，里面有4个属性：checksumStart = 33,checksumPos = 41,dataStart = 541,dataPos = 1141&lt;/p&gt;

&lt;p&gt;可以看出这几个的意思分别是 check 的开始位置和结束为止，data的开始位置和结束为止，之所以留了 33个位置，是 Packet 的 header。然后还有一个 buffer数组，里面就是按照检查数据和数据。&lt;/p&gt;

&lt;p&gt;这时候 Packet 的结构我们已经一清二楚了。&lt;/p&gt;

&lt;p&gt;相关详细内容可以继续深入查看源码。waitAndQueueCurrentPacket() 可以看具体代码，这时候已经报连接超时异常了。接下来我们调试发送数据到 DataNode。&lt;/p&gt;

&lt;h1 id=&#34;三-dfsoutputstream-datastreamer-发送-packet&#34;&gt;三.DFSOutputStream.DataStreamer 发送 packet&lt;/h1&gt;

&lt;p&gt;上面已经调试到：waitAndQueueCurrentPacket() ,会将 Packet 发送给 DFSOutputStream.DataStreamer&lt;/p&gt;

&lt;p&gt;DFSOutputStream.DataStreamer 是一个线程，里面有个 stage 标识到了哪一步。还有一个 response 用来回复消息。&lt;/p&gt;

&lt;p&gt;DataStreamer 会从 dataQueue 中拿出 packet 发送到 pipeline , 相关代码很长。取出部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;synchronized (dataQueue) {

	 // 发送packet，dataQueue为null，则发送一个心跳
	 if (dataQueue.isEmpty()) {
	   one = createHeartbeatPacket();
	 } else {
	   one = dataQueue.getFirst(); // regular data packet
	 }
	}
	
        // 建立pipeline
        setPipeline(nextBlockOutputStream());
        // 启动ResponseProcessor线程，更新DataStreamer的状态为DATA_STREAMING

// 当前packet是block的最后一个packet，等待接收之前所有packet的ack
      if (one.lastPacketInBlock) {
        // wait for all data packets have been successfully acked
        synchronized (dataQueue) {
          while (!streamerClosed &amp;amp;&amp;amp; !hasError &amp;amp;&amp;amp; 
              ackQueue.size() != 0 &amp;amp;&amp;amp; dfsClient.clientRunning) {
            try {
              // wait for acks to arrive from datanodes
              dataQueue.wait(1000);
            } catch (InterruptedException  e) {
              DFSClient.LOG.warn(&amp;quot;Caught exception &amp;quot;, e);
            }
          }
        }
        if (streamerClosed || hasError || !dfsClient.clientRunning) {
          continue;
        }
        stage = BlockConstructionStage.PIPELINE_CLOSE;
      }
       
     
     // 将 packet 从 dataQueue 移到 ackQueue，准备发送packet
      synchronized (dataQueue) {
        // move packet from dataQueue to ackQueue
        if (!one.isHeartbeatPacket()) {
          dataQueue.removeFirst();
          ackQueue.addLast(one);
          dataQueue.notifyAll();
        }
      }
     // 将packet写入pipeline
        one.writeTo(blockStream);
        blockStream.flush();   
    
      // 如果当前packet是最后一个，则继续等待此packet的ack，
      // 然后endBlock
    if (one.lastPacketInBlock) {
        // wait for the close packet has been acked
        synchronized (dataQueue) {
          while (!streamerClosed &amp;amp;&amp;amp; !hasError &amp;amp;&amp;amp; 
              ackQueue.size() != 0 &amp;amp;&amp;amp; dfsClient.clientRunning) {
            dataQueue.wait(1000);// wait for acks to arrive from datanodes
          }
        }
        if (streamerClosed || hasError || !dfsClient.clientRunning) {
          continue;
        }
        endBlock();
      }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代码很长也比较杂乱，我们主要看一下 setPipeline(nextBlockOutputStream()); 和 one.writeTo(blockStream);blockStream.flush();  等&lt;/p&gt;

&lt;p&gt;第一步是：one = dataQueue.getFirst();&lt;br /&gt;
我们看看取到的 Packet 是什么样子：和我们上面发送的一样，buf=[0,0,0(33个0),11,50..(6个检测码),0,0,(很多0)，97,97,97(600个97)，],lastPacketInBlock=false &amp;hellip;&lt;/p&gt;

&lt;p&gt;nextBlockOutputStream 是通过 namenode 得到一个 LocatedBlock ，而 setPipeline 是和 Datanode 的通道。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;nextBlockOutputStream(){
lb = locateFollowingBlock(startTime,excluded.length &amp;gt; 0 ? excluded : null); 
-- dfsClient.namenode.addBlock(src, dfsClient.clientName,block, excludedNodes, fileId, favoredNodes);

success = createBlockOutputStream(nodes, storageTypes, 0L, false);

blockStream = out; //给写出流赋值。
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;createBlockOutputStream 对于我们第一次调试来说，关注三个就够了。
创建连接： /到 datanode 的 socket连接 Socket[addr=/127.0.0.1,port=50010,localport=58006]，
new Sender(out).writeBlock 建立 block&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;createBlockOutputStream{}
// 到 datanode 的 socket连接 Socket[addr=/127.0.0.1,port=50010,localport=58006]
s = createSocketForPipeline(nodes[0], nodes.length, dfsClient);
long writeTimeout = dfsClient.getDatanodeWriteTimeout(nodes.length);

OutputStream unbufOut = NetUtils.getOutputStream(s, writeTimeout);
InputStream unbufIn = NetUtils.getInputStream(s);
IOStreamPair saslStreams = dfsClient.saslClient.socketSend(s,
  unbufOut, unbufIn, dfsClient, accessToken, nodes[0]);
unbufOut = saslStreams.out;
unbufIn = saslStreams.in;
out = new DataOutputStream(new BufferedOutputStream(unbufOut,
    HdfsConstants.SMALL_BUFFER_SIZE));
    
-- 发送写block请求，
new Sender(out).writeBlock(blockCopy, nodeStorageTypes[0], accessToken,
dfsClient.clientName, nodes, nodeStorageTypes, null, bcs, 
nodes.length, block.getNumBytes(), bytesSent, newGS,
checksum4WriteBlock, cachingStrategy.get(), isLazyPersistFile);

blockStream = out; //给写出流赋值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;回到 run 方法，通过 initDataStreaming ，然后调用 one.writeTo(blockStream); 这个 blockStream 上面已经赋值了，就是通过 socket 建立 的连接。这里只是将packet写入pipeline中的第一个dn。&lt;/p&gt;

&lt;p&gt;看看 Packet 的 writeTo 方法，Packet 的成员变量上面写了，是检查点位置，检查长度，数据位置，数据长度，等。&lt;/p&gt;

&lt;p&gt;主要步骤：
- 计算 pktLen 头长度+检查长度+数据长度
- 新建Header，包括 packet 是否是最后一个packet的信息等。
- 判断 checksumPos != dataStart 不等于需要删掉中间的空缺数据，&lt;code&gt;System.arraycopy(buf, checksumStart, buf, dataStart - checksumLen , checksumLen)&lt;/code&gt;
这个是因为 packet 容量是好几万，我们假设 10000，能容纳的 chunk 是 20个左右，所以应该有 20 * 4 = 80 的检查数据。所以前80个位置留给了检查位置，数据从81开始写。
但是如果我们没写满一个 Packet，检查数据就不需要80个，数据也是从 81开始写，这就空缺了一些数据。
- 将 header.getBytes() [0 = 0,1 = 0,2 = 2,3 = 100,4 = 0,5 = 25 &amp;hellip;.(一共33个值)] 的值放到 Packet 的头部。
- stm.write(buf, headerStart, header.getSerializedSize() + checksumLen + dataLen);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void writeTo(DataOutputStream stm) throws IOException {
  
  final int dataLen = dataPos - dataStart;  1411 - 541
  final int checksumLen = checksumPos - checksumStart; 
  final int pktLen = HdfsConstants.BYTES_IN_INTEGER + dataLen + checksumLen;
  PacketHeader header = new PacketHeader(
    pktLen, offsetInBlock, seqno, lastPacketInBlock, dataLen, syncBlock);
    
  // checksumPos不等于dataStart时，将checksum移动到data前面，
  // 紧挨着data，为header空出足够的空间
  if (checksumPos != dataStart) {
    // Move the checksum to cover the gap. This can happen for the last
    // packet or during an hflush/hsync call.
    System.arraycopy(buf, checksumStart, buf, 
                     dataStart - checksumLen , checksumLen); 
    checksumPos = dataStart;
    checksumStart = checksumPos - checksumLen;
  }
  
  final int headerStart = checksumStart - header.getSerializedSize();
  assert checksumStart + 1 &amp;gt;= header.getSerializedSize();
  assert checksumPos == dataStart;
  assert headerStart &amp;gt;= 0;
  assert headerStart + header.getSerializedSize() == checksumStart;
  
  // Copy the header data into the buffer immediately preceding the checksum
  // data.
  
  // 将header复制到packet的buf中，组成一个完整的packet
  System.arraycopy(header.getBytes(), 0, buf, headerStart,
      header.getSerializedSize());
  
  // corrupt the data for testing.
  if (DFSClientFaultInjector.get().corruptPacket()) {
    buf[headerStart+header.getSerializedSize() + checksumLen + dataLen-1] ^= 0xff;
  }
  // Write the now contiguous full packet to the output stream.
  // 将buf写入输出流中
  stm.write(buf, headerStart, header.getSerializedSize() + checksumLen + dataLen);
  
  // undo corruption.
  if (DFSClientFaultInjector.get().uncorruptPacket()) {
    buf[headerStart+header.getSerializedSize() + checksumLen + dataLen-1] ^= 0xff;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看一下 最后的 stm.write， 通过跟踪我们发现最终调用： channel.write(buf);  是通过 NIO实现的。&lt;/p&gt;

&lt;p&gt;最后我们可以看到打印了错误信息： Exception in thread &amp;ldquo;main&amp;rdquo; java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting&amp;hellip;
这是因为我们调试时间长，连接已经断了。这个错误是哪一步打印的我们后续可以研究研究。&lt;/p&gt;

&lt;p&gt;其实这里有个疑问，这个 Packet 是最后一个 Packet，但是 它的 lastPacketInBlock=false？，其实这个确实不是最后一个，后面还要发送一个空的 Packet，只有 37个字节的头信息。&lt;/p&gt;

&lt;h1 id=&#34;四-dataxceiver-线程写入-datanode&#34;&gt;四、DataXceiver 线程写入 DataNode&lt;/h1&gt;

&lt;p&gt;注意：&lt;/p&gt;

&lt;p&gt;服务端的调试和客户端调试是反过来的，
需要先 stop-dfs.sh, 然后 &lt;code&gt;hadoop-daemons.sh start namenode&lt;/code&gt; &lt;code&gt;hadoop-daemons.sh start secondarynamenode&lt;/code&gt;  启动 namenode，然后我们在 IDEA 中运行 datanode
然后我们通过客户端命令: hadoop fs -copyFromLocal data.txt /tmp/data.txt
另外多线程调试不太方便，每次只能在一个线程打赏断点，否则会跳来跳去很麻烦，我们就在 DataXCerver 的 writeBlock 方法打上断点&lt;/p&gt;

&lt;p&gt;以上的流程可以看做是client端，client端将数据发送到dn上，由dn负责将packet写入本地磁盘，并向下一个dn发送。
DataXceiverServer 是在 DataNode 启动的线程，run 方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void run() {
  Peer peer = null;
  while (datanode.shouldRun &amp;amp;&amp;amp; !datanode.shutdownForUpgrade) {
    try {
      // 接收client的socket请求
      peer = peerServer.accept();
     
     // 一个 Daemon线程
      new Daemon(datanode.threadGroup,
          DataXceiver.create(peer, datanode, this))
          .start();
    } catch 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里先循环接受请求，每次接受到一个就新建一个线程，加入线程组中。每个 DataXceiver 线程的 run 方法就是处理请求的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;dataXceiverServer.addPeer(peer, Thread.currentThread(), this);
peer.setWriteTimeout(datanode.getDnConf().socketWriteTimeout);
InputStream input = socketIn;
try {
  IOStreamPair saslStreams = datanode.saslServer.receive(peer, socketOut,
    socketIn, datanode.getXferAddress().getPort(),
    datanode.getDatanodeId());
  input = new BufferedInputStream(saslStreams.in,
    HdfsConstants.SMALL_BUFFER_SIZE);
  socketOut = saslStreams.out;
} catch 

super.initialize(new DataInputStream(input));

op = readOp();
processOp(op);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;processOp():&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;switch(op) {
    case READ_BLOCK:
      opReadBlock();
      break;
    case WRITE_BLOCK:
      opWriteBlock(in);
      break;

    default:
      throw new IOException(&amp;quot;Unknown op &amp;quot; + op + &amp;quot; in data stream&amp;quot;);
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void opWriteBlock(DataInputStream in) throws IOException {
    final OpWriteBlockProto proto = OpWriteBlockProto.parseFrom(vintPrefixed(in));
    final DatanodeInfo[] targets = PBHelper.convert(proto.getTargetsList());
    TraceScope traceScope = continueTraceSpan(proto.getHeader(),
        proto.getClass().getSimpleName());
    try {
      writeBlock(PBHelper.convert(proto.getHeader().getBaseHeader().getBlock()),
          PBHelper.convertStorageType(proto.getStorageType()),
          PBHelper.convert(proto.getHeader().getBaseHeader().getToken()),
          proto.getHeader().getClientName(),
          targets,
          PBHelper.convertStorageTypes(proto.getTargetStorageTypesList(), targets.length),
          PBHelper.convert(proto.getSource()),
          fromProto(proto.getStage()),
          proto.getPipelineSize(),
          proto.getMinBytesRcvd(), proto.getMaxBytesRcvd(),
          proto.getLatestGenerationStamp(),
          fromProto(proto.getRequestedChecksum()),
          (proto.hasCachingStrategy() ?
              getCachingStrategy(proto.getCachingStrategy()) :
            CachingStrategy.newDefaultStrategy()),
            (proto.hasAllowLazyPersist() ? proto.getAllowLazyPersist() : false));
     } finally {
      if (traceScope != null) traceScope.close();
     }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个方法有我们的断点，我们会在里面进行调试 writeBlock ，大致步骤为：&lt;/p&gt;

&lt;p&gt;新建 给客户端发确认消息的 replyOut 流，
新建 给其他DataNode 发消息的 mirror 流
新建 BlockReceiver  接收数据，接收到 Packet 后进行判断，如果不是最后一个，写到输出流，如果是最后一个或者长度为0，不做处理。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public void writeBlock(final ExtendedBlock block,
    final StorageType storageType, 
    final Token&amp;lt;BlockTokenIdentifier&amp;gt; blockToken,
    final String clientname,
    final DatanodeInfo[] targets,
    final StorageType[] targetStorageTypes, 
    final DatanodeInfo srcDataNode,
    final BlockConstructionStage stage,
    final int pipelineSize,
    final long minBytesRcvd,
    final long maxBytesRcvd,
    final long latestGenerationStamp,
    DataChecksum requestedChecksum,
    CachingStrategy cachingStrategy,
    final boolean allowLazyPersist) throws IOException {
    
    // 我们简单取一部分代码
    
    // 输出流，现在在 DataXCerver 中，输入流就是客户端写，输出流自然即时发送到客户端的
    final DataOutputStream replyOut = new DataOutputStream(
        new BufferedOutputStream(
            getOutputStream(),
            HdfsConstants.SMALL_BUFFER_SIZE));
    
    }
    
    // 这里一大堆的 mirrorOut 开头的流都是 数据写到 DataNode 后复制副本用的，由于在本地只有一个副本，所以都是 null 
    DataOutputStream mirrorOut = null;  // stream to next target
    DataInputStream mirrorIn = null;    // reply from next target
    Socket mirrorSock = null;           // socket to next target
    String mirrorNode = null;           // the name:port of next target
    String firstBadLink = &amp;quot;&amp;quot;;           // first datanode that failed in connection setup
    Status mirrorInStatus = SUCCESS;
    final String storageUuid;
    
    // 新建 BlockReceiver， BlockReceiver 的作用可以好好看注释，另外它的构造方法也有很大的信息量，其中有个 in 输入流，
    // 是在 DataXCerver 的 run 方法中：super.initialize(new DataInputStream(input)); 也就是对输入的 socket 流的二层包装
    blockReceiver = new BlockReceiver(block, storageType, in,
    peer.getRemoteAddressString(),
    peer.getLocalAddressString(),
    stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,
    clientname, srcDataNode, datanode, requestedChecksum,
    cachingStrategy, allowLazyPersist)
    
    // 然后是一大堆的副本拷贝，我们本地调试线跳过。
    if (targets.length &amp;gt; 0) {// 跳过}
    
      // 给客户端发一个应答消息
      if (isClient &amp;amp;&amp;amp; !isTransfer) {
        if (LOG.isDebugEnabled() || mirrorInStatus != SUCCESS) {
          LOG.info(&amp;quot;Datanode &amp;quot; + targets.length +
                   &amp;quot; forwarding connect ack to upstream firstbadlink is &amp;quot; +
                   firstBadLink);
        }
        BlockOpResponseProto.newBuilder()
          .setStatus(mirrorInStatus)
          .setFirstBadLink(firstBadLink)
          .build()
          .writeDelimitedTo(replyOut);
        replyOut.flush();
      }
      
      // 这里开始写数据，
    blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,mirrorAddr, null, targets, false);
    
    // 后续处理
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看一下 blockReceiver.receiveBlock&lt;/p&gt;

&lt;p&gt;new PacketResponder
receivePacket()&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 如果是来自客户端而且传输，新建回复的线程
if (isClient &amp;amp;&amp;amp; !isTransfer) {
        responder = new Daemon(datanode.threadGroup, 
            new PacketResponder(replyOut, mirrIn, downstreams));
        responder.start(); // start thread to processes responses
      }

// 循环写
while (receivePacket() &amp;gt;= 0) { /* R} 这里就是写所在逻辑了

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;receivePacket 方法：&lt;/p&gt;

&lt;p&gt;packetReceiver.receiveNextPacket(in); 接受一个 Packet&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;receivePacket{
packetReceiver.receiveNextPacket(in);

PacketHeader header = packetReceiver.getHeader();

// 这里把数据写到 副本上面
//First write the packet to the mirror:
    if (mirrorOut != null &amp;amp;&amp;amp; !mirrorError) {
      try {
        long begin = Time.monotonicNow();
        packetReceiver.mirrorPacketTo(mirrorOut);
        mirrorOut.flush();
        long duration = Time.monotonicNow() - begin;
        if (duration &amp;gt; datanodeSlowLogThresholdMs) {
          LOG.warn(&amp;quot;Slow BlockReceiver write packet to mirror took &amp;quot; + duration
              + &amp;quot;ms (threshold=&amp;quot; + datanodeSlowLogThresholdMs + &amp;quot;ms)&amp;quot;);
        }
      } catch (IOException e) {
        handleMirrorOutError(e);
      }
    }
    
    // 得到 数据和 检查数据
    ByteBuffer dataBuf = packetReceiver.getDataSlice();
    ByteBuffer checksumBuf = packetReceiver.getChecksumSlice();
    
    // 如果是最后一个 packet
    if (lastPacketInBlock || len == 0) {
      if(LOG.isDebugEnabled()) {
        LOG.debug(&amp;quot;Receiving an empty packet or the end of the block &amp;quot; + block);
      }
      // sync block if requested
      if (syncBlock) {
        flushOrSync(true);
      }
    } else {
        。。。。。
        out.write(dataBuf.array(), startByteToDisk, numBytesToDisk);
    }
    // 这里就行 check 很复杂，部分数据的 check 需要重新计算。
    checksumOut.write(buf);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的代码太复杂，而且调试的时候稍微时间长一点就出现 连接异常。可以通过配置参数解决。
然后得到了 dataBuf 和 checksumBuf，如果不是最后一个，我们需要写到 DataNode 的具体数据中。
到这里整个写的操作就完成。中间的 和客户端心跳应答、失败处理。都没有涉及。简单梳理一下：&lt;/p&gt;

&lt;h1 id=&#34;五-pipelineack-和-packetresponder-信息处理&#34;&gt;五、PipeLineAck 和 PacketResponder 信息处理&lt;/h1&gt;

&lt;p&gt;上面的 one.writeTo(blockStream); 代码是将 Packet 写入到输出流，写出之前有一段代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; // send the packet
 synchronized (dataQueue) {
   // move packet from dataQueue to ackQueue
   if (!one.isHeartbeatPacket()) {
     dataQueue.removeFirst();
     ackQueue.addLast(one);
     dataQueue.notifyAll();
   }
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就是将 Packet 放进 ackQueue 中，很明显这又是一个 消费者生产者。&lt;/p&gt;

&lt;p&gt;新建 DataStreamer 的run中，得到输出流，
建立 pipeLine 之后，会有 initDataStreaming 操作，还要启一个新的线程 ResponseProcessor 接收packet的ack，这个线程在initDataStreaming中启动，并更新DataStreamer线程的状态为DATA_STREAMING
ResponseProcessor，在 ResponseProcessor 的run方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;synchronized (dataQueue) {
  one = ackQueue.getFirst();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意每次锁住的都是 dataQueue 对象。
与他对应的是 BlockReceiver 中的 PacketResponder 。 PacketResponder 的 run 方法比较长，主要是按照 packet 的写入顺序发送 ack。&lt;/p&gt;

&lt;p&gt;由于调试器的问题，这里一直跳不进去，能看到大概逻辑： 当数据节点顺利处理完数据，而且当前节点处在数据节点中间（收到下游DataNode的消息）
如果 ackQueue 中有数据，获取一个记录，接下来如果当前节点位于数据管道的中间，就在mirror流读取下游的确认，我们在本地调试是没有这一步的。&lt;/p&gt;

&lt;p&gt;如果当前节点位于数据管道的最后， 调用 pkt = waitForAckHead(seqno) 从 ackQueue 取出对应的 pkt ，然后调用 lastPacketInBlock = pkt.lastPacketInBlock;
然后是  if (lastPacketInBlock) {finalizeBlock(startTime);} ，然后是 sendAckUpstream ，这个就是给客户端发送 ack&lt;/p&gt;

&lt;p&gt;然后 ResponseProcessor 中收到了 ack，进行处理。逻辑比较简单，ack.readFields(blockReplyStream) 读取 ask，从输入流中读取的ack的seqno与ackQueue中取得的seqno不一样则抛出异常&lt;/p&gt;

&lt;p&gt;// 接收到ack后，从ackQueue中移除packet
      synchronized (dataQueue) {
        lastAckedSeqno = seqno;
        ackQueue.removeFirst();
        dataQueue.notifyAll();
        one.releaseBuffer(byteArrayManager);
      }
。&lt;/p&gt;

&lt;h1 id=&#34;6-namenode-处理&#34;&gt;6.NameNode 处理&lt;/h1&gt;

&lt;p&gt;上面我们说了 NameNode 的处理我们没法调试所以我们跳过了NameNode，原因是客户端通过远程的RPC调用执行，这次我们在IDEA启动NameNode，然后查看NameNode是如何处理写文件的。&lt;/p&gt;

&lt;p&gt;通过 RPC 调用 NameNodeRpcServer.create -&amp;gt; namesystem.startFile -&amp;gt; startFileInt -&amp;gt; startFileInternal&lt;/p&gt;

&lt;p&gt;中间有上锁的步骤，还有 BlockManager 的验证，namesystem 中有一个 dir:FSDirectory 的属性，a pure in-memory data structure ，
里面又有一个 rootDir：INodeDirectory 代表根节点，rootDir 中有一个 List&lt;INode&gt; children 代表所以的文件 ，还有一个 INodeMap 对象，保存。
注意还有一个 INodesInPath 类，从他的方法我们看出，它代表一个文件递归得到所有父目录的 InpPath 文件。&lt;/p&gt;

&lt;p&gt;startFileInternal 方法主要步骤如下：
- 根据 src 得到 INodesInPath，再得到 INodeFile 进行检验。
- newNode = dir.addFile(src, permissions, replication, blockSize,holder, clientMachine);
- getEditLog().logOpenFile(src, newNode, overwrite, logRetryEntry); 记录日志
- leaseManager.addLease(newNode.getFileUnderConstructionFeature()&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; private BlocksMapUpdateInfo startFileInternal(FSPermissionChecker pc, 
      String src, PermissionStatus permissions, String holder, 
      String clientMachine, boolean create, boolean overwrite, 
      boolean createParent, short replication, long blockSize, 
      boolean isLazyPersist, CipherSuite suite, CryptoProtocolVersion version,
      EncryptedKeyVersion edek, boolean logRetryEntry)

//得到文件
final INodeFile myFile = INodeFile.valueOf(inode, src, true);

try {
      BlocksMapUpdateInfo toRemoveBlocks = null;
      if (myFile == null) {
      // 判断是否创建
        if (!create) {
          throw new FileNotFoundException(&amp;quot;Can&#39;t overwrite non-existent &amp;quot; +
              src + &amp;quot; for client &amp;quot; + clientMachine);
        }
      } else {
      // 是否覆盖
        if (overwrite) {
          toRemoveBlocks = new BlocksMapUpdateInfo();
          List&amp;lt;INode&amp;gt; toRemoveINodes = new ChunkedArrayList&amp;lt;INode&amp;gt;();
          long ret = dir.delete(src, toRemoveBlocks, toRemoveINodes, now());
          if (ret &amp;gt;= 0) {
            incrDeletedFileCount(ret);
            removePathAndBlocks(src, null, toRemoveINodes, true);
          }
        } else {
        // 存在而且不覆盖的情况？操作 lease
          // If lease soft limit time is expired, recover the lease
          recoverLeaseInternal(myFile, src, holder, clientMachine, false);
          throw new FileAlreadyExistsException(src + &amp;quot; for client &amp;quot; +
              clientMachine + &amp;quot; already exists&amp;quot;);
        }
      }

// Always do an implicit mkdirs for parent directory tree.
// 父目录
      Path parent = new Path(src).getParent();
      if (parent != null &amp;amp;&amp;amp; mkdirsRecursively(parent.toString(),
              permissions, true, now())) {
              // 添加到 namespace
        newNode = dir.addFile(src, permissions, replication, blockSize,
                              holder, clientMachine);
      }
      // 操作 lease
      leaseManager.addLease(newNode.getFileUnderConstructionFeature()
          .getClientName(), src);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;INodesInPath：&lt;/p&gt;

&lt;p&gt;newNode = dir.addFile(src, permissions, replication, blockSize,holder, clientMachine);&lt;/p&gt;

&lt;p&gt;这个 dir 是 FSDirectory 类型的变量，最终调用了 INodeDirectory.addChild(INode) 方法，时间上就是给他的 children add 一个 INode&lt;/p&gt;

&lt;p&gt;和 addlease :&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;synchronized Lease addLease(String holder, String src) {
    Lease lease = getLease(holder);
    if (lease == null) {
      lease = new Lease(holder);
      leases.put(holder, lease);
      sortedLeases.add(lease);
    } else {
      renewLease(lease);
    }
    sortedLeasesByPath.put(src, lease);
    lease.paths.add(src);
    return lease;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  /** Get a lease and start automatic renewal */
  private void beginFileLease(final long inodeId, final DFSOutputStream out)
      throws IOException {
    getLeaseRenewer().put(inodeId, out, this);
  }
  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用完 startFileInternal 后，会调用
stat = dir.getFileInfo(src, false, FSDirectory.isReservedRawName(srcArg), true);
实际上就是得到一个 HdfsFileStatus 的对象，返回给客户端。NameNode 穿件文件元数据信息的过程大致如此。&lt;/p&gt;

&lt;h1 id=&#34;七-datanode-创建文件&#34;&gt;七、DataNode 创建文件&lt;/h1&gt;

&lt;p&gt;上面讲了在 DataNode 的 DataXCeiver 的写数据过程，但是我们忽略了一些和流式接口无关的部分，包括创建数据块等。&lt;/p&gt;

&lt;p&gt;实际上客户端 DFSClient 发送创建元数据给 NameNode 以后，就要根据 HdfsFileStatus 创建到 DataNode 的输出流。
在 DataStreamer 的 createBlockOutputStream 方法中创建了 blockStream = out，实际上创建之前有个步骤：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// send the request
new Sender(out).writeBlock(blockCopy, nodeStorageTypes[0], accessToken,
    dfsClient.clientName, nodes, nodeStorageTypes, null, bcs, 
    nodes.length, block.getNumBytes(), bytesSent, newGS,
    checksum4WriteBlock, cachingStrategy.get(), isLazyPersistFile);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 Sender 和 DataXCerver 一样，继承自 DataTransferProtocol ，我们可以理解为 DataTransferProtocol 是客户端和 DataNode 通信协议，通信实现包含了创建 数据块和发送数据，
而 Sender 和 DataXCerver 就分别是创建数据块和发送数据的实现，分别是 TCP 和 RPC 通信方式实现。&lt;/p&gt;

&lt;p&gt;new Sender(out).writeBlock 只是简单的将信息以 ProtoBuf 的格式发送出去。实际上就是发送了一个 op ，这个 op 服务端会收到并解析，然后根据 op 的值调用不同方法，最后调用了：&lt;/p&gt;

&lt;p&gt;前面分析过： BlockReceiver.receiveBlock 。里面就有构建输出流写出，但是我们没有相关这个输出流是怎么来的，实际上就是一个文件流。我们看一下 BlockReceiver 的构造方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.block = block;

switch (stage) {
        case PIPELINE_SETUP_CREATE:
          replicaInfo = datanode.data.createRbw(storageType, block, allowLazyPersist);
          datanode.notifyNamenodeReceivingBlock(
              block, replicaInfo.getStorageUuid());
          break;


streams = replicaInfo.createStreams(isCreate, requestedChecksum);
this.out = streams.getDataOut();
this.checksumOut = new DataOutputStream(new BufferedOutputStream(
          streams.getChecksumOut(), HdfsConstants.SMALL_BUFFER_SIZE));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里有个 switch (stage)，实际上写文件都是一个 PIPELINE ，包括输入某个 client - DataNode - DataNode - DataNode ，由于我是本地模式调试，所以感觉不到这种 PIPELINE 的模式而已。&lt;/p&gt;

&lt;p&gt;datanode.data 是一个 FSDataSetImpl 类型的变量，控制着整个 DataNode 的文件信息。类型结构大致如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FSDataSetImpl 
    DataStorage
        bpStorageMap&amp;lt;bp,BlockPoolSliceStorage&amp;gt;
    FSVolumnList
        List&amp;lt;FSVolumnImpl&amp;gt;
             bpSlices&amp;lt;bp, BlockPoolSlice&amp;gt;
    volumeMap:ReplicaMap&amp;lt;bp, Map&amp;lt;blockid, ReplicaInfo&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FSDataSetImpl 代表整个 DataNode 的文件存储，FSVolumnList 是因为我们配置的 data 存储路径，可以用逗号隔开，一般情况下配置1个路径，FSVolumnList 里面就一个 FsVolumeImpl。
FsVolumeImpl 里面有分为 多个 blockpool 存储，一个 blockpool 对应一个文件夹而已，这在一开始版本是没有的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Storage

  List&amp;lt;StorageDirectory&amp;gt; storageDirs
  public int   layoutVersion;   // layout version of the storage data
  public int   namespaceID;     // id of the file system
  public String clusterID;      // id of the cluster
  public long  cTime;   
  static class StorageDirectory
      File root

DataStorage
   private String datanodeUuid = null;
   Map&amp;lt;String, BlockPoolSliceStorage&amp;gt; bpStorageMap
   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FsVolumeImpl&lt;/p&gt;

&lt;p&gt;replicaInfo 保存了文件的位置信息，所以可以用来创建输出流。&lt;/p&gt;

&lt;h1 id=&#34;八-租约处理&#34;&gt;八、租约处理&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;synchronized void put(final long inodeId, final DFSOutputStream out,
      final DFSClient dfsc) {
    if (dfsc.isClientRunning()) {
      if (!isRunning() || isRenewerExpired()) {
        //start a new deamon with a new id.
        final int id = ++currentId;
        daemon = new Daemon(new Runnable() {
          @Override
          public void run() {
            try {
              if (LOG.isDebugEnabled()) {
                LOG.debug(&amp;quot;Lease renewer daemon for &amp;quot; + clientsString()
                    + &amp;quot; with renew id &amp;quot; + id + &amp;quot; started&amp;quot;);
              }
              LeaseRenewer.this.run(id);
            } catch(InterruptedException e) {
              if (LOG.isDebugEnabled()) {
                LOG.debug(LeaseRenewer.this.getClass().getSimpleName()
                    + &amp;quot; is interrupted.&amp;quot;, e);
              }
            } finally {
              synchronized(LeaseRenewer.this) {
                Factory.INSTANCE.remove(LeaseRenewer.this);
              }
              if (LOG.isDebugEnabled()) {
                LOG.debug(&amp;quot;Lease renewer daemon for &amp;quot; + clientsString()
                    + &amp;quot; with renew id &amp;quot; + id + &amp;quot; exited&amp;quot;);
              }
            }
          }
          
          @Override
          public String toString() {
            return String.valueOf(LeaseRenewer.this);
          }
        });
        daemon.start();
      }
      dfsc.putFileBeingWritten(inodeId, out);
      emptyTime = Long.MAX_VALUE;
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最重要的就是  LeaseRenewer.this.run(id)， 在run中调用renew对租约续约。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for(long lastRenewed = Time.now(); !Thread.interrupted();
        Thread.sleep(getSleepPeriod())) {
      final long elapsed = Time.now() - lastRenewed;
      if (elapsed &amp;gt;= getRenewalTime()) {
        try {
          renew();
          if (LOG.isDebugEnabled()) {
            LOG.debug(&amp;quot;Lease renewer daemon for &amp;quot; + clientsString()
                + &amp;quot; with renew id &amp;quot; + id + &amp;quot; executed&amp;quot;);
          }
          lastRenewed = Time.now();
        } catch (SocketTimeoutException ie) {
          LOG.warn(&amp;quot;Failed to renew lease for &amp;quot; + clientsString() + &amp;quot; for &amp;quot;
              + (elapsed/1000) + &amp;quot; seconds.  Aborting ...&amp;quot;, ie);
          synchronized (this) {
            while (!dfsclients.isEmpty()) {
              dfsclients.get(0).abort();
            }
          }
          break;
        } catch (IOException ie) {
          LOG.warn(&amp;quot;Failed to renew lease for &amp;quot; + clientsString() + &amp;quot; for &amp;quot;
              + (elapsed/1000) + &amp;quot; seconds.  Will retry shortly ...&amp;quot;, ie);
        }
      }

&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>resourcemanager</title>
      <link>https://dengziming.github.io/post/hadoop/first/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/first/</guid>
      
        <description>&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/&#34;&gt;https://hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>yarn-nodemanager-剖析</title>
      <link>https://dengziming.github.io/post/hadoop/yarn-nodemanager-1/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/yarn-nodemanager-1/</guid>
      
        <description>

&lt;h1 id=&#34;架构&#34;&gt;架构&lt;/h1&gt;

&lt;p&gt;ContainerManagementImpl&lt;/p&gt;

&lt;h1 id=&#34;container-生命周期&#34;&gt;Container 生命周期&lt;/h1&gt;

&lt;p&gt;第一步是 RM 的 applicationMasterLauncher ，创建 ApplicationMasterLauncher 后，遇到 launch 时间 ，
case LAUNCH: launch(application); =&amp;gt; new AMLauncher(context, application, event, getConfig());&lt;/p&gt;

&lt;p&gt;这个任务放进 队列里面等待执行，一旦执行会调用 launch() 方法，然后调用 containerMgrProxy.startContainers(allRequests); 这是 RPC 调用&lt;/p&gt;

&lt;p&gt;实际上就是 ContainerManagementImpl ，然后会调用 startContainerInternal ，然后就是 new ContainerImpl 。&lt;/p&gt;

&lt;p&gt;这是 APPMaster 启动需要的 container ，实际上还有 APPMaster 调度任务需要更多的 Container ，继续向 ContainerManagementImpl 请求&lt;/p&gt;

&lt;h2 id=&#34;1-资源本地化&#34;&gt;1. 资源本地化&lt;/h2&gt;

&lt;p&gt;实际上就是 ContainerManagementImpl ，然后会调用 startContainerInternal ，然后就是 new ContainerImpl 。
然后通过 if (null == context.getApplications().putIfAbsent(applicationID,application)) 判断是否是该 NodeManager 第一个 Container ，如果是的话，new ApplicationImpl
向 ApplicationImpl 发送 ApplicationInitEvent 事件，同时发送 ApplicationContainerInitEvent 事件。&lt;/p&gt;

&lt;p&gt;这些事件会触发 ACL、log等相关的事件， 收到 ApplicationContainerInitEvent 后将 Container 加入 ApplicationImpl 的维护列表。&lt;/p&gt;

&lt;p&gt;logHandle 处理完成之后会发送一个 log 事件，applicationImpl 收到后向 ResourceLocalizeService 发送 事件，
为 private 和 application 级别的资源创建 LocalResourceTrackerImp ，为下载资源作准备。&lt;/p&gt;

&lt;p&gt;private 的资源用户可见，如果该用户已经提交过了，无需创建。同理，如果 application 已经启动过 container 了，则同一个 application 的新 container 不必在创建。&lt;/p&gt;

&lt;p&gt;经过上面操作后，ResourceLocalizeService 向 ApplicationImpl 发送 Application_Init&lt;/p&gt;

&lt;p&gt;ApplicationImpl 收到 INIT 后，向所有的 ContainerImpl 发送 InitContainer ，ApplicationImpl 也从 ApplicationState.INITING 变为 ApplicationState.RUNNING,&lt;/p&gt;

&lt;p&gt;InitContainer 命令后，和 AuxService 交互，然后从 ContainerLaunchContext 得到各类可见性资源并保存到相应数据结构，然后发送给 ResourceLocalizeService 。&lt;/p&gt;

&lt;p&gt;ResourceLocalizeService 调用 handleInitContainerResources((ContainerLocalizationRequestEvent) event); 实际是 是发送给 LocalResourcesTrackerImpl 。&lt;/p&gt;

&lt;p&gt;LocalResourcesTrackerImpl 会 判断是否需要下载等，为对应的资源创建 LocalizedResource 状态机，将 Request 发送给 LocalizedResource。&lt;/p&gt;

&lt;p&gt;后续还是这样的时间驱动，总之可以概括为 ： NodeManager 上同一个 App 所有的 ContainerImpl 异步并发向向资源下载服务 ResourceLocalizeService 发送待下载的资源，
ResourceLocalizeService下载完成后会通知依赖资源的所以 Container ，当一个 Container 依赖的资源全部下载完毕，Container 将会进入 运行阶段&lt;/p&gt;

&lt;h2 id=&#34;2-container-运行&#34;&gt;2. Container 运行&lt;/h2&gt;

&lt;p&gt;运行是 ContainerLauncher 服务实现的，主要过程为： 将待运行 Container 所需要的环境变量和运行命令写到 &lt;code&gt;launch_container.sh&lt;/code&gt; 中，
将启动该脚本的命令写入：&lt;code&gt;default_container_executor.sh&lt;/code&gt; 中。&lt;/p&gt;

&lt;p&gt;通过运行该脚本启动 Container 。主要有四步：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ContainerImpl 向 ContainersLauncher 发送 Launch_container ，请求启动 container。
dispatcher.getEventHandler().handle(new ContainersLauncherEvent(this, launcherEvent));&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ContainersLauncher 收到后，&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Application app =context.getApplications().get(containerId.getApplicationAttemptId().getApplicationId());
ContainerLaunch launch = new ContainerLaunch(context, getConfig(), dispatcher, exec, app,event.getContainer(), dirsHandler, containerManager);
containerLauncher.submit(launch);
running.put(containerId, launch);
break;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ContainerLaunch 放到线程池执行，对应的 call 方法为：&lt;/p&gt;

&lt;p&gt;为 Container 创建 token 文件 和 &lt;code&gt;launch_container.sh&lt;/code&gt; ，将他们保存到 NodeManager 私有目录 nmPrivate 下面， &lt;code&gt;launch_container.sh&lt;/code&gt;包含了运行所以的命令。
一般都是前面 export 环境变量，最后有个 exec 命令 。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;准备好了 命令，
&lt;code&gt;Container_Launcher&lt;/code&gt; 首先向 ContainerImpl 发送 &lt;code&gt;Container_LANUCHED&lt;/code&gt; 命令，然他启动监控等。然后调用 ContainerExector launchContainer 启动 Container 。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;然后是启动监控，汇报信息等。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>yarn-resourcemanager-1</title>
      <link>https://dengziming.github.io/post/hadoop/yarn-resourcemanager-1/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/yarn-resourcemanager-1/</guid>
      
        <description>

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/&#34;&gt;https://hortonworks.com/blog/apache-hadoop-yarn-resourcemanager/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;提交应用程序的过程&#34;&gt;提交应用程序的过程&lt;/h1&gt;

&lt;h2 id=&#34;1-yarnclient-submitapplication-appcontext&#34;&gt;1. yarnClient.submitApplication(appContext);&lt;/h2&gt;

&lt;p&gt;新建请求，最终调用： rmClient.submitApplication(request);&lt;/p&gt;

&lt;p&gt;实际上会通过RPC调用 ClientRMService.submitApplication(SubmitApplicationRequest request)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;得到APPID：ApplicationId applicationId = submissionContext.getApplicationId();&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;rmAppManager.submitApplication(submissionContext, System.currentTimeMillis(), user);&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;放到 rmAppManager 中，rmAppManager 中存放了所有的 application。
跟进去，发现调用了：&lt;/p&gt;

&lt;p&gt;this.rmContext.getDispatcher().getEventHandler().handle(new RMAppEvent(applicationId, RMAppEventType.START));&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void handle(RMAppEvent event) {
      ApplicationId appID = event.getApplicationId();
      RMApp rmApp = this.rmContext.getRMApps().get(appID);
      if (rmApp != null) {
        try {
          rmApp.handle(event);
        } catch (Throwable t) {
          LOG.error(&amp;quot;Error in handling event type &amp;quot; + event.getType()
              + &amp;quot; for application &amp;quot; + appID, t);
        }
      }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后导致这个 applicationId 所在的 RMAppEvent 状态机发生变化。&lt;/p&gt;

&lt;h2 id=&#34;2-registerapplicationmasterresponse-response-amrmclient-registerapplicationmaster-appmasterhostname-appmasterrpcport-appmastertrackingurl&#34;&gt;2.RegisterApplicationMasterResponse response = amRMClient.registerApplicationMaster(appMasterHostname, appMasterRpcPort,appMasterTrackingUrl);&lt;/h2&gt;

&lt;p&gt;注册 ApplicationMaster，注意这段代码是在用户编写的 ApplicationMaster 类中，所以这段代码运行在yarn给APPMaster分配的Container中。&lt;/p&gt;

&lt;p&gt;RegisterApplicationMasterResponse response = client.registerApplicationMaster(appHostName, appHostPort, appTrackingUrl);&lt;/p&gt;

&lt;p&gt;会调用：RegisterApplicationMasterResponse response = rmClient.registerApplicationMaster(request);&lt;/p&gt;

&lt;p&gt;最终会通过RPC调用：ApplicationMasterServeice.registerApplicationMaster(RegisterApplicationMasterRequest request)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.rmContext
        .getDispatcher()
        .getEventHandler()
        .handle(
          new RMAppAttemptRegistrationEvent(applicationAttemptId, request
            .getHost(), request.getRpcPort(), request.getTrackingUrl()));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种 RMAppAttemptEventType 类型的会 通过handle进行处理：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void handle(RMAppAttemptEvent event) {
      ApplicationAttemptId appAttemptID = event.getApplicationAttemptId();
      ApplicationId appAttemptId = appAttemptID.getApplicationId();
      RMApp rmApp = this.rmContext.getRMApps().get(appAttemptId);
      if (rmApp != null) {
        RMAppAttempt rmAppAttempt = rmApp.getRMAppAttempt(appAttemptID);
        if (rmAppAttempt != null) {
          try {
            rmAppAttempt.handle(event);
          } catch (Throwable t) {
            LOG.error(&amp;quot;Error in handling event type &amp;quot; + event.getType()
                + &amp;quot; for applicationAttempt &amp;quot; + appAttemptId, t);
          }
        }
      }
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和上面的 RMAppEvent 一样，会进入一个状态机进行处理。&lt;/p&gt;

&lt;h3 id=&#34;1-状态机相互转换细节&#34;&gt;1.状态机相互转换细节&lt;/h3&gt;

&lt;p&gt;上面的过程细化一下：&lt;/p&gt;

&lt;p&gt;RMAppImpl 收到 RMAppEventType.START 事件后，会调用 RMStateStore#storeApplication，以日志记录 RMAppImpl 当前信息，&lt;/p&gt;

&lt;p&gt;至此，RMAppImpl 的运行状态由 NEW 转移为 NEW_SAVING。该步骤就较为复杂了，下面详细介绍下。&lt;/p&gt;

&lt;p&gt;其中 RMAppEventType 注册到中央异步调度器的地方在 ResourceManager.java 中，new ApplicationEventDispatcher(rmContext) 进行处理，
处理方式很简单：通过appid得到得到 RMAppImpl ，最终会给  RMAppImpl自己处理，进入他的状态机处理。状态机有这么一个事件：&lt;/p&gt;

&lt;p&gt;addTransition(RMAppState.NEW, RMAppState.NEW_SAVING, RMAppEventType.START, new RMAppNewlySavingTransition())&lt;/p&gt;

&lt;p&gt;RMAppNewlySavingTransition 的 transition 就是 app.rmContext.getStateStore().storeNewApplication(app);  实际上就是保存应用的相关信息。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public synchronized void storeNewApplication(RMApp app) {  
    //app=RMAppImpl  
    LOG.info(&amp;quot;begin to storeNewApplication,app=&amp;quot;+app.toString());  
    ApplicationSubmissionContext context = app.getApplicationSubmissionContext();  
    assert context instanceof ApplicationSubmissionContextPBImpl;  
    ApplicationState appState =  
        new ApplicationState(app.getSubmitTime(), app.getStartTime(), context,app.getUser());  
    dispatcher.getEventHandler().handle(new RMStateStoreAppEvent(appState));  
  }  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意： dispatcher.getEventHandler().handle(new RMStateStoreAppEvent(appState));  这里会调用 RMStateStore 状态机的 transition，实际上就是 store + notifyDoneStoringApplication&lt;/p&gt;

&lt;p&gt;&lt;code&gt;rmDispatcher.getEventHandler().handle(new RMAppNewSavedEvent(appId, storedException));&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个事件又会进入 RMAppImpl 的状态机，对应代码 addTransition(RMAppState.NEW_SAVING, RMAppState.SUBMITTED, RMAppEventType.APP_NEW_SAVED, new AddApplicationToSchedulerTransition())&lt;/p&gt;

&lt;p&gt;调用：app.handler.handle(new AppAddedSchedulerEvent(app.applicationId,app.submissionContext.getQueue(), app.user));&lt;/p&gt;

&lt;p&gt;会触发： RMAppImpl 处理 AppAddedSchedulerEvent&lt;/p&gt;

&lt;p&gt;然后这个事件会分配给：CapacityScheduler ，&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;case APP_ADDED:  
    {  
      AppAddedSchedulerEvent appAddedEvent = (AppAddedSchedulerEvent) event;  
      addApplication(appAddedEvent.getApplicationId(),  
        appAddedEvent.getQueue(), appAddedEvent.getUser());  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;addApplication 会调用 rmContext.getDispatcher().getEventHandler().handle(new RMAppEvent(applicationId, RMAppEventType.APP_ACCEPTED));&lt;/p&gt;

&lt;p&gt;RMAppImpl 会触发 ：addTransition(RMAppState.SUBMITTED, RMAppState.ACCEPTED,  RMAppEventType.APP_ACCEPTED, new StartAppAttemptTransition())&lt;/p&gt;

&lt;p&gt;对应的transition： createNewAttempt(); handler.handle(new RMAppStartAttemptEvent(currentAttempt.getAppAttemptId(),  transferStateFromPreviousAttempt));&lt;br /&gt;
实际上就是触发 RMAppAttemptImpl 状态机操作。&lt;/p&gt;

&lt;p&gt;RMAppAttemptImpl 接受 RMAppAttemptEventType.START 事件后，进行一系列初始化工作。将自身状态由NEW转换为SUBMITTED，并调用 AttemptStartedTransition。&lt;/p&gt;

&lt;p&gt;AttemptStartedTransition appAttempt.eventHandler.handle(new AppAttemptAddedSchedulerEvent(  appAttempt.applicationAttemptId, transferStateFromPreviousAttempt));&lt;/p&gt;

&lt;p&gt;AppAttemptAddedSchedulerEvent 会交给 CapacityScheduler 。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;case APP_ATTEMPT_ADDED:  
    {  
      AppAttemptAddedSchedulerEvent appAttemptAddedEvent =  
          (AppAttemptAddedSchedulerEvent) event;  
      addApplicationAttempt(appAttemptAddedEvent.getApplicationAttemptId(),  
        appAttemptAddedEvent.getTransferStateFromPreviousAttempt(),  
        appAttemptAddedEvent.getShouldNotifyAttemptAdded());  
    }  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际上就是讲这个 attempt 放进队列，等待处理。并且：rmContext.getDispatcher().getEventHandler().handle( new RMAppAttemptEvent(applicationAttemptId, RMAppAttemptEventType.ATTEMPT_ADDED));&lt;/p&gt;

&lt;p&gt;RMAppAttemptImpl 接受到事件 RMAppAttemptEventType.ATTEMPT_ADDED 后，状态由SUBMITTED转换为SCHEDULED。进入内部类ScheduleTransition的transition函数：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private static final class ScheduleTransition  
      implements  
      MultipleArcTransition&amp;lt;RMAppAttemptImpl, RMAppAttemptEvent, RMAppAttemptState&amp;gt; {  
    @Override  
    public RMAppAttemptState transition(RMAppAttemptImpl appAttempt,  
        RMAppAttemptEvent event) {  
        LOG.info(&amp;quot;class::ScheduleTransition, func::transition, begin.&amp;quot;);  
      if (!appAttempt.submissionContext.getUnmanagedAM()) {  
        // Request a container for the AM.  
        ResourceRequest request =  
            BuilderUtils.newResourceRequest(  
                AM_CONTAINER_PRIORITY, ResourceRequest.ANY, appAttempt  
                    .getSubmissionContext().getResource(), 1);  
  
        // SchedulerUtils.validateResourceRequests is not necessary because  
        // AM resource has been checked when submission  
        Allocation amContainerAllocation = appAttempt.scheduler.allocate(  
            appAttempt.applicationAttemptId,  
            Collections.singletonList(request), EMPTY_CONTAINER_RELEASE_LIST, null, null);  
        if (amContainerAllocation != null  
            &amp;amp;&amp;amp; amContainerAllocation.getContainers() != null) {  
          assert (amContainerAllocation.getContainers().size() == 0);  
        }  
        return RMAppAttemptState.SCHEDULED;  
      } else {  
        // save state and then go to LAUNCHED state  
        appAttempt.storeAttempt();  
        return RMAppAttemptState.LAUNCHED_UNMANAGED_SAVING;  
      }  
    }  
  } 
   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里面就是：新建资源 ResourceRequest ，然后 appAttempt.scheduler.allocate&lt;/p&gt;

&lt;p&gt;&amp;mdash;&amp;mdash; 这里断层了,谁触发了 AMContainerImpl 启动和分配 Container，需要后续再看。&lt;/p&gt;

&lt;p&gt;这里有个疑问需要解答一下，之前一直好奇是哪里启动了 AMContainerImpl，上面的 schedule.allocate 将需要的资源提交给 schedule ，实际上 schedule 会分配。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;application.updateResourceRequests(ask);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这一句话，&lt;/p&gt;

&lt;p&gt;以  FairScheduler 为例，启动服务会调用 initScheduler(conf); 里面有三行代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;schedulingThread = new ContinuousSchedulingThread();
schedulingThread.setName(&amp;quot;FairSchedulerContinuousScheduling&amp;quot;);
schedulingThread.setDaemon(true);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会有守护线程调用 continuousSchedulingAttempt(); 实际上会调用：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    for (NodeId nodeId : nodeIdList) {
      FSSchedulerNode node = getFSSchedulerNode(nodeId);
      try {
        if (node != null &amp;amp;&amp;amp; Resources.fitsIn(minimumAllocation,
            node.getAvailableResource())) {
          attemptScheduling(node);
        }
      } catch (Throwable ex) {
        LOG.error(&amp;quot;Error while attempting scheduling for node &amp;quot; + node +
            &amp;quot;: &amp;quot; + ex.toString(), ex);
      }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 attemptScheduling(node); 就会创建 AMContainerImpl 实例，至于怎么创建，需要了解各个 Schedule 的内部细节。&lt;/p&gt;

&lt;p&gt;ResourceManager 为应用程序的 AM 分配资源后，创建一个 RMContainerImpl，并向它发送一个 RMContainerEventType.START 事件。&lt;/p&gt;

&lt;p&gt;RMContainerImpl 收到 RMContainerEventType.START 事件后，直接向 RMAppAttemptImpl 发送一个 RMAppAttemptEventType.CONTAINER_ALLOCATED&lt;/p&gt;

&lt;p&gt;RMAppAttemptImpl 收到 RMAppAttemptEventType.CONTAINER_ALLOCATED 事件后：调用 AMContainerAllocatedTransition：&lt;/p&gt;

&lt;p&gt;transition函数中，调用 scheduler.allocate 获取分配的资源，scheduler 返回资源之前，会向 RMContainerImpl 发送 RMContainerEventType.ALLOCATED事件。&lt;/p&gt;

&lt;p&gt;RMAppAttemptImpl 收到资源后，向 RMStateStore 发送 MStateStoreEventType.STORE_APP_ATTEMPT 事件请求记录日志。&lt;/p&gt;

&lt;p&gt;至此，RMAppAttemptImpl 状态从 SCHEDULED 转换为 ALLOCATED_SAVING。&lt;/p&gt;

&lt;p&gt;日志记录完成后，RMStateStore 向 RMAppAttemptImpl 发送 RMAppAttemptEventType.ATTEMPT_NEW_SAVED 事件。&lt;/p&gt;

&lt;p&gt;RMAppAttemptImpl 收到 RMAppAttemptEventType.ATTEMPT_NEW_SAVED 事件后，
向 ApplicationMasterLauncher 发送 AMLauncherEventType.LAUNCH 事件，
至此，RMAppAttemptImpl 状态从 ALLOCATED_SAVING 转换为 ALLOCATED。&lt;/p&gt;

&lt;p&gt;后面的和这里类似，不过涉及到了 RMContainer状态机，先跳过。&lt;/p&gt;

&lt;h2 id=&#34;3-总结&#34;&gt;3.总结&lt;/h2&gt;

&lt;p&gt;通过这个实例我们大概了解了yarn中的RPC、调度器、服务、状态机配合的过程。
一般是客户端（可以使用户的client、nodeManager进程或者它启动的container进程）发送请求，中间通过RPC调用了ResourceManager中的某个服务，这个服务会触发一定的事件，并且返回。&lt;/p&gt;

&lt;p&gt;例如客户端提交一个应用程序，首先有个 appid，每个appid对应的有一个 RMApp ，放在 rmAppManager 的一个map中。这个 RMApp 是一个状态机。&lt;/p&gt;

&lt;p&gt;然后会调用 this.rmContext.getDispatcher().getEventHandler().handle(new RMAppEvent(applicationId, RMAppEventType.START));&lt;/p&gt;

&lt;p&gt;调度器会启动对应的 EventHandle 去处理这个事件，而 对应的 EventHandle 会根据appid 通过 rmAppManager 得到对应的 RMApp，调用对应的状态转化函数就实现了状态转化。&lt;/p&gt;

&lt;p&gt;再例如某个container启动 APPMaster，也是调用
this.rmContext.getDispatcher().getEventHandler().handle
(new RMAppAttemptRegistrationEvent(applicationAttemptId, request.getHost(), request.getRpcPort(), request.getTrackingUrl()));&lt;/p&gt;

&lt;p&gt;然后调度器会启动对应的 EventHandle 去处理这个事件，而 对应的 EventHandle 会根据appid 通过 rmAppManager 得到对应的 RMApp，
这时候事件类似是 RMAppAttemptEvent，处理逻辑变了，会在另一个状态机进行操作。&lt;/p&gt;

&lt;h2 id=&#34;4-rmcontainer状态机&#34;&gt;4.RMContainer状态机&lt;/h2&gt;

&lt;p&gt;上面分析了 两个状态机，实际上还有一个 RMContainer ，这个和上面两个类似吧。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>yarn-基础库</title>
      <link>https://dengziming.github.io/post/hadoop/yarn-%E5%9F%BA%E7%A1%80%E5%BA%93/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/hadoop/yarn-%E5%9F%BA%E7%A1%80%E5%BA%93/</guid>
      
        <description>

&lt;h1 id=&#34;yarn-事件库和服务库&#34;&gt;yarn-事件库和服务库&lt;/h1&gt;

&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;新建Event和EventType&lt;/li&gt;
&lt;li&gt;新建 AsyncDispatcher 并给 AsyncDispatcher 注册 Event 和对应的 EventHandler&lt;Event&gt;&lt;/li&gt;
&lt;li&gt;调用 AsyncDispatcher 的 getEventHandler 得到 EventHandler 然后调用 handler 的 handle 方法处理 Event&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;基本原理&#34;&gt;基本原理：&lt;/h2&gt;

&lt;p&gt;AsyncDispatcher 注册 EventHandler&lt;Event&gt; 的过程实际上生成了一个 map，保存了每个事件对应的handler。同时有一个 队列，用于放置 Event&lt;/p&gt;

&lt;p&gt;调用 handle 的时候 将Event放进queue中，内部启动一个线程不断处理 queue的任务。&lt;/p&gt;

&lt;h1 id=&#34;yarn-状态机&#34;&gt;yarn-状态机&lt;/h1&gt;

&lt;h2 id=&#34;使用-1&#34;&gt;使用&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;初始化&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;StateMachineFactory
.addTransition(JobStateInternal.NEW, JobStateInternal.INITED, JobEventType.JOB_INIT,new InitTransition())
.addTransition(JobStateInternal.INITED, JobStateInternal.SETUP, JobEventType.JOB_START,new StartTransition())
.installTopology()
.make()
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新建对应的 Transition&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static class InitTransition implements SingleArcTransition&amp;lt;JobStateMachine,JobEvent&amp;gt;{

        @Override
        public void transition(JobStateMachine job, JobEvent event) {
            System.out.println(&amp;quot;Receiving event &amp;quot; + event);
        }

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;调用 StateMachine 的 doTransition(event.getType(), event)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;

&lt;p&gt;installTopology的时候创建一个拓扑图，记录每个 State 能接受的 Event，以及接受该 Event 后的操作，以及操作后的 State。&lt;/p&gt;

&lt;p&gt;每次有Event传入，调用对应的 Transition ，并且将 此时刻 的状态变为 操作后的状态。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>JanusGraph官网文档</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E5%AE%98%E7%BD%91%E6%96%87%E6%A1%A3/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E5%AE%98%E7%BD%91%E6%96%87%E6%A1%A3/</guid>
      
        <description>

&lt;h1 id=&#34;一-janusgraph-basics&#34;&gt;一、JanusGraph Basics&lt;/h1&gt;

&lt;h2 id=&#34;1-config&#34;&gt;1.config&lt;/h2&gt;

&lt;h2 id=&#34;chapter-3-getting-started&#34;&gt;Chapter 3. Getting Started&lt;/h2&gt;

&lt;p&gt;janus 使用 gremin 的基本语法，详情考：&lt;a href=&#34;http://tinkerpop.apache.org/docs/current/reference/&#34;&gt;http://tinkerpop.apache.org/docs/current/reference/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;基本操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; graph = JanusGraphFactory.open(&#39;conf/janusgraph-cassandra-es.properties&#39;)
==&amp;gt;standardjanusgraph[cassandrathrift:[127.0.0.1]]
gremlin&amp;gt; GraphOfTheGodsFactory.load(graph)
==&amp;gt;null
gremlin&amp;gt; g = graph.traversal()
==&amp;gt;graphtraversalsource[standardjanusgraph[cassandrathrift:[127.0.0.1]], standard]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里我们首先通过工厂模式 JanusGraphFactory 的 open 方法 打开一个库，然后调用 load 方法，给这个库插入数据和索引，调用 traversal 方法得到一个遍历对象 g，后续操作都基于这个 g。&lt;/p&gt;

&lt;p&gt;这里的配置文件可以修改，如果你不适用 es 作为 索引存储，这样就使用 GraphOfTheGodsFactory.loadWithoutMixedIndex() ，背后就不需要使用索引。&lt;/p&gt;

&lt;h3 id=&#34;3-3-global-graph-indices&#34;&gt;3.3. Global Graph Indices&lt;/h3&gt;

&lt;p&gt;图查询需要有一个点作为入口，然后就是通过相应的接口进行查询：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; saturn = g.V().has(&#39;name&#39;, &#39;saturn&#39;).next()
==&amp;gt;v[256]
gremlin&amp;gt; g.V(saturn).valueMap()
==&amp;gt;[name:[saturn], age:[10000]]
gremlin&amp;gt; g.V(saturn).in(&#39;father&#39;).in(&#39;father&#39;).values(&#39;name&#39;)
==&amp;gt;hercules
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里先用 has 方法，得到 name 为 saturn 的一个点 ，然后得到这个点的所有属性，通过入边找到他的 孙子。稍微复杂的查询：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; g.E().has(&#39;place&#39;, geoWithin(Geoshape.circle(37.97, 23.72, 50)))
==&amp;gt;e[a9x-co8-9hx-39s][16424-battled-&amp;gt;4240]
==&amp;gt;e[9vp-co8-9hx-9ns][16424-battled-&amp;gt;12520]
gremlin&amp;gt; g.E().has(&#39;place&#39;, geoWithin(Geoshape.circle(37.97, 23.72, 50))).as(&#39;source&#39;).inV().as(&#39;god2&#39;).select(&#39;source&#39;).outV().as(&#39;god1&#39;).select(&#39;god1&#39;, &#39;god2&#39;).by(&#39;name&#39;)
==&amp;gt;[god1:hercules, god2:hydra]
==&amp;gt;[god1:hercules, god2:nemean]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里先得到 place 位置在某个圆内的边，然后 通过 as 进行临时命令，然后得到在这个边对应的 in 和 out 的顶点。&lt;/p&gt;

&lt;p&gt;Graph indices （图索引）是 janus 索引的一种，另一种索引是 vertex-centric indices ，它用来在 janus 内部加速遍历，&lt;/p&gt;

&lt;h4 id=&#34;3-3-1-graph-traversal-examples&#34;&gt;3.3.1. Graph Traversal Examples&lt;/h4&gt;

&lt;p&gt;可以查看 &lt;a href=&#34;http://tinkerpop.apache.org/docs/current/reference/&#34;&gt;http://tinkerpop.apache.org/docs/current/reference/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;chapter-5-schema-and-data-modeling&#34;&gt;Chapter 5. Schema and Data Modeling&lt;/h2&gt;

&lt;h3 id=&#34;5-1-defining-edge-labels&#34;&gt;5.1. Defining Edge Labels&lt;/h3&gt;

&lt;p&gt;To define an edge label, call makeEdgeLabel(String) on an open graph or management transaction and provide the name of the edge label as the argument. Edge label names must be unique in the graph.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt = graph.openManagement()
follow = mgmt.makeEdgeLabel(&#39;follow&#39;).multiplicity(MULTI).make()
mother = mgmt.makeEdgeLabel(&#39;mother&#39;).multiplicity(MANY2ONE).make()
mgmt.commit()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-2-defining-property-keys&#34;&gt;5.2. Defining Property Keys&lt;/h3&gt;

&lt;p&gt;call makePropertyKey(String) on an open graph or management transaction and provide the name of the property key as the argument.&lt;/p&gt;

&lt;p&gt;Use dataType(Class) to define the data type of a property key.&lt;/p&gt;

&lt;p&gt;Use cardinality(Cardinality) to define the allowed cardinality of the values associated with the key on any given vertex.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt = graph.openManagement()
birthDate = mgmt.makePropertyKey(&#39;birthDate&#39;).dataType(Long.class).cardinality(Cardinality.SINGLE).make()
name = mgmt.makePropertyKey(&#39;name&#39;).dataType(String.class).cardinality(Cardinality.SET).make()
sensorReading = mgmt.makePropertyKey(&#39;sensorReading&#39;).dataType(Double.class).cardinality(Cardinality.LIST).make()
mgmt.commit()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-3-relation-types&#34;&gt;5.3. Relation Types&lt;/h3&gt;

&lt;p&gt;Edge labels and property keys are jointly referred to as relation types.&lt;/p&gt;

&lt;p&gt;property keys and edge labels cannot have the same name.&lt;/p&gt;

&lt;p&gt;There are methods in the JanusGraph API to query for the existence or retrieve relation types which encompasses both property keys and edge labels.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt = graph.openManagement()
if (mgmt.containsRelationType(&#39;name&#39;))
    name = mgmt.getPropertyKey(&#39;name&#39;)
mgmt.getRelationTypes(EdgeLabel.class)
mgmt.commit()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-4-defining-vertex-labels&#34;&gt;5.4. Defining Vertex Labels&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt = graph.openManagement()
person = mgmt.makeVertexLabel(&#39;person&#39;).make()
mgmt.commit()
// Create a labeled vertex
person = graph.addVertex(label, &#39;person&#39;)
// Create an unlabeled vertex
v = graph.addVertex()
graph.tx().commit()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-5-automatic-schema-maker&#34;&gt;5.5. Automatic Schema Maker&lt;/h3&gt;

&lt;h3 id=&#34;5-6-changing-schema-elements&#34;&gt;5.6. Changing Schema Elements&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt = graph.openManagement()
place = mgmt.getPropertyKey(&#39;place&#39;)
mgmt.changeName(place, &#39;location&#39;)
mgmt.commit()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note, that schema name changes may not be immediately visible in currently running transactions and other JanusGraph graph instances in the cluster.&lt;/p&gt;

&lt;h2 id=&#34;chapter-6-gremlin-query-language&#34;&gt;Chapter 6. Gremlin Query Language&lt;/h2&gt;

&lt;p&gt;Gremlin is a path-oriented language which succinctly expresses complex graph traversals and mutation operations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.janusgraph.org/latest/gremlin.html&#34;&gt;http://docs.janusgraph.org/latest/gremlin.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;6-1-introductory-traversals&#34;&gt;6.1. Introductory Traversals&lt;/h3&gt;

&lt;p&gt;A Gremlin query is a chain of operations/functions that are evaluated from left to right. A simple grandfather query is provided below over the Graph of the Gods dataset&lt;/p&gt;

&lt;p&gt;和sql相互转换： &lt;a href=&#34;http://sql2gremlin.com/&#34;&gt;http://sql2gremlin.com/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).out(&#39;father&#39;).out(&#39;father&#39;).values(&#39;name&#39;)
==&amp;gt;saturn
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;explain:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;g: for the current graph traversal.
V: for all vertices in the graph
has(&#39;name&#39;, &#39;hercules&#39;): filters the vertices down to those with name property &amp;quot;hercules&amp;quot; (there is only one).
out(&#39;father&#39;): traverse outgoing father edge’s from Hercules.
out(&#39;father&#39;): traverse outgoing father edge’s from Hercules&#39; father’s vertex (i.e. Jupiter).
name: get the name property of the &amp;quot;hercules&amp;quot; vertex’s grandfather.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; g
==&amp;gt;graphtraversalsource[janusgraph[cassandrathrift:127.0.0.1], standard]
gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;)
==&amp;gt;v[24]
gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).out(&#39;father&#39;)
==&amp;gt;v[16]
gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).out(&#39;father&#39;).out(&#39;father&#39;)
==&amp;gt;v[20]
gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).out(&#39;father&#39;).out(&#39;father&#39;).values(&#39;name&#39;)
==&amp;gt;saturn
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a sanity check, it is usually good to look at the properties of each return, not the assigned long id.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).values(&#39;name&#39;)
==&amp;gt;hercules
gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).out(&#39;father&#39;).values(&#39;name&#39;)
==&amp;gt;jupiter
gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).out(&#39;father&#39;).out(&#39;father&#39;).values(&#39;name&#39;)
==&amp;gt;saturn
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; g.V().has(&#39;name&#39;, &#39;hercules&#39;).repeat(out(&#39;father&#39;)).emit().values(&#39;name&#39;)
==&amp;gt;jupiter
==&amp;gt;saturn
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;gremlin&amp;gt; hercules = g.V().has(&#39;name&#39;, &#39;hercules&#39;).next()
==&amp;gt;v[1536]
gremlin&amp;gt; g.V(hercules).out(&#39;father&#39;, &#39;mother&#39;).label()
==&amp;gt;god
==&amp;gt;human
gremlin&amp;gt; g.V(hercules).out(&#39;battled&#39;).label()
==&amp;gt;monster
==&amp;gt;monster
==&amp;gt;monster
gremlin&amp;gt; g.V(hercules).out(&#39;battled&#39;).valueMap()
==&amp;gt;{name=nemean}
==&amp;gt;{name=hydra}
==&amp;gt;{name=cerberus}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;6-2-iterating-the-traversal&#34;&gt;6.2. Iterating the Traversal&lt;/h3&gt;

&lt;p&gt;4steps:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iterate() - Zero results are expected or can be ignored.
next() - Get one result. Make sure to check hasNext() first.
next(int n) - Get the next n results. Make sure to check hasNext() first.
toList() - Get all results as a list. If there are no results, an empty list is returned.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Traversal t = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;pluto&amp;quot;); // Define a traversal
// Note the traversal is not executed/iterated yet
Vertex pluto = null;
if (t.hasNext()) { // Check if results are available
    pluto = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;pluto&amp;quot;).next(); // Get one result
    g.V(pluto).drop().iterate(); // Execute a traversal to drop pluto from graph
}
// Note the traversal can be cloned for reuse
Traversal tt = t.asAdmin().clone();
if (tt.hasNext()) {
    System.err.println(&amp;quot;pluto was not dropped!&amp;quot;);
}
List&amp;lt;Vertex&amp;gt; gods = g.V().hasLabel(&amp;quot;god&amp;quot;).toList(); // Find all the gods
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chapter-7-janusgraph-server&#34;&gt;Chapter 7. JanusGraph Server&lt;/h2&gt;

&lt;p&gt;JanusGraph Server 应该就是类似hive的server，能够执行远程的Gremin语句。&lt;/p&gt;

&lt;h2 id=&#34;chapter-8-configuredgraphfactory&#34;&gt;Chapter 8. ConfiguredGraphFactory&lt;/h2&gt;

&lt;p&gt;应该是一个通过配置管理多个graph的工厂类。&lt;/p&gt;

&lt;h2 id=&#34;chapter-9-indexing-for-better-performance&#34;&gt;Chapter 9. Indexing for Better Performance&lt;/h2&gt;

&lt;p&gt;JanusGraph supports two different kinds of indexing to speed up query processing: graph indexes and vertex-centric indexes.&lt;/p&gt;

&lt;p&gt;Most graph queries start the traversal from a list of vertices or edges that are identified by their properties.
Graph indexes make these global retrieval operations efficient on large graphs.&lt;/p&gt;

&lt;p&gt;Vertex-centric indexes speed up the actual traversal through the graph, in particular when traversing through vertices with many incident edges.&lt;/p&gt;

&lt;h3 id=&#34;9-1-graph-index&#34;&gt;9.1. Graph Index&lt;/h3&gt;

&lt;h4 id=&#34;9-1-1-composite-index&#34;&gt;9.1.1. Composite Index&lt;/h4&gt;

&lt;h3 id=&#34;9-1-2-mixed-indexes-支持更多谓词查询&#34;&gt;9.1.2. Mixed indexes - 支持更多谓词查询&lt;/h3&gt;

&lt;p&gt;Mixed indexes - 支持更多谓词查询
composite indexes -等值查询&lt;/p&gt;

&lt;p&gt;代码： &lt;code&gt;mgmt.buildIndex(&#39;nameAndAge&#39;, Vertex.class).addKey(name).addKey(age).buildMixedIndex(&amp;quot;search&amp;quot;)&lt;/code&gt;
这里的名字 search 必须在配置中添加： index.search.backend&lt;/p&gt;

&lt;p&gt;查询方式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;g.V().has(&#39;name&#39;, textContains(&#39;hercules&#39;)).has(&#39;age&#39;, inside(20, 50))
g.V().has(&#39;name&#39;, textContains(&#39;hercules&#39;))
g.V().has(&#39;age&#39;, lt(50))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Graph indexes built against newly defined property keys, i.e. property keys that are defined in the same management transaction as the index, are immediately available. Graph indexes built against property keys that are already in use require the execution of a reindex procedure to ensure that the index contains all previously added elements. Until the reindex procedure has completed, the index will not be available. It is encouraged to define graph indexes in the same transaction as the initial schema.&lt;/p&gt;

&lt;p&gt;新定义的 properties 对应的 Graph indexes 可以马上使用，例如和 index 在一个事务中定义的 property key，马上就能使用。
对于已经在使用的 property key，需要 reindex 操作完成才能使用，所以尽量在一个事务中完成操作。&lt;/p&gt;

&lt;h4 id=&#34;9-1-3-ordering&#34;&gt;9.1.3. Ordering&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;g.V().has(&#39;name&#39;, textContains(&#39;hercules&#39;)).order().by(&#39;age&#39;, decr).limit(10)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Composite Index 不支持 order，调用 order 会很耗性能。
Mixed indexes 天生支持 order&lt;/p&gt;

&lt;h4 id=&#34;9-1-4-label-constraint&#34;&gt;9.1.4. Label Constraint&lt;/h4&gt;

&lt;p&gt;可能只想在人的 name 上面建索引，其他的顶点并没有 name 属性，这时候最好的办法就是 indexOnly
&lt;code&gt;mgmt.buildIndex(&#39;byNameAndLabel&#39;, Vertex.class).addKey(name).indexOnly(god).buildCompositeIndex()&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;9-2-vertex-centric-indexes&#34;&gt;9.2. Vertex-centric Indexes&lt;/h3&gt;

&lt;p&gt;一个顶点的入边可能有很多，遍历这些边很耗时，通过  Vertex-centric Indexes 可以得到哪些需要被选择的。&lt;/p&gt;

&lt;p&gt;查找和 hercules battled 时间为 10-20 的人。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;h = g.V().has(&#39;name&#39;, &#39;hercules&#39;).next()
g.V(h).outE(&#39;battled&#39;).has(&#39;time&#39;, inside(10, 20)).inV()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样会遍历，我们可以添加索引。我们可以： Building a vertex-centric index by time speeds up such traversal queries.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;graph.tx().rollback()  //Never create new indexes while a transaction is active
mgmt = graph.openManagement()
time = mgmt.getPropertyKey(&#39;time&#39;)
battled = mgmt.getEdgeLabel(&#39;battled&#39;)
mgmt.buildEdgeIndex(battled, &#39;battlesByTime&#39;, Direction.BOTH, Order.decr, time)
mgmt.commit()
//Wait for the index to become available
mgmt.awaitGraphIndexStatus(graph, &#39;battlesByTime&#39;).call()
//Reindex the existing data
mgmt = graph.openManagement()
mgmt.updateIndex(mgmt.getGraphIndex(&amp;quot;battlesByTime&amp;quot;), SchemaAction.REINDEX).get()
mgmt.commit()
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;9-2-1-ordered-traversals&#34;&gt;9.2.1. Ordered Traversals&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;h = g..V().has(&#39;name&#39;, &#39;hercules&#39;).next()
g.V(h).local(outE(&#39;battled&#39;).order().by(&#39;time&#39;, decr).limit(10)).inV().values(&#39;name&#39;)
g.V(h).local(outE(&#39;battled&#39;).has(&#39;rating&#39;, 5.0).order().by(&#39;time&#39;, decr).limit(10)).values(&#39;place&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;chapter-10-transactions&#34;&gt;Chapter 10. Transactions&lt;/h2&gt;

&lt;p&gt;所有的操作都是在一个 transaction 里面的， graph.tx().createThreadedTx() 创建 ThreadLocal 的 transatlantion 。但并不是 ACID ，因为底层的不支持，手动模拟 ACID 也很负责。&lt;/p&gt;

&lt;h3 id=&#34;10-1-transaction-handling&#34;&gt;10.1. Transaction Handling&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;graph = JanusGraphFactory.open(&amp;quot;berkeleyje:/tmp/janusgraph&amp;quot;)
juno = graph.addVertex() //Automatically opens a new transaction
juno.property(&amp;quot;name&amp;quot;, &amp;quot;juno&amp;quot;)
graph.tx().commit() //Commits transaction
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的第二段代码自动打开了一个 transaction 。&lt;/p&gt;

&lt;h3 id=&#34;10-2-transactional-scope&#34;&gt;10.2. Transactional Scope&lt;/h3&gt;

&lt;p&gt;图中的每个元素，例如边、顶点都是有 scope 的，按照 TinkerPop 的 transaction 约定，事务在第一条语句执行的时候自动创建，commit 或者 rollback 的时候会被关闭，
一旦关闭了，在事务中创建的元素都不能用了。但是，JanusGraph will automatically transition vertices and types into the new transactional scope:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;graph = JanusGraphFactory.open(&amp;quot;berkeleyje:/tmp/janusgraph&amp;quot;)
juno = graph.addVertex() //Automatically opens a new transaction
graph.tx().commit() //Ends transaction
juno.property(&amp;quot;name&amp;quot;, &amp;quot;juno&amp;quot;) //Vertex is automatically transitioned
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是边就不能这样&lt;/p&gt;

&lt;h3 id=&#34;10-3-transaction-failures&#34;&gt;10.3. Transaction Failures&lt;/h3&gt;

&lt;h3 id=&#34;10-4-multi-threaded-transactions&#34;&gt;10.4. Multi-Threaded Transactions&lt;/h3&gt;

&lt;h3 id=&#34;10-5-concurrent-algorithms&#34;&gt;10.5. Concurrent Algorithms&lt;/h3&gt;

&lt;h3 id=&#34;10-6-nested-transactions&#34;&gt;10.6. Nested Transactions&lt;/h3&gt;

&lt;h3 id=&#34;10-7-common-transaction-handling-problems&#34;&gt;10.7. Common Transaction Handling Problems&lt;/h3&gt;

&lt;h3 id=&#34;10-8-transaction-configuration&#34;&gt;10.8. Transaction Configuration&lt;/h3&gt;

&lt;h2 id=&#34;chapter-11-janusgraph-cache&#34;&gt;Chapter 11. JanusGraph Cache&lt;/h2&gt;

&lt;h2 id=&#34;chapter-12-transaction-log&#34;&gt;Chapter 12. Transaction Log&lt;/h2&gt;

&lt;h1 id=&#34;part-iii-storage-backends&#34;&gt;Part III. Storage Backends&lt;/h1&gt;

&lt;p&gt;hbase&lt;/p&gt;

&lt;p&gt;cassandra&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraph graph = JanusGraphFactory.build().
	set(&amp;quot;storage.backend&amp;quot;, &amp;quot;hbase&amp;quot;).
	open();
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;iv-index-backends&#34;&gt;IV. Index Backends&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Elasticsearch&lt;/li&gt;
&lt;li&gt;Apache Solr&lt;/li&gt;
&lt;li&gt;Apache Lucene&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;v-advanced-topics&#34;&gt;V. Advanced Topics&lt;/h1&gt;

&lt;h1 id=&#34;vi-janusgraph-internals&#34;&gt;VI. JanusGraph Internals&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://docs.janusgraph.org/latest/data-model.html&#34;&gt;http://docs.janusgraph.org/latest/data-model.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;chapter-38-janusgraph-data-model&#34;&gt;Chapter 38. JanusGraph Data Model&lt;/h2&gt;
</description>
      
    </item>
    
    <item>
      <title>分布式算法理论</title>
      <link>https://dengziming.github.io/post/%E7%90%86%E8%AE%BA/first/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E7%90%86%E8%AE%BA/first/</guid>
      
        <description>

&lt;h2 id=&#34;一-算法&#34;&gt;一、算法&lt;/h2&gt;

&lt;h2 id=&#34;二-理论&#34;&gt;二、理论&lt;/h2&gt;

&lt;h3 id=&#34;1-two-phase-commit-protocol&#34;&gt;1. Two-phase commit protocol&lt;/h3&gt;

&lt;p&gt;直接翻译维基百科的解释了：
&lt;a href=&#34;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&#34;&gt;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In transaction processing, databases, and computer networking, the two-phase commit protocol (2PC) is a type of atomic commitment protocol (ACP).&lt;/p&gt;

&lt;p&gt;在处理事务、数据库和计算机网络，2PC是一种原子性提交协议&lt;/p&gt;

&lt;p&gt;It is a distributed algorithm that coordinates all the processes that participate in a distributed atomic transaction on whether to commit or abort (roll back)
the transaction (it is a specialized type of consensus protocol).&lt;/p&gt;

&lt;p&gt;2PC是一种 协调所有参与分布式原子事务的进程 是否 提交或者放弃提交事务 的分布式算法。&lt;/p&gt;

&lt;p&gt;The protocol achieves its goal even in many cases of temporary system failure (involving either process, network node, communication, etc. failures),
and is thus widely used.[1][2][3] However, it is not resilient to all possible failure configurations,
and in rare cases, user (e.g., a system&amp;rsquo;s administrator) intervention is needed to remedy an outcome.&lt;/p&gt;

&lt;p&gt;这个协议在很多临时的系统系统失败的时候达到它的目的，所以会广泛应用。但是，这个挺不是在所有可能的配置都是可伸缩的。
在极少数情况下，需要用户人为干预补救结果。&lt;/p&gt;

&lt;p&gt;To accommodate recovery from failure (automatic in most cases) the protocol&amp;rsquo;s participants use logging of the protocol&amp;rsquo;s states.&lt;/p&gt;

&lt;p&gt;为了容纳失败后的恢复（大多时候是自动的），协议的参与者通过日志记录协议的状态。&lt;/p&gt;

&lt;p&gt;Log records, which are typically slow to generate but survive failures, are used by the protocol&amp;rsquo;s recovery procedures.&lt;/p&gt;

&lt;p&gt;日志记录，一般用在协议的恢复过程中，一般生成比较慢，但是失败的时候不会被删掉。&lt;/p&gt;

&lt;p&gt;Many protocol variants exist that primarily differ in logging strategies and recovery mechanisms.&lt;/p&gt;

&lt;p&gt;这个协议的有很多延伸算法，不同点主要是记录日志的策略和恢复机制。&lt;/p&gt;

&lt;p&gt;Though usually intended to be used infrequently, recovery procedures compose a substantial portion of the protocol,&lt;/p&gt;

&lt;p&gt;尽管很少被使用，恢复策略是这个协议的关键部分，&lt;/p&gt;

&lt;p&gt;due to many possible failure scenarios to be considered and supported by the protocol.&lt;/p&gt;

&lt;p&gt;由于许多可能的恢复场景都需要考虑支持这个协议。&lt;/p&gt;

&lt;p&gt;In a &amp;ldquo;normal execution&amp;rdquo; of any single distributed transaction ( i.e., when no failure occurs, which is typically the most frequent situation), the protocol consists of two phases:&lt;/p&gt;

&lt;p&gt;在很多单一的分布式系统事务中，一个简单普通操作，这个协议包含两部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The commit-request phase (or voting phase), in which a coordinator process attempts to prepare all the transaction&amp;rsquo;s participating processes (named participants, cohorts, or workers)
to take the necessary steps for either committing or aborting the transaction and to vote, either &amp;ldquo;Yes&amp;rdquo;: commit (if the transaction participant&amp;rsquo;s local portion execution has ended properly), or &amp;ldquo;No&amp;rdquo;: abort (if a problem has been detected with the local portion),&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第一个是请求提交阶段，或者投票阶段，这个阶段协调者尝试 准备所有的事务的参与者（我们也叫他们participants, cohorts, or workers）采取必要的步骤提交或者放弃，然后投票yes或者no，分别代表commit或者abort&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;and The commit phase, in which, based on voting of the cohorts, the coordinator decides whether to commit (only if all have voted &amp;ldquo;Yes&amp;rdquo;) or abort the transaction (otherwise),
and notifies the result to all the cohorts. The cohorts then follow with the needed actions (commit or abort) with their local transactional resources (also called recoverable resources; e.g., database data)
and their respective portions in the transaction&amp;rsquo;s other output (if applicable).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第二个阶段是提交截断，基于 cohorts 的投票结果，coordinator决定是否提交或者放弃。然后向 所有的 cohorts 通知结果。
cohorts将会使用本地资源(also called recoverable resources; e.g., database data) 和他们各自比例 来执行对应的actions 。&lt;/p&gt;

&lt;p&gt;Note that the two-phase commit (2PC) protocol should not be confused with the two-phase locking (2PL) protocol, a concurrency control protocol.&lt;/p&gt;

&lt;h4 id=&#34;assumptions&#34;&gt;Assumptions&lt;/h4&gt;

&lt;p&gt;The protocol works in the following manner: one node is a designated coordinator,
which is the master site, and the rest of the nodes in the network are designated the cohorts.&lt;/p&gt;

&lt;p&gt;该协议以如下方式工作：一个节点是指定的协调器，它是主站点，而网络中的其余节点被指定为同伙。&lt;/p&gt;

&lt;p&gt;The protocol assumes that there is stable storage at each node with a write-ahead log, that no node crashes forever,
that the data in the write-ahead log is never lost or corrupted in a crash, and that any two nodes can communicate with each other.&lt;/p&gt;

&lt;p&gt;该协议假定在每个节点上有一个提前写入日志的稳定存储，即没有节点永远崩溃，写入前日志中的数据在崩溃中从未丢失或损坏，并且任何两个节点可以彼此通信。&lt;/p&gt;

&lt;p&gt;The last assumption is not too restrictive, as network communication can typically be rerouted.
The first two assumptions are much stronger; if a node is totally destroyed then data can be lost.&lt;/p&gt;

&lt;p&gt;最后一个假设不是太严格，因为网络通信通常可以重新路由。前两个假设强得多；如果一个节点被完全破坏，那么数据就会丢失。&lt;/p&gt;

&lt;p&gt;The protocol is initiated by the coordinator after the last step of the transaction has been reached.
The cohorts then respond with an agreement message or an abort message depending on whether the transaction has been processed successfully at the cohort.&lt;/p&gt;

&lt;p&gt;该协议是在事务的最后一步到达之后由协调器发起的。同伙随后根据协议消息或中止消息来响应，这取决于事务是否在队列中被成功处理。&lt;/p&gt;

&lt;h4 id=&#34;basic-algorithm&#34;&gt;Basic algorithm&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Commit request phase or voting phase&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The coordinator sends a query to commit message to all cohorts and waits until it has received a reply from all cohorts.&lt;/p&gt;

&lt;p&gt;coordinator 给所有的 cohorts 发送一个commit message 然后等到所有的 cohorts 回复。&lt;/p&gt;

&lt;p&gt;The cohorts execute the transaction up to the point where they will be asked to commit.
They each write an entry to their undo log and an entry to their redo log.&lt;/p&gt;

&lt;p&gt;cohorts执行事务，那是他们将会被要求提交，他们各自写一个条目到他们的撤销日志和一个条目到他们的重做日志。&lt;/p&gt;

&lt;p&gt;Each cohort replies with an agreement message (cohort votes Yes to commit), if the cohort&amp;rsquo;s actions succeeded,
or an abort message (cohort votes No, not to commit), if the cohort experiences a failure that will make it impossible to commit.&lt;/p&gt;

&lt;p&gt;每个 cohort 回复一个 agreement message ，如果这个cohort的action成功（cohort votes Yes to commit），
或者 cohort experiences a failure that will make it impossible to commit，回复 an abort message (cohort votes No, not to commit)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Commit phase or Completion phase&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;Success：If the coordinator received an agreement message from all cohorts during the commit-request phase:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果 coordinator 收到从所有的 cohorts 收到一个an agreement message&lt;/p&gt;

&lt;p&gt;The coordinator sends a commit message to all the cohorts.&lt;/p&gt;

&lt;p&gt;coordinator 给所有的 cohorts 发送一个 commit message&lt;/p&gt;

&lt;p&gt;Each cohort completes the operation, and releases all the locks and resources held during the transaction.&lt;/p&gt;

&lt;p&gt;每个 cohort 完成 operation，释放 transaction 持有的 locks and resources&lt;/p&gt;

&lt;p&gt;Each cohort sends an acknowledgment to the coordinator.&lt;/p&gt;

&lt;p&gt;每个 cohort get coordinator 发送一个 acknowledgment。&lt;/p&gt;

&lt;p&gt;The coordinator completes the transaction when all acknowledgments have been received.&lt;/p&gt;

&lt;p&gt;coordinator 收到所有的 acknowledgments 完成 transaction 。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Failure：If any cohort votes No during the commit-request phase (or the coordinator&amp;rsquo;s timeout expires):&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The coordinator sends a rollback message to all the cohorts.&lt;/p&gt;

&lt;p&gt;Each cohort undoes the transaction using the undo log, and releases the resources and locks held during the transaction.&lt;/p&gt;

&lt;p&gt;Each cohort sends an acknowledgement to the coordinator.&lt;/p&gt;

&lt;p&gt;The coordinator undoes the transaction when all acknowledgements have been received.&lt;/p&gt;

&lt;p&gt;类似上面的过程。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Message flow&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;Coordinator                                         Cohort
                              QUERY TO COMMIT
                --------------------------------&amp;gt;
                              VOTE YES/NO           prepare*/abort*
                &amp;lt;-------------------------------
commit*/abort*                COMMIT/ROLLBACK
                --------------------------------&amp;gt;
                              ACKNOWLEDGMENT        commit*/abort*
                &amp;lt;--------------------------------  
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An * next to the record type means that the record is forced to stable storage.[4]&lt;/p&gt;

&lt;p&gt;&lt;code&gt;*&lt;/code&gt; 代表 record 已经强制刷新到 stable storage。&lt;/p&gt;

&lt;h2 id=&#34;disadvantages&#34;&gt;Disadvantages&lt;/h2&gt;

&lt;p&gt;The greatest disadvantage of the two-phase commit protocol is that it is a blocking protocol.
If the coordinator fails permanently, some cohorts will never resolve their transactions: After a cohort has sent an agreement message to the coordinator, it will block until a commit or rollback is received.&lt;/p&gt;

&lt;p&gt;是一个 阻塞式协议，coordinator 如果失败了，cohorts可能会永远得不到回复。&lt;/p&gt;

&lt;p&gt;上面介绍了 2PC，2PC的劣势已经了解，接下来我们认识3PC&lt;/p&gt;

&lt;h3 id=&#34;three-phase-commit-protocol&#34;&gt;Three-phase commit protocol&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;status Coordinator                              Cohort status
                              can COMMIT ?
                --------------------------------&amp;gt;
                              VOTE YES/NO           Uncertain
                &amp;lt;-------------------------------    timeout cause abort
commit authorized  
                              precommit
                --------------------------------&amp;gt;    prepare to commit
                              ACKNOWLEDGMENT        
                &amp;lt;--------------------------------  
finalize commit               do COMMIT
timeout cause abort --------------------------------&amp;gt;
                              have COMMITED           commited
                &amp;lt;--------------------------------  
end
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析1-下载编译启动</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph 了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-相关问题&#34;&gt;一、相关问题&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/JanusGraph/janusgraph/issues/1157&#34;&gt;https://github.com/JanusGraph/janusgraph/issues/1157&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;reindex 的时候，一直等待三分钟。并且打印日志：
&amp;ldquo;&amp;ldquo;2018-06-10 09:03:19 [Thread-15] ERROR o.j.g.d.management.ManagementLogger - Evicted [6@6d56b8c524955-pc-jblur-com3] from cache but waiting too long for transactions to close. Stale transaction alert on: [standardjanusgraphtx[0x67a3ba21], standardjanusgraphtx[0x6cf78315], standardjanusgraphtx[0x48ce7bcd], standardjanusgraphtx[0x1862c45e], standardjanusgraphtx[0x04c1309d], standardjanusgraphtx[0x13bda0b2], standardjanusgraphtx[0x1187c9e8]]&lt;/p&gt;

&lt;p&gt;实际上原因是
There is a bug when we are reindexing a new index in an empty database. The process tries to fetch data from the database but there are no data. Because of that, the process tries to get some data for 3 minutes with the similar error logged as this one:&lt;/p&gt;

&lt;p&gt;我已经做了修复并提交到 janusgraph 的源码，等待merge。
&lt;a href=&#34;https://github.com/JanusGraph/janusgraph/pull/1162&#34;&gt;https://github.com/JanusGraph/janusgraph/pull/1162&lt;/a&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析1-下载编译启动</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E4%B8%8B%E8%BD%BD%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E4%B8%8B%E8%BD%BD%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph 了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-下载编译&#34;&gt;一、下载编译&lt;/h2&gt;

&lt;p&gt;我直接使用github desktop打开了 janusgraph 的源码，使用IDEA打开，然后编译：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# 编译完整的
mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests clean install
# 只编译core部分
mvn -pl janusgraph-core -am clean install -Dlicense.skip=true -DskipTests -P prod

-rf :janusgraph-test
mvn -pl janusgraph-test -am clean install -Dlicense.skip=true -DskipTests -P prod
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们在 &lt;code&gt;janusgraph-test&lt;/code&gt; 下面编写一个例子 &lt;code&gt;FirstTest&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class FirstTest {

    public static void main(String[] args) {

        /*
         * The example below will open a JanusGraph graph instance and load The Graph of the Gods dataset diagrammed above.
         * JanusGraphFactory provides a set of static open methods,
         * each of which takes a configuration as its argument and returns a graph instance.
         * This tutorial calls one of these open methods on a configuration
         * that uses the BerkeleyDB storage backend and the Elasticsearch index backend,
         * then loads The Graph of the Gods using the helper class GraphOfTheGodsFactory.
         * This section skips over the configuration details, but additional information about storage backends,
         * index backends, and their configuration are available in
         * Part III, “Storage Backends”, Part IV, “Index Backends”, and Chapter 13, Configuration Reference.
         */

        // Loading the Graph of the Gods Into JanusGraph
        JanusGraph graph = JanusGraphFactory
                .open(&amp;quot;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;quot;);

        GraphOfTheGodsFactory.load(graph);
        GraphTraversalSource g = graph.traversal();

        /*
         * The typical pattern for accessing data in a graph database is to first locate the entry point into the graph
         * using a graph index. That entry point is an element (or set of elements) 
         * — i.e. a vertex or edge. From the entry elements,
         * a Gremlin path description describes how to traverse to other elements in the graph via the explicit graph structure.
         * Given that there is a unique index on name property, the Saturn vertex can be retrieved.
         * The property map (i.e. the key/value pairs of Saturn) can then be examined.
         * As demonstrated, the Saturn vertex has a name of &amp;quot;saturn, &amp;quot; an age of 10000, and a type of &amp;quot;titan.&amp;quot;
         * The grandchild of Saturn can be retrieved with a traversal that expresses:
         * &amp;quot;Who is Saturn’s grandchild?&amp;quot; (the inverse of &amp;quot;father&amp;quot; is &amp;quot;child&amp;quot;). The result is Hercules.
         */
        // Global Graph Indices
        Vertex saturn = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).next();
        GraphTraversal&amp;lt;Vertex, Map&amp;lt;String, Object&amp;gt;&amp;gt; vertexMapGraphTraversal = g.V(saturn).valueMap();

        GraphTraversal&amp;lt;Vertex, Object&amp;gt; values = g.V(saturn).in(&amp;quot;father&amp;quot;).in(&amp;quot;father&amp;quot;).values(&amp;quot;name&amp;quot;);

        /*
         * The property place is also in a graph index. The property place is an edge property.
         * Therefore, JanusGraph can index edges in a graph index.
         * It is possible to query The Graph of the Gods for all events that have happened within 50 kilometers of Athens
          * (latitude:37.97 and long:23.72).
          * Then, given that information, which vertices were involved in those events.
         */
		System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50))));
        System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50)))
                .as(&amp;quot;source&amp;quot;).inV()
                .as(&amp;quot;god2&amp;quot;)
                .select(&amp;quot;source&amp;quot;).outV()
                .as(&amp;quot;god1&amp;quot;).select(&amp;quot;god1&amp;quot;, &amp;quot;god2&amp;quot;)
                .by(&amp;quot;name&amp;quot;));
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在&amp;rdquo;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;rdquo; 文件中，将注释掉的内容取消注释。&lt;/p&gt;

&lt;p&gt;运行发现依赖挺麻烦。
首先运行报错了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.IllegalArgumentException: Could not find implementation class: org.janusgraph.diskstorage.berkeleyje.BerkeleyJEStoreManager
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;找到报错处的代码，我们发现 &lt;code&gt;janusgraph-core&lt;/code&gt; 中通过反射创建一个类，但是这个类在 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt; 中，而前者不依赖后者，所以找不到这个类，我们可以将后者加到前者的依赖，
但是我们发现后者依赖前者，如果加了依赖两个就相互依赖了，这是 Janus 官方设计的问题。我们只好在 FirstTest 所在的module中把两个依赖都加进来试试。
（注意，如果我们将所有的都打进一个包，这个问题就不存在了，但是在本地运行是不一样的，各自模块的编译输出文件在不同的地方。）在 &lt;code&gt;janusgraph-test&lt;/code&gt; 中添加：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.janusgraph&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;janusgraph-berkeleyje&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;0.3.0-SNAPSHOT&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;也依赖了 &lt;code&gt;janusgraph-test&lt;/code&gt;,又相互依赖了，好麻烦。我们写写代码一定要注意这个问题。这里我的解决方法是直接把 代码放到 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt; 中运行。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.IllegalArgumentException: Could not find implementation class: org.janusgraph.diskstorage.es.ElasticSearchIndex
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和上面一样，还依赖了 &lt;code&gt;janusgraph-es&lt;/code&gt;,我只好吧代码复制到 &lt;code&gt;janusgraph-es&lt;/code&gt; 的test代码块中运行（注意一点是test代码中），顺便在 &lt;code&gt;janusgraph-es&lt;/code&gt; 中 添加上&lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;的依赖。
运行成功了，但是报了连接失败，是因为我本地没有启动es，我启动一下es：&lt;code&gt;elasticsearch&lt;/code&gt;
然后在运行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Exception in thread &amp;quot;main&amp;quot; org.janusgraph.core.SchemaViolationException: Adding this property for key [~T$SchemaName] and value [rtname] violates a uniqueness constraint [SystemIndex#~T$SchemaName]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;经过google查到原因： &lt;a href=&#34;https://groups.google.com/forum/#!topic/aureliusgraphs/vZ_nTXlXj4k&#34;&gt;https://groups.google.com/forum/#!topic/aureliusgraphs/vZ_nTXlXj4k&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;This exception is thrown only when you already have added property key to index. So &amp;quot;name&amp;quot; is already added and next time when you run your program somewhere it is again adding &amp;quot;name&amp;quot; property key. So check if that particular code is running twice
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们可以在我们传入的配置文件找到：storage.directory=../db/berkeley  ，直接删除这个目录，再重新运行，就成功了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;11:20:17,051  INFO GraphDatabaseConfiguration:1285 - Set default timestamp provider MICRO
11:20:17,296  INFO GraphDatabaseConfiguration:1492 - Generated unique-instance-id=c0a815a789637-dengzimings-MacBook-Pro-local1
11:20:17,547  INFO Backend:462 - Configuring index [search]
11:20:19,279  INFO Backend:177 - Initiated backend operations thread pool of size 8
11:20:19,461  INFO KCVSLog:753 - Loaded unidentified ReadMarker start time 2018-04-26T03:20:19.408Z into org.janusgraph.diskstorage.log.kcvs.KCVSLog$MessagePuller@73cd37c0
[GraphStep(edge,[]), HasStep([place.geoWithin(BUFFER (POINT (23.72 37.97), 0.44966))])]
[GraphStep(edge,[]), HasStep([place.geoWithin(BUFFER (POINT (23.72 37.97), 0.44966))])@[source], EdgeVertexStep(IN)@[god2], SelectOneStep(last,source), EdgeVertexStep(OUT)@[god1], SelectStep(last,[god1, god2],[value(name)])]
11:20:29,578  INFO ManagementLogger:192 - Received all acknowledgements for eviction [1]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们可以去 ../db/berkeley  目录查看，多了一些文件，这些文件的作用我们后续再分析。
然后我们取es查看：&lt;code&gt;curl -XGET &#39;localhost:9200/_cat/indices?v&amp;amp;pretty&#39;&lt;/code&gt; ，发现多了两个index:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yellow open   janusgraph_edges    QT-E7AV6SMWr8Cu_ywKsXg   5   1          6            0     13.7kb         13.7kb
yellow open   janusgraph_vertices gE4TSXFATnSZUWYdAf46Xg   5   1          6            0     10.9kb         10.9kb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还可以具体查看内容。例如名字是titan的内容：&lt;code&gt;curl -XGET &#39;localhost:9200/janusgraph_vertices/_search?q=name:titan&amp;amp;pretty&#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;到现在我们第一个案例就结束了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50)))
                .as(&amp;quot;source&amp;quot;).inV()
                .as(&amp;quot;god2&amp;quot;)
                .select(&amp;quot;source&amp;quot;).outV()
                .as(&amp;quot;god1&amp;quot;).select(&amp;quot;god1&amp;quot;, &amp;quot;god2&amp;quot;)
                .by(&amp;quot;name&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种风格的代码实际上是groovy语言的代码，大家可以研究一下groovy语言。&lt;/p&gt;

&lt;p&gt;注意事项：
上述第一次运行问题的原因是 &lt;code&gt;janusgraph-core&lt;/code&gt;需要用到 &lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;的类，
但是&lt;code&gt;janusgraph-berkeleyje&lt;/code&gt;是依赖 &lt;code&gt;janusgraph-core&lt;/code&gt;的，所以两个相互依赖了。
janus的做法是在core中使用反射，所以编译通过了，打包到了一起就没问题了。但是本地运行没法成功。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析1-下载编译启动</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9010-gremin/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9010-gremin/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph 了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-调试&#34;&gt;一、调试&lt;/h2&gt;

&lt;p&gt;首先阅读以下 &lt;a href=&#34;http://tinkerpop.apache.org/docs/3.3.3/reference/#traversal&#34;&gt;http://tinkerpop.apache.org/docs/3.3.3/reference/#traversal&lt;/a&gt; ，了解一下。&lt;/p&gt;

&lt;p&gt;GraphTraversalSource g = graph.traversal();&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析2-实例debug</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%AE%9E%E4%BE%8Bdebug/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%AE%9E%E4%BE%8Bdebug/</guid>
      
        <description>

&lt;p&gt;#
研究了好久的 neo4j源码，现在公司要换 janusgraph，只要半途而废开始研究 janusgraph了
&lt;code&gt;https://github.com/JanusGraph/janusgraph&lt;/code&gt;和&lt;code&gt;http://janusgraph.org/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-第一遍调试&#34;&gt;一、第一遍调试&lt;/h2&gt;

&lt;p&gt;还是上次的例子 &lt;code&gt;FirstTest&lt;/code&gt;：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class FirstTest {

    public static void main(String[] args) {

        /*
         * The example below will open a JanusGraph graph instance and load The Graph of the Gods dataset diagrammed above.
         * JanusGraphFactory provides a set of static open methods,
         * each of which takes a configuration as its argument and returns a graph instance.
         * This tutorial calls one of these open methods on a configuration
         * that uses the BerkeleyDB storage backend and the Elasticsearch index backend,
         * then loads The Graph of the Gods using the helper class GraphOfTheGodsFactory.
         * This section skips over the configuration details, but additional information about storage backends,
         * index backends, and their configuration are available in
         * Part III, “Storage Backends”, Part IV, “Index Backends”, and Chapter 13, Configuration Reference.
         */

        // Loading the Graph of the Gods Into JanusGraph
        JanusGraph graph = JanusGraphFactory
                .open(&amp;quot;janusgraph-dist/src/assembly/cfilter/conf/janusgraph-berkeleyje-es.properties&amp;quot;);

        GraphOfTheGodsFactory.load(graph);
        GraphTraversalSource g = graph.traversal();

        /*
         * The typical pattern for accessing data in a graph database is to first locate the entry point into the graph
         * using a graph index. That entry point is an element (or set of elements) 
         * — i.e. a vertex or edge. From the entry elements,
         * a Gremlin path description describes how to traverse to other elements in the graph via the explicit graph structure.
         * Given that there is a unique index on name property, the Saturn vertex can be retrieved.
         * The property map (i.e. the key/value pairs of Saturn) can then be examined.
         * As demonstrated, the Saturn vertex has a name of &amp;quot;saturn, &amp;quot; an age of 10000, and a type of &amp;quot;titan.&amp;quot;
         * The grandchild of Saturn can be retrieved with a traversal that expresses:
         * &amp;quot;Who is Saturn’s grandchild?&amp;quot; (the inverse of &amp;quot;father&amp;quot; is &amp;quot;child&amp;quot;). The result is Hercules.
         */
        // Global Graph Indices
        Vertex saturn = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).next();
        GraphTraversal&amp;lt;Vertex, Map&amp;lt;String, Object&amp;gt;&amp;gt; vertexMapGraphTraversal = g.V(saturn).valueMap();

        GraphTraversal&amp;lt;Vertex, Object&amp;gt; values = g.V(saturn).in(&amp;quot;father&amp;quot;).in(&amp;quot;father&amp;quot;).values(&amp;quot;name&amp;quot;);

        /*
         * The property place is also in a graph index. The property place is an edge property.
         * Therefore, JanusGraph can index edges in a graph index.
         * It is possible to query The Graph of the Gods for all events that have happened within 50 kilometers of Athens
          * (latitude:37.97 and long:23.72).
          * Then, given that information, which vertices were involved in those events.
         */
		System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50))));
        System.out.println(g.E().has(&amp;quot;place&amp;quot;, geoWithin(Geoshape.circle(37.97, 23.72, 50)))
                .as(&amp;quot;source&amp;quot;).inV()
                .as(&amp;quot;god2&amp;quot;)
                .select(&amp;quot;source&amp;quot;).outV()
                .as(&amp;quot;god1&amp;quot;).select(&amp;quot;god1&amp;quot;, &amp;quot;god2&amp;quot;)
                .by(&amp;quot;name&amp;quot;));
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;删除 db 文件夹，打上断点，开始debug，首先进入：JanusGraphFactory.open&lt;/p&gt;

&lt;p&gt;JanusGraphFactory is used to open or instantiate a JanusGraph graph database.
Opens a {@link JanusGraph} database configured according to the provided configuration.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static JanusGraph open(ReadConfiguration configuration, String backupName) {
    final ModifiableConfiguration config = new ModifiableConfiguration(ROOT_NS, (WriteConfiguration) configuration, BasicConfiguration.Restriction.NONE);
    final String graphName = config.has(GRAPH_NAME) ? config.get(GRAPH_NAME) : backupName;
    final JanusGraphManager jgm = JanusGraphManagerUtility.getInstance();
    if (null != graphName) {
        Preconditions.checkState(jgm != null, JANUS_GRAPH_MANAGER_EXPECTED_STATE_MSG);
        return (JanusGraph) jgm.openGraph(graphName, gName -&amp;gt; new StandardJanusGraph(new GraphDatabaseConfiguration(configuration)));
    } else {
        if (jgm != null) {
            log.warn(&amp;quot;...&amp;quot;);
        }
        return new StandardJanusGraph(new GraphDatabaseConfiguration(configuration));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前面的部分先跳过，然后进入：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. return new StandardJanusGraph(new GraphDatabaseConfiguration(configuration));
    // 构造方法，分为静态代码和构造方法，这部分目前是跳过，但是后续是重点和核心。
    1. 父类：JanusGraphBlueprintsGraph
        static {
        TraversalStrategies graphStrategies = TraversalStrategies.GlobalCache.getStrategies(Graph.class).clone()
                .addStrategies(AdjacentVertexFilterOptimizerStrategy.instance(), JanusGraphLocalQueryOptimizerStrategy.instance(), JanusGraphStepStrategy.instance());

        //Register with cache
        TraversalStrategies.GlobalCache.registerStrategies(StandardJanusGraph.class, graphStrategies);
        TraversalStrategies.GlobalCache.registerStrategies(StandardJanusGraphTx.class, graphStrategies);
        }
    2. 新建配置，A graph database configuration is uniquely associated with a graph database and must not be used for multiple databases
    
    new GraphDatabaseConfiguration(configuration)
        1. storeManager 
        final KeyColumnValueStoreManager storeManager = Backend.getStorageManager(localBasicConfiguration);
        final StoreFeatures storeFeatures = storeManager.getFeatures();
        2. 检查参数，配置等
    
    3. 然后是构造方法
        1. 成员变量
        private final SchemaCache.StoreRetrieval typeCacheRetrieval = new SchemaCache.StoreRetrieval() {}
        2. backend
        this.backend = configuration.getBackend();
            1. Backend backend = new Backend(configuration);
                1. KeyColumnValueStoreManager manager = getStorageManager(configuration);
                2. indexes = getIndexes(configuration);
                
                3. //这里的 KCVS 是 keycolumnvaluestorageManager
                managementLogManager = getKCVSLogManager(MANAGEMENT_LOG);
        		txLogManager = getKCVSLogManager(TRANSACTION_LOG);
        		userLogManager = getLogManager(USER_LOG);
        		
        		4. scanner = new StandardScanner(storeManager);
                
            2. backend.initialize(configuration);
                1. store 新建
                KeyColumnValueStore idStore = storeManager.openDatabase(config.get(IDS_STORE_NAME));
                KeyColumnValueStore edgeStoreRaw = storeManagerLocking.openDatabase(EDGESTORE_NAME);
            	KeyColumnValueStore indexStoreRaw = storeManagerLocking.openDatabase(INDEXSTORE_NAME);
                
                2. cacheEnabled
                edgeStore = new NoKCVSCache(edgeStoreRaw);
                indexStore = new NoKCVSCache(indexStoreRaw);
            3. storeFeatures = backend.getStoreFeatures();
        3. 初始化
        this.idAssigner = config.getIDAssigner(backend);
        this.idManager = idAssigner.getIDManager();
        this.serializer = config.getSerializer();
        StoreFeatures storeFeatures = backend.getStoreFeatures();
        this.indexSerializer = new IndexSerializer(configuration.getConfiguration(), this.serializer,
        this.backend.getIndexInformation(), storeFeatures.isDistributed() &amp;amp;&amp;amp; storeFeatures.isKeyOrdered());
        this.edgeSerializer = new EdgeSerializer(this.serializer);
        this.vertexExistenceQuery = edgeSerializer.getQuery(BaseKey.VertexExists, Direction.OUT, new EdgeSerializer.TypedInterval[0]).setLimit(1);
        this.queryCache = new RelationQueryCache(this.edgeSerializer);
        this.schemaCache = configuration.getTypeCache(typeCacheRetrieval);
        this.times = configuration.getTimestampProvider();
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后是open完成后：GraphOfTheGodsFactory.load(graph);&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;1. 得到management
JanusGraphManagement management = graph.openManagement();
    
    1. new ManagementSystem
        1. 启动 tx
        this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();
            1.  graph.newTransaction(immutable);
                StandardJanusGraphTx tx = new StandardJanusGraphTx(this, configuration);
            	tx.setBackendTransaction(openBackendTransaction(tx));
            	openTransactions.add(tx);
2. 得到 PropertyKey
final PropertyKey name = management.makePropertyKey(&amp;quot;name&amp;quot;).dataType(String.class).make();
    1. return transaction.makePropertyKey(name);
        1. return new StandardPropertyKeyMaker(this, name, indexSerializer, attributeHandler);
            1. super(tx, name, indexSerializer, attributeHandler);
    2. public StandardPropertyKeyMaker dataType(Class&amp;lt;?&amp;gt; clazz)
    3. public PropertyKey make()
        1. TypeDefinitionMap definition = makeDefinition();        
        2. return tx.makePropertyKey(getName(), definition);
            1. return (PropertyKey) makeSchemaVertex(JanusGraphSchemaCategory.PROPERTYKEY, name, definition);
                1. ... 先跳过。
            
3. 新建 index
JanusGraphManagement.IndexBuilder nameIndexBuilder = management.buildIndex(&amp;quot;name&amp;quot;, Vertex.class).addKey(name);
    1. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调用：JanusGraphManagement management = graph.openManagement();然后：management.makeEdgeLabel(&amp;ldquo;father&amp;rdquo;).multiplicity(Multiplicity.MANY2ONE).make();&lt;/p&gt;

&lt;p&gt;然后就是查询数据库：&lt;code&gt;Vertex saturn = g.V().has(&amp;quot;name&amp;quot;, &amp;quot;saturn&amp;quot;).next();&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;二-第2遍调试&#34;&gt;二、第2遍调试&lt;/h2&gt;

&lt;p&gt;这次我们多关注一点细节实现，包括几个部分：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Backend backend = new Backend(configuration);
backend.~~~

this.idAssigner = config.getIDAssigner(backend);
this.idManager = idAssigner.getIDManager();

JanusGraphManagement management = graph.openManagement();
management.makePropertyKey(&amp;quot;name&amp;quot;).dataType(String.class).make();
management.buildIndex(&amp;quot;name&amp;quot;, Vertex.class).addKey(name);

Vertex tartarus = tx.addVertex(T.label, &amp;quot;location&amp;quot;, &amp;quot;name&amp;quot;, &amp;quot;tartarus&amp;quot;);
jupiter.addEdge(&amp;quot;father&amp;quot;, saturn);


&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;backend&#34;&gt;Backend&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public StandardJanusGraph(GraphDatabaseConfiguration configuration) 
{
    this.backend = configuration.getBackend();
    {
        Backend backend = new Backend(configuration);
        {
            this.configuration = configuration;
            KeyColumnValueStoreManager manager = getStorageManager(configuration);
            {
                反射生成一个 KeyColumnValueStoreManager 实现类
            }
            indexes = getIndexes(configuration);
            {
                IndexProvider provider = getImplementationClass(config.restrictTo(index), config.get(INDEX_BACKEND,index),
                    StandardIndexProvider.getAllProviderClasses());
                -- org.janusgraph.diskstorage.es.ElasticSearchIndex
                builder.put(index, provider);
                builder.build();
            }
            storeFeatures = storeManager.getFeatures();
            {
                ...
            }
            ...
        }
        
        backend.initialize(configuration);
        {
            KeyColumnValueStore idStore = storeManager.openDatabase(config.get(IDS_STORE_NAME));
            {
                openDatabase(&amp;quot;janusgraph_ids&amp;quot;, EMPTY)
                {
                    if (!stores.containsKey(name) || stores.get(name).isClosed()) {
                         OrderedKeyValueStoreAdapter store = wrapKeyValueStore(manager.openDatabase(name), keyLengths);
                         {
                             public BerkeleyJEKeyValueStore openDatabase(String name) throws BackendException 
                             {
                                 Database db = environment.openDatabase(null, name, dbConfig);
                                 BerkeleyJEKeyValueStore store = new BerkeleyJEKeyValueStore(name, db, this);
                                 stores.put(name, store);
                             }
                         }
                         stores.put(name, store);
                     }
                     return stores.get(name);
                }
            }
            
            KeyColumnValueStore edgeStoreRaw = storeManagerLocking.openDatabase(EDGESTORE_NAME);
            {
                同上：  
                openDatabase(&amp;quot;edgestore&amp;quot;, EMPTY)
            }
            KeyColumnValueStore indexStoreRaw = storeManagerLocking.openDatabase(INDEXSTORE_NAME);
            {
                同上：  
                openDatabase(&amp;quot;graphindex&amp;quot;, EMPTY)
            }
            
            txLogManager.openLog(SYSTEM_TX_LOG_NAME);
            managementLogManager.openLog(SYSTEM_MGMT_LOG_NAME);
            txLogStore = new NoKCVSCache(storeManager.openDatabase(SYSTEM_TX_LOG_NAME));
            
            KeyColumnValueStore systemConfigStore = storeManagerLocking.openDatabase(SYSTEM_PROPERTIES_STORE_NAME);
            {
                同上：  
                openDatabase(&amp;quot;system_properties&amp;quot;, EMPTY)
            }
            
        }
        storeFeatures = backend.getStoreFeatures();
    }
    
    this.idAssigner = config.getIDAssigner(backend);
    this.idManager = idAssigner.getIDManager();
    
}

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;management&#34;&gt;management&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraphManagement management = graph.openManagement();
{
   new ManagementSystem(this,backend.getGlobalSystemConfig(),backend.getSystemMgmtLog(), managementLogger, schemaCache);
   //参数分别是 graph config Log managementLogger schemaCache
   {
       this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();
       {
           graph.buildTransaction()
           {
               new StandardTransactionBuilder(getConfiguration(), this);
               {
                   
               }
           }
           disableBatchLoading()
           {
               
           }
           start()
           {
               new ImmutableTxCfg
               graph.newTransaction(immutable);
               {
                    StandardJanusGraphTx tx = new StandardJanusGraphTx(this, configuration);
                    {
                        父类： JanusGraphBlueprintsTransaction
                        太过复杂，跳过
                    }
                    tx.setBackendTransaction(openBackendTransaction(tx));
                    {
                        openBackendTransaction(tx)
                        {
                            IndexSerializer.IndexInfoRetriever retriever = indexSerializer.getIndexInfoRetriever(tx);
                            return backend.beginTransaction(tx.getConfiguration(), retriever);
                            {
                                StoreTransaction tx = storeManagerLocking.beginTransaction(configuration);
                                CacheTransaction cacheTx = new CacheTransaction(tx, storeManagerLocking, bufferSize, maxWriteTime, configuration.hasEnabledBatchLoading());
                                final Map&amp;lt;String, IndexTransaction&amp;gt; indexTx = new HashMap&amp;lt;&amp;gt;(indexes.size());
        						for (Map.Entry&amp;lt;String, IndexProvider&amp;gt; entry : indexes.entrySet()) {
        						    indexTx.put(entry.getKey(), new IndexTransaction(entry.getValue(), indexKeyRetriever.get(entry.getKey()), configuration, maxWriteTime));
        						}
        						return new BackendTransaction(cacheTx, configuration, storeFeatures,
                					edgeStore, indexStore, txLogStore,
                					maxReadTime, indexTx, threadPool);
                            }
                        }
                    }
                    openTransactions.add(tx);
                    return tx;
               }
           }
           
       }
   }
}

final PropertyKey name = management.makePropertyKey(&amp;quot;name&amp;quot;).dataType(String.class).make();
{
    management.makePropertyKey(&amp;quot;name&amp;quot;)
    {
        transaction.makePropertyKey(name);
        {
            new StandardPropertyKeyMaker(this, name, indexSerializer, attributeHandler);
            {
                super
                {
                    StandardRelationTypeMaker
                }
            }
        }
    }
    dataType(String.class)
    {
        dataType = clazz;
    }
    make();
    {
        new TypeDefinitionMap();
        tx.makePropertyKey(getName(), definition);
        {
            (PropertyKey) makeSchemaVertex(JanusGraphSchemaCategory.PROPERTYKEY, name, definition);
            {
                schemaVertex = new PropertyKeyVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.UserPropertyKey, temporaryIds.nextID()), ElementLifeCycle.New);
                {
                    //一层层嵌套
                    
                }
            }
        }
    }
}

management.buildIndex(&amp;quot;name&amp;quot;, Vertex.class).addKey(name).unique().buildCompositeIndex();
{
    new IndexBuilder(indexName, ElementCategory.getByClazz(elementType));
    {
        
    }
    addKey(name)
    {
        keys.put(key, null);
    }
    unique()
    {
        unique = true;
    }
    buildCompositeIndex()
    {
        createCompositeIndex(indexName, elementCategory, unique, constraint, keyArr);
        {
            JanusGraphSchemaVertex indexVertex = transaction.makeSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX, indexName, def);
            {
                schemaVertex = new JanusGraphSchemaVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.GenericSchemaType,temporaryIds.nextID()), ElementLifeCycle.New);
                {
                    //一层层嵌套
                    
                }
            }
            addSchemaEdge(indexVertex, keys[i], TypeDefinitionCategory.INDEX_FIELD, paras);
            
            updateSchemaVertex(indexVertex);
            JanusGraphIndexWrapper index = new JanusGraphIndexWrapper(indexVertex.asIndexType());
            updateIndex(index, SchemaAction.REGISTER_INDEX);
            return index;
        }
    }
    
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;containsvertexlabel&#34;&gt;containsVertexLabel&lt;/h3&gt;

&lt;p&gt;mgmt.getVertexLabels().iterator()
mgmt.containsVertexLabel(label)
这两个方法都可以得到 VertexLABEL&lt;/p&gt;

&lt;p&gt;首先看 mgmt.getVertexLabels().iterator(), 这里面首先通过了 guava 的 abstractIterator 转到一个 ResultSetIterator&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public ResultSetIterator(Iterator&amp;lt;R&amp;gt; inner, int limit) {
    this.iter = inner;
    this.limit = limit;
    count = 0;
    this.current = null;
    this.next = nextInternal();
    {
        QueryProcessor$LimitAdajustingIterator.hasNext()
        {
            ....省去一步调用
            executor.execute(query, backendQuery, executionInfo, profiler);
            {
                iter = new SubqueryIterator(indexQuery.getQuery(0), indexSerializer, txHandle, indexCache, indexQuery.getLimit(), getConversionFunction(query.getResultType()),
                        retrievals.isEmpty() ? null: QueryUtil.processIntersectingRetrievals(retrievals, indexQuery.getLimit()));
                {
                    stream = indexSerializer.query(subQuery, tx).map(r -&amp;gt; {
                        currentIds.add(r);
                        return r;
                    });
                    {
                        final List&amp;lt;EntryList&amp;gt; rs = sq.execute(tx);
                        {
                            EntryList next =tx.indexQuery(ksq.updateLimit(getLimit()-total));
                            {
                                return exe.call();
                                {
                                    return cacheEnabled?indexStore.getSlice(query, storeTx):
                                        indexStore.getSliceNoCache(query, storeTx);
                                    {
                                        CassandraThriftKeyColumnValueStore.getNamesSlice(ImmutableList.of(key),query,txh);
                                    }
                                }
                            }
                        }
                        
                    }
                }
            }
        }
        
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这上面已经是省略很多步骤的调用栈。。。&lt;/p&gt;

&lt;p&gt;mgmt.containsVertexLabel(label) 调用栈稍微少了一点：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraphSchemaVertex getSchemaVertex(String schemaName)
{
    id = retriever.retrieveSchemaByName(schemaName);
    {
        JanusGraphVertex v = Iterables.getOnlyElement(QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName), null);
        {
            new ResultSetIterator()
            {
                ....
                runWithMetrics
                iter = new SubqueryIterator(indexQuery.getQuery(0), indexSerializer, txHandle, indexCache, indexQuery.getLimit(), getConversionFunction(query.getResultType()),
                        retrievals.isEmpty() ? null: QueryUtil.processIntersectingRetrievals(retrievals, indexQuery.getLimit()));
                {
                    类似上面
                }
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;makevertexlabel&#34;&gt;makeVertexLabel&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt.makeVertexLabel(vType.toString()).make();
{
    StandardVertexLabelMaker.make
    return (VertexLabelVertex)tx.makeSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL,name,def);
    {
        
        public final JanusGraphSchemaVertex makeSchemaVertex(JanusGraphSchemaCategory schemaCategory, String name, TypeDefinitionMap definition) 
        {
            1. new VertexLabelVertex
            schemaVertex = new VertexLabelVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.GenericSchemaType,temporaryIds.nextID()), ElementLifeCycle.New);
            2. graph.assignID(schemaVertex, BaseVertexLabel.DEFAULT_VERTEXLABEL);
            
            3. addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));
            
            4. updateSchemaVertex(schemaVertex);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;assignID应该是 生产者消费者模式。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;IDBlock idBlock = idAuthority.getIDBlock(partition, idNamespace, renewTimeout);
{
    long nextStart = getCurrentID(partitionKey);
    {
        ......
        return idStore.getSlice(new KeySliceQuery(partitionKey, LOWER_SLICE, UPPER_SLICE).setLimit(5), txh);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;containspropertykey&#34;&gt;containsPropertyKey&lt;/h3&gt;

&lt;h3 id=&#34;makepropertykey&#34;&gt;makePropertyKey&lt;/h3&gt;

&lt;h3 id=&#34;containsedgelabel&#34;&gt;containsEdgeLabel&lt;/h3&gt;

&lt;h3 id=&#34;makeedgelabel&#34;&gt;makeEdgeLabel&lt;/h3&gt;

&lt;p&gt;基本上和上面类似，接下来深入分析一下这些调用栈涉及到的类。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>学习心得</title>
      <link>https://dengziming.github.io/post/%E5%BF%83%E5%BE%97/first/</link>
      <pubDate>Wed, 25 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E5%BF%83%E5%BE%97/first/</guid>
      
        <description>&lt;ol&gt;
&lt;li&gt;&lt;p&gt;结硬寨打呆战&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;独当一面&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;花时间钻研底层只是&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;元认知更重要&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>es架构-1</title>
      <link>https://dengziming.github.io/post/es/es%E6%9E%B6%E6%9E%84-1/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/es/es%E6%9E%B6%E6%9E%84-1/</guid>
      
        <description>

&lt;p&gt;es设计架构，良心参考资料：
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-anatomy-of-an-elasticsearch-cluster&#34;&gt;一、Anatomy of an Elasticsearch Cluster&lt;/h2&gt;

&lt;p&gt;很遗憾，Google的搜索技术不开源，es是搜索引擎的一个很好的替代品，本文主要覆盖了es的底层结构、数据原型、读写过程。es的功能主要有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;全文搜索
例如：怎么找到Wikipedia上面和某个名字最相关的文章&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;聚合&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;例如 显示广告网络上面的词条出价直方图&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;地理空间API&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;例如：设计一个能找到和骑手最近司机的骑行分享平台&lt;/p&gt;

&lt;p&gt;接下来就是内容，主要有以下几个方面：
1. 是主从架构还是无主架构
2. 存储模型
3. 读写工作流程
4. 搜索结果怎么相关&lt;/p&gt;

&lt;h3 id=&#34;1-the-confusion-between-elasticsearch-index-and-lucene-index-other-common-terms&#34;&gt;1.The confusion between Elasticsearch Index and Lucene Index + other common terms…&lt;/h3&gt;

&lt;p&gt;es 的 index 是一个组织数据的逻辑空间，就类似一个数据库。es index有一到多个 shards，一个shard就是一个真正存数据的lucene index，内部就是一个搜索引擎。&lt;/p&gt;

&lt;p&gt;每个 shard 都有0到多个replica，es index 有 type 的概念，就好比数据库里面的表，一个type里的所以type有相同的properties，就像schema一样。&lt;/p&gt;

&lt;h3 id=&#34;2-types-of-nodes&#34;&gt;2. Types of nodes&lt;/h3&gt;

&lt;h4 id=&#34;1-master-node&#34;&gt;（1）Master Node&lt;/h4&gt;

&lt;p&gt;控制集群，负责集群的操作，例如创建删除index，和集群的nodes联系，给节点分配shards。主节点一次处理一个集群状态，并将状态广播到所有节点，收到广播的节点对主节点进行确认回复。
an be configured to be eligible to become a master node by setting the node.master property to be true (default) in elasticsearch.yml.
大集群最好有专门的master node，去空值集群，不用处理任何用户请求&lt;/p&gt;

&lt;h4 id=&#34;2-data-node&#34;&gt;（2） Data Node&lt;/h4&gt;

&lt;p&gt;保存数据和倒排索引，By default, every node is configured to be a data node and the property node.data is set to true in elasticsearch.yml.
If you would like to have a dedicated master node, then change the node.data property to false.&lt;/p&gt;

&lt;h4 id=&#34;3-client-node&#34;&gt;（3）Client Node:&lt;/h4&gt;

&lt;p&gt;If you set both node.master and node.data to false, then the node gets configured as a client node and acts as a load balancer routing incoming requests to different nodes in the cluster.&lt;/p&gt;

&lt;h4 id=&#34;4-coordinating-node&#34;&gt;（4）coordinating node&lt;/h4&gt;

&lt;p&gt;注意没有专门的coordinating node，通过client连上的的es节点称为 coordinating node，将client request 路由到合适的shard。对于读请求，每次选择不同的shard 从而 balance the load.&lt;/p&gt;

&lt;h3 id=&#34;2-storage-model&#34;&gt;2. Storage Model&lt;/h3&gt;

&lt;p&gt;Elasticsearch uses Apache Lucene, a full-text search library written in Java and developed by Doug Cutting (creator of Apache Hadoop)。
es内部通过倒排索引的数据结构，从而处理可能延迟的查询。es中 document 是数据的存储 unit，通过将document的词进行分词创建 inverted index ，倒排索引能够创建排序的term并将和这个term相关的document进行管理。
和每本书背后的index类似，包含了很多词和那一页可以找到这些词，例如下面的两个document。&lt;/p&gt;

&lt;p&gt;Doc 1: Insight Data Engineering Fellows Program
Doc 2: Insight Data Science Fellows Program&lt;/p&gt;

&lt;p&gt;If we want to find documents which contain the term “insight”, we can scan the inverted index (where words are sorted), find the word “insight” and return the document IDs which contain this word, which in this case would be Doc 1 and Doc 2.&lt;/p&gt;

&lt;p&gt;为了更好的搜索性，文档先被分析。一般就是分词+标准化。&lt;/p&gt;

&lt;p&gt;综上，我们知道每个document存储模型，存储了document，以及对他们分词后的倒排索引。&lt;/p&gt;

&lt;h3 id=&#34;3-anatomy-of-a-write&#34;&gt;3.Anatomy of a Write&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&amp;copy;reate&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;When you send a request to the coordinating node to index a new document, the following set of operations take place:&lt;/p&gt;

&lt;p&gt;es所有的节点都包含了集群的元数据信息，包括哪些节点或者，有哪些分片。The coordinating node 通过 documentId将document和他对应的shard route起来，
es再通过 murmur3 hash算法将documentId进行取值，得到shard。&lt;code&gt;shard = hash(document_id) % (num_of_primary_shards)&lt;/code&gt;。
当节点收到 coordinating node 的 request ，request 会被写入到 translog 中，document 会被放进 memory buffer（&lt;a href=&#34;http://www.linfo.org/buffer.html），&#34;&gt;http://www.linfo.org/buffer.html），&lt;/a&gt;
如果在primary shard上执行成功，reques也会被发送到 replica shard上，
当 translog fsynced （&lt;a href=&#34;https://linux.die.net/man/2/fsync）&#34;&gt;https://linux.die.net/man/2/fsync）&lt;/a&gt; on all primary and replica shards.client receives acknowledgement that the request was successful。&lt;/p&gt;

&lt;p&gt;memory buffer会周期性更新 (defaults to 1 sec)，contents 会被写到一个 a new segment in filesystem cache ，
This segment is not yet fsync’ed, however, the segment is open and the contents are available for search.&lt;/p&gt;

&lt;p&gt;The translog is emptied and filesystem cache is fsync’ed every 30 minutes or when the translog gets too big. 这个过程称为flush
the in-memory buffer is cleared and the contents are written to a new segment.
A new commit point is created with the segments fsync’ed and flushed to disk. The old translog is deleted and a fresh one begins.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;(U)pdate and (D)elete&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;es的记录是无法更改的，删除和update实际上是新建，更改版本号。每个segment 都有一个 .del  file。
When a delete request is sent, the document is not really deleted, but marked as deleted in the .del file.
This document may still match a search query but is filtered out of the results.
When segments are merged, the documents marked as deleted in the .del file are not included in the new merged segment.&lt;/p&gt;

&lt;p&gt;update则是新建+删除，es给每个document一个version，每次改变，version都+增加，旧版本会被.del 文件标记为删除，
和删除一样，This older document may still match a search query but is filtered out of the results.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Anatomy of a &amp;reg;ead
Read operations consist of two parts:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Query Phase
Fetch Phase&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Query Phase
coordinating node route the search request to all the shards (primary or replica) in the index.
每个shard单独search，然后将结果放进一个优先队列，根据 relevance score (we’ll cover relevance score later in the post).
所有 shards将结果汇总，创建一个新的优先队列，取出相关度最高的一部分。这个过程类似spark的topn&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Fetch Phase
coordinating node 排好序之后，
it then requests the original documents from all the shards. All the shards enrich the documents and return them to the coordinating node.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;相关度：tf/idf （term frequency/inverse document frequency）算法。
tf 词频，在某文档出现的频率
idf 出现过得所有文档数&lt;/p&gt;

&lt;h2 id=&#34;what-next&#34;&gt;What next?&lt;/h2&gt;

&lt;p&gt;lit brain problem in Elasticsearch and how to avoid it
Transaction log
Lucene segments
Why deep pagination during search is dangerous?
Difficulties and trade-offs in calculating search relevance
Concurrency control
Why is Elasticsearch near real-time?
How to ensure consistent writes and reads?&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>es架构-2</title>
      <link>https://dengziming.github.io/post/es/es%E6%9E%B6%E6%9E%84-2/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/es/es%E6%9E%B6%E6%9E%84-2/</guid>
      
        <description>

&lt;p&gt;es设计架构，良心参考资料：
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-anatomy-of-an-elasticsearch-cluster-2&#34;&gt;一、Anatomy of an Elasticsearch Cluster -2&lt;/h2&gt;

&lt;p&gt;上一节我们说了：underlying storage model and CRUD operations in Elasticsearch.这一节的内容主要包括：
Consensus — split-brain problem and importance of quorum
Concurrency
Consistency: Ensuring consistent writes and reads
Translog (Write Ahead Log — WAL)
Lucene segments&lt;/p&gt;

&lt;h3 id=&#34;1-consensus-split-brain-problem-and-importance-of-quorum&#34;&gt;1. Consensus- Split-brain problem and importance of quorum&lt;/h3&gt;

&lt;p&gt;Consensus 算法包括 Raft、Paxos等，为了解决一致性问题，es的一致性算法有两个部分：&lt;/p&gt;

&lt;p&gt;Ping: The process nodes use to discover each other
Unicast: The module that contains a list of hostnames to control which nodes to ping&lt;/p&gt;

&lt;p&gt;es是一个P2P的系统，所有节点都和其他节点沟通，有一个主节点，控制和更新集群操作。一个新的集群需要经过选举，一个节点被选为master，其他的加入master。
As nodes join, they send a join request to the master with a default join_timeout which is 20 times the ping_timeout.
如果mster节点挂了，cluster重新开始ping，开始新的选举。这种ping过程也帮忙解决脑裂（某个节点突然觉得maste挂了，开始寻找新master）&lt;/p&gt;

&lt;p&gt;为了容错，master会ping 所有的 节点去检查是否 alive然后节点会ping master进行response。
默认配置下，es可能会有脑裂， 由于 network partition,a node 觉得 master 已经 failed然后自己当上master，导致连个master。
This may result in data loss and it may not be possible to merge the data correctly.
This can be avoided by setting the following property to a quorum of master eligible nodes.
&lt;code&gt;discovery.zen.minimum_master_nodes = int(# of master eligible nodes/2)+1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;设置这个配置之后，需要有 quorum of active master eligible nodes 参加完成master选举过程，并接受他的master身份。
This is an extremely important property to ensure cluster stability and can be dynamically updated if the cluster size changes.
NOTE: For a production cluster, it is recommended to have 3 dedicated master nodes, which do not serve any client requests, out of which 1 is active at any given time.&lt;/p&gt;

&lt;p&gt;这就是 Consensus 的内容&lt;/p&gt;

&lt;h3 id=&#34;2-concurrency&#34;&gt;2. Concurrency&lt;/h3&gt;

&lt;p&gt;对于高并发，es使用 optimistic concurrency control 乐冠锁进行控制，保证新纪录不被就记录覆盖。
每个document indexed 有一个 version number which is incremented with every change applied to that document。保证每次更新都能按照顺序。
为了保证数据不丢失，es可以让你自己指定id，如果你指定的id比present的小，更新就失败了。
How failed requests are handled can be controlled at the application level.
There are also other locking options available and you can read about them：&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/guide/2.x/concurrency-solutions.html&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/guide/2.x/concurrency-solutions.html&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;3-consistency-ensuring-consistent-writes-and-reads&#34;&gt;3. Consistency — Ensuring consistent writes and reads&lt;/h3&gt;

&lt;p&gt;写一致
对于怎样算写成功，可以设置 available的 shards 数量
The available options are quorum, one and all. By default it is set to quorum and that means that a write operation will be permitted only if a majority of the shards are available.&lt;/p&gt;

&lt;p&gt;尽管大多数available，也有可能出错。the replica is said to be faulty and the shard would be rebuilt on a different node.&lt;/p&gt;

&lt;p&gt;读一致：
new documents are not available for search until after the refresh interval.
为了保证读到最新的document，replication can be set to sync (default) 。这样只有 primary and replica shards 都写完了才会返回 write request 。
这样，从任何一个shard查询，都将返回最新的document。
Even if your application requires replication=async for higher indexing rate, there is a _preference parameter which can be set to primary for search requests.
这样，查询都走 primary shard ，保证结果都来自最新版本。&lt;/p&gt;

&lt;h3 id=&#34;2-translog&#34;&gt;2. Translog&lt;/h3&gt;

&lt;p&gt;WAL来自关系型数据库的世界，translog保证事件失败时候的数据完整性，通过底层的原则 :在将数据提交到磁盘的实际更改之前，必须记录并提交预期的更改。&lt;/p&gt;

&lt;p&gt;当新 document被index，或者旧的更改，Lucene index会改变，然后改变会被提交到磁盘进行持久化。每次update都进行提交很expensive，更好地办法是一次性提交很多。
上一节提到的，flush操作默认30min一次或者translog太大，这样的话，有可能丢失30min的数据。为了避免这个问题，es使用translog，update操作都将被写到translog，
translog is fsync’ed after every index/delete/update operation (or every 5 sec by default) 保证改变被持久化。
The client receives acknowledgement for writes after the translog is fsync’ed on both primary and replica shards.&lt;/p&gt;

&lt;p&gt;当两次flush之间出现问题，translog将会重新执行，从而恢复丢失的change，
NOTE: It is recommended to explicitly flush the translog before restarting Elasticsearch instances,
as the startup will be faster because the translog to be replayed will be empty.
POST /_all/_flush command can be used to flush all indices in the cluster.&lt;/p&gt;

&lt;p&gt;上面已经说了translog的flush操作，segments文件会被提交到磁盘来保证改变持久化。接下来我们看看什么是lucene的 segment。&lt;/p&gt;

&lt;h3 id=&#34;3-lucene-segments&#34;&gt;3.Lucene Segments&lt;/h3&gt;

&lt;p&gt;Lucene索引由多个段组成，并且段本身是一个全功能倒置索引。
是不可变的，它允许Lucene在不从头开始重建索引的情况下增量地向索引添加新文档。
对于每一个搜索请求，索引中的所有段都被搜索，并且每个段消耗CPU周期、文件句柄和内存。这意味着段数越高，搜索性能就越低。
为了解决这个问题，es将小的段合并成更大的段，将新合并的段提交到磁盘并删除旧的较小的段。
对于搜索请求，搜索给定的弹性搜索索引碎片中的所有Lucene段，但是，在排名结果中提取所有匹配的文档或文档对于弹性搜索集群是危险的。&lt;/p&gt;

&lt;h2 id=&#34;what-next&#34;&gt;What next?&lt;/h2&gt;

&lt;p&gt;在后续文章中，我们将看到这一点，并回顾下面的主题，其中包括在弹性搜索中进行的一些权衡，以在低延迟下服务相关搜索结果。&lt;/p&gt;

&lt;p&gt;lit brain problem in Elasticsearch and how to avoid it
Transaction log
Lucene segments
Why deep pagination during search is dangerous?
Difficulties and trade-offs in calculating search relevance
Concurrency control
Why is Elasticsearch near real-time?
How to ensure consistent writes and reads?&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>es架构-3</title>
      <link>https://dengziming.github.io/post/es/es%E6%9E%B6%E6%9E%84-3/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/es/es%E6%9E%B6%E6%9E%84-3/</guid>
      
        <description>

&lt;p&gt;es设计架构，良心参考资料：
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-i-7ac9a13b05db&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-ii-6db4e821b571&lt;/a&gt;
&lt;a href=&#34;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&#34;&gt;https://blog.insightdatascience.com/anatomy-of-an-elasticsearch-cluster-part-iii-8bb6ac84488d&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-anatomy-of-an-elasticsearch-cluster-3&#34;&gt;一、Anatomy of an Elasticsearch Cluster -3&lt;/h2&gt;

&lt;p&gt;上一节我们说了：how Elasticsearch approaches some of the fundamental challenges of a distributed system.这一节的内容主要包括：&lt;/p&gt;

&lt;p&gt;Near real-time search&lt;/p&gt;

&lt;p&gt;Why deep pagination in distributed search can be dangerous?&lt;/p&gt;

&lt;p&gt;Trade-offs in calculating search relevance&lt;/p&gt;

&lt;h3 id=&#34;1-near-real-time-search&#34;&gt;1. Near real-time search&lt;/h3&gt;

&lt;p&gt;尽管改变不会立即可见，但是es确实提供了近实时查询，前面的内容提到，lucene的segment改变提交到磁盘是很消耗性能的。&lt;/p&gt;

&lt;p&gt;为了避免search的同时提交改变到磁盘，es在memory buffer和disk之间提供了一个 filesystem cache，memory buffer 默认1s refreshed 一次，
一个包含倒排索引的segment也会在 filesystem cache中生成。segment是开放的可以查询。&lt;/p&gt;

&lt;p&gt;filesystem cache有文件句柄而且可以打开，读写，关闭，尽管它在内存中。
Since, the refresh interval is 1 sec by default,  the changes are not visible right away ，所以是准实时。
Since, the translog is a persistent record of changes not persisted to the disk, it also helps with the near real-time aspect for CRUD operations.
在查找相关段之前，在 translog 中搜索任何最近的变化，因此，客户端可以访问近实时的所有变化。&lt;/p&gt;

&lt;p&gt;你可以每次更新后手动刷新index，但是这样会产生很多小segment，不推荐。
For a search request, all Lucene segments in a given shard of an Elasticsearch index are searched。
however, fetching all matching documents or documents deep in the resulting pages is dangerous for your Elasticsearch cluster. Let’s see why that is.&lt;/p&gt;

&lt;h3 id=&#34;2-why-deep-pagination-in-distributed-search-can-be-dangerous&#34;&gt;2. Why deep pagination in distributed search can be dangerous?&lt;/h3&gt;

&lt;p&gt;当我们查到的es中有很多匹配到的document，默认返回最相关的10条，分页操作会提供from和size两个参数，然后每个shard上面会产生from+size个结果放进优先队列，最后汇总。&lt;/p&gt;

&lt;p&gt;加入你需要的是10000到100010个结果，每个shard的优先队列会返回10010个结果排序后放进 memory中，这样将会有很大的隐患。
scroll API （&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html）可以让你返回所有的结果。&#34;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html）可以让你返回所有的结果。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;前面说到es使用tf-idf算法，分布式系统计算idf时很麻烦的，需要有aggregate操作。es的做法是返回一个local idf：
Instead, every shard calculates a local idf to assign a relevance score to the resulting documents and returns the result for only the documents on that shard.
Similarly, all the shards return the resulting documents with relevant scores calculated using local idf and the coordinating node sorts all the results to return the top ones。
大多数情况可靠，但是数据倾斜时候就不太可靠了。&lt;/p&gt;

&lt;p&gt;对于上面的问题有两种 trade-off，都不太适合大规模数据。一种是只有一个shard，这样local idf就是 globe idf。另一种是 dfs_query_then_search，先把local idf合并成globe idf，然后在计算。&lt;/p&gt;

&lt;h2 id=&#34;what-next&#34;&gt;What next?&lt;/h2&gt;

&lt;p&gt;In the last few posts, we reviewed some of the fundamental principles of Elasticsearch which are important to understand in order to get started.&lt;/p&gt;

&lt;p&gt;接下来，我们要看看他的源码，或者看看怎么和spark、hadoop结合使用。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Java内存区域与内存溢出异常</title>
      <link>https://dengziming.github.io/post/java/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/</guid>
      
        <description>

&lt;h2 id=&#34;一-概述&#34;&gt;一、概述&lt;/h2&gt;

&lt;p&gt;我们的代码运行过程中的，虚拟机管理着内存的分配和使用。我们今天先了解内存区域，使我们深入了解JVM的第一步。&lt;/p&gt;

&lt;h2 id=&#34;二-运行时数据区域&#34;&gt;二、运行时数据区域&lt;/h2&gt;

&lt;p&gt;根据java虚拟机规范，虚拟机内存区域结构大概如图，我们详细介绍每个区域：
&lt;img src=&#34;./_image/2018-04-16-22-37-47.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-程序计数器&#34;&gt;1.程序计数器&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;我们简单想象有个helloworld程序运行。代码最终是一步一步解释为机器码，所以有一个程序计数器，记录当前的代码执行位置，也就是行号。&lt;/li&gt;
&lt;li&gt;假如有两个线程执行helloworld，那每个线程执行到第几行都需要各自保存，每个线程都有独立的计数器。&lt;/li&gt;
&lt;li&gt;如果是循环打印，字节码需要改变程序计数器的值取到下一条指令。&lt;/li&gt;
&lt;li&gt;如果是java方法，计数器指向的是代码位置，如果是native方法，计数器为空。&lt;/li&gt;
&lt;li&gt;程序计数器是唯一一个没有 outofmermoryError情况的区域。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-java虚拟机栈&#34;&gt;2. java虚拟机栈&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;和程序计数器一样，java虚拟机栈也是线程私有。&lt;/li&gt;
&lt;li&gt;我们debug代码的时候，debugger会显示某个正在运行的线程，然后自上而下一次为每个方法对应的栈帧，每个栈帧保存局部变量等，每个方法执行结束，就有一个栈帧入栈到出栈：
&lt;img src=&#34;./_image/2018-04-16-22-48-02.jpg&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;局部变量表存储的是各自基本数据类型（8种）和引用。64位的long和double占用两个变量空间，其余的是一个，一般来说，局部变量表的大小是固定的。&lt;/li&gt;
&lt;li&gt;栈有两种异常，Stack OverflowError 和 outofmermoryError，前者是方法调用栈太多，例如递归，后者是内存不够。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;3-本地方法栈&#34;&gt;3.本地方法栈&lt;/h3&gt;

&lt;p&gt;和栈类似，主要负责本地方法，实现上很自由，有的直接和栈合二为一。也有两种异常。&lt;/p&gt;

&lt;h3 id=&#34;4-java-堆&#34;&gt;4.java 堆&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;内存最大，线程共享，作用就是存放实例（几乎所有的实例，但是技术发展导致没这么绝对）。&lt;/li&gt;
&lt;li&gt;垃圾回收采用分带收集，所以堆包括了新生代、老年代。还可以细分为：eden、from survivor、to survivor。&lt;/li&gt;
&lt;li&gt;可能也有线程私有的内存缓冲区，只是为了更好分配和回收。&lt;/li&gt;
&lt;li&gt;只要逻辑上连续即可，无需物理连续。大小可以调节（-Xmx和-Xms）&lt;/li&gt;
&lt;li&gt;无法扩展并且没有内存分配示例，会有OutOfmermoryError。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;5-方法区&#34;&gt;5.方法区&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;我们运行了一个helloworld方法，对应的主类和常量、静态变量、编译后的代码都需要放在方法去，逻辑上和堆的一个部分。&lt;/li&gt;
&lt;li&gt;基本上不需要垃圾回收，所以有人叫他永久带，实际上只是一开始的JVM将它放在了永久代的而已。但是从1.7开始，已经把原本放在永久代的字符串常量池移出, 放在堆中。&lt;/li&gt;
&lt;li&gt;方法去无法满足内训分配需求，也会有OutOfmermoryError，但是从1.7开始，不在这样。&lt;/li&gt;
&lt;li&gt;类的元数据, 字符串池, 类的静态变量将会从永久代移除, 放入Java heap或者native memory.其中建议JVM的实现中将类的元数据放入 native memory, 将字符串池和类的静态变量放入java堆中. 这样可以加载多少类的元数据就不在由MaxPermSize控制, 而由系统的实际可用空间来控制.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;6-运行时常量池&#34;&gt;6. 运行时常量池&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;是方法区的一部分，.class 文件中除了有类的版本、字段、方法等信息，还有常量池，用于存放编译器的自变量和符号引用。这部分在加载后会进入方法去的运行时常量池。&lt;/li&gt;
&lt;li&gt;.class文件的每一部分格式都很严格。但是常量池很宽松。&lt;/li&gt;
&lt;li&gt;java语言并不要求一定要常量只能在编译时候产生，运行期间也可以将新的常量放入常量池。这种特性用的最多的是String的intern()方法。&lt;/li&gt;
&lt;li&gt;也会有OutOfmermoryError。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;7-直接内存&#34;&gt;7. 直接内存&lt;/h3&gt;

&lt;p&gt;这部分是由于java的NIO引起的&lt;/p&gt;

&lt;h2 id=&#34;三-hotspot对象探秘&#34;&gt;三、Hotspot对象探秘&lt;/h2&gt;

&lt;h3 id=&#34;1-对象的创建&#34;&gt;1.对象的创建&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;从写代码看，对象的创建（例如克隆，反序列化）只是一个new关键字，然后我们调试可以看到其实还执行了 初始化的&lt;init&gt;方法。&lt;/li&gt;
&lt;li&gt;从虚拟机角度看，首先是检查对应的引用能否在常量池中定位到一个类的符号引用，并检查是否已经加载解析和初始化过，如果没有，就要开始加载。&lt;/li&gt;
&lt;li&gt;类的加载我们以后讨论，加载完后需要分配内存。对象大小在加载完成后就已经完全确定了，如果java堆内存是绝对规整的，那么需要维护一个指针指向当前分配到的位置。如果不连续需要维护一个空闲列表。&lt;/li&gt;
&lt;li&gt;分配内存可能是多线程的，有安全问题。要么加锁，要么给每个内存一个预先分配的小内存，成为本地分配缓存。&lt;/li&gt;
&lt;li&gt;内存分配完成后需要初始化为0值，然后进行元数据设置，例如是那个类的实例，GC代等。&lt;/li&gt;
&lt;li&gt;这时候对象创建才刚刚开始，执行 &lt;init&gt;方法。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-对象的内存布局&#34;&gt;2.对象的内存布局&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;对象在内存中的存储布局可以分为3部分，对象头，实例数据、对象填充。对象头第一部分存储运行时数据，第二部分是类型指针。运行时数据hash码、分带年龄等。类型指针指向类元数据，数组还要记录数组长度。&lt;/li&gt;
&lt;li&gt;第二部分为实例数据，就是代码里面定义的数据内容&lt;/li&gt;
&lt;li&gt;第三部分没什么含义，仅仅是占位符。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;3-对象的访问&#34;&gt;3.对象的访问&lt;/h3&gt;

&lt;p&gt;1.对象的访问有两种方式，第一种是句柄。java堆会有一块专门的内存作为句柄池，栈存储的是句柄地址，句柄包含了对象示例数据（堆）和类型数据（方法区）各自的指针。
2. 第二中方法是指针访问，栈存储的直接是对象地址，堆的对象布局必须考虑如何放置访问类型数据。
3. 句柄最大的好处是对象改变时不需要改变栈的地址，使用直接内存好处是访问速度快，节省时间。&lt;/p&gt;

&lt;h2 id=&#34;四-实战-outofmermoryerror&#34;&gt;四、实战 OutOfmermoryError&lt;/h2&gt;

&lt;p&gt;除了程序计数器，都会有OutOfMermoryError异常，我们实战一下，在IDEA编写代码，并学习几个参数。&lt;/p&gt;

&lt;h3 id=&#34;1-堆溢出&#34;&gt;1.堆溢出&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 17/04/2018.
 * VM ARGS: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError
 */
public class HeapOOM {
    static class OOMObject{}
    public static void main(String[] args) {
        List&amp;lt;OOMObject&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        while (true){list.add(new OOMObject());}
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;VM ARGS:  -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError
马上报错：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;java.lang.OutOfMemoryError: Java heap space
Dumping heap to java_pid98722.hprof ...
Heap dump file created [27798040 bytes in 0.363 secs]
Exception in thread &amp;quot;main&amp;quot; java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOf(Arrays.java:3210)
	at java.util.Arrays.copyOf(Arrays.java:3181)
	at java.util.ArrayList.grow(ArrayList.java:261)
	at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235)
	at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227)
	at java.util.ArrayList.add(ArrayList.java:458)
	at io.github.dengziming.session2.HeapOOM.main(HeapOOM.java:21)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如何查看对文件和分析，我们后续有内容。简单分析两点：
1. 如果是内存泄露，通过GC工具查看泄露对象的GC引用链，定位代码位置
2. 如果内存溢出，可以考虑调大参数。 -Xmx -Xms&lt;/p&gt;

&lt;h3 id=&#34;2-虚拟机栈和本地方法溢出&#34;&gt;2.虚拟机栈和本地方法溢出&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 18/04/2018.
 * VM ARGS -Xss128k
 */
public class JavaVMStackSOF {

    private int stackLenth = 1;
    public void stackLeak(){
        stackLenth ++;
        stackLeak();
    }

    public static void main(String[] args) {
        JavaVMStackSOF oom = new JavaVMStackSOF();
        try{
            oom.stackLeak();
        }catch (Exception e){
            System.out.println(&amp;quot;stackLenth: &amp;quot; + oom.stackLenth);
            throw e;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Exception in thread &amp;ldquo;main&amp;rdquo; java.lang.StackOverflowError
结果表明，单线程下，无论是栈帧太大还是栈容量太小，内存无法分配的时候，都是Stack Overflow，如果多线程到不太一样。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 18/04/2018.
 * VM ARGS: -Xss20M
 */
public class JavaVMStackOOM {
    private void dontStop(){
        while (true){}
    }
    public void stackLeakByStack(){
        while (true){
            Thread thread = new Thread() {
                @Override
                public void run() {
                    dontStop();
                }
            };
            thread.start();
        }
    }

    public static void main(String[] args) {
        JavaVMStackOOM oom = new JavaVMStackOOM();
        oom.stackLeakByStack();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行完电脑卡死了，算了。这个内存越大反而容易耗尽资源，因为机器内存是固定的，减少容量可以获得更多的线程数。
注意：这时候通过减少内存解决内存溢出的方法，没有经验是不知道的。&lt;/p&gt;

&lt;h3 id=&#34;3-方法区和运行时常量池溢出&#34;&gt;3. 方法区和运行时常量池溢出&lt;/h3&gt;

&lt;p&gt;String.intern() 的含义是返回在代表常量池中这个字符串的对象。如果没有，就将这个字符串放进常量池，并返回引用。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Created by dengziming on 18/04/2018.
 * 
 * vm args: -XX:PermSize=10M -XX:MaxPermSize=10M
 */
public class RuntimeConstantPoolOOM {

    public static void main(String[] args) {

        List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        int i=0;
        while(true){
            list.add(String.valueOf(i++).intern());
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不好意思这个方法没有达到效果：
Java HotSpot&amp;trade; 64-Bit Server VM warning: ignoring option PermSize=10M; support was removed in 8.0
Java HotSpot&amp;trade; 64-Bit Server VM warning: ignoring option MaxPermSize=10M; support was removed in 8.0
jdk1.7 已经把原本放在永久代的字符串常量池移出, 放在堆中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    public static void main(String[] args) {

        while(true){
            Enhancer enhancer = new Enhancer();
            enhancer.setSupperClass(OOMObject.class);
            enhancer.setUserCache(false);
            enhancer.setCallBack(new MethodInterceptor(){
                public Object intercept(Object obj , Method method , Object []args , MethodProxy proxy)throw Throwable{
                    return proxy.invokeSuper(obj , args);
                }
            });
            enhancer.create();
        }
    }
    static class OOMObject{

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个也是一样。因为类的元数据, 字符串池, 类的静态变量从永久代移除, 放入Java heap或者native memory.其中建议JVM的实现中将类的元数据放入 native memory, 将字符串池和类的静态变量放入java堆中.&lt;/p&gt;

&lt;p&gt;String.intern() 在1.6和1.7有不同的实现。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class RuntimeConstantPoolOOM2 {

    public static void main(String[] args) {

        String str1 = new StringBuilder().append(&amp;quot;计算机&amp;quot;).append(&amp;quot;软件&amp;quot;).toString();
        System.out.println(str1.intern() == str1);

        String str2 = new StringBuilder().append(&amp;quot;ja&amp;quot;).append(&amp;quot;va&amp;quot;).toString();
        System.out.println(str2.intern() == str2);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1.6输出为false和false
1.7输出为true和false
原因是：1.6 的 intern返回在永久代的实例，如果是第一次遇到，会先复制到永久代。1.7不会复制到永久代，只是记录首次出现的实例的引用。
所以1.6的时候两个intern返回的是永久代的引用而不是字符串，1.7的时候 java 这个串已经出现过了。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>垃圾收集器和内存分配策略</title>
      <link>https://dengziming.github.io/post/java/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B9%9F%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B9%9F%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</guid>
      
        <description>

&lt;h2 id=&#34;一-概述&#34;&gt;一、概述&lt;/h2&gt;

&lt;p&gt;前面我们已经知道，栈的内存是固定的，栈帧多大都是已知。而堆就不一样了。&lt;/p&gt;

&lt;h2 id=&#34;二-判断对象存活状态&#34;&gt;二、判断对象存活状态&lt;/h2&gt;

&lt;p&gt;垃圾回收的第一件事就是判断对象是否还活着，是否可以回收。&lt;/p&gt;

&lt;h3 id=&#34;1-引用计数法&#34;&gt;1.引用计数法&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;给对象添加一个引用计数器，被引用时加一，失效时减一，计数器为0就不能被使用了。这种方法无法解决相互引用问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class ReferenceCountingGC {
    public Object instance = null;
    private static final int _1M = 1024 * 1024;
    //很大的内存
    private byte[] bigSize = new byte[2 * _1M];

    public static void main(String[] args) {
        testGC();
    }

    public static void testGC() {

        ReferenceCountingGC obj1 = new ReferenceCountingGC();
        ReferenceCountingGC obj2 = new ReferenceCountingGC();
        obj1.instance = obj2;
        obj2.instance = obj1;

        obj1 = null;
        obj2 = null;

        System.gc();
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的日志信息：
TODO 日志分析，gc文件查看&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;
4603k -&amp;gt; 210k

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;意味着并没有因为相互引用就不回收，说明虚拟机并不是通过引用计数实现的。&lt;/p&gt;

&lt;h3 id=&#34;2-可达性分析算法&#34;&gt;2. 可达性分析算法&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;主流语言都是通过可达性分析实现垃圾回收。就是通过一系列GCRoots作为七点，判断有没有被引用。如果一个对象到GCRoots没有引用链，用图论的语言就是不可达，那么可以回收。&lt;/li&gt;
&lt;li&gt;java的GCRoots包括 虚拟机栈（栈帧的本地变量表）引用的对象。、方法区中类静态属性引用的对象、方法区中常量引用的对象，本地方法（native方法）引用的对象。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;3-理解引用&#34;&gt;3.理解引用&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;引用实际上很重要，上面的两张方法都是通过引用来判断。如果reference类型的数据中存储的数值代表另一个内存的起始地址，就称这块内存代表一个引用。&lt;/li&gt;
&lt;li&gt;一个对象在这种定义下只有引用和被引用两种关系。所以这个定义太过狭隘。&lt;/li&gt;
&lt;li&gt;jdk1.2后java对引用的概念进行了扩充。分为强引用、软引用、弱引用、虚引用。&lt;/li&gt;
&lt;li&gt;四种引用相关的只是可以查询资料。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;4-最后的判断&#34;&gt;4.最后的判断&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;即使判断为不可达对象，也只是处于“缓刑”阶段。要彻底宣告死亡还得经过两次判断。第一次标记后进行筛选，筛选条件是该对象是否有必要执行finalize方法，当对象没有覆盖finalize方法或者已经被调用过，将会被标记为没必要执行。&lt;/li&gt;
&lt;li&gt;如果被标记为有必要执行，会被放在一个F-Queue中，稍后放在一个虚拟机级别的线程中执行这个finalize，但是不会等待它执行。&lt;/li&gt;
&lt;li&gt;finalize是对象拯救自己最后的机会，只要把自己引用到某个对象即可。但是每个对象的finalize只会调用一次，所以下面的代码拯救自己一次。第二次失败了。&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public class FinalizeEscapeGC {

    public static FinalizeEscapeGC SAVE_HOOK = null;

    public void isAlive(){
        System.out.println(&amp;quot;yes , i am alive&amp;quot;);
    }

    @Override
    protected void finalize() throws Throwable {
        super.finalize();
        System.out.println(&amp;quot;finalize method executed&amp;quot;);
        FinalizeEscapeGC.SAVE_HOOK = this;
    }

    public static void main(String[] args) throws Exception {
        SAVE_HOOK = new FinalizeEscapeGC();

        // 对象第一次成功拯救自己
        SAVE_HOOK = null;
        System.gc();

        //finalize 优先级低，等待执行
        Thread.sleep(1000);

        if (null != SAVE_HOOK) {
            SAVE_HOOK.isAlive();
        }else {
            System.out.println(&amp;quot;no, i am dead&amp;quot;);
        }

        //对象第二次拯救自己
        SAVE_HOOK = null;
        System.gc();
        //finalize 优先级低，等待执行
        Thread.sleep(1000);

        if (null != SAVE_HOOK) {
            SAVE_HOOK.isAlive();
        }else {
            System.out.println(&amp;quot;no, i am dead&amp;quot;);
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种方式太不推荐了。&lt;/p&gt;

&lt;h3 id=&#34;5-回收方法区&#34;&gt;5.回收方法区&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;很多人认为方法去是没有垃圾回收的，其实只是方法区垃圾回收效率低。&lt;/li&gt;
&lt;li&gt;永久代的垃圾回收主要是两部分，一部分是常量，另一部分是无用的类。废弃常量和堆的回收很类似，但是判断一个类是否是无用的类，就比较麻烦。&lt;/li&gt;
&lt;li&gt;无用的类判断条件是：所有实例都被回收了，ClassLoader被回收了，无法在任何地方通过反射得到该类的方法。&lt;/li&gt;
&lt;li&gt;在大量使用反射、动态代理、CGlib等技术的地方，频繁自定义classLoader的地方都要虚拟机具备类卸载的功能，保证永久代不溢出。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;三-垃圾回收算法&#34;&gt;三、垃圾回收算法&lt;/h2&gt;

&lt;h3 id=&#34;1-标记-清楚&#34;&gt;1.标记-清楚&lt;/h3&gt;

&lt;p&gt;对需要回收的对象标记，然后回收。标记和清除效率都不高，而且容易产生碎片。&lt;/p&gt;

&lt;h3 id=&#34;2-复制算法&#34;&gt;2.复制算法&lt;/h3&gt;

&lt;p&gt;将空间分为相同的两块，每次回收后移动到另一边。存活率较高时效率低，另外浪费一半空间&lt;/p&gt;

&lt;h3 id=&#34;3-标记-整理&#34;&gt;3.标记-整理&lt;/h3&gt;

&lt;p&gt;标记然后移动。&lt;/p&gt;

&lt;h3 id=&#34;4-分代回收&#34;&gt;4.分代回收&lt;/h3&gt;

&lt;p&gt;对不同对象用不同方法。&lt;/p&gt;

&lt;h2 id=&#34;四-算法实现&#34;&gt;四、算法实现&lt;/h2&gt;

&lt;p&gt;TODO&lt;/p&gt;

&lt;h2 id=&#34;五-常见垃圾收集器&#34;&gt;五、常见垃圾收集器&lt;/h2&gt;

&lt;h3 id=&#34;1-todo&#34;&gt;1.TODO&lt;/h3&gt;

&lt;h3 id=&#34;2-阅读gc日志&#34;&gt;2.阅读GC日志&lt;/h3&gt;

&lt;p&gt;gc 参数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;JVM的GC日志的主要参数包括如下几个：

-XX:+PrintGC 输出GC日志

-XX:+PrintGCDetails 输出GC的详细日志

-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）

-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）

-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息

-Xloggc:../logs/gc.log 日志文件的输出路径
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;日志：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0.756: [Full GC (System) 0.756: [CMS: 0K-&amp;gt;1696K(204800K), 0.0347096 secs] 11488K-&amp;gt;1696K(252608K), [CMS Perm : 10328K-&amp;gt;10320K(131072K)], 0.0347949 secs] [Times: user=0.06 sys=0.00, real=0.05 secs]  
5.617: [GC 5.617: [ParNew: 43296K-&amp;gt;7006K(47808K), 0.0136826 secs] 44992K-&amp;gt;8702K(252608K), 0.0137904 secs] [Times: user=0.03 sys=0.00, real=0.02 secs]  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解释如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;5.617（时间戳）: [GC（Young GC） 5.617（时间戳）: [ParNew（使用ParNew作为年轻代的垃圾回收器）: 43296K（年轻代垃圾回收前的大小）-&amp;gt;7006K（年轻代垃圾回收以后的大小）(47808K)（年轻代的总大小）, 0.0136826 secs（回收时间）] 44992K（堆区垃圾回收前的大小）-&amp;gt;8702K（堆区垃圾回收后的大小）(252608K)（堆区总大小）, 0.0137904 secs（回收时间）] [Times: user=0.03（Young GC用户耗时） sys=0.00（Young GC系统耗时）, real=0.02 secs（Young GC实际耗时）]  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个是时间戳，然后是GC或者FullGC代表垃圾回收类型。然后中括号括起来的是年轻代垃圾回收，第一个是垃圾回收器，例如：DefNew，PSYoungGen等，然后是年轻代的容量变化和总用量。中括号外的是堆的总容量。
后面三个是时间，分别是user,sys,real。分别是用户态CPU时间、内核态CPU时间、墙钟时间，墙钟时间包含各种非运算的等待耗时，例如IO阻塞，CPU时间则不包含这些世界，当计算机是多核这些世界会累加，所以看到real或者sys超过real也正常。&lt;/p&gt;

&lt;h3 id=&#34;3-垃圾收集器参数&#34;&gt;3.垃圾收集器参数&lt;/h3&gt;
</description>
      
    </item>
    
    <item>
      <title>spark-天池o2o竞赛</title>
      <link>https://dengziming.github.io/post/project/tianchi/%E5%A4%A9%E6%B1%A0o2o%E7%AB%9E%E8%B5%9B/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/project/tianchi/%E5%A4%A9%E6%B1%A0o2o%E7%AB%9E%E8%B5%9B/</guid>
      
        <description>

&lt;h1 id=&#34;优惠券敏感人群分析&#34;&gt;优惠券敏感人群分析&lt;/h1&gt;

&lt;p&gt;源代码地址放在Reward处。&lt;/p&gt;

&lt;p&gt;互联网给我们老百姓带来的最直接的福利要从补贴开始说起，从滴滴快的烧钱大战，美团饿了么的外卖红包，补贴的硝烟似乎从未停止。补贴不仅仅是发发优惠券那么简单的事，补贴是一门纯技术活。告别了快速占领市场时粗犷的烧钱方式，进入成熟期互联网公司大都开始了精细化运营，如何把补贴用在最需要的用户身上，如何在降低补贴的同时带来更多用户和订单量的提升，毕竟商业变现是每个公司必须面对的问题，实现盈利就要降低成本和提高收入。这一次，将让我们一起来探讨下高频产品外卖行业的高效补贴方式。
如何选定筛选优惠敏感度的指标，来发现优惠敏感用户，一般认为是下单意愿强弱受优惠和价格高低影响大的用户，而运营要做的就是根据用户的消费水平，历史补贴情况，及主动寻找优惠行为等分析来确定如何通过补贴提高用户下单率。主动获取优惠维度筛选，比如有以下几个行为：分享渠道领取优惠券、参加商家满减凑单活动、具有拆单行为的用户、高频点折扣菜、从banner活动落地页获得优惠。综合考虑用户的历史订单补贴率、历史单均价以及主动获取优惠行为，初步确定这些指标后，即可以制定初版探索方案验证这些指标是否能带来提升，然后再进入数据分析挖掘阶段寻找最佳阈值。
我们这次通过完成天池大数据竞赛的一个赛题，来更加深入理解这个问题。我们的目标很简单，就是通过已有的数据分析出用户接下来的是否会使用优惠券。&lt;/p&gt;

&lt;h2 id=&#34;一-赛题背景&#34;&gt;一、赛题背景&lt;/h2&gt;

&lt;p&gt;O2O（Online to Offline）消费
O2O：是指将线下的商务机会与互联网结合，让互联网成为线下交易的平台
以优惠券盘活老用户或吸引新客户进店消费是O2O的一种重要营销方式&lt;/p&gt;

&lt;h3 id=&#34;1-赛题目标&#34;&gt;1.赛题目标&lt;/h3&gt;

&lt;p&gt;个性化投放优惠券，提高核销率
通过分析建模，精准预测用户是否会在规定时间内使用相应优惠券
已知：用户在2016年1月1日至2016年6月30日之间真实线上线下消费行为
预测：用户在2016年7月领取优惠券后15天以内的使用情况
评价标准：优惠券核销预测的平均AUC（ROC曲线下面积）。即对每个优惠券coupon_id单独计算核销预测的AUC值，再对所有优惠券的AUC值求平均作为最终的评价标准。 关于AUC的含义与具体计算方法，可参考维基百科&lt;/p&gt;

&lt;h3 id=&#34;2-数据简介&#34;&gt;2.数据简介&lt;/h3&gt;

&lt;p&gt;一共四个表格，前两个表格是数据，第三个是用来预测的数据，第四个是提交的文件格式。：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Table 1: 用户线下消费和优惠券领取行为，ccf_offline_stage1_train.csv
Table 2: 用户线上点击/消费和优惠券领取行为，ccf_online_stage1_train
Table 3：用户O2O线下优惠券使用预测样本，ccf_offline_stage1_test_revised.csv
Table 4：选手提交文件字段，其中user_id,coupon_id和date_received均来自Table 3,而Probability为预测值
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TABLE 1： 用户线下消费和优惠券领取行为
&lt;img src=&#34;../images/2018-03-21-17-40-02.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Table 2: 用户线上点击/消费和优惠券领取行为
&lt;img src=&#34;../images/2018-03-21-17-40-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Table 3：用户O2O线下优惠券使用预测样本
&lt;img src=&#34;../images/2018-03-21-17-41-12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Table 4选手提交文件字段
其中user_id,coupon_id和date_received均来自Table 3,而Probability为预测值
&lt;img src=&#34;../images/2018-03-21-17-41-25.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;二-初步分析和项目设计&#34;&gt;二、初步分析和项目设计&lt;/h2&gt;

&lt;h3 id=&#34;1-认识数据&#34;&gt;1.认识数据&lt;/h3&gt;

&lt;h4 id=&#34;table1-分析结构&#34;&gt;TABLE1 分析结构&lt;/h4&gt;

&lt;p&gt;数据采样：
&lt;img src=&#34;../images/2018-03-22-14-11-46.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;特点：
– 标题：用户线下消费和优惠券领取行为
– 场景：线下
– 行为：消费、优惠券领取
– 数据：优惠券领取、使用情况，消费情况，用户常活动地点与最近门店距离
分析1：用户行为有三种情况
– 领了优惠券 &amp;amp;&amp;amp; 未消费 =&amp;gt; 负样本 （Date=null &amp;amp; Coupon_id != null）
– 没领优惠券 &amp;amp;&amp;amp; 已消费（Date!=null &amp;amp; Coupon_id = null）
– 领了优惠券 &amp;amp;&amp;amp; 已消费（Date!=null &amp;amp; Coupon_id != null）
– 总结：本数据作为刻画用户特点的主要依据较为合理
分析2：优惠率
– 总结：有可能用户会根据优惠率来决定是否进行消费
分析3：距离
– 离用户近的门店可能会总领取优惠券，但不一定会使用。
– 离用户远的门店如果有优惠券，则可能会为了很大的优惠率专程去使用。
总结
– 本数据集主要刻画线下用户特征。&lt;/p&gt;

&lt;h4 id=&#34;table-2-分析&#34;&gt;TABLE 2 分析&lt;/h4&gt;

&lt;p&gt;数据采样：
&lt;img src=&#34;../images/2018-03-22-14-12-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;特点：
– 标题：用户线上点击/消费和优惠券领取行为
– 场景：线上
– 行为：点击、消费、优惠券领取
– 数据：用户是否点击。购买。领取优惠券。
分析1：用户行为有三种情况
– 领了优惠券 &amp;amp;&amp;amp; 未消费 = 负样本（Date=null &amp;amp; Coupon_id != null）
– 没领优惠券 &amp;amp;&amp;amp; 已消费 （Date!=null &amp;amp; Coupon_id = null）
– 领了优惠券 &amp;amp;&amp;amp; 已消费 （Date!=null &amp;amp; Coupon_id != null）
分析2：用户点击、消费、优惠券情况
– 用户点击了 &amp;amp;&amp;amp; 没领优惠券 &amp;amp;&amp;amp; 未消费 =&amp;gt; 负样本
– 用户点击了 &amp;amp;&amp;amp; 领了优惠券 &amp;amp;&amp;amp; 未消费
– 用户点击了 &amp;amp;&amp;amp; 领了优惠券 &amp;amp;&amp;amp; 已消费
– 用户点击了 &amp;amp;&amp;amp; 没领优惠券 &amp;amp;&amp;amp; 已消费
– 用户没点击
总结
– 本数据集主要刻画线上用户特征。&lt;/p&gt;

&lt;p&gt;然后大家可以针对数据做一些统计然后将数据进行可视化展示，不过网络上已经有人做好了统计，我们直接从网络上面下载过了，下面是基本的一些指标：
&lt;img src=&#34;../images/2018-03-22-14-16-35.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2018-03-22-14-17-00.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2018-03-22-14-24-18.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2018-03-22-14-24-33.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-项目设计&#34;&gt;2.项目设计&lt;/h3&gt;

&lt;p&gt;提供数据的区间是2016-01-01~2016-06-30，预测七月份用户领券使用情况，即用或者不用，转化为二分类问题，然后通过分类算法预测结果。首先就是特征工程，其中涉及对数据集合的划分，包括提取特征的区间和训练数据区间。接着就是从特征区间中提取特征，包括用户特征、商户特征、优惠券特征、用户商户组合特征、用户优惠券组合特征。然后使用GBDT、RandomForest、LR进行基于rank的分类模型融合，模型完成以后我们需要进行验证。&lt;/p&gt;

&lt;h3 id=&#34;3-数据预览和简单实现&#34;&gt;3.数据预览和简单实现&lt;/h3&gt;

&lt;p&gt;为了更加深入理解项目目标，我们通过python脚本一步一步理解一下数据，同时熟悉一下python相关的API的使用，对数据进行简单的统计。&lt;/p&gt;

&lt;h4 id=&#34;1-分析正负数据样本&#34;&gt;1. 分析正负数据样本&lt;/h4&gt;

&lt;p&gt;新建一个python脚本&lt;code&gt;tianchi_1.py&lt;/code&gt;，
加上下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;

data = pd.read_csv(path_to_offline)

print(data.head())
print(data.shape[0])
print(data.shape[1])

# 最终发现数据有：1754884行

# 我们发现 其中有很多Coupon_id为null的数据。我们做的是优惠券使用预测，可是这些数据都没有用优惠劵，所以，首先将这些数据挑选出来。

# 不为空的数据
data1 = data[data[&#39;coupon_id&#39;] != &amp;quot;null&amp;quot;]
print(data1.head())
print(data1.shape)

# 为空的数据
data2 = data[data[&#39;coupon_id&#39;] == &amp;quot;null&amp;quot;]
print(data2.head())
print(data2.shape)

# 最终发现null数据有：701602行，不为空的：1053282行，保存为.csv备用


# 这两段代码保存数据
data1.to_csv(&#39;ccf_offline_stage1_train_NoNull.csv&#39;,index=False,header=True)
data2.to_csv(&#39;ccf_offline_stage1_train_Null.csv&#39;,index=False,header=True)
print &amp;quot;检查数据&amp;quot;

# 首先检查没有优惠券的数据
data = data2

test = data[data[&#39;date&#39;] == &amp;quot;null&amp;quot;]
print(test.head())
print(&amp;quot;没有优惠券的数据中，没有消费的条数为：&amp;quot;)
print(test.shape[0])

# 这里打印出来发现没有消费的条数为0？
# 阿里提供数据的时候提供的都是消费数据，因为没有领取优惠劵，也没有实际消费的，在阿里不会能留下数据给我们！

# 所以，我们在预测的时候，如果没有领取优惠券，可以直接预测为消费！ 当然数据里面没有这种情况。


# 再看优惠券不为空的数据集合
data = data1

test1 = data[data[&#39;date&#39;] == &amp;quot;null&amp;quot;]
print(test1.head())
print(&amp;quot;有优惠券的数据中，没有消费的条数为：&amp;quot;)
print(test1.shape[0])
test1.to_csv(&#39;ccf_offline_stage1_train_N.csv&#39;, index=False, header=True)


test2 = data[data[&#39;date&#39;] != &amp;quot;null&amp;quot;]
print(test2.head())
print(&amp;quot;有优惠券的数据中，并且消费的条数为：&amp;quot;)
print(test2.shape[0])
test2.to_csv(&#39;ccf_offline_stage1_train_P.csv&#39;, index=False, header=True)

# 正样本：75382个 负样本 977900个
# 那么平均的使用率为75382/1053282=0.071569
print (test2.shape[0] * 1.0 / (test1.shape[0] + test2.shape[0]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;相关代码的含义我们已经解释清楚了，只需要大家根据注释一步一步运行即可。另外最后运行完成后会在当前代码下生成四份数据，作为接下来的数据实验样本。&lt;/p&gt;

&lt;h4 id=&#34;2-简单进行topn分析&#34;&gt;2. 简单进行topN分析&lt;/h4&gt;

&lt;p&gt;重新新建一个python文件&lt;code&gt;tianchi_2.py&lt;/code&gt;，添加下面的代码，一步一步运行查看。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;

data = pd.read_csv(path_to_offline)

# 输出排名前列和后列的商户ID ，发现了两级分化严重啊，小店铺真的可怜，看来不一定做生意就能赚钱啊。
d1 = data[&#39;merchant_id&#39;]
print(d1.value_counts())

# 输出排名前列和后列的用户ID ，发现用户层两级分化更严重啊，土豪的日志就是买买买，但是穷人们。。。
d1 = data[&#39;user_id&#39;]
print(d1.value_counts())

# 直观感觉土豪估计以后还是会买买买，穷人基本上不会买了。中间层才有数据分析和挖掘的价值。

# 同理我们统计一下线上的店铺信息
print &amp;quot;统计线下信息&amp;quot;
data = pd.read_csv(path_to_online)

# 线上线下就是不一样，线上交易明显量更多
d1 = data[&#39;merchant_id&#39;]
print(d1.value_counts())

# 输出排名前列和后列的用户ID ，发现线上用户消费更多，线上土豪的更土豪了
d1 = data[&#39;user_id&#39;]
print(d1.value_counts())
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-特征工程&#34;&gt;3.特征工程&lt;/h4&gt;

&lt;p&gt;然后可以用一个简单的模型运行一下，思路很简单，就是先提取特征和正负例样本，生成模型，然后对数据进行预测。我们直接用下面的几个特征：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#用户相关特征：
#FUser1 线下领取优惠券后消费次数
#FUser2 线下消费总次数
#商户相关特征：
#FMer1 线下总领取优惠券次数
#FMer2 线下总领取优惠券后消费次数
#FMer3 线下总消费次数
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先我们提取用户特征，新建python文件&lt;code&gt;tianchi_3.py&lt;/code&gt;，添加下面的代码，提取用户的两个特征，保存到文件中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;

OffTrain = pd.read_csv(path_to_offline, low_memory=False)

# 头文件信息，输出：user_id,merchant_id,coupon_id,discount_rate,distance,date_received,date
print OffTrain.head()

# 把其中出现的所有的用户ID都统计出来
FUser = OffTrain[[&#39;user_id&#39;]]
print(&amp;quot;FUser.shape=&amp;quot;, FUser.shape)

# 去重，总共有539438个独立用户
FUser.drop_duplicates(inplace=True)
OffTrainUser = FUser.shape[0]
print(&amp;quot;OffTrainUser=&amp;quot;, OffTrainUser)
FUser = FUser.reset_index(drop=True)

# 读取正样本，总共75382个正样本
OffTrainP = pd.read_csv(&#39;ccf_offline_stage1_train_P.csv&#39;)
OffTrainPNumber = OffTrainP.shape[0]
print(&amp;quot;OffTrainPNumber=&amp;quot;, OffTrainPNumber)
OffTrainPperUser = OffTrainPNumber * 1.0 / OffTrainUser
# 每个独立用户可能购买的几率是13.974173%
print(&amp;quot;OffTrainPperUser=&amp;quot;, OffTrainPperUser)

# 寻找同样的ID在P样本中出现的次数


# 得到userid列
t = OffTrainP[[&#39;user_id&#39;]]
# 添加 Feature1，线下消费总次数
t[&#39;FUser1&#39;] = 1
# 对数据进行求和，得到每个userid的购买次数
t = t.groupby(&#39;user_id&#39;).agg(&#39;sum&#39;).reset_index()
# join操作
FUser = pd.merge(FUser, t, on=[&#39;user_id&#39;], how=&#39;left&#39;)
print(FUser.head(5))

# 把所有NaN填充为0
FUser = FUser.fillna(0)
print(FUser.head(5))

t = OffTrain[OffTrain[&#39;date&#39;] != &amp;quot;null&amp;quot;]
t = t[[&#39;user_id&#39;]]
# 添加特征2，领取优惠券后消费的次数
t[&#39;FUser2&#39;] = 1
# 求和
t = t.groupby(&#39;user_id&#39;).agg(&#39;sum&#39;).reset_index()

# join
FUser = pd.merge(FUser, t, on=[&#39;user_id&#39;], how=&#39;left&#39;)
FUser = FUser.fillna(0)
print(FUser.head(5))

print(FUser.FUser2.describe())
FUser.to_csv(&#39;FUser.csv&#39;, index=False, header=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行完后会生成用户特征文件：FUser.csv。
然后我们提取商户特征，新建python文件&lt;code&gt;tianchi_4.py&lt;/code&gt;，添加下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd

path_to_offline = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;~/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;

OffTrain = pd.read_csv(path_to_offline, low_memory=False)

# 头文件信息，输出：user_id,merchant_id,coupon_id,discount_rate,distance,date_received,date
print OffTrain.head()

# 把线下商户ID都提取出来
FMer = OffTrain[[&#39;merchant_id&#39;]]
print(&amp;quot;FMer.shape=%s&amp;quot;, FMer.shape)
# 去掉重复的
FMer.drop_duplicates(inplace=True)
print(&amp;quot;FMer.shape=&amp;quot;, FMer.shape)
# 重新建立索引
FMer = FMer.reset_index(drop=True)
t = OffTrain[OffTrain[&#39;coupon_id&#39;] != &amp;quot;null&amp;quot;]  # 取出所有有领取优惠券的部分
# print(t.shape)
t = t[[&#39;merchant_id&#39;]]
t[&#39;FMer1&#39;] = 1  # 特征1
t = t.groupby(&#39;merchant_id&#39;).agg(&#39;sum&#39;).reset_index()  # 求和
# print(t.head())
FMer = pd.merge(FMer, t, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
FMer = FMer.fillna(0)
print(FMer.head())
# FMer2 线下总领取优惠券后消费次数
t = OffTrain[OffTrain[&#39;coupon_id&#39;] != &amp;quot;null&amp;quot;]  # 取出所有有领取优惠券的部分
print(t.shape)
t = t[t[&#39;date&#39;] != &#39;null&#39;]
print(t.shape)
t = t[[&#39;merchant_id&#39;]]
t[&#39;FMer2&#39;] = 1  # 特征2
t = t.groupby(&#39;merchant_id&#39;).agg(&#39;sum&#39;).reset_index()  # 求和
# print(t.head())
FMer = pd.merge(FMer, t, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
FMer = FMer.fillna(0)
print(FMer.head())
# FMer3 线下总消费次数
t = OffTrain[OffTrain[&#39;date&#39;] != &amp;quot;null&amp;quot;]  # 取出所有有消费的部分
print(t.shape)
t = t[[&#39;merchant_id&#39;]]
t[&#39;FMer3&#39;] = 1  # 特征3
t = t.groupby(&#39;merchant_id&#39;).agg(&#39;sum&#39;).reset_index()  # 求和
# print(t.head())
FMer = pd.merge(FMer, t, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
FMer = FMer.fillna(0)
print(FMer.head())
FMer.to_csv(&#39;FMer.csv&#39;, index=False, header=True)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实和之前的是相似的,运行完成后会生成你的&lt;code&gt;FMer.csv&lt;/code&gt;文件。&lt;/p&gt;

&lt;h4 id=&#34;4-建模预测&#34;&gt;4.建模预测&lt;/h4&gt;

&lt;p&gt;我们选择使用python的随机森林模型进行建模预测。新建&lt;code&gt;tianchi_5.py&lt;/code&gt;,添加下面的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# coding=utf-8
import pandas as pd
import numpy as np
import time
from sklearn.ensemble import RandomForestRegressor

path_to_offline = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_offline_stage1_train.csv&amp;quot;
path_to_online = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_online_stage1_train.csv&amp;quot;
path_to_test = &amp;quot;/Users/dengziming/Desktop/hongya/tmp/day10/ccf_offline_stage1_test_revised.csv&amp;quot;
path_to_offline_train_N = &#39;ccf_offline_stage1_train_N.csv&#39;
path_to_offline_train_P = &#39;ccf_offline_stage1_train_P.csv&#39;
path_to_FMer = &amp;quot;FMer.csv&amp;quot;
path_to_FUser = &amp;quot;FUser.csv&amp;quot;
path_to_Result = &amp;quot;sample_submission20180401.csv&amp;quot;

OffTrain = pd.read_csv(path_to_offline, low_memory=False)

# 头文件信息，输出：user_id,merchant_id,coupon_id,discount_rate,distance,date_received,date
print OffTrain.head()

# 读取特征文件
FMer = pd.read_csv(path_to_FMer)  # 商户特征
FUser = pd.read_csv(path_to_FUser)  # 用户特征

# 读取样本数据
OffTrainN = pd.read_csv(path_to_offline_train_N)
OffTrainP = pd.read_csv(path_to_offline_train_P)

# 加入FLag区分P和N
OffTrainN[&#39;Flag&#39;] = 0
OffTrainP[&#39;Flag&#39;] = 1

# 负样本建立特征列
print(&amp;quot;OffTrainN&amp;quot;, OffTrainN.shape)
# 和特征join，添加特征
OffTrainN = pd.merge(OffTrainN, FUser, on=[&#39;user_id&#39;], how=&#39;left&#39;)
print OffTrainN.head()
OffTrainN = pd.merge(OffTrainN, FMer, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)

print(OffTrainN.shape)
print (OffTrainN.head())

# 正样本建立特征列
print(&amp;quot;OffTrainP&amp;quot;, OffTrainP.shape)
# 和特征join，添加特征

OffTrainP = pd.merge(OffTrainP, FUser, on=[&#39;user_id&#39;], how=&#39;left&#39;)
OffTrainP = pd.merge(OffTrainP, FMer, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)

print(OffTrainP.shape)
OffTrainP.head()

# 生成Flag数组
OffTrainFlagP = OffTrainP[&#39;Flag&#39;].values
print(&amp;quot;OffTrainFlagP&amp;quot;, OffTrainFlagP)
print(OffTrainFlagP.shape)
OffTrainFlagN = OffTrainN[&#39;Flag&#39;].values
print(&amp;quot;OffTrainFlagN&amp;quot;, OffTrainFlagN)
print(OffTrainFlagN.shape)

# 合并Flag
OffTrainFlag = np.append(OffTrainFlagP, OffTrainFlagN)
print(&amp;quot;OffTrainFlag&amp;quot;, OffTrainFlag)
print(OffTrainFlag.shape[0])

# 生成特征数组
OffTrainFeatureP = OffTrainP[[&#39;FUser1&#39;, &#39;FUser2&#39;, &#39;FMer1&#39;, &#39;FMer2&#39;, &#39;FMer3&#39;]].values
print(&amp;quot;OffTrainFeatureP&amp;quot;, OffTrainFeatureP)
print(OffTrainFeatureP.shape)
OffTrainFeatureN = OffTrainN[[&#39;FUser1&#39;, &#39;FUser2&#39;, &#39;FMer1&#39;, &#39;FMer2&#39;, &#39;FMer3&#39;]].values
print(&amp;quot;OffTrainFeatureN&amp;quot;, OffTrainFeatureN)
print(OffTrainFeatureN.shape)

# 合并特征
OffTrainFeature = np.append(OffTrainFeatureP, OffTrainFeatureN, axis=0)
print(&amp;quot;OffTrainFeature&amp;quot;, OffTrainFeature)
print(OffTrainFeature.shape)

&#39;&#39;&#39;训练模型&#39;&#39;&#39;
print &amp;quot;开始计算模型&amp;quot;
# 使用模型
rf = RandomForestRegressor()  # 这里使用了默认的参数设置
rf.fit(OffTrainFeature, OffTrainFlag)  # 进行模型的训练

# 使用模型预估
temp = rf.predict(OffTrainFeature)
start = time.time()
err = 0
for i in range(OffTrainFeature.shape[0]):
    t = temp[i] - OffTrainFlag[i]
    if (t &amp;gt; 0.5) | (t &amp;lt; -0.5):
        err += 1
err = err * 1.0 / OffTrainFeature.shape[0]
end = time.time()
print (&amp;quot;建模时间：&amp;quot;)
print(end - start)
print (&amp;quot;模型在测试数据上的精度：&amp;quot;)
print(1 - err)

# 读取测试集
Test = pd.read_csv(path_to_test)

Test = pd.merge(Test, FUser, on=[&#39;user_id&#39;], how=&#39;left&#39;)
Test = pd.merge(Test, FMer, on=[&#39;merchant_id&#39;], how=&#39;left&#39;)
Test[&#39;Flag&#39;] = 0.0
print(Test.shape)
print(Test.head())
Test = Test.fillna(0)
TestFeature = Test[[&#39;FUser1&#39;, &#39;FUser2&#39;, &#39;FMer1&#39;, &#39;FMer2&#39;, &#39;FMer3&#39;]].values
print(TestFeature.shape)
print(TestFeature)
start = time.time()
temp = rf.predict(TestFeature)
end = time.time()
print(end - start)
Test[&#39;Flag&#39;] = temp
Test.head()
Test.to_csv(path_to_Result, columns=[&#39;user_id&#39;, &#39;coupon_id&#39;, &#39;date_received&#39;, &#39;Flag&#39;],
            index=False, header=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里我们的结果数据就产生了，最后我们计算了模型在测试数据上的精度为：0.958539118679，还算比较高，当然在实际提交到天池官网精度只是略大于0.5而已。&lt;/p&gt;

&lt;h2 id=&#34;三-开发环境搭建&#34;&gt;三、开发环境搭建&lt;/h2&gt;

&lt;p&gt;我们使用spark进行数据分析，实际上你可以将表格保存到hive上面，使用hive进行数据的清洗，但是我们为了避免遇到很多环境的问题，直接使用spark读取文件，进行数据清洗即可。&lt;/p&gt;

&lt;h3 id=&#34;1-新建项目&#34;&gt;1.新建项目&lt;/h3&gt;

&lt;p&gt;我们以前新建项目都是打开IDEA，新建一个maven项目&lt;code&gt;hongya-coupon-analyze&lt;/code&gt;，选择scala的archetype，填好GroupId和ArtificialId：
&lt;img src=&#34;../images/2018-04-14-20-36-09.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后配置maven地址等，这个步骤以及做过很多遍，这里就不截图了。&lt;/p&gt;

&lt;p&gt;然后我们可能要新建一些模块，由于模块类型我们没定，所以暂时可以放在下一步中完成。
注意在pom文件添加多环境配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;profiles&amp;gt;
    &amp;lt;profile&amp;gt;
      &amp;lt;!-- 本地开发环境 --&amp;gt;
      &amp;lt;id&amp;gt;dev&amp;lt;/id&amp;gt;
      &amp;lt;properties&amp;gt;
        &amp;lt;package.environment&amp;gt;dev&amp;lt;/package.environment&amp;gt;
        &amp;lt;spark.scope&amp;gt;compile&amp;lt;/spark.scope&amp;gt;
      &amp;lt;/properties&amp;gt;
      &amp;lt;activation&amp;gt;
        &amp;lt;activeByDefault&amp;gt;true&amp;lt;/activeByDefault&amp;gt;
      &amp;lt;/activation&amp;gt;
    &amp;lt;/profile&amp;gt;
    &amp;lt;profile&amp;gt;
      &amp;lt;!-- 测试环境 --&amp;gt;
      &amp;lt;id&amp;gt;test&amp;lt;/id&amp;gt;
      &amp;lt;properties&amp;gt;
        &amp;lt;package.environment&amp;gt;test&amp;lt;/package.environment&amp;gt;
        &amp;lt;spark.scope&amp;gt;provided&amp;lt;/spark.scope&amp;gt;
      &amp;lt;/properties&amp;gt;
    &amp;lt;/profile&amp;gt;
    &amp;lt;profile&amp;gt;
      &amp;lt;!-- 生产环境 --&amp;gt;
      &amp;lt;id&amp;gt;prod&amp;lt;/id&amp;gt;
      &amp;lt;properties&amp;gt;
        &amp;lt;package.environment&amp;gt;prod&amp;lt;/package.environment&amp;gt;
        &amp;lt;spark.scope&amp;gt;provided&amp;lt;/spark.scope&amp;gt;
      &amp;lt;/properties&amp;gt;
    &amp;lt;/profile&amp;gt;
  &amp;lt;/profiles&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-加入依赖&#34;&gt;2.加入依赖&lt;/h3&gt;

&lt;p&gt;我们这次的开发需要使用到的依赖是spark-core和spark-mllib，开发也有可能用到其他的库，到时候再加入即可，我们完整的pom文件的依赖可以参考项目。我们删掉项目新建完成后自带的测试scala文件和依赖。&lt;/p&gt;

&lt;h2 id=&#34;三-项目开发&#34;&gt;三、项目开发&lt;/h2&gt;

&lt;p&gt;项目开发按照上面的步骤进行。&lt;/p&gt;

&lt;h3 id=&#34;1-数据清洗部分开发&#34;&gt;1.数据清洗部分开发&lt;/h3&gt;

&lt;p&gt;由于我们是多环境下工作，我们需要解析配置文件，首先新建一个&lt;code&gt;Settings&lt;/code&gt;类，用来解析配置，路径为 &lt;code&gt;com.hongya.bigdata.coupon.util&lt;/code&gt;,相关代码可以参考以前的代码，其实就是读取配置：
&lt;img src=&#34;../images/2018-04-15-08-44-16.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们通过读取数据进行ETL操作，在&lt;code&gt;com.hongya.bigdata.coupon.etl&lt;/code&gt;包下新建DataEtl类，然后添加数据ETL的代码，代码主要是读取数据，将消费和未消费的数据取出分别保存，相关代码可以查看我们给的源码：
&lt;img src=&#34;../images/2018-04-15-09-18-00.jpg&#34; alt=&#34;&#34; /&gt;
然后我们在&lt;code&gt;src/main/resources&lt;/code&gt;下面新建dev文件夹，添加config.properties文件。添加Etl需要的三个文件路径，分别是输入的offline数据路径，正负例样本路径：
&lt;img src=&#34;../images/2018-04-15-09-30-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后打开idea自带的终端，输打包命令：&lt;code&gt;mvn clean install -P dev&lt;/code&gt;
&lt;img src=&#34;../images/2018-04-15-09-25-43.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;稍等编译完成就可以点击&lt;code&gt;DataEtl&lt;/code&gt;类的运行：
&lt;img src=&#34;../images/2018-04-15-09-26-46.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;运行完成后你会在你配置的路径下面看到输出文件：
&lt;img src=&#34;../images/2018-04-15-09-35-44.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-特征工程部分代码&#34;&gt;2.特征工程部分代码&lt;/h3&gt;

&lt;p&gt;我们首先要取到数据进行特征提取。类似前面的逻辑，首先在&lt;code&gt;com.hongya.bigdata.coupon.feature&lt;/code&gt;包下面新建&lt;code&gt;UserFeature&lt;/code&gt;类，添加提取用户特征的代码：
&lt;img src=&#34;../images/2018-04-15-09-40-45.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;代码详情可以查看源码，注意我们使用了一个sql语句提取用户特征：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.user_id,
    b.FUser1,
    c.FUser2
from
    (select distinct user_id from train_P ) a
left join
    (select user_id,sum(1) as FUser1 from train_P group by user_id) b
on
    a.user_id = b.user_id
left join
    (select user_id,sum(1) as FUser2 from train_P where date&amp;lt;&amp;gt;&#39;null&#39; group by user_id) c
on
    a.user_id = c.user_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个sql的含义大家自己理解，我们可以使用更加复杂的sql提取更多特征。
然后我们在配置文件配置用户特征的保存路径：
&lt;img src=&#34;../images/2018-04-15-09-42-11.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;点击运行代码：
&lt;img src=&#34;../images/2018-04-15-09-42-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;运行完成后可以看到我们配置的目录下有用户特征文件:
&lt;img src=&#34;../images/2018-04-15-09-52-19.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;同理新建MerchantFeature文件：
&lt;img src=&#34;../images/2018-04-15-09-55-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意我们获得特征的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.merchant_id,
    b.FMer1,
    c.FMer2,
    d.FMer3
from
    (select distinct merchant_id from train ) a
left join
    (select merchant_id,sum(1) as FMer1 from train where coupon_id&amp;lt;&amp;gt;&#39;null&#39; group by merchant_id) b
on
    a.merchant_id = b.merchant_id
left join
    (select merchant_id,sum(1) as FMer2 from train where coupon_id&amp;lt;&amp;gt;&#39;null&#39; and date&amp;lt;&amp;gt;&#39;null&#39; group by merchant_id) c
on
    a.merchant_id = c.merchant_id
left join
    (select merchant_id,sum(1) as FMer3 from train where date&amp;lt;&amp;gt;&#39;null&#39; group by merchant_id) d
on
    a.merchant_id = d.merchant_id

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加merchant配置：
&lt;img src=&#34;../images/2018-04-15-09-58-27.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后点击运行，完成后会有FMer文件夹生成，数据有空值，这需要我们后续处理的时候进行进一步填值：
&lt;img src=&#34;../images/2018-04-15-09-59-36.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-建模预测&#34;&gt;3.建模预测&lt;/h3&gt;

&lt;p&gt;新建模型计算的代码，读取数据进行预测，相关代码可以参考源码：
&lt;img src=&#34;../images/2018-04-15-12-29-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意我们使用了sql语句将数据变成我们模型的入口格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.user_id,
    a.merchant_id,
    coalesce(b.FUser1,0) as FUser1,
    coalesce(b.FUser2,0) as FUser2,
    coalesce(c.FMer1,0) as FMer1,
    coalesce(c.FMer2,0) as FMer2,
    coalesce(c.FMer3,0) as FMer3,
    a.label as label
from
    (
    select
        user_id ,
        merchant_id,
        1 as label
    from
        train_P
    union all
    select
        user_id ,
        merchant_id,
        0 as label
    from
        train_N
    ) a
left join
    FUser b
on
    a.user_id = b.user_id
left join
    FMer c
on
    a.merchant_id = c.merchant_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外我们使用类似的sql将需要提交的数据变成我们模型的输入格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select
    a.user_id,
    a.merchant_id,
    a.coupon_id,
    a.date_received,
    coalesce(b.FUser1,0) as FUser1,
    coalesce(b.FUser2,0) as FUser2,
    coalesce(c.FMer1,0) as FMer1,
    coalesce(c.FMer2,0) as FMer2,
    coalesce(c.FMer3,0) as FMer3
from
    (
    select
        user_id ,
        merchant_id,
        coupon_id,
        date_received
    from
        testData
    ) a
left join
    FUser b
on
    a.user_id = b.user_id
left join
    FMer c
on
    a.merchant_id = c.merchant_id
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们将原始数据分成两部分分别进行模型计算和测试，最后用模型计算天池提供的数据，生成提交文件。整个过程需要一定的时间，完成后会生产提交文件的文件，放在我们配置的文件中。&lt;/p&gt;

&lt;h2 id=&#34;四-集群部署&#34;&gt;四、集群部署&lt;/h2&gt;

&lt;h3 id=&#34;1-生产环境配置&#34;&gt;1.生产环境配置&lt;/h3&gt;

&lt;p&gt;我们前面配置了开发环境，现在改为生产环境即可，在resources下新建prod文件夹，和dev一样：
&lt;img src=&#34;../images/2018-04-15-12-42-48.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后将config.properties的配置也改一下即可，注意修改相应的配置为你的机器配置。然后启动项目即可:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-properties&#34;&gt;env=prod
# 配置输入路径
path_to_offline = hdfs://node1:8020/hongya/day10/input/ccf_offline_stage1_train.csv
path_to_online = hdfs://node1:8020/hongya/day10/input/cf_online_stage1_train.csv
path_to_test = hdfs://node1:8020/hongya/day10/input/ccf_offline_stage1_test_revised.csv
path_to_offline_train_N = hdfs://node1:8020/hongya/day10/output/ccf_offline_stage1_train_N
path_to_offline_train_P = hdfs://node1:8020/hongya/day10/output/ccf_offline_stage1_train_P
path_to_FMer = hdfs://node1:8020/hongya/day10/output/FMer
path_to_FUser = hdfs://node1:8020/hongya/day10/FUser
path_to_Result = hdfs://node1:8020/hongya/day10/output/sample_submission20180401
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们打包，执行命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn clean install -P prod
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打完包以后可以看到 &lt;code&gt;hongya-broker-analyze/order-handle/target&lt;/code&gt; 目录下有两个jar包，其中比较大一点的就是完整的jar，小一点的是我们代码编译后的输出。然后我们复制这个大一点的jar到集群环境下，提交相应的任务即可，一共三个任务：
&lt;img src=&#34;../images/2018-04-15-12-44-47.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-启动&#34;&gt;2.启动&lt;/h3&gt;

&lt;p&gt;我们将jar包和生产环境下的config.properties拷贝到集群环境下，再将原始的数据上传到hdfs上面，然后提交任务。
ETL任务的启动命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.etl.DataEtl \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_etl \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以在浏览器访问yarn的的8088端口查看应用程序了。执行完成后，可以用hadoop命令查看对应的路径上面的文件。&lt;/p&gt;

&lt;p&gt;第二个任务,提取商户特征：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.feature.MerchantFeature \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_merchant_feature \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第三个任务，提取用户特征：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.feature.UserFeature \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_user_feature \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第四个任务，新建模型并生成结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;${SPARK_HOME}/bin/spark-submit --master=yarn --deploy-mode=cluster \
--num-executors 5 \
--executor-memory 4g \
--executor-cores 1 \
--driver-memory 2g  \
--driver-cores 1 \
--files config.properties \
--class= com.hongya.bigdata.coupon.model.Model \
--conf spark.dynamicAllocation.enabled=false \
--name=hongaya_coupon_analyze_user_feature \
hongya-coupon-analyze-1.0-SNAPSHOT-fat.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然这几个任务你可以放在一个shell脚本中，一次性提交。&lt;/p&gt;

&lt;h3 id=&#34;3-查看结果数据&#34;&gt;3.查看结果数据&lt;/h3&gt;

&lt;p&gt;结果保存在我们配置的&lt;code&gt;path_to_Result&lt;/code&gt;中，我们通过hadoop命令即可查看，为了验证准确率，我们可以提交到天池的官网上面进行验证，相关步骤可以查看天池官网，经过验证了我们的模型准确率只有59%左右，基本上就比随机猜好一点点，这也是因为我们对数据的建模比较粗糙，大家可以提取更多的特征进行分析。&lt;/p&gt;

&lt;h2 id=&#34;五-实验总结&#34;&gt;五、实验总结&lt;/h2&gt;

&lt;h3 id=&#34;1-注意事项&#34;&gt;1.注意事项&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;测试环境下的开发过程比较需要一步一步来，数据量可能比较大，大家可以自己从文件中截取一千行作为测试数据；&lt;/li&gt;
&lt;li&gt;使用python进行数据分析的过程是我们从数据清洗、特征工程、建模、预测的完整步骤，大家需要一步一步亲自动手才行，最好多操作几遍；&lt;/li&gt;
&lt;li&gt;使用spark和python进行分析的过程大家可以对比，python是动态语言，所以在类型操作更加方便，python代码更加简介。但是spark实际上也不复杂，而且我们使用的是低版本的spark风格，实际上高版本的spark直接基于DataFrame代码就很简洁了。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-心得体会&#34;&gt;2.心得体会&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;数据分析大部分时间都是特征工程，建模时间是很少的，建模最复杂的是调参；&lt;/li&gt;
&lt;li&gt;spark机器学习库和python的机器学习操作代码是很类似的， 所以大家只要掌握了一种工具，再学习另外一种就很简单了；&lt;/li&gt;
&lt;li&gt;本次实验体验了一次天池大数据竞赛的题目，对于数据分析项目有了更加深入的理解，以后能后快速上手类似的数据分析项目。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;源码地址：&lt;code&gt;https://github.com/dengziming/hongya-coupon-analyze&lt;/code&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>hadoop网站日志分析项目架构</title>
      <link>https://dengziming.github.io/post/project/hadoop/hadoop/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/project/hadoop/hadoop/</guid>
      
        <description>

&lt;p&gt;项目简介：大数据涉及到的业务很多很复杂，从一开始的项目架构，再到后台的网站搭建，以及数据的收集，数据的分析，数据的迁移，业务开发，后台运维，等等。我们没办法一个实验将所有的过程都学习到。本次试验我们将会将重点放在项目架构上，后面的项目我们将重点放在每一部分的实现上。通过本次实验，你将能了解到一个大数据架构师工作的基本步骤，虽然本次实验我们也有复杂的代码分析过程，但是大家没有必要将自己的重点放在代码上面，大家应该更加站在架构师的角度，专注于整个项目每一部分的连接，每个部分具体实现的细节，大家可以不必太深入，我们后期会有专门的实验放在这上面。
有关代码我们已经实现并且提供，大家直接打开，然后阅读熟悉每部分的意义即可。
本次项目我们是架构一个日志分析，我们的要完成的任务包括后台和前端的实现，网站的搭建，nginx反向代理的搭建，etl数据清洗程序，数据分析，数据报表的实现。&lt;/p&gt;

&lt;h2 id=&#34;一-业务分析和需求文档&#34;&gt;一、业务分析和需求文档&lt;/h2&gt;

&lt;h3 id=&#34;1-业务分析概述&#34;&gt;1.业务分析概述&lt;/h3&gt;

&lt;p&gt;本次试验我们主要是分析类似淘宝等购物网站上的点击流，从而进行展示分析。在本次项目中我们分别从七个大的角度来进行分析，分别为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;用户基本信息分析模块、浏览器信息分析模块、地域信息分析模块、用户浏览深度分析模块、外链数据分析模块、订单分析模块以及事件分析模块。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意几个概念:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;用户/访客：表示同一个浏览器代表的用户。唯一标示用户
会员：表示网站的一个正常的会员用户。
会话：一段时间内的连续操作，就是一个会话中的所有操作。
Pv：访问页面的数量
在本次项目中，所有的计数都是去重过的。比如：活跃用户/访客，计算uuid的去重后的个数。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们分析数据的需求文档和最终的展示结果大概如下。&lt;/p&gt;

&lt;h3 id=&#34;2-用户基本信息分析模块&#34;&gt;2.用户基本信息分析模块&lt;/h3&gt;

&lt;p&gt;用户基本信息分析模块主要是从用户/访客和会员两个主要角度分析浏览相关信息，包括但不限于新增用户，活跃用户，总用户，新增会员，活跃会员，总会员以及会话分析等。下面就各个不同的用户信息角度来进行分析：&lt;/p&gt;

&lt;h4 id=&#34;1-用户分析&#34;&gt;(1).用户分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析新增用户、活跃用户以及总用户的相关信息。
新访客:老访客(活跃访客中) =  1:7~10
&lt;img src=&#34;../images/2017-06-20-21-21-54.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-会员分析&#34;&gt;(2).会员分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析新增会员、活跃会员以及总会员的相关信息。
&lt;img src=&#34;../images/2017-06-20-21-22-26.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-会话分析&#34;&gt;(3).会话分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析会话个数、会话长度和平均会话长度相关的信息。
&lt;img src=&#34;../images/2017-06-20-21-23-17.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-hourly分析&#34;&gt;(4).Hourly分析&lt;/h4&gt;

&lt;p&gt;该分析主要分析每天每小时的用户、会话个数以及会话长度的相关信息。
&lt;img src=&#34;../images/2017-06-20-21-24-07.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-其他模块分析&#34;&gt;3.其他模块分析&lt;/h3&gt;

&lt;p&gt;在用户模块的基础上，我们可以添加其他的六个模块分析，我们本次试验先不展示所有的模块，只是作简单介绍，例如地域分布模块：
&lt;img src=&#34;../images/2017-06-20-21-25-43.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面分析的业务需求大家可能不太懂，没关系，注意在下面的项目中，时不时回头看看我们的需求，就能明白了。&lt;/p&gt;

&lt;h2 id=&#34;二-开发环境搭建&#34;&gt;二、开发环境搭建&lt;/h2&gt;

&lt;p&gt;为了方便管理，我们以后按照管理，尽量使用maven构建java和scala项目。另外我们的软件安装在D盘的&lt;code&gt;soft&lt;/code&gt;目录下，我们的开发项目放在D盘的&lt;code&gt;workspace&lt;/code&gt;目录下。&lt;/p&gt;

&lt;h3 id=&#34;1-下载安装软件&#34;&gt;1.下载安装软件&lt;/h3&gt;

&lt;p&gt;分别在&lt;code&gt;http://tomcat.apache.org&lt;/code&gt;和&lt;code&gt;http://maven.apache.org&lt;/code&gt;下载tomcat和maven，解压后放在D盘的soft目录，然后配置环境变量，需要配置的环境变量包括 &lt;code&gt;MAVEN_HOME&lt;/code&gt;和&lt;code&gt;TOMCAT_HOME&lt;/code&gt;，并且将他们的bin目录添加到&lt;code&gt;PATH&lt;/code&gt;中。安装配置完成后，在命令行输入start-up和mvn命令，检查是否安装正确。
确保无误后，我们的开发环境使用IDEA，安装好IDEA，打开，配置maven的目录，如下图的方法，搜索maven，在Maven的配置填写maven的路径。
&lt;img src=&#34;../images/2017-06-20-19-07-00.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-搭建服务器&#34;&gt;2.搭建服务器&lt;/h3&gt;

&lt;h4 id=&#34;1-布置开发环境&#34;&gt;(1).布置开发环境&lt;/h4&gt;

&lt;p&gt;如果大家熟悉javaEE开发，这一段就比较简单。我们搭建服务器就是新建一个javaEE项目，然后启动，这个过程需要借助tomcat实现。首先打开IDEA，IDEA中已经配置好了maven的路径。
点击File -&amp;gt;New -&amp;gt; Project ，选择java的web application，然后下一步:
&lt;img src=&#34;../images/2017-06-20-19-09-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在下一步我们设置项目路径，我们的项目名为&lt;code&gt;taobaopayment&lt;/code&gt;，放在D盘下的workspace目录下。然后点击完成。这时候就新建了一个web项目，我们在项目的web文件下能看到一个index.jsp文件，这个文件你可以修改为自定义的内容，例如我修改为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;%@ page contentType=&amp;quot;text/html;charset=UTF-8&amp;quot; language=&amp;quot;java&amp;quot; %&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;taobaopayment&amp;lt;/title&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
  支付页面
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-本地发布项目&#34;&gt;(2).本地发布项目&lt;/h4&gt;

&lt;p&gt;菜单栏选择Run -&amp;gt;Edit Configuration或者点击右上角按钮添加tomcat的发布参数，依次点击 加号 -&amp;gt;tomcat server -&amp;gt; local ，添加tomcat：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2017-06-20-19-18-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在右边的配置页面配置好名字、地址、端口：
&lt;img src=&#34;../images/2017-06-20-19-20-30.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后在deployment选项下面点击加号添加发布选项，然后设置你content名字，我们设置为 &lt;code&gt;taobaopayment&lt;/code&gt;：
&lt;img src=&#34;../images/2017-06-20-19-21-52.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;点击确定后，我们可以看到右上方和下方都出现了可以启动的三角形按钮，点击启动：
&lt;img src=&#34;../images/2017-06-20-19-25-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;启动成功后打开浏览器，输入&lt;code&gt;http://localhost:8080/taobaopayment/&lt;/code&gt;，出现我们刚刚编辑的jsp页面，剩下的操作自己实验。
&lt;img src=&#34;../images/2017-06-20-19-24-42.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;三-web服务器开发&#34;&gt;三、Web服务器开发&lt;/h2&gt;

&lt;p&gt;根据我们的需求文档，我们需要实现支付成功和退款页面。这里又分为两部分，一是前端的页面传来的请求数据，这部分代码使用JavaScript编写，另一方面是后台的服务器发送过来的代码，通过Java语言编写。&lt;/p&gt;

&lt;h3 id=&#34;1-后端开发&#34;&gt;1.后端开发&lt;/h3&gt;

&lt;h4 id=&#34;1-程序后台事件分析&#34;&gt;(1).程序后台事件分析&lt;/h4&gt;

&lt;p&gt;本项目中在程序后台会有chargeSuccess事件，本事件的主要作用是发送订单成功的信息给nginx服务器。发送格式同pc端发送方式， 也是访问同一个url来进行数据的传输。格式为:
&lt;code&gt;http://hongyahuayu.com/index.jpg?query1=spark&lt;/code&gt;
当会员最终支付成功的时候触发chargeSuccess该事件，该事件需要程序主动调用，然后向后台发送数据：
&lt;code&gt;u_mid=maomao&amp;amp;c_time=1449142044528&amp;amp;oid=orderid_1&amp;amp;ver=1&amp;amp;en=e_cs&amp;amp;pl=jdk&amp;amp;sdk=java&lt;/code&gt;，其中 &lt;code&gt;u_mid&lt;/code&gt;和&lt;code&gt;oid&lt;/code&gt;代表用户id和订单id。
前面我们分析了后端的业务，如果你不太懂，我们尅简单地说，后端程序的工作流如下：
&lt;img src=&#34;../images/2017-06-20-21-52-16.jpg&#34; alt=&#34;&#34; /&gt;
简单说，后端就是要设计方法，当&lt;code&gt;chargeSuccess&lt;/code&gt;触发的时候，我们给后台发送数据。&lt;/p&gt;

&lt;h4 id=&#34;2-后端程序开发&#34;&gt;(2).后端程序开发&lt;/h4&gt;

&lt;p&gt;程序开发有一定难度，另外由于我们本次试验的重点是后面的数据分析，这一块不作太高的要求，大家能够理解即可，核心代码如下，其余代码可以在项目中查看：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;	public static boolean onChargeSuccess(String orderId, String memberId) {
		try {
			if (isEmpty(orderId) || isEmpty(memberId)) {
				// 订单id或者memberid为空
				log.log(Level.WARNING, &amp;quot;订单id和会员id不能为空&amp;quot;);
				return false;
			}
			// 代码执行到这儿，表示订单id和会员id都不为空。
			Map&amp;lt;String, String&amp;gt; data = new HashMap&amp;lt;String, String&amp;gt;();
			data.put(&amp;quot;u_mid&amp;quot;, memberId);
			data.put(&amp;quot;oid&amp;quot;, orderId);
			data.put(&amp;quot;c_time&amp;quot;, String.valueOf(System.currentTimeMillis()));
			data.put(&amp;quot;ver&amp;quot;, version);
			data.put(&amp;quot;en&amp;quot;, &amp;quot;e_cs&amp;quot;);
			data.put(&amp;quot;pl&amp;quot;, platformName);
			data.put(&amp;quot;sdk&amp;quot;, sdkName);
			// 创建url
			String url = buildUrl(data);
			// 发送url&amp;amp;将url加入到队列
			SendDataMonitor.addSendUrl(url);
			return true;
		} catch (Throwable e) {
			log.log(Level.WARNING, &amp;quot;发送数据异常&amp;quot;, e);
		}
		return false;
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;注意事项&lt;/em&gt;&lt;/strong&gt; 修改代码这里url地址为自己服务器的地址：
&lt;img src=&#34;../images/2017-06-20-23-42-54.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-前端开发&#34;&gt;2.前端开发&lt;/h3&gt;

&lt;h4 id=&#34;1-前端事件分析&#34;&gt;(1).前端事件分析&lt;/h4&gt;

&lt;p&gt;前面我们说后端的事件主要是chargeSuccess，前端的时间处理就更复杂了。针对我们最终的不同分析模块，我们需要不同的数据，接下来分别从各个模块分析，每个模块需要的数据。
1. 用户基本信息就是用户的浏览行为信息分析，也就是我们只需要pageview事件就可以了；
2. 浏览器信息分析以及地域信息分析其实就是在用户基本信息分析的基础上添加浏览器和地域这个维度信息，其中浏览器信息我们可以通过浏览器的window.navigator.userAgent来进行分析，地域信息可以通过nginx服务器来收集用户的ip地址来进行分析，也就是说pageview事件也可以满足这两个模块的分析。
3. 外链数据分析以及用户浏览深度分析我们可以在pageview事件中添加访问页面的当前url和前一个页面的url来进行处理分析，也就是说pageview事件也可以满足这两个模块的分析。
4. 订单信息分析要求pc端发送一个订单产生的事件，那么对应这个模块的分析，我们需要一个新的事件chargeRequest。对于事件分析我们也需要一个pc端发送一个新的事件数据，我们可以定义为event。
我们要分析的模块包括：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;用户基本信息分析
浏览器信息分析
地域信息分析
外链数据分析
用户浏览深度分析
订单信息分析
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们处理的事件包括：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pageview事件
chargeRequest事件
launch事件
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一，Launch事件。当用户第一次访问网站的时候触发该事件，不提供对外调用的接口，只实现该事件的数据收集。
第二，Pageview事件，当用户访问页面/刷新页面的时候触发该事件。该事件会自动调用，也可以让程序员手动调用。
第三，chargeRequest事件。当用户下订单的时候触发该事件，该事件需要程序主动调用。
每次都会发送对应的数据，例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;u_sd=8E9559B3-DA35-44E1-AC98-85EB37D1F263&amp;amp;c_time=1449139048231&amp;amp;oid=orderid123&amp;amp;on=%E4%BA%A7%E5%93%81%E5%90%8D%E7%A7%B0&amp;amp;cua=1000&amp;amp;cut=%E4%BA%BA%E6%B0%91%E5%B8%81&amp;amp;pt=%E6%B7%98%E5%AE%9D&amp;amp;ver=1&amp;amp;en=e_cr&amp;amp;pl=website&amp;amp;sdk=js&amp;amp;b_rst=1920*1080&amp;amp;u_ud=12BF4079-223E-4A57-AC60-C1A04D8F7A2F&amp;amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%206.1%3B%20WOW64)%20AppleWebKit%2F537.1%20(KHTML%2C%20like%20Gecko)%20Chrome%2F21.0.1180.77%20Safari%2F537.1&amp;amp;l=zh-CN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个url的字段比较多，字段词典如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;参数名称	类型	描述
en	string	事件名称, eg: e_pv
ver	string	版本号, eg: 0.0.1
pl	string	平台, eg: website
sdk	string	Sdk类型, eg: js
b_rst	string	浏览器分辨率，eg: 1800*678
b_iev	string	浏览器信息useragent
u_ud	string	用户/访客唯一标识符
l	string	客户端语言
u_mid	string	会员id，和业务系统一致
u_sd	string	会话id
c_time	string	客户端时间
p_url	string	当前页面的url
p_ref	string	上一个页面的url
tt	string	当前页面的标题
ca	string	Event事件的Category名称
ac	string	Event事件的action名称
kv_*	string	Event事件的自定义属性
du	string	Event事件的持续时间
oid	string	订单id
on	string	订单名称
cua	string	支付金额
cut	string	支付货币类型
pt	string	支付方式
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-前端程序开发&#34;&gt;(2).前端程序开发&lt;/h4&gt;

&lt;p&gt;前面我们简单实现了后端开发，现在前端的JavaScript代码实现可能就更复杂了，对大家来说难度略大，但是还好这不是我们的重点，我大概展示几个函数：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;onPageView: function() {
				// 触发page view事件
				if (this.preCallApi()) {
					var time = new Date().getTime();
					var pageviewEvent = {};
					pageviewEvent[this.columns.eventName] = this.keys.pageView;
					pageviewEvent[this.columns.currentUrl] = window.location.href; // 设置当前url
					pageviewEvent[this.columns.referrerUrl] = document.referrer; // 设置前一个页面的url
					pageviewEvent[this.columns.title] = document.title; // 设置title
					this.setCommonColumns(pageviewEvent); // 设置公用columns
					this.sendDataToServer(this.parseParam(pageviewEvent)); // 最终发送编码后的数据ss
					this.updatePreVisitTime(time);
				}
			},

			onChargeRequest: function(orderId, name, currencyAmount, currencyType, paymentType) {
				// 触发订单产生事件
				if (this.preCallApi()) {
					if (!orderId || !currencyType || !paymentType) {
						this.log(&amp;quot;订单id、货币类型以及支付方式不能为空&amp;quot;);
						return ;
					}

					if (typeof(currencyAmount) == &amp;quot;number&amp;quot;) {
						// 金额必须是数字
						var time = new Date().getTime();
						var chargeRequestEvent = {};
						chargeRequestEvent[this.columns.eventName] = this.keys.chargeRequestEvent;
						chargeRequestEvent[this.columns.orderId] = orderId;
						chargeRequestEvent[this.columns.orderName] = name;
						chargeRequestEvent[this.columns.currencyAmount] = currencyAmount;
						chargeRequestEvent[this.columns.currencyType] = currencyType;
						chargeRequestEvent[this.columns.paymentType] = paymentType;
						this.setCommonColumns(chargeRequestEvent); // 设置公用columns
						this.sendDataToServer(this.parseParam(chargeRequestEvent)); // 最终发送编码后的数据ss
						this.updatePreVisitTime(time);
					} else {
						this.log(&amp;quot;订单金额必须是数字&amp;quot;);
						return ;
					}	
				}
			},
			
			onEventDuration: function(category, action, map, duration) {
				// 触发event事件
				if (this.preCallApi()) {
					if (category &amp;amp;&amp;amp; action) {
						var time = new Date().getTime();
						var event = {};
						event[this.columns.eventName] = this.keys.eventDurationEvent;
						event[this.columns.category] = category;
						event[this.columns.action] = action;
						if (map) {
							for (var k in map){
								if (k &amp;amp;&amp;amp; map[k]) {
									event[this.columns.kv + k] = map[k];
								}
							}
						}
						if (duration) {
							event[this.columns.duration] = duration;
						}
						this.setCommonColumns(event); // 设置公用columns
						this.sendDataToServer(this.parseParam(event)); // 最终发送编码后的数据ss
						this.updatePreVisitTime(time);
					} else {
						this.log(&amp;quot;category和action不能为空&amp;quot;);
					}
				}
			}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;完整的代码，如果有兴趣自己可以详细研究，
*** 注意事项 ***，发布的时候一定要将代码中的url改为你的服务器的url：
&lt;img src=&#34;../images/2017-06-20-23-05-24.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-项目发布&#34;&gt;3.项目发布&lt;/h3&gt;

&lt;h4 id=&#34;1-本地项目发布&#34;&gt;(1).本地项目发布&lt;/h4&gt;

&lt;p&gt;前面我们已经简单的实现了后台和前端的代码，首先我们在本地启动服务，方法和前面一样，只是我们将自己的代码添加进去了，点击启动按钮。
&lt;img src=&#34;../images/2017-06-20-22-14-58.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后去浏览器访问 &lt;code&gt;http://localhost:8080/taobaopayment/demo4.jsp&lt;/code&gt;，然后点击跳转按钮测试
&lt;img src=&#34;../images/2017-06-20-22-16-22.jpg&#34; alt=&#34;&#34; /&gt;
截止现在我们的后台项目基本完成，这里面的代码比较难，大家可以根据情况查看，不用花太多的精力。&lt;/p&gt;

&lt;h4 id=&#34;2-发布到linux的tomcat上&#34;&gt;(2).发布到linux的tomcat上&lt;/h4&gt;

&lt;p&gt;我们的项目不可能放在本地运行，需要放到Linux的集群环境才能正常运行。首先打开Xshell，连上linux节点。
第一步，在Linux上安装tomcat。
安装的过程很简单，首先要安装java配置JAVA相关环境变量，然后在tomcat的官网下载tomcat的tar.gz包，解压，然后配置tomcat相关环境变量。启动tomcat的命令是tomcat安装目录下面的bin下面的&lt;code&gt;startup.sh&lt;/code&gt;，执行就能启动tomcat，然后访问节点的8080端口，如图：
&lt;img src=&#34;../images/2017-06-20-22-27-11.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第二步，将项目打成war包。
类似以前打jar包，点开project structure -&amp;gt; artificts，添加一个artifict，名字为taobaopayment，type选择 Web Application:Archive，设置好对应的输出目录output idrectory，一般默认即可，然后点击确定&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/2017-06-20-22-28-57.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;设置好后，点击build -&amp;gt; build artifacts，构建war包
&lt;img src=&#34;../images/2017-06-20-22-32-33.jpg&#34; alt=&#34;&#34; /&gt;
构建结束后，进入刚刚设置的输出目录，你将会在刚刚设置的目录下看到一个war包。&lt;/p&gt;

&lt;p&gt;通过xshell的xftp工具，将打出来的war包拷贝放在linux的tomcat安装目录的webapps目录下：
&lt;img src=&#34;../images/2017-06-20-22-35-41.jpg&#34; alt=&#34;&#34; /&gt;
然后tomcat会自动解压war包，我们就可以在浏览器访问刚刚发布的项目了：
&lt;img src=&#34;../images/2017-06-20-22-39-45.jpg&#34; alt=&#34;&#34; /&gt;
到这里我们的整个后端项目就发布成功了。&lt;/p&gt;

&lt;h2 id=&#34;四-数据分析系统开发&#34;&gt;四、数据分析系统开发&lt;/h2&gt;

&lt;p&gt;本次我们的重心是整个系统的搭建，这部分的开发过程比较复杂，大家酌情进行学习，代码我们已经写好，大家只要稍作理解。细节和逻辑我们后续的实验还会讲解。&lt;/p&gt;

&lt;h3 id=&#34;1-需求回顾&#34;&gt;1.需求回顾&lt;/h3&gt;

&lt;p&gt;之前我们已经做过需求分析，这时候大家再回头看看我们一开始的需求设计，我们是要完成几个关键指标的设计分析。假设我们已经配置好了tomcat和nginx，那么我们知道每次用有浏览等行为时，我们的服务器就会给我们的设置的url发送数据，然后nginx就会收到我们发送的数据。接下来就是分析nginx收集到的数据。&lt;/p&gt;

&lt;p&gt;随便选取一条数据查看：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;192.168.126.1^A1458731952.690^A192.168.126.11^A/log.gif?en=e_pv&amp;amp;p_url=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;p_ref=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;tt=%E6%B5%8B%E8%AF%95%E9%A1%B5%E9%9D%A21&amp;amp;ver=1&amp;amp;pl=website&amp;amp;sdk=js&amp;amp;u_ud=EAB36BC9-0347-4D33-8579-AA8C331D001A&amp;amp;u_mid=laoxiao&amp;amp;u_sd=2D24B8A2-B2EF-450C-8C86-4F8B0F3E2785&amp;amp;c_time=1458731943823&amp;amp;l=zh-CN&amp;amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A45.0)%20Gecko%2F20100101%20Firefox%2F45.0&amp;amp;b_rst=1366*768
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这条数据提取了很多来自url的query信息，通过^A隔开，我们需要编写代码分析这种数据。&lt;/p&gt;

&lt;h3 id=&#34;2-etl处理&#34;&gt;2.ETL处理&lt;/h3&gt;

&lt;h4 id=&#34;1-定义工具类&#34;&gt;(1).定义工具类&lt;/h4&gt;

&lt;p&gt;本次试验的工具类主要是从一个url中抽取KPI信息，我们前面的业务需要的信息包括了地址、浏览器、操作系统等，根据我们的分析，所以我们需要使用IP地址解析等工具。解析url的工具类我们放在&lt;code&gt;com.hongya.etl.util&lt;/code&gt;下面，大家自己认真分析。&lt;/p&gt;

&lt;h4 id=&#34;2-定义相关常量类&#34;&gt;(2).定义相关常量类&lt;/h4&gt;

&lt;p&gt;我们的数据分析是有时间段的，我们分析的结果放进hbase中的表中，表名、字段名、时间范围等都是需要用到的常量，我们放在&lt;code&gt;com.hongya.common&lt;/code&gt;下面，大家可以查看。&lt;/p&gt;

&lt;h4 id=&#34;3-业务代码&#34;&gt;(3).业务代码&lt;/h4&gt;

&lt;p&gt;我们的数据字段含义在前面已经讲过了，现在我们需要将数据解析后放进hbase中。ETL过程就是简单的字符串处理，只需要一个Mapper程序即可完成。相应的代码在&lt;code&gt;com.hongya.etl.mr.ald&lt;/code&gt;中，大家可以查看。&lt;/p&gt;

&lt;h4 id=&#34;4-本地测试运行&#34;&gt;(4).本地测试运行&lt;/h4&gt;

&lt;p&gt;然后我们在本地新建一个文件，将上面哪一行测试数据放进去：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;192.168.126.1^A1458731952.690^A192.168.126.11^A/log.gif?en=e_pv&amp;amp;p_url=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;p_ref=http%3A%2F%2Flocalhost%3A8080%2FBIG_DATA_LOG2%2Fdemo.jsp&amp;amp;tt=%E6%B5%8B%E8%AF%95%E9%A1%B5%E9%9D%A21&amp;amp;ver=1&amp;amp;pl=website&amp;amp;sdk=js&amp;amp;u_ud=EAB36BC9-0347-4D33-8579-AA8C331D001A&amp;amp;u_mid=laoxiao&amp;amp;u_sd=2D24B8A2-B2EF-450C-8C86-4F8B0F3E2785&amp;amp;c_time=1458731943823&amp;amp;l=zh-CN&amp;amp;b_iev=Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A45.0)%20Gecko%2F20100101%20Firefox%2F45.0&amp;amp;b_rst=1366*768
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们将&lt;code&gt;com.hongya.etl.mr.ald.AnalyserLogDataRunner&lt;/code&gt;中的&lt;code&gt;setJobInputPaths&lt;/code&gt;方法的路径改为刚刚添加的文件的路径，并且在&lt;code&gt;setConf&lt;/code&gt;方法设置一下zookeeper地址，并且启动zookeeper，就可以点击运行，在本地观察结果。
&lt;img src=&#34;../images/2017-06-21-01-16-19.jpg&#34; alt=&#34;&#34; /&gt;
如图我们可以看出ETL后将这一行数据转化为了Hbase的一条Put，这里一直运行不结束是因为我没有启动Hbase，所以一直没法写进去，发布项目的时候是需要启动的。
这个Mapper读取数据格式上面有，而写出的数据格式是Hbase的Put。不知道大家是否记得Hbase的javaAPI，我们介绍过Put的使用。最后我们每一条记录将会放进Hbase的表格中，例如上面的示例数据最后会解析为一条Put数据，我们可以看出它的rowKey是带着日期的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rowKey 1458731952690_84973288
cf: info ,key:tt value:测试页面1
cf: info ,key:country value:unknown
cf: info ,key:ver value:1
cf: info ,key:u_mid value:laoxiao
cf: info ,key:os value:Windows
cf: info ,key:city value:unknown
cf: info ,key:ip value:192.168.126.1
cf: info ,key:b_rst value:1366*768
cf: info ,key:en value:e_pv
cf: info ,key:c_time value:1458731943823
cf: info ,key:l value:zh-CN
cf: info ,key:u_sd value:2D24B8A2-B2EF-450C-8C86-4F8B0F3E2785
cf: info ,key:u_ud value:EAB36BC9-0347-4D33-8579-AA8C331D001A
cf: info ,key:os_v value:Windows
cf: info ,key:p_ref value:http://localhost:8080/BIG_DATA_LOG2/demo.jsp
cf: info ,key:province value:unknown
cf: info ,key:s_time value:1458731952690
cf: info ,key:p_url value:http://localhost:8080/BIG_DATA_LOG2/demo.jsp
cf: info ,key:browser value:Firefox
cf: info ,key:sdk value:js
cf: info ,key:pl value:website
cf: info ,key:browser_v value:45.0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-关键指标分析&#34;&gt;3.关键指标分析&lt;/h3&gt;

&lt;p&gt;上面的ETL完成后我们的结果数据都放在hbase的event_logs表格的info列族中，现在我们需要运行代码分析这些数据，对我们的数据进行我们前面的设计文档中的关键指标分析。&lt;/p&gt;

&lt;h4 id=&#34;1-代码结构规范&#34;&gt;(1).代码结构规范&lt;/h4&gt;

&lt;p&gt;我们的程序需要定期分析hbase的数据，我们分析的指标有很多，我们需要从hbase中提取的数据也有很多。最后分析完每个指标后我们放进mysql中，供echart做展示。
1. 首先我们分析的指标需要即KPI需要专门的类定义好，放在&lt;code&gt;com.hongya.common.KpiType&lt;/code&gt;下面。
2. 我们需要自定义Key和Value的类型，这些类型包含了需要统计的关键维度信息，作为mapreduce任务的输入输出key，我们定义好了放在&lt;code&gt;com.hongya.transformer.model.dim&lt;/code&gt;下面。
3. 我们的hadoop任务写mysql需要有专门的OutputFormat，我们放在&lt;code&gt;com.hongya.transformer.service&lt;/code&gt;下面，由于每个唯独统计任务写mysql都不一样，所以我们通过配置文件的方式传入，在&lt;code&gt;output-collector.xml&lt;/code&gt;中有相关配置。
4. 无论是读写mysql还是hbase都有配置，我们通过配置文件的方式传入，配置文件有&lt;code&gt;query-mapping.xml&lt;/code&gt;，&lt;code&gt;transfomer-env.xml&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;2-业务代码实现&#34;&gt;(2).业务代码实现&lt;/h4&gt;

&lt;p&gt;上面分析了业务，我们开始写mapreduce程序统计分析指标。
我们知道我们现在的mapreduce读取hbase的数据，然后写进mysql中，相关代码我们放在了&lt;code&gt;com.hongya.transformer.mr&lt;/code&gt;包下面。
由于时间关系，我们的业务只实现了new user指标的统计，大家可以查看&lt;code&gt;com.hongya.transformer.mr.nu&lt;/code&gt;包下的内容。
当我们的hbase中有数据时，运行&lt;code&gt;com.hongya.transformer.mr.nu.NewInstallUserRunner&lt;/code&gt;，就能看到下面的结果。
&lt;img src=&#34;../images/2017-06-21-13-10-29.jpg&#34; alt=&#34;&#34; /&gt;
如果你map完成后reduce就失败 ，没关系，是因为你的mysql还没有配置好，我们在后面会介绍的。&lt;/p&gt;

&lt;h2 id=&#34;四-数据分析系统架构&#34;&gt;四、数据分析系统架构&lt;/h2&gt;

&lt;p&gt;我们有了服务器后，接下来的任务就是对服务器的数据进行收集处理，处理后的数据进行展示。我们需要搭建一个完整的服务器，这时候首先需要一个集群，我们在云端直接使用一个节点的centos作为服务器。首先打开Xshell，连上centos节点，我们这里节点名为&lt;code&gt;node1&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;1-部署hadoop和hbase&#34;&gt;1.部署hadoop和Hbase&lt;/h3&gt;

&lt;h4 id=&#34;1-部署hadoop&#34;&gt;(1).部署hadoop&lt;/h4&gt;

&lt;p&gt;hadoop单节点安装很简单，以前讲过。直接解压后，配置&lt;code&gt;hadoop-env.sh、core-site.xml、hdfs-site.xml&lt;/code&gt;
1. hadoop-env.sh配置 JAVA_HOME
2. core-site.xml配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt; &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://localhost:8020&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/hadoop&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就能够格式化，启动：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hdfs namenode -format
start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-配置hbase&#34;&gt;(2).配置Hbase&lt;/h4&gt;

&lt;p&gt;首先安装单节点的zookeeper，安装好后启动，这个不细说：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后解压Hbase安装包.
1. 配置hbase-env.sh，配置JAVA_HOME，然后将 HBASE_MANAGES_ZK改为false
2. 配置hbase-site.xm&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://localhost:8020/hbase&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;localhost&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;复制hadoop配置
复制hadoop的 core-site.xml和hdf-site.xml到hbase的conf目录下
然后就能启动Hbase了。
启动hbase后使用hbase shell进入交互窗口，执行建表语句：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;create &#39;event_logs&#39; ,&#39;info&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果执行成功了就可以开始下一步了。&lt;/p&gt;

&lt;h3 id=&#34;2-部署nginx服务&#34;&gt;2.部署nginx服务&lt;/h3&gt;

&lt;p&gt;前面我们将项目发布到tomcat上面了。正常情况下我们需要通过nginx进行负载均衡，同时收集url的请求日志。
我们可以安装nginx，也可以安装淘宝开源的tengine，比一般nginx多一些功能，而且淘宝上有中文文档。&lt;/p&gt;

&lt;h4 id=&#34;1-nginx安装&#34;&gt;(1).nginx安装&lt;/h4&gt;

&lt;p&gt;步骤如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1.安装GCC编译器等工具：
yum install -y gcc gcc-c++ autoconf automake libtool make openssl openssl-devel pcre pcre-devel
2.下载安装Nginx:
wget http://nginx.org/download/nginx-1.6.3.tar.gz
注：这里也可以下载tengine压缩包，比一般nginx多一些功能
tar -zxvf nginx-1.6.3.tar.gz 
cd nginx-1.6.3/  
./configure --prefix=/usr/local/nginx
--sbin-path=/usr/local/nginx/sbin/nginx
--conf-path=/usr/local/nginx/conf/nginx.conf
--pid-path=/usr/local/nginx/logs/nginx.pid \
--with-http_ssl_module \
--with-http_stub_status_module \
--with-http_gzip_static_module \ 
make &amp;amp;&amp;amp; make install 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果正常的话，就安装好了，然后启动nginx服务即可。记住启动之前需要先关闭之前的tomcat，因为他们两个的端口冲突了。启动命令是就是nginx，启动以后，如果不修改配置，我们可以直接打开浏览器访问8080端口，出现这样就算是成功了。
&lt;img src=&#34;../images/2017-06-21-15-52-28.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-nginx配置&#34;&gt;(2).nginx配置&lt;/h4&gt;

&lt;p&gt;现在我们已经安装了nginx，我们要配置nginx的反向代理，让他替我们监听我们的需要监听的端口。上面我们安装的时候已经配置了配置文件的路径：&lt;code&gt;/usr/local/nginx/conf/nginx.conf&lt;/code&gt;。现在我们修改他的内容。
我们让它监听80端口，这样我们给80端口发送的数据就可以被nginx收集然后我们后期处理：
我们只需要添加下面的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log_format my_format &#39;$remote_addr^A$msec^A$http_host^A$request_uri&#39;;

location = /log.gif {
   root html;
   ## 配置日志文件保存位置
   access_log /opt/data/access.log my_format;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改后的nginx.conf内容大概是这样的，其实就是添加了一行log_format，然后修改了端口信息：
&lt;img src=&#34;../images/2017-06-21-16-06-08.jpg&#34; alt=&#34;&#34; /&gt;
然后我们通过命令让配置文件生效： sudo nginx -s reload&lt;/p&gt;

&lt;h4 id=&#34;3-测试nginx收集日志&#34;&gt;(3).测试nginx收集日志&lt;/h4&gt;

&lt;p&gt;这时候我们可以启动我们之前的web项目，启动之前记得修改代码的url为刚刚配置的地址格式：
&lt;img src=&#34;../images/2017-06-21-16-11-05.jpg&#34; alt=&#34;&#34; /&gt;
然后我们发布运行项目，或者打war包放在tomcat里面，然后启动tomcat。在浏览器输入：&lt;code&gt;http://localhost:8080/taobaopayment/demo4.jsp&lt;/code&gt; 模拟用户点击。如果你发现浏览器一直处于刷新状态，可能你需要换一个浏览器：
&lt;img src=&#34;../images/2017-06-21-16-14-49.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;你还可以运行我们的Test类，来模拟后台的数据，报错没关系，只需要手动点击停止程序：
&lt;img src=&#34;../images/2017-06-21-16-16-11.jpg&#34; alt=&#34;&#34; /&gt;
然后我们查看刚刚配置的文件，已经有了几条记录，是刚刚我们发送的，而且都是我们配置的格式：
&lt;img src=&#34;../images/2017-06-21-16-25-15.jpg&#34; alt=&#34;&#34; /&gt;
到这里就恭喜，我们的gninx基本完成。&lt;/p&gt;

&lt;h3 id=&#34;3-日志收集系统&#34;&gt;3.日志收集系统&lt;/h3&gt;

&lt;p&gt;日志手机一般有两种方式，shell实现和flume实现。
shell命令前面大家都熟悉过，flume使用在前面的SparkStreaming实验也使用过，我们不介绍过多，简单回顾一下即可。
首先安装好flume，配置JAVA_HOME和HADOOP_HOME，然后新建或者复制一个配置文件，log.cfg ，添加下面的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 配置三个组件的名字
agent.sources = r1
agent.channels = c1
agent.sinks = k1

# For each one of the sources, the type is defined
agent.sources.r1.type = exec
## 这里配置你刚刚手机日志的文件
agent.sources.r1.command = tail -F /Users/dengziming/opt/data/hongya/taobaopayment/access.log
agent.sources.r1.port = 44444

# The channel can be defined as follows.
agent.channels.c1.type = memory
agent.channels.c1.capacity = 1000
agent.channels.c1.transactionCapacity = 1000

# Each sink&#39;s type must be defined
agent.sinks.k1.type = hdfs
agent.sinks.k1.hdfs.path = hdfs://localhost:8020/flume/events/%Y-%m-%d/%H%M/
agent.sinks.k1.hdfs.filePrefix = events-
agent.sinks.k1.hdfs.round = true
agent.sinks.k1.hdfs.roundValue = 10
agent.sinks.k1.hdfs.roundUnit = minute
agent.sinks.k1.hdfs.useLocalTimeStamp = true

#Specify the channel the sink should use
agent.sources.r1.channels = c1
agent.sinks.k1.channel = c1
agent.channels.memoryChannel.capacity = 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置好后适用命令启动：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bin/flume-ng agent --conf conf --conf-file conf/log.cfg --name agent -D flume.root.logger=INFO,console
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会收集我们刚刚nginx的日志到hadoop的 &lt;code&gt;/flume/events/%Y-%m-%d/%H%M/&lt;/code&gt; 路径下
恭喜你，马上就要进入数据分析部分&lt;/p&gt;

&lt;h3 id=&#34;4-提交数据分析任务&#34;&gt;4.提交数据分析任务&lt;/h3&gt;

&lt;p&gt;现在我们要开始运行程序，分析数据了。&lt;/p&gt;

&lt;h4 id=&#34;1-启动zookeeper-hadoop-hbase&#34;&gt;(1).启动zookeeper、hadoop、hbase&lt;/h4&gt;

&lt;p&gt;启动命令就不说了，然后记得之前我们已经在hbase中创建了表格：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;create &#39;event_logs&#39; ,&#39;info&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;../images/2017-06-21-16-45-52.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-运行etl任务&#34;&gt;(2).运行ETL任务&lt;/h4&gt;

&lt;p&gt;我们的etl的任务是 &lt;code&gt;com.hongya.etl.mr.ald.AnalyserLogDataRunner&lt;/code&gt;，打开这段代码，我们修改几个路径和配置，因为是测试，我们把数据放在本地运行。修改的主要是zookeeper地址和我们刚刚的日志路径：
&lt;img src=&#34;../images/2017-06-21-16-41-30.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后运行程序：
&lt;img src=&#34;../images/2017-06-21-16-46-55.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后我们可以根据日志看到打印的rowKey，我们可以在hbase中查看这些rowKey
&lt;img src=&#34;../images/2017-06-21-16-48-51.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-创建mysql表格&#34;&gt;(3).创建mysql表格&lt;/h4&gt;

&lt;p&gt;我们的etl完成后数据放在hbase中，然后我们需要进行统计分析，结果放在mysql，首先是建立mysql表格，我们的表格统一放在数据库report下面，首先建库，然后按照下面的语句依次建表：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;DROP TABLE IF EXISTS `stats_user`;
CREATE TABLE `stats_user` (
  `date_dimension_id` int(11) NOT NULL,
  `platform_dimension_id` int(11) NOT NULL,
  `active_users` int(11) DEFAULT &#39;0&#39; COMMENT &#39;活跃用户数&#39;,
  `new_install_users` int(11) DEFAULT &#39;0&#39; COMMENT &#39;新增用户数&#39;,
  `total_install_users` int(11) DEFAULT &#39;0&#39; COMMENT &#39;总用户数&#39;,
  `sessions` int(11) DEFAULT &#39;0&#39; COMMENT &#39;会话个数&#39;,
  `sessions_length` int(11) DEFAULT &#39;0&#39; COMMENT &#39;会话长度&#39;,
  `total_members` int(11) unsigned DEFAULT &#39;0&#39; COMMENT &#39;总会员数&#39;,
  `active_members` int(11) unsigned DEFAULT &#39;0&#39; COMMENT &#39;活跃会员数&#39;,
  `new_members` int(11) unsigned DEFAULT &#39;0&#39; COMMENT &#39;新增会员数&#39;,
  `created` date DEFAULT NULL,
  PRIMARY KEY (`platform_dimension_id`,`date_dimension_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT COMMENT=&#39;统计用户基本信息的统计表&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这只是一个表格，由于我们的表格太多，这里不展示，我们会将所有数据库的建表语句放在文件中，大家可以参考，最终如图：
&lt;img src=&#34;../images/2017-06-21-16-55-12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;4-运行统计任务&#34;&gt;(4).运行统计任务&lt;/h4&gt;

&lt;p&gt;新用户点击分析任务放在&lt;code&gt;com.hongya.transformer.mr.nu.NewInstallUserRunner&lt;/code&gt;中，大家可以查看代码，然后我们修改一下配置，主要是mysql的用户名密码，在DimensionConverterImpl中，另外我们还有查看核对 src/transformer-env.xml 下的内容：
如图，修改用户名密码为你的mysql设置：
&lt;img src=&#34;../images/2017-06-21-16-58-32.jpg&#34; alt=&#34;&#34; /&gt;
修改zookeeper地址和运行的起始日期，你可以设置的小一点：
&lt;img src=&#34;../images/2017-06-21-16-57-33.jpg&#34; alt=&#34;&#34; /&gt;
然后我们点击运行，我们就可以根据日志看到map和reduce执行的过程:
&lt;img src=&#34;../images/2017-06-21-17-02-13.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;执行完成后，我们查看我们刚刚的mysql的report库的stats_device_browser和stats_user表格：
&lt;img src=&#34;../images/2017-06-21-17-03-45.jpg&#34; alt=&#34;&#34; /&gt;
当然我们还可以查看dimension_browser等其他表格。
程序执行成功。&lt;/p&gt;

&lt;h3 id=&#34;4-数据转移系统&#34;&gt;4.数据转移系统&lt;/h3&gt;

&lt;p&gt;数据转移系统我们使用sqoop，由于我们的部分mapreduce任务每次运行的结果都放在hadoop或者Hbase上面，我们可能需要手动将关键指标转移到关系型数据库，然后编写代码进行展示。但是在这里，我们都写进了mysql，就暂时不适用sqoop了，也是为了减轻大家的负担。&lt;/p&gt;

&lt;h3 id=&#34;5-数据展示&#34;&gt;5.数据展示&lt;/h3&gt;

&lt;p&gt;数据展示我们使用 jquery + Echart吧。真正项目的echart展示部分一般不需要我们管，会有专门的前端高手负责，所以我们就简单的做一下吧。以浏览器维度为例，我们直接写sql语句&lt;code&gt;select name,count(*) from dimension_browser group by browser_name&lt;/code&gt;，将结果文件写到echart的option属性中：
&lt;img src=&#34;../images/2017-06-21-20-20-50.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然后重新再浏览器段查看吧：
&lt;img src=&#34;../images/2017-06-21-20-21-47.jpg&#34; alt=&#34;&#34; /&gt;
当然我这是一种不可取的做法，因为这种方式显然是不符合企业生产环境的。真正的生产环境肯定是通过后台和数据库交互，通过ajax将数据传给前端展示，我们做的很敷衍，是因为这不是我们的重点。&lt;/p&gt;

&lt;h3 id=&#34;6-项目发布&#34;&gt;6.项目发布&lt;/h3&gt;

&lt;p&gt;这上面的所有步骤都完成了，就可以发布项目了，我们需要一套任务调度系统。azkaban是目前来说用的比较多的任务调度系统，我们推荐大家课后了解一下azkaban的安装使用。这里我们没法演示了。&lt;/p&gt;

&lt;h2 id=&#34;项目上线&#34;&gt;项目上线&lt;/h2&gt;

&lt;h3 id=&#34;1-基本步骤&#34;&gt;1.基本步骤&lt;/h3&gt;

&lt;p&gt;将整个项目设计好以后，就可以上线了，这里我们总结一下真实项目上线的过程。
1. 软件的安装
本地安装开发环境需要的东西，以及相关的依赖。服务器需要安装tomcat、nginx、zookeeper、hadoop、Hbase
2. 项目开发
这里的项目开发有三部分，服务端程序，日志分析程序，前端展示程序，其中日志分析程序我们只完成了new user 开发，剩下的业务由大家自己开发。前端展示程序我们只是简单展示，没有开发，这不是重点。
3. 搭建nginx服务器，监听80端口
nginx的安装和部署需要注意很多，安装完成后修改配置文件。
4. 启动flume，收集来自nginx的数据
flume配置完成后会收集日志文件的日志，按照时间放到hadoop上面。
5. 发布web项目
将项目打成war包，放到tomcat上，然后浏览器就可以访问，有访问时会向80端口发送数据。
6. 建表
新建hbase的表格和mysql表格
7. 定时启动hadoop任务
我们通过以前说过的方法将程序打成jar包，上传到linux，在Linux上通过&lt;code&gt;hadoop jar&lt;/code&gt;命令提交。
8. 启动展示任务
这里我们简单处理一下忽略掉。
9. 将运行和展示任务添加到定时任务进行调度
这部分比较复杂，需要专门的时间学习。&lt;/p&gt;

&lt;h3 id=&#34;2-自己动手发布程序&#34;&gt;2.自己动手发布程序&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;安装相关软件，我这里已经安装完成，大家自己检查安装。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装hadoop、zookeeper、hbase、flume并配置
这部分不详细讲解，配置方法上面都有，配置好以后启动相应集群。启动命令分别为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start-dfs.sh
start-yarn.sh
start-hbase.sh
bin/flume-ng agent -c ./conf -f ./conf/log.cfg -n agent 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至少有这些java进程：
&lt;img src=&#34;../images/2017-06-21-21-38-57.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装nginx，启动nginx服务，修改nginx的配置文件，监听80端口，并且收集格式为： /log.gif 的url。
可以在浏览器访问linux的80端口：
&lt;img src=&#34;../images/2017-06-21-21-40-36.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;项目打war包，放到tomcat中。
打包之前，修改代码的url为你的linux节点加上log.gif
&lt;img src=&#34;../images/2017-06-21-21-57-51.jpg&#34; alt=&#34;&#34; /&gt;
然后打成war包，名字为：&lt;code&gt;taobaopayment.war&lt;/code&gt;，放在tomcat的webapps目录下，使员工startup.sh 启动tomcat，访问8080端口，然后访&lt;code&gt;http://node1:8080/taobaopayment/demo4.jsp&lt;/code&gt;：
如果这里一直在刷新，那么需要换一个浏览器：
&lt;img src=&#34;../images/2017-06-21-22-06-20.jpg&#34; alt=&#34;&#34; /&gt;
比如我用Safari浏览器，不断点击，产生数据：
&lt;img src=&#34;../images/2017-06-21-22-07-45.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;创建hbase和mysql表格
hbase创建event_logs表格，info列族，
mysql建表语句文件里有。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;执行mapreduce的ETL任务
你可以选择打jar包，或者在本地执行，执行的主类是：&lt;code&gt;com.hongya.etl.mr.ald.AnalyserLogDataRunner&lt;/code&gt;
需要修改zookeeper配置和输入路径，如果在集群上运行，这个输入路径是前面配置的flume手机日志的路径。
&lt;img src=&#34;../images/2017-06-21-22-12-59.jpg&#34; alt=&#34;&#34; /&gt;
执行完成后，可以去hbase查看数据。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;运行分析程序
分析程序基于我们刚刚的结果，主类为：&lt;code&gt;com.hongya.transformer.mr.nu.NewInstallUserRunner&lt;/code&gt;，运行之前需要在&lt;code&gt;DimensionConverterImpl&lt;/code&gt;类中设置mysql的连接信息。
&lt;img src=&#34;../images/2017-06-21-22-16-00.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;查看mysql数据库的结果，并展示
查看mysql的结果：
&lt;img src=&#34;../images/2017-06-21-22-16-54.jpg&#34; alt=&#34;&#34; /&gt;
数据展示模块，需要使用Echart，脱离了我们的实验主题，我们简单模拟，访问浏览器的：&lt;code&gt;http://node1:8080/taobaopayment/showUser.jsp&lt;/code&gt;和&lt;code&gt;http://node1:8080/taobaopayment/showBrowser.jsp&lt;/code&gt;
&lt;img src=&#34;../images/2017-06-21-22-18-47.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>JavaNIO</title>
      <link>https://dengziming.github.io/post/java/javanio/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/javanio/</guid>
      
        <description>

&lt;p&gt;// 参考资料
&lt;a href=&#34;http://tutorials.jenkov.com/java-nio/nio-vs-io.html#main-differences-between-java-nio-and-io&#34;&gt;http://tutorials.jenkov.com/java-nio/nio-vs-io.html#main-differences-between-java-nio-and-io&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;一-io和nio有什么区别&#34;&gt;一、IO和NIO有什么区别&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Stream Oriented vs. Buffer Oriented&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Blocking vs. Non-blocking IO&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;IO是阻塞的，一旦调用了 read() or write()，线程就堵住了，NIO非阻塞。&lt;/p&gt;

&lt;h2 id=&#34;二-channels-and-buffers&#34;&gt;二、Channels and Buffers&lt;/h2&gt;

&lt;p&gt;Typically, all IO in NIO starts with a Channel.
A Channel is a bit like a stream. From the Channel data can be read into a Buffer.
Data can also be written from a Buffer into a Channel.&lt;/p&gt;

&lt;p&gt;There are several Channel and Buffer types. Here is a list of the primary Channel implementations in Java NIO:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FileChannel
DatagramChannel
SocketChannel
ServerSocketChannel
As you can see, these channels cover UDP + TCP network IO, and file IO.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is a list of the core Buffer implementations in Java NIO:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer
CharBuffer
DoubleBuffer
FloatBuffer
IntBuffer
LongBuffer
ShortBuffer
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;1-channel&#34;&gt;1. Channel&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;RandomAccessFile aFile = new RandomAccessFile(&amp;quot;data/nio-data.txt&amp;quot;, &amp;quot;rw&amp;quot;);
    FileChannel inChannel = aFile.getChannel();

    ByteBuffer buf = ByteBuffer.allocate(48);

    int bytesRead = inChannel.read(buf);
    while (bytesRead != -1) {

      System.out.println(&amp;quot;Read &amp;quot; + bytesRead);
      buf.flip();

      while(buf.hasRemaining()){
          System.out.print((char) buf.get());
      }

      buf.clear();
      bytesRead = inChannel.read(buf);
    }
    aFile.close();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the buf.flip() call. First you read into a Buffer. Then you flip it. Then you read out of it.&lt;/p&gt;

&lt;h3 id=&#34;2-buffer&#34;&gt;2.Buffer&lt;/h3&gt;

&lt;p&gt;Java NIO Buffers are used when interacting with NIO Channels. As you know, data is read from channels into buffers, and written from buffers into channels.&lt;/p&gt;

&lt;p&gt;A buffer is essentially a block of memory into which you can write data, which you can then later read again.
This memory block is wrapped in a NIO Buffer object, which provides a set of methods that makes it easier to work with the memory block.&lt;/p&gt;

&lt;p&gt;Using a Buffer to read and write data typically follows this little 4-step process:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. Write data into the Buffer
2. Call buffer.flip()
3. Read data out of the Buffer
4. Call buffer.clear() or buffer.compact()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When you write data into a buffer, the buffer keeps track of how much data you have written.
Once you need to read the data, you need to switch the buffer from writing mode into reading mode using the flip() method call.
In reading mode the buffer lets you read all the data written into the buffer.&lt;/p&gt;

&lt;p&gt;Once you have read all the data, you need to clear the buffer, to make it ready for writing again.
You can do this in two ways: By calling clear() or by calling compact(). The clear() method clears the whole buffer.
The compact() method only clears the data which you have already read.
Any unread data is moved to the beginning of the buffer, and data will now be written into the buffer after the unread data.&lt;/p&gt;

&lt;p&gt;above had given a simple Buffer usage example, with the write, flip, read and clear operations maked in bold.&lt;/p&gt;

&lt;h3 id=&#34;3-buffer-capacity-position-and-limit&#34;&gt;3. Buffer Capacity, Position and Limit&lt;/h3&gt;

&lt;p&gt;A Buffer has three properties you need to be familiar with, in order to understand how a Buffer works. These are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;capacity
position
limit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The meaning of position and limit depends on whether the Buffer is in read or write mode. Capacity always means the same, no matter the buffer mode.&lt;/p&gt;

&lt;p&gt;position and limit依赖于模式，而capacity在两种模式下都是一样的。&lt;/p&gt;

&lt;p&gt;Being a memory block, a Buffer has a certain fixed size, also called its &amp;ldquo;capacity&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;When you write data into the Buffer, you do so at a certain position. Initially the position is 0.
When a byte, long etc. has been written into the Buffer the position is advanced to point to the next cell in the buffer to insert data into.
Position can maximally become capacity - 1.&lt;/p&gt;

&lt;p&gt;When you read data from a Buffer you also do so from a given position.
 When you flip a Buffer from writing mode to reading mode, the position is reset back to 0.
As you read data from the Buffer you do so from position, and position is advanced to next position to read.&lt;/p&gt;

&lt;p&gt;In write mode the limit of a Buffer is the limit of how much data you can write into the buffer. In write mode the limit = capacity&lt;/p&gt;

&lt;p&gt;When flipping the Buffer into read mode, limit means the limit of how much data you can read from the data.
Therefore, when flipping a Buffer into read mode, limit is set to write position of the write mode.&lt;/p&gt;

&lt;h3 id=&#34;4-buffer-types&#34;&gt;4. Buffer Types&lt;/h3&gt;

&lt;p&gt;Java NIO comes with the following Buffer types:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer
MappedByteBuffer
CharBuffer
DoubleBuffer
FloatBuffer
IntBuffer
LongBuffer
ShortBuffer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, these Buffer types represent different data types. In other words, they let you work with the bytes in the buffer as char, short, int, long, float or double instead.&lt;/p&gt;

&lt;p&gt;The MappedByteBuffer is a bit special, and will be covered in its own text.&lt;/p&gt;

&lt;h3 id=&#34;5-allocating-a-buffer&#34;&gt;5. Allocating a Buffer&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer buf = ByteBuffer.allocate(48);

CharBuffer buf = CharBuffer.allocate(1024);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;6-writing-data-to-a-buffer&#34;&gt;6. Writing Data to a Buffer&lt;/h3&gt;

&lt;p&gt;You can write data into a Buffer in two ways:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Write data from a Channel into a Buffer
int bytesRead = inChannel.read(buf); //read into buffer.
//
Write data into the Buffer yourself, via the buffer&#39;s put() methods.
buf.put(127);    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;7-flip&#34;&gt;7. flip&lt;/h3&gt;

&lt;p&gt;The flip() method switches a Buffer from writing mode to reading mode.
Calling flip() sets the position back to 0, and sets the limit to where position just was.&lt;/p&gt;

&lt;h3 id=&#34;8-reading-data-from-a-buffer&#34;&gt;8. Reading Data from a Buffer&lt;/h3&gt;

&lt;p&gt;There are two ways you can read data from a Buffer.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Read data from the buffer into a channel.
//read from buffer into channel.
int bytesWritten = inChannel.write(buf);

Read data from the buffer yourself, using one of the get() methods.
byte aByte = buf.get();    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;9-rewind&#34;&gt;9. rewind&lt;/h3&gt;

&lt;p&gt;The Buffer.rewind() sets the position back to 0, so you can reread all the data in the buffer.&lt;/p&gt;

&lt;p&gt;The limit remains untouched, thus still marking how many elements (bytes, chars etc.) that can be read from the Buffer.&lt;/p&gt;

&lt;h3 id=&#34;10-clear-and-compact&#34;&gt;10. clear() and compact()&lt;/h3&gt;

&lt;p&gt;Once you are done reading data out of the Buffer you have to make the Buffer ready for writing again. You can do so either by calling clear() or by calling compact().&lt;/p&gt;

&lt;p&gt;If you call clear() the position is set back to 0 and the limit to capacity. In other words, the Buffer is cleared.
The data in the Buffer is not cleared. Only the markers telling where you can write data into the Buffer are.&lt;/p&gt;

&lt;p&gt;compact() copies all unread data to the beginning of the Buffer. Then it sets position to right after the last unread element.
The limit property is still set to capacity, just like clear() does. Now the Buffer is ready for writing, but you will not overwrite the unread data.&lt;/p&gt;

&lt;h3 id=&#34;11-mark-and-reset&#34;&gt;11. mark() and reset()&lt;/h3&gt;

&lt;p&gt;You can mark a given position in a Buffer by calling the Buffer.mark() method. You can then later reset the position back to the marked position by calling the Buffer.reset() method. Here is an example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;buffer.mark();

//call buffer.get() a couple of times, e.g. during parsing.

buffer.reset();  //set position back to mark.    
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;五-java-nio-scatter-gather&#34;&gt;五、Java NIO Scatter / Gather&lt;/h2&gt;

&lt;p&gt;javaNIO自带了Scatter/gather的支持，用于从Channel读数据和写数据。&lt;/p&gt;

&lt;p&gt;scattering read from a channel：从channel读数据到不止一个Buffer，所以会 &amp;ldquo;scatters&amp;rdquo; the data from the channel into multiple buffers.&lt;/p&gt;

&lt;p&gt;gathering write to a channel: 从多个 buffer 写到一个Channel，多疑 &amp;ldquo;gathers&amp;rdquo; the data from multiple buffers into one channel。&lt;/p&gt;

&lt;h3 id=&#34;1-scattering-reads&#34;&gt;1. Scattering Reads&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ByteBuffer header = ByteBuffer.allocate(128);
ByteBuffer body   = ByteBuffer.allocate(1024);

ByteBuffer[] bufferArray = { header, body };

channel.read(bufferArray);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
public static void scatter() throws Exception {

        RandomAccessFile aFile = new RandomAccessFile(&amp;quot;src/main/resources/data/nio-data.txt&amp;quot;, &amp;quot;rw&amp;quot;);

        FileChannel inChannel = aFile.getChannel();


        ByteBuffer header = ByteBuffer.allocate(128);
        ByteBuffer body   = ByteBuffer.allocate(1028);

        ByteBuffer[] bufferArray = { header, body };

        long bytesRead = inChannel.read(bufferArray);

        System.out.println(&amp;quot;Read &amp;quot; + bytesRead);
        header.flip();
        body.flip();

        while(header.hasRemaining()){
            System.out.print((char) header.get());
        }
        while(body.hasRemaining()){
            System.out.print((char) body.get());
        }

        header.clear();
        body.clear();


        aFile.close();

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The fact that scattering reads fill up one buffer before moving on to the next, means that it is not suited for dynamically sized message parts.&lt;/p&gt;

&lt;h3 id=&#34;2-gathering-writes&#34;&gt;2. Gathering Writes&lt;/h3&gt;

&lt;p&gt;Here is a code example that shows how to perform a gathering write:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ByteBuffer header = ByteBuffer.allocate(128);
ByteBuffer body   = ByteBuffer.allocate(1024);

//write data into buffers

ByteBuffer[] bufferArray = { header, body };

channel.write(bufferArray);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行下面的代码，会得到一个文件，里面是 header+body&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static void gather() throws Exception {

        RandomAccessFile aFile = new RandomAccessFile(&amp;quot;src/main/resources/data/nio-in.txt&amp;quot;, &amp;quot;rw&amp;quot;);

        FileChannel inChannel = aFile.getChannel();

        ByteBuffer header = ByteBuffer.allocate(12);

        header.put(&amp;quot;header&amp;quot;.getBytes());
        header.put(&amp;quot;body&amp;quot;.getBytes());
        ByteBuffer body   = ByteBuffer.allocate(120);

        ByteBuffer[] bufferArray = { header, body };

        header.flip();
        body.flip();
        inChannel.write(bufferArray);

        inChannel.force(true);
        inChannel.close();
        header.clear();
        body.clear();

        aFile.close();

    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;四-java-nio-channel-to-channel-transfers&#34;&gt;四、Java NIO Channel to Channel Transfers&lt;/h2&gt;

&lt;p&gt;channel的传输工具，类似IOUtils&lt;/p&gt;

&lt;h3 id=&#34;1&#34;&gt;1.&lt;/h3&gt;

&lt;p&gt;The FileChannel.transferFrom() method transfers data from a source channel into the FileChannel. Here is a simple example: transferFrom()&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
RandomAccessFile fromFile = new RandomAccessFile(&amp;quot;fromFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      fromChannel = fromFile.getChannel();

RandomAccessFile toFile = new RandomAccessFile(&amp;quot;toFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      toChannel = toFile.getChannel();

long position = 0;
long count    = fromChannel.size();

toChannel.transferFrom(fromChannel, position, count);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The parameters position and count, tell where in the destination file to start writing (position), and how many bytes to transfer maximally (count). If the source channel has fewer than count bytes, less is transfered.&lt;/p&gt;

&lt;p&gt;Additionally, some SocketChannel implementations may transfer only the data the SocketChannel has ready in its internal buffer here and now - even if the SocketChannel may later have more data available. Thus, it may not transfer the entire data requested (count) from the SocketChannel into FileChannel.&lt;/p&gt;

&lt;h3 id=&#34;2&#34;&gt;2.&lt;/h3&gt;

&lt;p&gt;The transferTo() method transfer from a FileChannel into some other channel. Here is a simple example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;RandomAccessFile fromFile = new RandomAccessFile(&amp;quot;fromFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      fromChannel = fromFile.getChannel();

RandomAccessFile toFile = new RandomAccessFile(&amp;quot;toFile.txt&amp;quot;, &amp;quot;rw&amp;quot;);
FileChannel      toChannel = toFile.getChannel();

long position = 0;
long count    = fromChannel.size();

fromChannel.transferTo(position, count, toChannel);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice how similar the example is to the previous. The only real difference is the which FileChannel object the method is called on. The rest is the same.&lt;/p&gt;

&lt;p&gt;The issue with SocketChannel is also present with the transferTo() method. The SocketChannel implementation may only transfer bytes from the FileChannel until the send buffer is full, and then stop.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://tutorials.jenkov.com/java-nio/selectors.html&#34;&gt;http://tutorials.jenkov.com/java-nio/selectors.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;四-selectors&#34;&gt;四、Selectors&lt;/h2&gt;

&lt;p&gt;NIO&amp;rsquo;s Selectors 允许一个 a single thread 去 monitor multiple channels of input。
你可以注册 multiple channels with a selector，然后用一个线程去 &amp;ldquo;select&amp;rdquo; the channels that have input available for processing,
或者 or select the channels that are ready for writing。
This selector mechanism makes it easy for a single thread to manage multiple channels.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>On Disk IO</title>
      <link>https://dengziming.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%A3%81%E7%9B%98io/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%A3%81%E7%9B%98io/</guid>
      
        <description>

&lt;p&gt;文章来源：&lt;a href=&#34;https://medium.com/databasss/on-disk-io-part-1-flavours-of-io-8e1ace1de017&#34;&gt;https://medium.com/databasss/on-disk-io-part-1-flavours-of-io-8e1ace1de017&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;了解 IO 原理有助于工作。Network IO 相关问题经常讨论，然而和磁盘相关的问题很少讨论。一方面实现上，网络 IO 更为复杂的巧妙，Filesystem 相关 tools 很少。
另一方面，大家都使用 databases 作为存储系统，和底层打交道的事情交给了数据库设计人员，但是了解相关资料 依然重要。&lt;/p&gt;

&lt;p&gt;目录：
- Syscalls: open, write, read, fsync, sync, close
- Standard IO: fopen, fwrite, fread, fflush, fclose
- Vectored IO: writev, readv
- Memory mapped IO: open, mmap, msync, munmap&lt;/p&gt;

&lt;h2 id=&#34;buffered-io&#34;&gt;Buffered IO&lt;/h2&gt;

&lt;p&gt;“buffering”  总是让人困惑，当使用 Standard IO，可以选择  full and line buffering 或者 out from any buffering whatsoever，
这些其实和我们要讨论的 Kernel buffering (Page Cache)  没什么关系。你可以吧上面的称之为 caching。&lt;/p&gt;

&lt;h2 id=&#34;sector-block-page&#34;&gt;Sector/Block/Page&lt;/h2&gt;

&lt;p&gt;块状设备（Block Device ）是为读取提供  HDDs or SSDs 等硬件设备提供 buffered access 的特殊文件类型。
Block Devices 工作于 Sectors（一组相邻的 bytes） 之上，Most disk devices have a sector size of 512 bytes。
Sector 是 block device 之间数据传输的最小单元，读取数据不可能比 Sector 更小，但是却可以同时读 multiple adjacent segments。
File System  最小读取单元就是 Block，Block就是一组相邻的sectors，block sizes 一般为 512, 1024, 2048 and 4096 bytes。
通常 IO操作会通过 Virtual Memory，将 filesystem blocks 缓存到 memory 中作为buffer提供中间操作，
Virtual Memory 又和 pages 一起工作，pages 会 map 到 blocks，Typical page size is 4096 bytes。&lt;/p&gt;

&lt;p&gt;总结来说，Virtual Memory 和 pages 一起工作，map 到 Filesystem blocks，blocks 又 map 到 Block Device sectors。&lt;/p&gt;

&lt;h2 id=&#34;standard-io&#34;&gt;Standard IO&lt;/h2&gt;

&lt;p&gt;通过 read() and write()  方法操作文件系统。&lt;/p&gt;

&lt;p&gt;reading: 首先访问 Page Cache，如果 Page Cache 中没有需要的数据，将会触发 Page Fault 然后将需要的数据 paged in。所以读取 unmapped 文件会慢一些，尽管对用户是透明的。&lt;/p&gt;

&lt;p&gt;writes: buffer contents 首先写到 Page Cache，数据并不会立马写进磁盘，真正的 hardware write 是当 Kernel 决定进行  writeback of the dirty page.&lt;/p&gt;

&lt;h2 id=&#34;page-cache&#34;&gt;Page Cache&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/torvalds/linux/blob/master/include/linux/buffer_head.h&#34;&gt;https://github.com/torvalds/linux/blob/master/include/linux/buffer_head.h&lt;/a&gt;
将最近访问过的 fragments 存储起来，read() and write() 操作并不会触发磁盘操作而是通过Page Cache 。&lt;/p&gt;

&lt;p&gt;读的时候，读的时候会查看 Page Cache，如果有的话直接给用户，没有的话先加载再给用户，如果满了，least recently used pages 会被刷到磁盘，并且 evicted from cache。&lt;/p&gt;

&lt;p&gt;写操作仅仅是将数据放到 Page Cache，marking the written page as dirty。后续会有 flush or writeback 的进程将数据写到磁盘。&lt;/p&gt;

&lt;p&gt;标记为dirty 的page会被flush到磁盘，这个过程被称作 writeback。writeback 有缺点，例如 queuing up IO requests。&lt;/p&gt;

&lt;p&gt;Page Cache 的理论是 时间本地性原则，也就是刚刚被访问的内容很有可能被再次访问。当然还有空间本地性原则，也就是被访问的数据附近的数据很有可能被访问，prefetch 操作就是机遇这个原则。&lt;/p&gt;

&lt;p&gt;Page Cache ，保存了最近访问的和将要访问的 file chunks，read-write-read 的操作可以直接通过缓存，加快了速度。&lt;/p&gt;

&lt;h2 id=&#34;delaying-errors&#34;&gt;Delaying Errors&lt;/h2&gt;

&lt;p&gt;既然不会立即写到磁盘，就会有 可能突然出错没有写到磁盘的问题，可以查看： &lt;a href=&#34;https://lwn.net/Articles/457667/&#34;&gt;https://lwn.net/Articles/457667/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;direct-io&#34;&gt;Direct IO&lt;/h2&gt;

&lt;p&gt;当我们不想用 Kernel Page Cache。打开文件的时候使用 O_DIRECT 标志，直接读取绕过 Page Cache，写也是直接写到磁盘。
大部分使用 Direct IO 的application 都会导致性能的 下降，但是高手可以通过 fine-grained 操作提高性能，因为会实现自己的缓存，例如 PostgreSQL and MySQL use Direct IO 。&lt;/p&gt;

&lt;p&gt;例如 write-ahead-log，一般不会立即查看。同时使用 O_DIRECT 和 PageCache 打开文件会带来很多问题，不鼓励。&lt;/p&gt;

&lt;h2 id=&#34;block-alignment&#34;&gt;Block Alignment&lt;/h2&gt;

&lt;p&gt;使用 Direct IO 的时候，最好让操作都对准 sector 的边界上。也就是说，每个操作的 starting offset 是 512 的倍数，缓存大小也是 512 的倍数，
Crossing segment boundary 会导致加载多个sectors。&lt;/p&gt;

&lt;p&gt;Page Cache 会在内存自动对齐，所以不需要。&lt;/p&gt;

&lt;h2 id=&#34;memory-mapping&#34;&gt;Memory Mapping&lt;/h2&gt;

&lt;p&gt;Memory Mapping (mmap) 让你可以像整个文件都放进内存了一样访问文件。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>guava学习</title>
      <link>https://dengziming.github.io/post/java/guava/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/guava/</guid>
      
        <description>

&lt;p&gt;&lt;a href=&#34;https://www.tutorialspoint.com/guava/guava_optional_class.htm&#34;&gt;https://www.tutorialspoint.com/guava/guava_optional_class.htm&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;optional&#34;&gt;Optional&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.base.Optional;

public class GuavaTester {
   public static void main(String args[]) {
      GuavaTester guavaTester = new GuavaTester();

      Integer value1 =  null;
      Integer value2 =  new Integer(10);
      
      //Optional.fromNullable - allows passed parameter to be null.
      Optional&amp;lt;Integer&amp;gt; a = Optional.fromNullable(value1);
      
      //Optional.of - throws NullPointerException if passed parameter is null
      Optional&amp;lt;Integer&amp;gt; b = Optional.of(value2);		

      System.out.println(guavaTester.sum(a,b));
   }

   public Integer sum(Optional&amp;lt;Integer&amp;gt; a, Optional&amp;lt;Integer&amp;gt; b) {
      //Optional.isPresent - checks the value is present or not
      System.out.println(&amp;quot;First parameter is present: &amp;quot; + a.isPresent());

      System.out.println(&amp;quot;Second parameter is present: &amp;quot; + b.isPresent());

      //Optional.or - returns the value if present otherwise returns
      //the default value passed.
      Integer value1 = a.or(new Integer(0));	

      //Optional.get - gets the value, value should be present
      Integer value2 = b.get();

      return value1 + value2;
   }	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Optional 主要方法为 fromNullable 、of 、isPresent 、or 、 get
结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;First parameter is present: false
Second parameter is present: true
10
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;preconditions&#34;&gt;Preconditions&lt;/h2&gt;

&lt;p&gt;Preconditions 用来检查参数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.base.Preconditions;

public class GuavaTester {

   public static void main(String args[]) {
      GuavaTester guavaTester = new GuavaTester();

      try {
         System.out.println(guavaTester.sqrt(-3.0));
      } catch(IllegalArgumentException e) {
         System.out.println(e.getMessage());
      }

      try {
         System.out.println(guavaTester.sum(null,3));
      } catch(NullPointerException e) {
         System.out.println(e.getMessage());
      }

      try {
         System.out.println(guavaTester.getValue(6));
      } catch(IndexOutOfBoundsException e) {
         System.out.println(e.getMessage());
      }
   }

   public double sqrt(double input) throws IllegalArgumentException {
      Preconditions.checkArgument(input &amp;gt; 0.0,
         &amp;quot;Illegal Argument passed: Negative value %s.&amp;quot;, input);
      return Math.sqrt(input);
   }

   public int sum(Integer a, Integer b) {
      a = Preconditions.checkNotNull(a, &amp;quot;Illegal Argument passed: First parameter is Null.&amp;quot;);
      b = Preconditions.checkNotNull(b, &amp;quot;Illegal Argument passed: Second parameter is Null.&amp;quot;);

      return a+b;
   }

   public int getValue(int input) {
      int[] data = {1,2,3,4,5};
      Preconditions.checkElementIndex(input,data.length, &amp;quot;Illegal Argument passed: Invalid index.&amp;quot;);
      return 0;
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出主要方法： checkArgument 、 checkNotNull 、checkElementIndex&lt;/p&gt;

&lt;p&gt;返回结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Illegal Argument passed: Negative value -3.0.
Illegal Argument passed: First parameter is Null.
Illegal Argument passed: Invalid index. (6) must be less than size (5)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ordering&#34;&gt;Ordering&lt;/h2&gt;

&lt;p&gt;enriched comparator&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

import com.google.common.collect.Ordering;

public class GuavaTester {
   public static void main(String args[]) {
      List&amp;lt;Integer&amp;gt; numbers = new ArrayList&amp;lt;Integer&amp;gt;();
      
      numbers.add(new Integer(5));
      numbers.add(new Integer(2));
      numbers.add(new Integer(15));
      numbers.add(new Integer(51));
      numbers.add(new Integer(53));
      numbers.add(new Integer(35));
      numbers.add(new Integer(45));
      numbers.add(new Integer(32));
      numbers.add(new Integer(43));
      numbers.add(new Integer(16));

      Ordering ordering = Ordering.natural();
      System.out.println(&amp;quot;Input List: &amp;quot;);
      System.out.println(numbers);		
         
      Collections.sort(numbers,ordering );
      System.out.println(&amp;quot;Sorted List: &amp;quot;);
      System.out.println(numbers);
         
      System.out.println(&amp;quot;======================&amp;quot;);
      System.out.println(&amp;quot;List is sorted: &amp;quot; + ordering.isOrdered(numbers));
      System.out.println(&amp;quot;Minimum: &amp;quot; + ordering.min(numbers));
      System.out.println(&amp;quot;Maximum: &amp;quot; + ordering.max(numbers));
         
      Collections.sort(numbers,ordering.reverse());
      System.out.println(&amp;quot;Reverse: &amp;quot; + numbers);

      numbers.add(null);
      System.out.println(&amp;quot;Null added to Sorted List: &amp;quot;);
      System.out.println(numbers);		

      Collections.sort(numbers,ordering.nullsFirst());
      System.out.println(&amp;quot;Null first Sorted List: &amp;quot;);
      System.out.println(numbers);
      System.out.println(&amp;quot;======================&amp;quot;);

      List&amp;lt;String&amp;gt; names = new ArrayList&amp;lt;String&amp;gt;();
      
      names.add(&amp;quot;Ram&amp;quot;);
      names.add(&amp;quot;Shyam&amp;quot;);
      names.add(&amp;quot;Mohan&amp;quot;);
      names.add(&amp;quot;Sohan&amp;quot;);
      names.add(&amp;quot;Ramesh&amp;quot;);
      names.add(&amp;quot;Suresh&amp;quot;);
      names.add(&amp;quot;Naresh&amp;quot;);
      names.add(&amp;quot;Mahesh&amp;quot;);
      names.add(null);
      names.add(&amp;quot;Vikas&amp;quot;);
      names.add(&amp;quot;Deepak&amp;quot;);

      System.out.println(&amp;quot;Another List: &amp;quot;);
      System.out.println(names);

      Collections.sort(names,ordering.nullsFirst().reverse());
      System.out.println(&amp;quot;Null first then reverse sorted list: &amp;quot;);
      System.out.println(names);
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出主要方法：natural、Collections.sort(numbers,ordering ) 、min、max、reverse、nullsFirst&lt;/p&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Input List: 
[5, 2, 15, 51, 53, 35, 45, 32, 43, 16]
Sorted List: 
[2, 5, 15, 16, 32, 35, 43, 45, 51, 53]
======================
List is sorted: true
Minimum: 2
Maximum: 53
Reverse: [53, 51, 45, 43, 35, 32, 16, 15, 5, 2]
Null added to Sorted List: 
[53, 51, 45, 43, 35, 32, 16, 15, 5, 2, null]
Null first Sorted List: 
[null, 2, 5, 15, 16, 32, 35, 43, 45, 51, 53]
======================
Another List: 
[Ram, Shyam, Mohan, Sohan, Ramesh, Suresh, Naresh, Mahesh, null, Vikas, Deepak]
Null first then reverse sorted list: 
[Vikas, Suresh, Sohan, Shyam, Ramesh, Ram, Naresh, Mohan, Mahesh, Deepak, null]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;objects&#34;&gt;Objects&lt;/h2&gt;

&lt;p&gt;Objects class provides helper functions applicable to all objects such as equals, hashCode, etc.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.base.Objects;

public class GuavaTester {
   public static void main(String args[]) {
      Student s1 = new Student(&amp;quot;Mahesh&amp;quot;, &amp;quot;Parashar&amp;quot;, 1, &amp;quot;VI&amp;quot;);	
      Student s2 = new Student(&amp;quot;Suresh&amp;quot;, null, 3, null);	
	  
      System.out.println(s1.equals(s2));
      System.out.println(s1.hashCode());	
      System.out.println(
         Objects.toStringHelper(s1)
         .add(&amp;quot;Name&amp;quot;,s1.getFirstName()+&amp;quot; &amp;quot; + s1.getLastName())
         .add(&amp;quot;Class&amp;quot;, s1.getClassName())
         .add(&amp;quot;Roll No&amp;quot;, s1.getRollNo())
         .toString());
   }
}

class Student {
   private String firstName;
   private String lastName;
   private int rollNo;
   private String className;

   public Student(String firstName, String lastName, int rollNo, String className) {
      this.firstName = firstName;
      this.lastName = lastName;
      this.rollNo = rollNo;
      this.className = className;		
   }

   @Override
   public boolean equals(Object object) {
      if(!(object instanceof Student) || object == null) {
         return false;
      }
      Student student = (Student)object;
      // no need to handle null here		
      // Objects.equal(&amp;quot;test&amp;quot;, &amp;quot;test&amp;quot;) == true
      // Objects.equal(&amp;quot;test&amp;quot;, null) == false
      // Objects.equal(null, &amp;quot;test&amp;quot;) == false
      // Objects.equal(null, null) == true		
      return Objects.equal(firstName, student.firstName)  // first name can be null
         &amp;amp;&amp;amp; Objects.equal(lastName, student.lastName)     // last name can be null
         &amp;amp;&amp;amp; Objects.equal(rollNo, student.rollNo)	
         &amp;amp;&amp;amp; Objects.equal(className, student.className);  // class name can be null
   }

   @Override
   public int hashCode() {
      //no need to compute hashCode by self
      return Objects.hashCode(className,rollNo);
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出主要方法： hashCode、equal、toStringHelper 等&lt;/p&gt;

&lt;p&gt;结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-false&#34;&gt;85871
Student{Name=Mahesh Parashar, Class=VI, Roll No=1}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;range&#34;&gt;Range&lt;/h2&gt;

&lt;p&gt;类似 scala&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.collect.ContiguousSet;
import com.google.common.collect.DiscreteDomain;
import com.google.common.collect.Range;
import com.google.common.primitives.Ints;

public class GuavaTester {

   public static void main(String args[]) {
      GuavaTester tester = new GuavaTester();
      tester.testRange();
   }

   private void testRange() {

      //create a range [a,b] = { x | a &amp;lt;= x &amp;lt;= b}
      Range&amp;lt;Integer&amp;gt; range1 = Range.closed(0, 9);	
      System.out.print(&amp;quot;[0,9] : &amp;quot;);
      printRange(range1);		
      
      System.out.println(&amp;quot;5 is present: &amp;quot; + range1.contains(5));
      System.out.println(&amp;quot;(1,2,3) is present: &amp;quot; + range1.containsAll(Ints.asList(1, 2, 3)));
      System.out.println(&amp;quot;Lower Bound: &amp;quot; + range1.lowerEndpoint());
      System.out.println(&amp;quot;Upper Bound: &amp;quot; + range1.upperEndpoint());

      //create a range (a,b) = { x | a &amp;lt; x &amp;lt; b}
      Range&amp;lt;Integer&amp;gt; range2 = Range.open(0, 9);
      System.out.print(&amp;quot;(0,9) : &amp;quot;);
      printRange(range2);

      //create a range (a,b] = { x | a &amp;lt; x &amp;lt;= b}
      Range&amp;lt;Integer&amp;gt; range3 = Range.openClosed(0, 9);
      System.out.print(&amp;quot;(0,9] : &amp;quot;);
      printRange(range3);

      //create a range [a,b) = { x | a &amp;lt;= x &amp;lt; b}
      Range&amp;lt;Integer&amp;gt; range4 = Range.closedOpen(0, 9);
      System.out.print(&amp;quot;[0,9) : &amp;quot;);
      printRange(range4);

      //create an open ended range (9, infinity
      Range&amp;lt;Integer&amp;gt; range5 = Range.greaterThan(9);
      System.out.println(&amp;quot;(9,infinity) : &amp;quot;);
      System.out.println(&amp;quot;Lower Bound: &amp;quot; + range5.lowerEndpoint());
      System.out.println(&amp;quot;Upper Bound present: &amp;quot; + range5.hasUpperBound());

      Range&amp;lt;Integer&amp;gt; range6 = Range.closed(3, 5);	
      printRange(range6);

      //check a subrange [3,5] in [0,9]
      System.out.println(&amp;quot;[0,9] encloses [3,5]:&amp;quot; + range1.encloses(range6));

      Range&amp;lt;Integer&amp;gt; range7 = Range.closed(9, 20);	
      printRange(range7);
      
      //check ranges to be connected		
      System.out.println(&amp;quot;[0,9] is connected [9,20]:&amp;quot; + range1.isConnected(range7));
      Range&amp;lt;Integer&amp;gt; range8 = Range.closed(5, 15);	

      //intersection
      printRange(range1.intersection(range8));

      //span
      printRange(range1.span(range8));
   }

   private void printRange(Range&amp;lt;Integer&amp;gt; range) {		
   
      System.out.print(&amp;quot;[ &amp;quot;);
      
      for(int grade : ContiguousSet.create(range, DiscreteDomain.integers())) {
         System.out.print(grade +&amp;quot; &amp;quot;);
      }
      System.out.println(&amp;quot;]&amp;quot;);
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要方法：contains 、containsAll、lowerEndpoint、upperEndpoint、open、closed、closedOpen、openClosed、greaterThan、hasUpperBound、encloses&lt;/p&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[0,9] : [ 0 1 2 3 4 5 6 7 8 9 ]
5 is present: true
(1,2,3) is present: true
Lower Bound: 0
Upper Bound: 9
(0,9) : [ 1 2 3 4 5 6 7 8 ]
(0,9] : [ 1 2 3 4 5 6 7 8 9 ]
[0,9) : [ 0 1 2 3 4 5 6 7 8 ]
(9,infinity) : 
Lower Bound: 9
Upper Bound present: false
[ 3 4 5 ]
[0,9] encloses [3,5]:true
[ 9 10 11 12 13 14 15 16 17 18 19 20 ]
[0,9] is connected [9,20]:true
[ 5 6 7 8 9 ]
[ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;throwable&#34;&gt;Throwable&lt;/h2&gt;

&lt;p&gt;抛出异常：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.io.IOException;

import com.google.common.base.Objects;
import com.google.common.base.Throwables;

public class GuavaTester {
   public static void main(String args[]) {
   
      GuavaTester tester = new GuavaTester();

      try {
         tester.showcaseThrowables();
         
      } catch (InvalidInputException e) {
         //get the root cause
         System.out.println(Throwables.getRootCause(e));
      
      } catch (Exception e) {
         //get the stack trace in string format
         System.out.println(Throwables.getStackTraceAsString(e));
      }

      try {
         tester.showcaseThrowables1();

      } catch (Exception e) {
         System.out.println(Throwables.getStackTraceAsString(e));
      }
   }

   public void showcaseThrowables() throws InvalidInputException {
      try {
         sqrt(-3.0);
      } catch (Throwable e) {
         //check the type of exception and throw it
         Throwables.propagateIfInstanceOf(e, InvalidInputException.class);
         Throwables.propagate(e);
      }
   }

   public void showcaseThrowables1() {
      try {
         int[] data = {1,2,3};
         getValue(data, 4);
      } catch (Throwable e) {
         Throwables.propagateIfInstanceOf(e, IndexOutOfBoundsException.class);
         Throwables.propagate(e);
      }
   }

   public double sqrt(double input) throws InvalidInputException {
      if(input &amp;lt; 0) throw new InvalidInputException();
      return Math.sqrt(input);
   }

   public double getValue(int[] list, int index) throws IndexOutOfBoundsException {
      return list[index];
   }

   public void dummyIO() throws IOException {
      throw new IOException();
   }
}

class InvalidInputException extends Exception {
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要方法：
getStackTraceAsString、propagate、propagateIfInstanceOf、getRootCause
结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;InvalidInputException
java.lang.ArrayIndexOutOfBoundsException: 4
   at GuavaTester.getValue(GuavaTester.java:52)
   at GuavaTester.showcaseThrowables1(GuavaTester.java:38)
   at GuavaTester.main(GuavaTester.java:19)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;collections&#34;&gt;Collections&lt;/h2&gt;

&lt;h3 id=&#34;multiset&#34;&gt;Multiset&lt;/h3&gt;

&lt;p&gt;可以有重复元素&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.Iterator;
import java.util.Set;

import com.google.common.collect.HashMultiset;
import com.google.common.collect.Multiset;

public class GuavaTester {

   public static void main(String args[]) {
   
      //create a multiset collection
      Multiset&amp;lt;String&amp;gt; multiset = HashMultiset.create();
      
      multiset.add(&amp;quot;a&amp;quot;);
      multiset.add(&amp;quot;b&amp;quot;);
      multiset.add(&amp;quot;c&amp;quot;);
      multiset.add(&amp;quot;d&amp;quot;);
      multiset.add(&amp;quot;a&amp;quot;);
      multiset.add(&amp;quot;b&amp;quot;);
      multiset.add(&amp;quot;c&amp;quot;);
      multiset.add(&amp;quot;b&amp;quot;);
      multiset.add(&amp;quot;b&amp;quot;);
      multiset.add(&amp;quot;b&amp;quot;);
      
      //print the occurrence of an element
      System.out.println(&amp;quot;Occurrence of &#39;b&#39; : &amp;quot;+multiset.count(&amp;quot;b&amp;quot;));
      
      //print the total size of the multiset
      System.out.println(&amp;quot;Total Size : &amp;quot;+multiset.size());
      
      //get the distinct elements of the multiset as set
      Set&amp;lt;String&amp;gt; set = multiset.elementSet();

      //display the elements of the set
      System.out.println(&amp;quot;Set [&amp;quot;);
      
      for (String s : set) {
         System.out.println(s);
      }

      System.out.println(&amp;quot;]&amp;quot;);
      
      //display all the elements of the multiset using iterator
      Iterator&amp;lt;String&amp;gt; iterator  = multiset.iterator();
      System.out.println(&amp;quot;MultiSet [&amp;quot;);

      while(iterator.hasNext()) {
         System.out.println(iterator.next());
      }
      
      System.out.println(&amp;quot;]&amp;quot;);
      
      //display the distinct elements of the multiset with their occurrence count
      System.out.println(&amp;quot;MultiSet [&amp;quot;);

      for (Multiset.Entry&amp;lt;String&amp;gt; entry : multiset.entrySet()) {
         System.out.println(&amp;quot;Element: &amp;quot; + entry.getElement() + &amp;quot;, Occurrence(s): &amp;quot; + entry.getCount());
      }
      System.out.println(&amp;quot;]&amp;quot;);

      //remove extra occurrences
      multiset.remove(&amp;quot;b&amp;quot;,2);
      
      //print the occurrence of an element
      System.out.println(&amp;quot;Occurence of &#39;b&#39; : &amp;quot; + multiset.count(&amp;quot;b&amp;quot;));
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要方法：HashMultiset.create();、 add 、count、size、elementSet、iterator、entrySet&lt;/p&gt;

&lt;h3 id=&#34;multimap&#34;&gt;Multimap&lt;/h3&gt;

&lt;p&gt;和MultiSet类似，每个 key 可以隐射多个值&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.Collection;
import java.util.List;
import java.util.Map;
import java.util.Set;

import com.google.common.collect.ArrayListMultimap;
import com.google.common.collect.Multimap;

public class GuavaTester {
   public static void main(String args[]) {
   
      GuavaTester tester = new GuavaTester();
      Multimap&amp;lt;String,String&amp;gt; multimap = tester.getMultimap();

      List&amp;lt;String&amp;gt; lowerList = (List&amp;lt;String&amp;gt;)multimap.get(&amp;quot;lower&amp;quot;);
      System.out.println(&amp;quot;Initial lower case list&amp;quot;);
      System.out.println(lowerList.toString());

      lowerList.add(&amp;quot;f&amp;quot;);
      System.out.println(&amp;quot;Modified lower case list&amp;quot;);
      System.out.println(lowerList.toString());

      List&amp;lt;String&amp;gt; upperList = (List&amp;lt;String&amp;gt;)multimap.get(&amp;quot;upper&amp;quot;);
      System.out.println(&amp;quot;Initial upper case list&amp;quot;);
      System.out.println(upperList.toString());

      upperList.remove(&amp;quot;D&amp;quot;);
      System.out.println(&amp;quot;Modified upper case list&amp;quot;);
      System.out.println(upperList.toString());

      Map&amp;lt;String, Collection&amp;lt;String&amp;gt;&amp;gt; map = multimap.asMap();
      System.out.println(&amp;quot;Multimap as a map&amp;quot;);

      for (Map.Entry&amp;lt;String,  Collection&amp;lt;String&amp;gt;&amp;gt; entry : map.entrySet()) {
         String key = entry.getKey();
         Collection&amp;lt;String&amp;gt; value =  multimap.get(&amp;quot;lower&amp;quot;);
         System.out.println(key + &amp;quot;:&amp;quot; + value);
      }

      System.out.println(&amp;quot;Keys of Multimap&amp;quot;);
      Set&amp;lt;String&amp;gt; keys =  multimap.keySet();

      for(String key:keys) {
         System.out.println(key);
      }

      System.out.println(&amp;quot;Values of Multimap&amp;quot;);
      Collection&amp;lt;String&amp;gt; values = multimap.values();
      System.out.println(values);
   }

   private Multimap&amp;lt;String,String&amp;gt; getMultimap() {

      //Map&amp;lt;String, List&amp;lt;String&amp;gt;&amp;gt;
      // lower -&amp;gt; a, b, c, d, e
      // upper -&amp;gt; A, B, C, D

      Multimap&amp;lt;String,String&amp;gt; multimap = ArrayListMultimap.create();

      multimap.put(&amp;quot;lower&amp;quot;, &amp;quot;a&amp;quot;);
      multimap.put(&amp;quot;lower&amp;quot;, &amp;quot;b&amp;quot;);
      multimap.put(&amp;quot;lower&amp;quot;, &amp;quot;c&amp;quot;);
      multimap.put(&amp;quot;lower&amp;quot;, &amp;quot;d&amp;quot;);
      multimap.put(&amp;quot;lower&amp;quot;, &amp;quot;e&amp;quot;);

      multimap.put(&amp;quot;upper&amp;quot;, &amp;quot;A&amp;quot;);
      multimap.put(&amp;quot;upper&amp;quot;, &amp;quot;B&amp;quot;);
      multimap.put(&amp;quot;upper&amp;quot;, &amp;quot;C&amp;quot;);
      multimap.put(&amp;quot;upper&amp;quot;, &amp;quot;D&amp;quot;);		

      return multimap;
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Initial lower case list
[a, b, c, d, e]
Modified lower case list
[a, b, c, d, e, f]
Initial upper case list
[A, B, C, D]
Modified upper case list
[A, B, C]
Multimap as a map
upper:[a, b, c, d, e, f]
lower:[a, b, c, d, e, f]
Keys of Multimap
upper
lower
Values of Multimap
[a, b, c, d, e, f, A, B, C]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;bimap&#34;&gt;Bimap&lt;/h3&gt;

&lt;p&gt;A BiMap is a special kind of map which maintains an inverse view of the map while ensuring that no duplicate values are present in the map and a value can be used safely to get the key back.&lt;/p&gt;

&lt;p&gt;biMap 内部将 key value进行反转，保存了一个 value-key的对，保证 Value不重复。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.collect.BiMap;
import com.google.common.collect.HashBiMap;

public class GuavaTester {

   public static void main(String args[]) {
      BiMap&amp;lt;Integer, String&amp;gt; empIDNameMap = HashBiMap.create();

      empIDNameMap.put(new Integer(101), &amp;quot;Mahesh&amp;quot;);
      empIDNameMap.put(new Integer(102), &amp;quot;Sohan&amp;quot;);
      empIDNameMap.put(new Integer(103), &amp;quot;Ramesh&amp;quot;);

      //Emp Id of Employee &amp;quot;Mahesh&amp;quot;
      System.out.println(empIDNameMap.inverse().get(&amp;quot;Mahesh&amp;quot;));
   }	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;101
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is similar to creating a map of maps.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.Map;
import java.util.Set;

import com.google.common.collect.HashBasedTable;
import com.google.common.collect.Table;

public class GuavaTester {
   public static void main(String args[]) {
   
      //Table&amp;lt;R,C,V&amp;gt; == Map&amp;lt;R,Map&amp;lt;C,V&amp;gt;&amp;gt;
      /*
      *  Company: IBM, Microsoft, TCS
      *  IBM 		-&amp;gt; {101:Mahesh, 102:Ramesh, 103:Suresh}
      *  Microsoft 	-&amp;gt; {101:Sohan, 102:Mohan, 103:Rohan } 
      *  TCS 		-&amp;gt; {101:Ram, 102: Shyam, 103: Sunil } 
      * 
      * */
      
      //create a table
      Table&amp;lt;String, String, String&amp;gt; employeeTable = HashBasedTable.create();

      //initialize the table with employee details
      employeeTable.put(&amp;quot;IBM&amp;quot;, &amp;quot;101&amp;quot;,&amp;quot;Mahesh&amp;quot;);
      employeeTable.put(&amp;quot;IBM&amp;quot;, &amp;quot;102&amp;quot;,&amp;quot;Ramesh&amp;quot;);
      employeeTable.put(&amp;quot;IBM&amp;quot;, &amp;quot;103&amp;quot;,&amp;quot;Suresh&amp;quot;);

      employeeTable.put(&amp;quot;Microsoft&amp;quot;, &amp;quot;111&amp;quot;,&amp;quot;Sohan&amp;quot;);
      employeeTable.put(&amp;quot;Microsoft&amp;quot;, &amp;quot;112&amp;quot;,&amp;quot;Mohan&amp;quot;);
      employeeTable.put(&amp;quot;Microsoft&amp;quot;, &amp;quot;113&amp;quot;,&amp;quot;Rohan&amp;quot;);

      employeeTable.put(&amp;quot;TCS&amp;quot;, &amp;quot;121&amp;quot;,&amp;quot;Ram&amp;quot;);
      employeeTable.put(&amp;quot;TCS&amp;quot;, &amp;quot;122&amp;quot;,&amp;quot;Shyam&amp;quot;);
      employeeTable.put(&amp;quot;TCS&amp;quot;, &amp;quot;123&amp;quot;,&amp;quot;Sunil&amp;quot;);

      //get Map corresponding to IBM
      Map&amp;lt;String,String&amp;gt; ibmEmployees =  employeeTable.row(&amp;quot;IBM&amp;quot;);

      System.out.println(&amp;quot;List of IBM Employees&amp;quot;);
      
      for(Map.Entry&amp;lt;String, String&amp;gt; entry : ibmEmployees.entrySet()) {
         System.out.println(&amp;quot;Emp Id: &amp;quot; + entry.getKey() + &amp;quot;, Name: &amp;quot; + entry.getValue());
      }

      //get all the unique keys of the table
      Set&amp;lt;String&amp;gt; employers = employeeTable.rowKeySet();
      System.out.print(&amp;quot;Employers: &amp;quot;);
      
      for(String employer: employers) {
         System.out.print(employer + &amp;quot; &amp;quot;);
      }
      
      System.out.println();

      //get a Map corresponding to 102
      Map&amp;lt;String,String&amp;gt; EmployerMap =  employeeTable.column(&amp;quot;102&amp;quot;);
      
      for(Map.Entry&amp;lt;String, String&amp;gt; entry : EmployerMap.entrySet()) {
         System.out.println(&amp;quot;Employer: &amp;quot; + entry.getKey() + &amp;quot;, Name: &amp;quot; + entry.getValue());
      }		
   }	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;loadingcache&#34;&gt;LoadingCache&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.TimeUnit;

import com.google.common.base.MoreObjects;
import com.google.common.cache.CacheBuilder;
import com.google.common.cache.CacheLoader;
import com.google.common.cache.LoadingCache;

public class GuavaTester {
   public static void main(String args[]) {
   
      //create a cache for employees based on their employee id
      LoadingCache&amp;lt;String, Employee&amp;gt; employeeCache = 
         CacheBuilder.newBuilder()
         .maximumSize(100)                             // maximum 100 records can be cached
         .expireAfterAccess(30, TimeUnit.MINUTES)      // cache will expire after 30 minutes of access
         .build(new CacheLoader&amp;lt;String, Employee&amp;gt;() {  // build the cacheloader
            
            @Override
            public Employee load(String empId) throws Exception {
               //make the expensive call
               return getFromDatabase(empId);
            } 
         });

      try {			
         //on first invocation, cache will be populated with corresponding
         //employee record
         System.out.println(&amp;quot;Invocation #1&amp;quot;);
         System.out.println(employeeCache.get(&amp;quot;100&amp;quot;));
         System.out.println(employeeCache.get(&amp;quot;103&amp;quot;));
         System.out.println(employeeCache.get(&amp;quot;110&amp;quot;));
         
         //second invocation, data will be returned from cache
         System.out.println(&amp;quot;Invocation #2&amp;quot;);
         System.out.println(employeeCache.get(&amp;quot;100&amp;quot;));
         System.out.println(employeeCache.get(&amp;quot;103&amp;quot;));
         System.out.println(employeeCache.get(&amp;quot;110&amp;quot;));

      } catch (ExecutionException e) {
         e.printStackTrace();
      }
   }

   private static Employee getFromDatabase(String empId) {
   
      Employee e1 = new Employee(&amp;quot;Mahesh&amp;quot;, &amp;quot;Finance&amp;quot;, &amp;quot;100&amp;quot;);
      Employee e2 = new Employee(&amp;quot;Rohan&amp;quot;, &amp;quot;IT&amp;quot;, &amp;quot;103&amp;quot;);
      Employee e3 = new Employee(&amp;quot;Sohan&amp;quot;, &amp;quot;Admin&amp;quot;, &amp;quot;110&amp;quot;);

      Map&amp;lt;String, Employee&amp;gt; database = new HashMap&amp;lt;String, Employee&amp;gt;();
      
      database.put(&amp;quot;100&amp;quot;, e1);
      database.put(&amp;quot;103&amp;quot;, e2);
      database.put(&amp;quot;110&amp;quot;, e3);
      
      System.out.println(&amp;quot;Database hit for&amp;quot; + empId);
      
      return database.get(empId);		
   }
}

class Employee {
   String name;
   String dept;
   String emplD;

   public Employee(String name, String dept, String empID) {
      this.name = name;
      this.dept = dept;
      this.emplD = empID;
   }
   
   public String getName() {
      return name;
   }
   
   public void setName(String name) {
      this.name = name;
   }
   
   public String getDept() {
      return dept;
   }
   
   public void setDept(String dept) {
      this.dept = dept;
   }
   
   public String getEmplD() {
      return emplD;
   }
   
   public void setEmplD(String emplD) {
      this.emplD = emplD;
   }

   @Override
   public String toString() {
      return MoreObjects.toStringHelper(Employee.class)
      .add(&amp;quot;Name&amp;quot;, name)
      .add(&amp;quot;Department&amp;quot;, dept)
      .add(&amp;quot;Emp Id&amp;quot;, emplD).toString();
   }	
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Invocation #1
Database hit for100
Employee{Name=Mahesh, Department=Finance, Emp Id=100}
Database hit for103
Employee{Name=Rohan, Department=IT, Emp Id=103}
Database hit for110
Employee{Name=Sohan, Department=Admin, Emp Id=110}
Invocation #2
Employee{Name=Mahesh, Department=Finance, Emp Id=100}
Employee{Name=Rohan, Department=IT, Emp Id=103}
Employee{Name=Sohan, Department=Admin, Emp Id=110}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出 第一次 invocation 去查数据，第二次直接读的缓存。&lt;/p&gt;

&lt;h2 id=&#34;string&#34;&gt;String&lt;/h2&gt;

&lt;h3 id=&#34;joiner&#34;&gt;Joiner&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.Arrays;
import com.google.common.base.Joiner;

public class GuavaTester {
   public static void main(String args[]) {
      GuavaTester tester = new GuavaTester();
      tester.testJoiner();	
   }

   private void testJoiner() {
      System.out.println(Joiner.on(&amp;quot;,&amp;quot;)
         .skipNulls()
         .join(Arrays.asList(1,2,3,4,5,null,6)));
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;code&gt;1,2,3,4,5,6&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;splitter&#34;&gt;Splitter&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.base.Splitter;

public class GuavaTester {
   public static void main(String args[]) {
      GuavaTester tester = new GuavaTester();
      tester.testSplitter();
   }

   private void testSplitter() {
      System.out.println(Splitter.on(&#39;,&#39;)
         .trimResults()
         .omitEmptyStrings()
         .split(&amp;quot;the ,quick, ,brown, fox, jumps, over, the, lazy, little dog.&amp;quot;));
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：[the, quick, brown, fox, jumps, over, the, lazy, little dog.]&lt;/p&gt;

&lt;h3 id=&#34;charmatcher&#34;&gt;CharMatcher&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.base.CharMatcher;
import com.google.common.base.Splitter;

public class GuavaTester {
   public static void main(String args[]) {
      GuavaTester tester = new GuavaTester();
      tester.testCharMatcher();
   }

   private void testCharMatcher() {
      System.out.println(CharMatcher.DIGIT.retainFrom(&amp;quot;mahesh123&amp;quot;));    // only the digits
      System.out.println(CharMatcher.WHITESPACE.trimAndCollapseFrom(&amp;quot;     Mahesh     Parashar &amp;quot;, &#39; &#39;));

      // trim whitespace at ends, and replace/collapse whitespace into single spaces
      System.out.println(CharMatcher.JAVA_DIGIT.replaceFrom(&amp;quot;mahesh123&amp;quot;, &amp;quot;*&amp;quot;));  // star out all digits
      System.out.println(CharMatcher.JAVA_DIGIT.or(CharMatcher.JAVA_LOWER_CASE).retainFrom(&amp;quot;mahesh123&amp;quot;));

      // eliminate all characters that aren&#39;t digits or lowercase
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;123
Mahesh Parashar
mahesh***
mahesh123
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;caseformat&#34;&gt;CaseFormat&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import com.google.common.base.CaseFormat;

public class GuavaTester {
   public static void main(String args[]) {
      GuavaTester tester = new GuavaTester();
      tester.testCaseFormat();
   }

   private void testCaseFormat() {
      String data = &amp;quot;test_data&amp;quot;;
      System.out.println(CaseFormat.LOWER_HYPHEN.to(CaseFormat.LOWER_CAMEL, &amp;quot;test-data&amp;quot;));
      System.out.println(CaseFormat.LOWER_UNDERSCORE.to(CaseFormat.LOWER_CAMEL, &amp;quot;test_data&amp;quot;));
      System.out.println(CaseFormat.UPPER_UNDERSCORE.to(CaseFormat.UPPER_CAMEL, &amp;quot;test_data&amp;quot;));
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;testData
testData
TestData
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;primitive&#34;&gt;Primitive&lt;/h2&gt;

&lt;p&gt;原始类型，例如：ints&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.List;

import com.google.common.primitives.Ints;

public class GuavaTester {

   public static void main(String args[]) {
      GuavaTester tester = new GuavaTester();
      tester.testInts();
   }

   private void testInts() {
      int[] intArray = {1,2,3,4,5,6,7,8,9};

      //convert array of primitives to array of objects
      List&amp;lt;Integer&amp;gt; objectArray = Ints.asList(intArray);
      System.out.println(objectArray.toString());

      //convert array of objects to array of primitives
      intArray = Ints.toArray(objectArray);
      System.out.print(&amp;quot;[ &amp;quot;);
      
      for(int i = 0; i&amp;lt; intArray.length ; i++) {
         System.out.print(intArray[i] + &amp;quot; &amp;quot;);
      }
      
      System.out.println(&amp;quot;]&amp;quot;);
      
      //check if element is present in the list of primitives or not
      System.out.println(&amp;quot;5 is in list? &amp;quot; + Ints.contains(intArray, 5));

      //Returns the minimum		
      System.out.println(&amp;quot;Min: &amp;quot; + Ints.min(intArray));

      //Returns the maximum		
      System.out.println(&amp;quot;Max: &amp;quot; + Ints.max(intArray));

      //get the byte array from an integer
      byte[] byteArray = Ints.toByteArray(20000);
      
      for(int i = 0; i&amp;lt; byteArray.length ; i++) {
         System.out.print(byteArray[i] + &amp;quot; &amp;quot;);
      }
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;[1, 2, 3, 4, 5, 6, 7, 8, 9]
[ 1 2 3 4 5 6 7 8 9 ]
5 is in list? true
Min: 1
Max: 9
0 0 78 32
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;

&lt;p&gt;数学计算库&lt;/p&gt;

&lt;h2 id=&#34;iterators&#34;&gt;Iterators&lt;/h2&gt;

&lt;p&gt;使用迭代器简化操作&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; List&amp;lt;String&amp;gt; list = Lists.newArrayList(&amp;quot;Apple&amp;quot;,&amp;quot;Pear&amp;quot;,&amp;quot;Peach&amp;quot;,&amp;quot;Banana&amp;quot;);

Predicate&amp;lt;String&amp;gt; condition = new Predicate&amp;lt;String&amp;gt;() {
    @Override
    public boolean apply(String input) {
        return ((String)input).startsWith(&amp;quot;P&amp;quot;);
    }
};
boolean allIsStartsWithP = Iterators.all(list.iterator(), condition);
System.out.println(&amp;quot;all result == &amp;quot; + allIsStartsWithP);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;all方法的第一个参数是Iterator，第二个参数是Predicate&lt;String&gt;的实现，这个方法的意义是不需要我们自己去写while循环了，他的内部实现中帮我们做了循环，把循环体中的条件判断抽象出来了。&lt;/p&gt;

&lt;p&gt;Iterators类中有partition(Iterator iterator, int size)和 paddedPartition(Iterator iterator, int size)两个函数，
它们都是将iterator中的元素以数量为size分成Iterators.size(iterator) / size + (Iterators.size(iterator) % size == 0 ? 0 : 1)组，
唯一的区别是partition当最后一组数量不是size个时，不会补充；而paddedPartition当最后一组数量不是size个时，会填充null，使得最后一组元素数量也为size个。如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Iterable&amp;lt;String&amp;gt; wyp = Splitter.on(&amp;quot;,&amp;quot;).split(&amp;quot;w,y,p,h,a&amp;quot;);
Iterator&amp;lt;String&amp;gt; iterator = wyp.iterator();
UnmodifiableIterator&amp;lt;List&amp;lt;String&amp;gt;&amp;gt; listUnmodifiableIterator = Iterators.partition(iterator, 3);
while (listUnmodifiableIterator.hasNext()){
     System.out.println(listUnmodifiableIterator.next());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[w, y, p]
[h, a]
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph源码分析3-调用栈</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-%E8%B0%83%E7%94%A8%E6%A0%88/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-%E8%B0%83%E7%94%A8%E6%A0%88/</guid>
      
        <description>

&lt;p&gt;我们可以在比较关键的地方大断点，然后分析整个调用栈，进行进一步分析。哪里是关键点是需要一定经验判断的。&lt;/p&gt;

&lt;p&gt;例如我们基于 hadoop spark 等框架的时候，我们写的代码就是关键的，打断点可以看到合适调用，怎么被调用。
我们关心怎么写数据，可以在和底层数据交互的地方打断点。总之我们关心谁就在哪里打断点。&lt;/p&gt;

&lt;p&gt;记住：打断点的地方基本上是最终的调用点。&lt;/p&gt;

&lt;h2 id=&#34;整体调试找关键&#34;&gt;整体调试找关键&lt;/h2&gt;

&lt;p&gt;首先是存储类，我们使用本地文件存储，存储使用类是：&lt;code&gt;com.sleepycat.je.Database&lt;/code&gt; 这个类具体功能是啥可以具体研究。我们发现它有 get delete put 等方法，我们可以打上断点。然后查看调用栈。&lt;/p&gt;

&lt;p&gt;得到 普通 的调用信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;main@1&amp;quot; prio=5 tid=0x1 nid=NA runnable
  java.lang.Thread.State: RUNNABLE
	  at com.sleepycat.je.Database.put(Database.java:1574)
	  at com.sleepycat.je.Database.put(Database.java:1627)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:195)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:184)
	  at org.janusgraph.diskstorage.keycolumnvalue.keyvalue.OrderedKeyValueStoreAdapter.mutate(OrderedKeyValueStoreAdapter.java:99)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration$2.call(KCVSConfiguration.java:154)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration$2.call(KCVSConfiguration.java:149)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:147)
	  at org.janusgraph.diskstorage.util.BackendOperation$1.call(BackendOperation.java:161)
	  at org.janusgraph.diskstorage.util.BackendOperation.executeDirect(BackendOperation.java:68)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:54)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:158)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration.set(KCVSConfiguration.java:149)
	  at org.janusgraph.diskstorage.configuration.backend.KCVSConfiguration.set(KCVSConfiguration.java:126)
	  at org.janusgraph.diskstorage.configuration.ModifiableConfiguration.set(ModifiableConfiguration.java:40)
	  at org.janusgraph.diskstorage.configuration.ModifiableConfiguration.setAll(ModifiableConfiguration.java:47)
	  at org.janusgraph.graphdb.configuration.GraphDatabaseConfiguration.&amp;lt;init&amp;gt;(GraphDatabaseConfiguration.java:1266)
	  at org.janusgraph.core.JanusGraphFactory.open(JanusGraphFactory.java:160)
	  at org.janusgraph.core.JanusGraphFactory.open(JanusGraphFactory.java:131)
	  at org.janusgraph.core.JanusGraphFactory.open(JanusGraphFactory.java:78)
	  at org.janusgraph.test.dengziming.FirstTest.main(FirstTest.java:37)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从下往上可以看出，顺序：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;new GraphDatabaseConfiguration
ModifiableConfiguration.setAll(getGlobalSubset(localBasicConfiguration.getAll())); 
KCVSConfiguration.set(key,value,null,false);
BackendOperation.execute(new BackendOperation.Transactional&amp;lt;Boolean&amp;gt;() {@Override public Boolean call}
然后调用 上面new 的 BackendOperation.Transactional 的 call 方法
然后是 store.mutate
status = db.put(tx, key.as(ENTRY_FACTORY), value.as(ENTRY_FACTORY));
put(txn, key, data, Put.OVERWRITE, null);
result = cursor.putInternal(key, data, putType, options);
最终调用的是 cursor.putNotify 插入数据。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个 put 会多次调用，config 会设置 &amp;ldquo;startup-time&amp;rdquo; 等属性，都是通过这个put方法实现。&lt;/p&gt;

&lt;p&gt;第二次用到这个方法是 创建 VertexLabel 的时候会分配 id， 这时候我们可以看一下更详细的调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;JanusGraphID(0)(4)[0]@5358&amp;quot; prio=5 tid=0x24 nid=NA runnable
  java.lang.Thread.State: RUNNABLE
	  at com.sleepycat.je.dbi.CursorImpl.insertRecordInternal(CursorImpl.java:1364)
	  at com.sleepycat.je.dbi.CursorImpl.insertOrUpdateRecord(CursorImpl.java:1221)
	  at com.sleepycat.je.Cursor.putNoNotify(Cursor.java:2962)
	  at com.sleepycat.je.Cursor.putNotify(Cursor.java:2800)
	  at com.sleepycat.je.Cursor.putNoDups(Cursor.java:2647)
	  at com.sleepycat.je.Cursor.putInternal(Cursor.java:2478)
	  - locked &amp;lt;0x1536&amp;gt; (a com.sleepycat.je.Transaction)
	  at com.sleepycat.je.Cursor.putInternal(Cursor.java:830)
	  at com.sleepycat.je.Database.put(Database.java:1574)
	  at com.sleepycat.je.Database.put(Database.java:1627)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:195)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:184)
	  at org.janusgraph.diskstorage.keycolumnvalue.keyvalue.OrderedKeyValueStoreAdapter.mutate(OrderedKeyValueStoreAdapter.java:99)
	  at org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority.lambda$getIDBlock$1(ConsistentKeyIDAuthority.java:261)
	  at org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority$$Lambda$71.1795053717.call(Unknown Source:-1)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:147)
	  at org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority.getIDBlock(ConsistentKeyIDAuthority.java:260)
	  - locked &amp;lt;0x14f8&amp;gt; (a org.janusgraph.diskstorage.idmanagement.ConsistentKeyIDAuthority)
	  at org.janusgraph.graphdb.database.idassigner.StandardIDPool$IDBlockGetter.call(StandardIDPool.java:288)
	  at org.janusgraph.graphdb.database.idassigner.StandardIDPool$IDBlockGetter.call(StandardIDPool.java:255)
	  ...
	  at java.lang.Thread.run(Thread.java:745)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的调用栈没有显示这么多，实际上我们也没必要关心 &lt;code&gt;com.sleepycat.je.Database.put(Database.java:1627)&lt;/code&gt; 之后的东西，
因为这些东西都是 数据库的写 API，而生产环境我们会使用 hbase和cassandra ，所以每次只要 debug 到 KeyColumnValueStore 的 相应方法即可，再 debug 就是数据库的方法。&lt;/p&gt;

&lt;p&gt;到这里我们明白，增删改查都是 通过 KeyColumnValueStore 类完成。接下来我们直接在 BerkeleyJEKeyValueStore 的 增删改查方法 打断点就行。&lt;/p&gt;

&lt;h3 id=&#34;management-commit&#34;&gt;management.commit();&lt;/h3&gt;

&lt;p&gt;management 是用来操作 schema 的类，我们可以猜测 schema 也是以系统属性的方式存在数据库中。通过打断点发现，前面的操作都没有触发 BerkeleyJEKeyValueStore 的insert ，直到 commit，
先取出调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;main@1&amp;quot; prio=5 tid=0x1 nid=NA runnable
  java.lang.Thread.State: RUNNABLE
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:195)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEKeyValueStore.insert(BerkeleyJEKeyValueStore.java:184)
	  at org.janusgraph.diskstorage.berkeleyje.BerkeleyJEStoreManager.mutateMany(BerkeleyJEStoreManager.java:208)
	  at org.janusgraph.diskstorage.keycolumnvalue.keyvalue.OrderedKeyValueStoreManagerAdapter.mutateMany(OrderedKeyValueStoreManagerAdapter.java:125)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction$1.call(CacheTransaction.java:94)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction$1.call(CacheTransaction.java:91)
	  at org.janusgraph.diskstorage.util.BackendOperation.executeDirect(BackendOperation.java:68)
	  at org.janusgraph.diskstorage.util.BackendOperation.execute(BackendOperation.java:54)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction.persist(CacheTransaction.java:91)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction.flushInternal(CacheTransaction.java:139)
	  at org.janusgraph.diskstorage.keycolumnvalue.cache.CacheTransaction.commit(CacheTransaction.java:196)
	  at org.janusgraph.diskstorage.BackendTransaction.commitStorage(BackendTransaction.java:134)
	  at org.janusgraph.graphdb.database.StandardJanusGraph.commit(StandardJanusGraph.java:733)
	  at org.janusgraph.graphdb.transaction.StandardJanusGraphTx.commit(StandardJanusGraphTx.java:1372)
	  - locked &amp;lt;0x113a&amp;gt; (a org.janusgraph.graphdb.transaction.StandardJanusGraphTx)
	  at org.janusgraph.graphdb.database.management.ManagementSystem.commit(ManagementSystem.java:239)
	  - locked &amp;lt;0x102b&amp;gt; (a org.janusgraph.graphdb.database.management.ManagementSystem)
	  at org.janusgraph.example.GraphOfTheGodsFactory.load(GraphOfTheGodsFactory.java:111)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里面好像还有锁，这个先不讨论。&lt;/p&gt;

&lt;p&gt;主要的几个调用：&lt;/p&gt;

&lt;p&gt;StandardJanusGraphTx.commit()&lt;/p&gt;

&lt;p&gt;StandardJanusGraph.commit(addedRelations.getAll(), deletedRelations.values(), this); &amp;ndash; 这个 commit 的逻辑挺复杂，需要仔细查看。&lt;/p&gt;

&lt;p&gt;BackendTransaction.commitStorage();&lt;/p&gt;

&lt;p&gt;CacheTransaction.commit()&lt;/p&gt;

&lt;p&gt;OrderedKeyValueStoreManagerAdapter.mutateMany&lt;/p&gt;

&lt;p&gt;BerkeleyJEStoreManager.mutateMany(subMutations, tx);&lt;/p&gt;

&lt;p&gt;BerkeleyJEKeyValueStore.insert();&lt;/p&gt;

&lt;p&gt;然后接下来就是一个个分析这几个类每一个的属性和方法。&lt;/p&gt;

&lt;p&gt;首先看一下类的继承结构&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SchemaInspector	
	StandardJanusGraphTx (org.janusgraph.graphdb.transaction)
	SchemaManager (org.janusgraph.core.schema)
	    Transaction (org.janusgraph.core)
	        JanusGraphTransaction (org.janusgraph.core)
	            JanusGraphBlueprintsTransaction (org.janusgraph.graphdb.tinkerpop)
	                StandardJanusGraphTx (org.janusgraph.graphdb.transaction)
	        JanusGraph (org.janusgraph.core)
	            JanusGraphBlueprintsGraph (org.janusgraph.graphdb.tinkerpop)
	                StandardJanusGraph (org.janusgraph.graphdb.database)
	    JanusGraphManagement (org.janusgraph.core.schema)
	        ManagementSystem (org.janusgraph.graphdb.database.management)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SchemaInspector 接口定义了检查 schema 的一些方法，
例如：containsRelationType getRelationType containsPropertyKey getOrCreatePropertyKey getEdgeLabel getOrCreateVertexLabel
这些方法有四类，分别是是 RelationType 相关的，PropertyKey 相关，EdgeLabel 相关，VertexLabel 相关。这四个代表啥大家应该都清楚了。&lt;/p&gt;

&lt;p&gt;SchemaManager 接口 在 SchemaInspector 的基础上添加了 6 个方法 ：makePropertyKey makeEdgeLabel makeVertexLabel addProperties addProperties addConnection 。
其实前三个返回的是 Maker，后面三个返回的就是 Label。这六个方法左右主要是给 schema 添加更多信息，例如添加 properties。&lt;/p&gt;

&lt;p&gt;Transaction 继承自 SchemaManager 和 Graph ，定义了 addVertex 和 query 等操作。很奇怪为什么只有 addVertex 没有 addEdge 和 addProperty 的操作。&lt;/p&gt;

&lt;p&gt;JanusGraphManagement 继承自 SchemaManager 和 JanusGraphConfiguration ，定义了 buildEdgeIndex buildPropertyIndex commit 等操作
大部分都和 index 相关，例如构建查询更新。还有 getRelationTypes getVertexLabels 两个方法。&lt;/p&gt;

&lt;p&gt;ManagementSystem 继承自 JanusGraphManagement ，通过代理 StandardJanusGraphTx ，实现了 getGraphIndex commit 等操作。&lt;/p&gt;

&lt;p&gt;JanusGraphTransaction 继承自 Transaction ，定义了 addVertex getVertex commit rollback 等，和 Transaction 不同的是他的这些方法操作的都是 id，而后者操作的是 用户传入的 String&lt;/p&gt;

&lt;p&gt;JanusGraphBlueprintsTransaction 继承自 JanusGraphTransaction ，目前看到的就是简单封装一下抽象方法，同时实现了 addVertex 方法。&lt;/p&gt;

&lt;p&gt;StandardJanusGraphTx 继承自 JanusGraphBlueprintsTransaction ，实现了抽象的方法。&lt;/p&gt;

&lt;p&gt;JanusGraph 继承自 Transaction， 定义了 buildTransaction openManagement close 等方法。&lt;/p&gt;

&lt;p&gt;JanusGraphBlueprintsGraph 继承自 JanusGraph ，通过 ThreadLocal 实现线程隔离。
StandardJanusGraph 继承自 JanusGraphBlueprintsGraph 就是我们使用的 Graph 。&lt;/p&gt;

&lt;p&gt;所以了解janus比较重要的是 StandardJanusGraphTx ，了解多线程的 JanusGraphBlueprintsGraph。&lt;/p&gt;

&lt;p&gt;从继承结构大概可以看出所有的操作分为数据操作和 schema 操作，而分别由 JanusGraph 和 JanusGraphManagement 完成，实际上都是代理或者适配装饰了 StandardJanusGraphTx。StandardJanusGraphTx 内容很多。&lt;/p&gt;

&lt;h3 id=&#34;standardjanusgraph&#34;&gt;StandardJanusGraph&lt;/h3&gt;

&lt;p&gt;上面我们已经看出了实际上最重要的就是  StandardJanusGraphTx 的实现逻辑，我们就以他为入口，而不是 main 方法。它的构造方法里面需要用到 StandardJanusGraph ，我们先大概了解一下 。&lt;/p&gt;

&lt;h4 id=&#34;我们先看一下它的属性&#34;&gt;我们先看一下它的属性：&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;log
config
backend
idManager
idAssigner
times
indexSerializer
edgeSerializer
serializer
vertexExistenceQuery
queryCache
schemaCache
managementLogger
shutdownHook
isOpen
txCounter
openTransactions
name
typeCacheRetrieval
SCHEMA_FILTER
NO_SCHEMA_FILTER
NO_FILTER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GraphDatabaseConfiguration config 是图的配置，由于配置也是保存在数据库，所以也是需要访问数据库的。&lt;/p&gt;

&lt;p&gt;Backend backend 是在 config.getBackend 中初始化的，Backend 的构造方法很复杂，主要创建出了 StoreManager indexes txLogManager 等管理存储很重要的属性。&lt;/p&gt;

&lt;p&gt;idManager 和 idAssigner 都是和 id 相关的。 所属类为 IDManager ，VertexIDAssigner，有比较复杂的id分配算法。&lt;/p&gt;

&lt;p&gt;IndexSerializer 和 EdgeSerializer 、Serializer 用于序列化，Serializer 在 config 中初始化，其他两个都是基于 Serializer 的封装。&lt;/p&gt;

&lt;p&gt;vertexExistenceQuery:SliceQuery queryCache:RelationQueryCache schemaCache:SchemaCache 都是 cache 相关。&lt;/p&gt;

&lt;p&gt;managementLogger 是 用来记录操作日志的。&lt;/p&gt;

&lt;p&gt;typeCacheRetrieval ，看到 Retrieval 就知道是获取某些属性用的，他通过 &lt;code&gt;QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName)&lt;/code&gt; 获得 JanusGraphVertex。&lt;/p&gt;

&lt;h4 id=&#34;然后再看方法&#34;&gt;然后再看方法&lt;/h4&gt;

&lt;p&gt;除了 getset 以外，主要是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;isOpen
isClosed
close
closeInternal
prepareCommit
commit
openManagement
newTransaction
buildTransaction
newThreadBoundTransaction
newTransaction
openBackendTransaction
closeTransaction
getVertexIDs
edgeQuery
edgeMultiQuery
assignID
assignID
acquireLock
acquireLock
getTTL
getTTL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和 transaction 有关的打开关闭提交等，查询边和顶点，分配id，获得锁。这里的 edgeQuery 并不是查询边，而是查询 edgestore 这个表格，这个表格存放了所有的数据。
细心分析发现，这些方法主要都是进行查询操作，得到查询结果 List&lt;EntryList&gt;，并没有进行数据增删改查的操作 API。&lt;/p&gt;

&lt;h3 id=&#34;managementsystem&#34;&gt;ManagementSystem&lt;/h3&gt;

&lt;p&gt;StandardJanusGraph 用来操作数据，而 ManagementSystem 主要是管理 schema。&lt;/p&gt;

&lt;h4 id=&#34;属性&#34;&gt;属性：&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;LOGGER
CURRENT_INSTANCE_SUFFIX
graph
sysLog
managementLogger
transactionalConfig
modifyConfig
userConfig
schemaCache
transaction
updatedTypes
evictGraphFromCache
updatedTypeTriggers
txStartTime
graphShutdownRequired
isOpen
configVerifier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;graph 和 managementLogger 就是上面的 StandardJanusGraph 和 managementLogger。sysLog 也是和日志有关。&lt;/p&gt;

&lt;p&gt;TransactionalConfiguration 是事务的配置，实际上他应该是记录了变化，能够判断是否有改变，从而进行 commit 和 rollback&lt;/p&gt;

&lt;p&gt;SchemaCache 就是 StandardJanusGraph 的 SchemaCache。&lt;/p&gt;

&lt;p&gt;transaction 是 StandardJanusGraphTx。&lt;/p&gt;

&lt;p&gt;updatedTypes 应该也是记录更新&lt;/p&gt;

&lt;p&gt;其他的暂时还不太懂。&lt;/p&gt;

&lt;h4 id=&#34;方法&#34;&gt;方法：&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;IndexBuilder
GraphCacheEvictionCompleteTrigger
EmptyIndexJobFuture
UpdateStatusTrigger
IndexJobStatus
IndexIdentifier
ManagementSystem

getOpenInstancesInternal
getOpenInstances
forceCloseInstance
ensureOpen
commit
rollback
isOpen
close
getWrappedTx
addSchemaEdge
getSchemaElement
buildEdgeIndex
buildEdgeIndex
buildPropertyIndex
buildPropertyIndex
buildRelationTypeIndex
composeRelationTypeIndexName
containsRelationIndex
getRelationIndex
getRelationIndexes
getGraphIndexDirect
containsGraphIndex
getGraphIndex
getGraphIndexes
awaitGraphIndexStatus
awaitRelationIndexStatus
checkIndexName
createMixedIndex
addIndexKey
createCompositeIndex
buildIndex
updateIndex
evictGraphFromCache
setUpdateTrigger
setStatus
setStatusVertex
setStatusEdges
getIndexJobStatus
changeName
updateConnectionEdgeConstraints
getSchemaVertex
updateSchemaVertex
getConsistency
setConsistency
getTTL
setTTL
setTypeModifier
containsRelationType
getRelationType
containsPropertyKey
getPropertyKey
containsEdgeLabel
getOrCreateEdgeLabel
getOrCreatePropertyKey
getEdgeLabel
makePropertyKey
makeEdgeLabel
getRelationTypes
containsVertexLabel
getVertexLabel
getOrCreateVertexLabel
makeVertexLabel
addProperties
addProperties
addConnection
getVertexLabels
get
set
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;强制关闭、操作事务、添加顶点边Label属性索引。&lt;/p&gt;

&lt;p&gt;索引都是  buildRelationTypeIndex 方法，说明 RelationType(PropertyKey 和 EdgeLabel)才有索引，分别是 graphIndex 和 vertexIncdicentIndex ，VertexLabel 没有索引。
而 getVertexLabels 等带s的方法 是 调用 QueryUtil.getVertices ，说明得到所有的需要查询数据库。&lt;/p&gt;

&lt;p&gt;很多方法都是直接调用 StandardJanusGraphTx 的 对应方法。但是 build Index 并没有使用到 StandardJanusGraphTx。说明 index 并不是马上就插入数据库？或者因为 Index 建完以后还要等待？？&lt;/p&gt;

&lt;h3 id=&#34;standardjanusgraphtx&#34;&gt;StandardJanusGraphTx&lt;/h3&gt;

&lt;p&gt;上面大致了解了  StandardJanusGraph 和 ManagementSystem ，StandardJanusGraphTx 内部才是最重要的，&lt;/p&gt;

&lt;h4 id=&#34;属性-1&#34;&gt;属性：&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;log
EMPTY_DELETED_RELATIONS
UNINITIALIZED_LOCKS
LOCK_TIMEOUT
MIN_VERTEX_CACHE_SIZE
graph
config
idManager
idInspector
attributeHandler
txHandle
edgeSerializer
indexSerializer
vertexCache
addedRelations
deletedRelations
indexCache
newVertexIndexEntries
uniqueLocks
newTypeCache
temporaryIds
times
isOpen
existingVertexRetriever
externalVertexRetriever
internalVertexRetriever
edgeProcessor
edgeProcessorImpl
elementProcessor
elementProcessorImpl
vertexIDConversionFct
edgeIDConversionFct
propertyIDConversionFct
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前面的属性都是在 graph 获得的&lt;/p&gt;

&lt;p&gt;vertexCache = new GuavaVertexCache(effectiveVertexCacheSize,concurrencyLevel,config.getDirtyVertexSize()); 是缓存 vertex 的。&lt;/p&gt;

&lt;p&gt;addedRelations = new ConcurrentBufferAddedRelations(); 是缓存 Relation 的。&lt;/p&gt;

&lt;p&gt;deletedRelations 同上&lt;/p&gt;

&lt;p&gt;indexCache 缓存 index ， 类似 vertexCache ，需要传入一个  retrival&lt;/p&gt;

&lt;p&gt;existingVertexRetriever externalVertexRetriever internalVertexRetriever 都是给 vertexCache 用来查 vertex 的。&lt;/p&gt;

&lt;p&gt;edgeProcessor 是一个 QueryExecutor。用来查询的。&lt;/p&gt;

&lt;p&gt;elementProcessor 一样是用来查询的。&lt;/p&gt;

&lt;h4 id=&#34;方法-1&#34;&gt;方法&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;StandardJanusGraphTx
setBackendTransaction
verifyWriteAccess
verifyAccess
verifyOpen
getNextTx
getConfiguration
getGraph
getTxHandle
getEdgeSerializer
getIdInspector
isPartitionedVertex
getCanonicalVertex
getOtherPartitionVertex
getAllRepresentatives
containsVertex
isValidVertexId
getVertex
getVertices
getExistingVertex
getInternalVertex
addVertex
addVertex
addVertex
getInternalVertices
validDataType
verifyAttribute
removeRelation
isRemovedRelation
getLock
getLock
getUniquenessLock
checkPropertyConstraintForVertexOrCreatePropertyConstraint
checkPropertyConstraintForEdgeOrCreatePropertyConstraint
checkConnectionConstraintOrCreateConnectionConstraint
addEdge
connectRelation
addProperty
addProperty
getEdges
makeSchemaVertex
updateSchemaVertex
makePropertyKey
makeEdgeLabel
addSchemaEdge
addProperties
addProperties
addConnection
getSchemaVertex
containsRelationType
getRelationType
containsPropertyKey
containsEdgeLabel
getExistingRelationType
getPropertyKey
getOrCreatePropertyKey
getOrCreatePropertyKey
getEdgeLabel
getOrCreateEdgeLabel
makePropertyKey
makeEdgeLabel
getExistingVertexLabel
containsVertexLabel
getVertexLabel
getOrCreateVertexLabel
makeVertexLabel
query
multiQuery
multiQuery
executeMultiQuery
getConversionFunction
query
indexQuery
commit
rollback
releaseTransaction
isOpen
isClosed
hasModifications
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;schema 操作的 makeEdgeLabel makePropertyKey 等，数据操作的 getVertex addEdge 等，事务操作的 rollback 等。
好像没有 index ？因为 index 属于 schema， 相关的方法都是在 management 中完成的。
实际上，StandardJanusGraphTx 有 addEdge addProperties addVertex 等操作数据的方法，同时还有 makePropertyKey，EdgeLabel 等操作 schema 的方法。
原因是 makePropertyKey 等 schema 实际上也是以顶点的形式保存在 janus 中，所以 schema 操作本质还是数据操作，只不过这部分数据都会被读入内存。
所以 schema 操作都会触发 makeSchemaVertex 的方法，makeSchemaVertex 就是添加一个顶点，只不过是 schema 的订单。&lt;/p&gt;

&lt;h3 id=&#34;backendtransaction&#34;&gt;BackendTransaction&lt;/h3&gt;

&lt;p&gt;我们在看 StandardJanusGraphTx 代码的时候 ，发现 BackendTransaction 也很重要，看看他的继承体系&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BaseTransaction
	LoggableTransaction (org.janusgraph.diskstorage)
	    CacheTransaction (org.janusgraph.diskstorage.keycolumnvalue.cache)
	    IndexTransaction (org.janusgraph.diskstorage.indexing)
	    BackendTransaction (org.janusgraph.diskstorage)
	BaseTransactionConfigurable (org.janusgraph.diskstorage)
	    Transaction in LuceneIndex (org.janusgraph.diskstorage.lucene)
	    DefaultTransaction (org.janusgraph.diskstorage.util)
	    StoreTransaction (org.janusgraph.diskstorage.keycolumnvalue)
	        AbstractStoreTransaction (org.janusgraph.diskstorage.common)
	            CQLTransaction (org.janusgraph.diskstorage.cql)
	            BerkeleyJETx (org.janusgraph.diskstorage.berkeleyje)
	            CassandraTransaction (org.janusgraph.diskstorage.cassandra)
	            HBaseTransaction (org.janusgraph.diskstorage.hbase)
	            NoOpStoreTransaction (org.janusgraph.diskstorage.common)
	            InMemoryTransaction in InMemoryStoreManager (org.janusgraph.diskstorage.keycolumnvalue.inmemory)
	        CacheTransaction (org.janusgraph.diskstorage.keycolumnvalue.cache)
	        ExpectedValueCheckingTransaction (org.janusgraph.diskstorage.locking.consistentkey)
	IndexTransaction (org.janusgraph.diskstorage.indexing)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;BaseTransaction 只有 comimit 和 roolback 两个方法。LoggableTransaction 只有 LoggableTransaction ，BaseTransactionConfigurable 多了一个 getConfiguration 。&lt;/p&gt;

&lt;p&gt;IndexTransaction BackendTransaction CacheTransaction 继承自 LoggableTransaction ， 前者是处理索引，后者可以处理其他的读写事务，最后的是内存中的事务处理。&lt;/p&gt;

&lt;p&gt;IndexTransaction 中有一个 BaseTransaction 属性，用来实现真正的事务读写，实现一般是 IndexProvider 生成，主要是 ES、LUCENE、Solr 三种实现。
CacheTransaction 中有 StoreTransaction 属性，用来实现持久化。
BackendTransaction 中则有 CacheTransaction edgeStore indexStore txLogStore Map&lt;String, IndexTransaction&gt; indexTx; 等属性，显然这才是最重要的实现事务管控的类。&lt;/p&gt;

&lt;p&gt;我们通过代码分析可以看出 BackendTransaction 的创建是在 StandardJanusGraph 完成，而使用主要是 StandardJanusGraphTx 。
StandardJanusGraph 的 newTransaction 创建 BackendTransaction 和 StandardJanusGraphTx ，并进行赋值。
StandardJanusGraph 什么时候会调用 newTransaction ？一个在 typeCacheRetrieval 中，另一个就是我们代码创建新的 transaction，还有一个是 在没有 transactional isolation 的存储系统上面， commit 的时候需要操作 schema&lt;/p&gt;

&lt;h2 id=&#34;关键类分析&#34;&gt;关键类分析&lt;/h2&gt;

&lt;p&gt;上面整体的调试已经找到了比较关键的大类，以及事务相关的类的关系，我们可以反过来再看一遍调用栈，就更清晰了。现在反过来从细节开始研究具体的类的功能。&lt;/p&gt;

&lt;h3 id=&#34;storemanager&#34;&gt;StoreManager&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;StoreManager
	KeyValueStoreManager (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    OrderedKeyValueStoreManager (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	        BerkeleyJEStoreManager (org.janusgraph.diskstorage.berkeleyje)
	AbstractStoreManager (org.janusgraph.diskstorage.common)
	    DistributedStoreManager (org.janusgraph.diskstorage.common)
	        CQLStoreManager (org.janusgraph.diskstorage.cql)
	            CachingCQLStoreManager (org.janusgraph.diskstorage.cql)
	        AbstractCassandraStoreManager (org.janusgraph.diskstorage.cassandra)
	            CassandraThriftStoreManager (org.janusgraph.diskstorage.cassandra.thrift)
	            CassandraEmbeddedStoreManager (org.janusgraph.diskstorage.cassandra.embedded)
	            AstyanaxStoreManager (org.janusgraph.diskstorage.cassandra.astyanax)
	        HBaseStoreManager (org.janusgraph.diskstorage.hbase)
	    LocalStoreManager (org.janusgraph.diskstorage.common)
	        BerkeleyJEStoreManager (org.janusgraph.diskstorage.berkeleyje)
	                    LocalStoreManagerSampleImplementation in LocalStoreManagerTest (org.janusgraph.diskstorage.common)
	            KeyColumnValueStoreManager (org.janusgraph.diskstorage.keycolumnvalue)
	    CQLStoreManager (org.janusgraph.diskstorage.cql)
	        CachingCQLStoreManager (org.janusgraph.diskstorage.cql)
	    OrderedKeyValueStoreManagerAdapter (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    InMemoryStoreManager (org.janusgraph.diskstorage.keycolumnvalue.inmemory)
	    KCVSManagerProxy (org.janusgraph.diskstorage.keycolumnvalue)
	        ExpectedValueCheckingStoreManager (org.janusgraph.diskstorage.locking.consistentkey)
	        TTLKCVSManager (org.janusgraph.diskstorage.keycolumnvalue.ttl)
	    MetricInstrumentedStoreManager (org.janusgraph.diskstorage.util)
	    AbstractCassandraStoreManager (org.janusgraph.diskstorage.cassandra)
	        CassandraThriftStoreManager (org.janusgraph.diskstorage.cassandra.thrift)
	        CassandraEmbeddedStoreManager (org.janusgraph.diskstorage.cassandra.embedded)
	        AstyanaxStoreManager (org.janusgraph.diskstorage.cassandra.astyanax)
	    HBaseStoreManager (org.janusgraph.diskstorage.hbase)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;StoreManager 接口主要功能 beginTransaction 得到一个 StoreTransaction 和 close ，clean 等，还有得到 store 相关的信息。看着上面好像很多继承类，实际上是因为有重复继承导致的。&lt;/p&gt;

&lt;p&gt;KeyValueStoreManager 是测试的。DistributedStoreManager 和 KeyColumnValueStoreManager 是两个抽象，我们使用的 cassandra 和 hbase 的 storeManager 都继承自这两个。
这几个 storeManager 就有我们需要的操作数据的方法。&lt;/p&gt;

&lt;h3 id=&#34;keycolumnvaluestore-keyvaluestore&#34;&gt;KeyColumnValueStore &amp;amp; KeyValueStore&lt;/h3&gt;

&lt;p&gt;KeyValueStore 是测试的，KeyColumnValueStore 是真正的。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;KeyColumnValueStore
	KCVSProxy (org.janusgraph.diskstorage.keycolumnvalue)
	    TTLKCVS (org.janusgraph.diskstorage.keycolumnvalue.ttl)
	    ExpectedValueCheckingStore (org.janusgraph.diskstorage.locking.consistentkey)
	    KCVSCache (org.janusgraph.diskstorage.keycolumnvalue.cache)
	        ExpirationKCVSCache (org.janusgraph.diskstorage.keycolumnvalue.cache)
	        NoKCVSCache (org.janusgraph.diskstorage.keycolumnvalue.cache)
	    ReadOnlyKeyColumnValueStore (org.janusgraph.diskstorage.keycolumnvalue)
	BaseKeyColumnValueAdapter (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    OrderedKeyValueStoreAdapter (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	CQLKeyColumnValueStore (org.janusgraph.diskstorage.cql)
	HBaseKeyColumnValueStore (org.janusgraph.diskstorage.hbase)
	CassandraEmbeddedKeyColumnValueStore (org.janusgraph.diskstorage.cassandra.embedded)
	CassandraThriftKeyColumnValueStore (org.janusgraph.diskstorage.cassandra.thrift)
	AstyanaxKeyColumnValueStore (org.janusgraph.diskstorage.cassandra.astyanax)
	MetricInstrumentedStore (org.janusgraph.diskstorage.util)
	CounterKCVS in KCVSCacheTest (org.janusgraph.diskstorage.cache)
	InMemoryKeyColumnValueStore (org.janusgraph.diskstorage.keycolumnvalue.inmemory)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;KeyColumnValueStore 的作用我暂时不是很清楚，从继承类的构造方法看，需要传入一个 StoreManager connection table columnFamily store 。大概能猜出一个 Store 代表一个表格，或者代表一个列族，应该是代表某种数据，例如索引，日志等。&lt;/p&gt;

&lt;p&gt;从他的方法可以看出主要是查询库， 如 getKeySlice mutate mutateMany 。&lt;/p&gt;

&lt;p&gt;KCVSCache 也继承自 KeyColumnValueStore，名字可以看出是放在内存的 store ，自然也有 getSlice 等方法，我们可以看他的实现类 ExpirationKCVSCache。
这个类里面有一个 Cache&lt;KeySliceQuery,EntryList&gt; cache 的对象，用来缓存查询结果。而 KCVSCache 继承自 KCVSProxy ，这个类则代理 KeyColumnValueStore 对象。其实还有一个 TTLKCVS ，应该是带过期时间的 store&lt;/p&gt;

&lt;h3 id=&#34;logmanager&#34;&gt;LogManager&lt;/h3&gt;

&lt;p&gt;LogManager 的注释：Manager interface for opening {@link Log}s against a particular Log implementation.&lt;/p&gt;

&lt;p&gt;KCVSLogManager 实现类的注释：
Implementation of {@link LogManager} against an arbitrary {@link KeyColumnValueStoreManager}.
Issues {@link Log} instances which wrap around a {@link KeyColumnValueStore}.&lt;/p&gt;

&lt;p&gt;可以看出 LogManager 主要是将 通过 KeyColumnValueStoreManager 实现 Log，而 log 则是 围绕 KeyColumnValueStore 。&lt;/p&gt;

&lt;p&gt;而我们的log包括三部分： managementLogManager txLogManager userLogManager&lt;/p&gt;

&lt;h3 id=&#34;log&#34;&gt;Log&lt;/h3&gt;

&lt;p&gt;Log 的注释：
Represents a log that allows content to be added to it in the form of messages and
to read messages and their content from the log via registered {@link MessageReader}s.&lt;/p&gt;

&lt;p&gt;KCVSLog 的注释很长。可以看出主要通过 KeyColumnValueStore 实现。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/**
 * Implementation of {@link Log} wrapped around a {@link KeyColumnValueStore}. Each message is written as a column-value pair ({@link Entry})
 * into a timeslice slot. A timeslice slot is uniquely identified by:
 * &amp;lt;ul&amp;gt;
 *     &amp;lt;li&amp;gt;The partition id: On storage backends that are key-ordered, a partition bit width can be configured which configures the number of
 *     first bits that comprise the partition id. On unordered storage backends, this is always 0&amp;lt;/li&amp;gt;
 *     &amp;lt;li&amp;gt;A bucket id: The number of parallel buckets that should be maintained is configured by
 *     {@link org.janusgraph.graphdb.configuration.GraphDatabaseConfiguration#LOG_NUM_BUCKETS}. Messages are written to the buckets
 *     in round-robin fashion and each bucket is identified by a bucket id.
 *     Having multiple buckets per timeslice allows for load balancing across multiple keys in the storage backend.&amp;lt;/li&amp;gt;
 *     &amp;lt;li&amp;gt;The start time of the timeslice: Each time slice is {@link #TIMESLICE_INTERVAL} microseconds long. And all messages that are added between
 *     start-time and start-time+{@link #TIMESLICE_INTERVAL} end up in the same timeslice. For high throughput logs that might be more messages
 *     than the underlying storage backend can handle per key. In that case, ensure that (2^(partition-bit-width) x (num-buckets) is large enough
 *     to distribute the load.&amp;lt;/li&amp;gt;
 * &amp;lt;/ul&amp;gt;
 *
 * Each message is uniquely identified by its timestamp, sender id (which uniquely identifies a particular instance of {@link KCVSLogManager}), and the
 * message id (which is auto-incrementing). These three data points comprise the column of a log message. The actual content of the message
 * is written into the value.
 * &amp;lt;/p&amp;gt;
 * When {@link MessageReader} are registered, one reader thread per partition id and bucket is created which periodically (as configured) checks for
 * new messages in the storage backend and invokes the reader. &amp;lt;/br&amp;gt;
 * Read-markers are maintained (for each partition-id &amp;amp; bucket id combination) under a dedicated key in the same {@link KeyColumnValueStoreManager} as the
 * log messages. The read markers are updated to the current position before each new iteration of reading messages from the log. If the system fails
 * while reading a batch of messages, a subsequently restarted log reader may therefore read messages twice. Hence, {@link MessageReader} implementations
 * should exhibit correct behavior for the (rare) circumstance that messages are read twice.
 *
 * Note: All time values in this class are in microseconds. Hence, there are many cases where milliseconds are converted to microseconds.
 *
 * @author Matthias Broecheler (me@matthiasb.com)
 */
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;英语不好就为难了。
每个消息都由它的时间戳、发件人ID，以及消息ID（它是自动递增的）唯一标识。这三个数据组成包括日志消息的列名。消息的实际内容被写入值中。&lt;/p&gt;

&lt;h3 id=&#34;indexprovider&#34;&gt;IndexProvider&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;IndexProvider (org.janusgraph.diskstorage.indexing)
    LuceneIndex (org.janusgraph.diskstorage.lucene)
    TestMockIndexProvider (org.janusgraph.graphdb)
    SolrIndex (org.janusgraph.diskstorage.solr)
    ElasticSearchIndex (org.janusgraph.diskstorage.es)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的 IndexTransaction 包含了 对 IndexProvider的操作。&lt;/p&gt;

&lt;h3 id=&#34;vertexidassigner-standardidpool-idblock&#34;&gt;VertexIDAssigner StandardIDPool IDBlock&lt;/h3&gt;

&lt;p&gt;负责分配 id ，分配原则我们通过运行 VertexIDAssignerTest 查看。&lt;/p&gt;

&lt;h3 id=&#34;element&#34;&gt;Element&lt;/h3&gt;

&lt;p&gt;我们在操作的过程中有很多的 Vertex Property Edge 等，实际上都继承自一个 Element，继承体系确实有点吓人，这里就不展示了，几个 schema 都这么多东西，我们先分类。&lt;/p&gt;

&lt;p&gt;首先我们思考一下，为什么会有这么多。其实 gremin 语法本身定义了一堆schema ，而 janus 也有自己的schema ，两个要进行适配器模式，所以还有一组适配器的schema。所以会比较多？&lt;/p&gt;

&lt;p&gt;我们先看一下 gremin 的接口 ,主要有三个，&lt;code&gt;org.apache.tinkerpop.gremlin.structure&lt;/code&gt;下面：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;VertexProperty
Vertex
Edge
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;分别代表了属性，顶点，边，然后 gremin 本身对他们进行了一些实现。然后死 janusgraph 的 &lt;code&gt;org.janusgraph.core&lt;/code&gt; 包下面，有很多一些接口：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;JanusGraphElement
    JanusGraphVertex
        InternalVertex (org.janusgraph.graphdb.internal)
        RelationType (org.janusgraph.core)
        VertexLabel (org.janusgraph.core)
	JanusGraphRelation
		JanusGraphEdge (org.janusgraph.core)
		    AbstractEdge (org.janusgraph.graphdb.relations)
		        CacheEdge (org.janusgraph.graphdb.relations)
		        StandardEdge (org.janusgraph.graphdb.relations)
		JanusGraphVertexProperty (org.janusgraph.core)
		    FulgoraVertexProperty (org.janusgraph.graphdb.olap.computer)
		    AbstractVertexProperty (org.janusgraph.graphdb.relations)
		        StandardVertexProperty (org.janusgraph.graphdb.relations)
		        CacheVertexProperty (org.janusgraph.graphdb.relations)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里展示的并不完整。整个 janus 的schema很复杂。只是大概从注释看出，
在 core 包中，JanusGraphVertex 是顶点，JanusGraphRelation 代表顶点关系，分为属性和边两种 ：JanusGraphVertexProperty 和 JanusGraphEdge。
在 internal 包中，对 core 包的类添加些 janus 特有的方法。&lt;/p&gt;

&lt;p&gt;另外在 schema 包中还有 RelationType 和 VertexLabel ，两个都是继承自 JanusGraphVertex ，意思是说 VertexLabel VertexProperty EdgeLabel 都是顶点？？？。
这样就好像明白一点，janus 中的 PropertyKey VertexLabel EdgeLabel 都是以顶点的形式保存起来的。&lt;/p&gt;

&lt;p&gt;所以我们看 Edge 类型继承体系比较简单，就是 CacheEdge (org.janusgraph.graphdb.relations) StandardEdge (org.janusgraph.graphdb.relations) 继承自
AbstractEdge ，然后继承 JanusGraphEdge，Edge。
而 Vertex 继承体系很复杂，除了类似 Edge 的继承体系以外，CacheVertex 还多了 JanusGraphSchemaVertex 这个子类，这个子类还有 RelationTypeVertex 和 VertexLabelVertex 两个子类，
实际上很明显，CacheVertex 的子类 JanusGraphSchemaVertex 代表的就是 graph 的 schema ，也是作为 Vertex 保存的。&lt;/p&gt;

&lt;p&gt;这个给别人讲一句话就懂了，但是自己分析可能要好几个小时才能明白。这也是学习和自己研究的不同。&lt;/p&gt;

&lt;h3 id=&#34;index&#34;&gt;Index&lt;/h3&gt;

&lt;p&gt;索引肯定是数据库的重点，我们到目前没有分析过和所以有关的内容。IndexTransaction 是我们遇到的可能和索引相关的内容了，就从 他开始。
IndexTransaction 中有个 BaseTransaction 的对象用来实现事务，通过 IndexProvider 来产生。我们以 ElasticSearchIndex 为例，可以看看他的方法。&lt;/p&gt;

&lt;p&gt;例如 register 方法会创建索引，还有 restore 等操作事务的方法。在 ManagementSystem 的 updateIndex 方法中，定义了各种操作 index 的方法。&lt;/p&gt;

&lt;p&gt;Index 类继承了 JanusGraphSchemaElement，主要有两类实现类 JanusGraphIndex 和 RelationTypeIndex 。&lt;/p&gt;

&lt;p&gt;JanusGraphIndex 的实现类是 JanusGraphIndexWrapper 。可以通过 JanusGraphManagement#buildIndex(String, Class) 新建 。&lt;/p&gt;

&lt;p&gt;RelationTypeIndex 的实现类是 RelationTypeIndexWrapper，可以通过
JanusGraphManagement#buildEdgeIndex(org.janusgraph.core.EdgeLabel, String, org.apache.tinkerpop.gremlin.structure.Direction, org.apache.tinkerpop.gremlin.process.traversal.Order, org.janusgraph.core.PropertyKey&amp;hellip;)
和 JanusGraphManagement#buildPropertyIndex(org.janusgraph.core.PropertyKey, String, org.apache.tinkerpop.gremlin.process.traversal.Order, org.janusgraph.core.PropertyKey&amp;hellip;)
两个方法建 RelationTypeIndex。&lt;/p&gt;

&lt;p&gt;IndexType 定义所有的 JanusGraphIndex，实现包括 CompositeIndexType 和 MixedIndexType。&lt;/p&gt;

&lt;p&gt;IndexType IndexProvider 和 Index 的不同在于，Index 和他的实现类 JanusGraphIndex RelationTypeIndexWrapper 都是继承自 JanusGraphSchemaElement ，和 Vertex 一样，代表的是 janus 中的一个顶点。
IndexType 代表了所以类型 ，IndexProvider 则代表的是和索引相关的操作方法 例如 ElasticSearchIndex SolrIndex LuceneIndex。&lt;/p&gt;

&lt;h3 id=&#34;standardscanner&#34;&gt;StandardScanner&lt;/h3&gt;

&lt;p&gt;在 Backend 构造方法最后有一句 new StandardScanner。我们看看这个是干啥用的，主要调用地方是  buildStoreIndexScanJob 这个方法，我们发现这个新建了一个 Job。
buildEdgeScanJob 主要就是在 ManagementSystem 的 updateIndex 方法使用，根据方法名可以看出，这是在遍历数据库的job。&lt;/p&gt;

&lt;p&gt;StandardScanner 的重点很明显就是它的内部类 Builder。Builder 内部有一个 ScanJob 的变量，实际上 Builder 就是有个 execute 方法，能够执行 ScanJob ，例如 IndexUpdateJob 和 IndexRepairJob。&lt;/p&gt;

&lt;p&gt;这个越看越复杂，还是后续分析吧。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janusgraph线上schema过程Debug</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-schema/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-schema/</guid>
      
        <description>

&lt;h1 id=&#34;初步调试&#34;&gt;初步调试&lt;/h1&gt;

&lt;h2 id=&#34;回顾&#34;&gt;回顾&lt;/h2&gt;

&lt;p&gt;首先我们通过 debug 官方的 GraphOfGod 大概进行一个简单的调试，然后我们仔细查看 janusgraph 调用栈，分析了关键类。
这次我们主要看看schema 的建立过程，我们上次分析已经知道，其实 schema也是以Vertex的方式存储在内存和数据库中的。
通过 CacheVertex 的子类 JanusGraphSchemaVertex 实现。JanusGraphSchemaVertex 有两个个子类，&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
AbstractElement (org.janusgraph.graphdb.internal)
	AbstractVertex (org.janusgraph.graphdb.vertices)
		StandardVertex (org.janusgraph.graphdb.vertices)
			CacheVertex (org.janusgraph.graphdb.vertices)
				JanusGraphSchemaVertex (org.janusgraph.graphdb.types.vertices)
					RelationTypeVertex (org.janusgraph.graphdb.types.vertices)
					    PropertyKeyVertex (org.janusgraph.graphdb.types.vertices)
					    EdgeLabelVertex (org.janusgraph.graphdb.types.vertices)
					VertexLabelVertex (org.janusgraph.graphdb.types)
````

中间省略了一些接口。

所以每次 new 一个 EdgeLabelVertex、VertexLabelVertex、PropertyKeyVertex 的时候，调用栈会非常深。

我们大概查看一下这些类的功能。

### AbstractElement

只有一个属性：private long id; 这个id是唯一的。小于0 的是临时id，事务提交时候会分配大于0的id，等于0的是虚拟的并不存在的，大雨0的是物理persist的。

### InternalVertex

图上没有展示 InternalVertex ，这是一个接口，继承自 JanusGraphVertex 和 InternalElement。凡是带 Internal 的都是比原来的多一个 janus 专属方法的类。
所以 InternalVertex 也是比 JanusGraphVertex 多一些 janus 专属的方法 例如： removeRelation addRelation tx()。
JanusGraphVertex 中则是 janus 和 gremin 都会有的方法 ， 例如 addEdge property label。
InternalVertex 有 query() 等方法，

### AbstractVertex

AbstractVertex 继承自 AbstractElement 和 InternalVertex，
AbstractVertex 比 AbstractElement 的 id 基础上多了一个 StandardJanusGraphTx tx 的属性。也就是多了一个事务空值对象。

### StandardVertex

StandardVertex 继承自 AbstractVertex，多了一个 lifecycle 属性和 volatile AddedRelationsContainer addedRelations 属性。应该是通过缓存空值。

### CacheVertex
CacheVertex 继承自 StandardVertex 。多了一个 queryCache 属性。

### JanusGraphSchemaVertex 

JanusGraphSchemaVertex 就是保存 Schema 的 Vertex ，分为两类 RelationTypeVertex 和 VertexLabelVertex。其中 RelationTypeVertex 分为 PropertyKeyVertex 和 EdgeLabelVertex。

## 预览

schema 操作是通过 ManagementSystem &amp;lt;: JanusGraphManagement 完成的。ManagementSystem 内容很复杂，上次已经大概看了他的方法和属性，这次我们着重看一下方法的实现，首先还是再次浏览一下方法。

### 属性

```java
private static final String CURRENT_INSTANCE_SUFFIX = &amp;quot;(current)&amp;quot;;

private final StandardJanusGraph graph;
private final Log sysLog;
private final ManagementLogger mgmtLogger;

private final KCVSConfiguration baseConfig;
private final TransactionalConfiguration transactionalConfig;
private final ModifiableConfiguration modifyConfig;
private final UserModifiableConfiguration userConfig;
private final SchemaCache schemaCache;

private final StandardJanusGraphTx transaction;

private final Set&amp;lt;JanusGraphSchemaVertex&amp;gt; updatedTypes;
private final List&amp;lt;Callable&amp;lt;Boolean&amp;gt;&amp;gt; updatedTypeTriggers;

private final Instant txStartTime;
private boolean graphShutdownRequired;
private boolean isOpen;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;构造方法&#34;&gt;构造方法&lt;/h3&gt;

&lt;p&gt;基本都是直接赋值。StandardJanusGraph 的 openManagement 方法返回一个 ManagementSystem 。&lt;/p&gt;

&lt;h3 id=&#34;instances-操作&#34;&gt;Instances 操作&lt;/h3&gt;

&lt;p&gt;getOpenInstancesInternal
getOpenInstances
forceCloseInstance&lt;/p&gt;

&lt;p&gt;判断正在运行的 instance 。&lt;/p&gt;

&lt;h3 id=&#34;commit-和-rollback&#34;&gt;commit 和 rollback&lt;/h3&gt;

&lt;p&gt;commit 方法有四步。
1. 判断 transactionalConfig 是否变化，如果变化，将变化写出。
2. transactionalConfig.commit();
3. transaction.commit();
4. 判断 updatedTypes 是否有更新，进行 expire 操作。&lt;/p&gt;

&lt;p&gt;rollback 方法，则很简单。直接调用两个 transaction 的 callback ，然后 close。&lt;/p&gt;

&lt;h3 id=&#34;getschemaelement&#34;&gt;getSchemaElement&lt;/h3&gt;

&lt;p&gt;这个方法返回一个 JanusGraphSchemaElement ，但是实际上返回的是 RelationTypeIndexWrapper 或者 JanusGraphIndexWrapper ，原因未知，这两个类上一节介绍过，。&lt;/p&gt;

&lt;h3 id=&#34;buildrelationtypeindex&#34;&gt;buildRelationTypeIndex&lt;/h3&gt;

&lt;p&gt;包括 buildPropertyIndex 和 buildEdgeIndex。
步骤都是先 生成对应的 RelationTypeMaker，然后 make，然后调用 addSchemaEdge， 最后调用 updateIndex&lt;/p&gt;

&lt;h3 id=&#34;getrelationindex&#34;&gt;getRelationIndex&lt;/h3&gt;

&lt;p&gt;得到 RelationType 的 Index。
调用 QueryUtil.getVertices(transaction, BaseKey.SchemaName, JanusGraphSchemaCategory.getRelationTypeName(composedName))
然后 return new RelationTypeIndexWrapper((InternalRelationType) v);&lt;/p&gt;

&lt;h3 id=&#34;getrelationindexes&#34;&gt;getRelationIndexes&lt;/h3&gt;

&lt;p&gt;得到所有的  Indexs。&lt;/p&gt;

&lt;h3 id=&#34;getgraphindexdirect&#34;&gt;getGraphIndexDirect&lt;/h3&gt;

&lt;p&gt;直接调用 transaction.getSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX.getSchemaName(name));
得到 GraphIndex ，GraphIndex 和 RelationTypeIndex 不一样，一个是基于关系的，前者是基于属性的。&lt;/p&gt;

&lt;h3 id=&#34;getgraphindexes&#34;&gt;getGraphIndexes&lt;/h3&gt;

&lt;p&gt;返回所有的 GraphIndex&lt;/p&gt;

&lt;h3 id=&#34;createmixedindex&#34;&gt;createMixedIndex&lt;/h3&gt;

&lt;p&gt;调用 JanusGraphSchemaVertex indexVertex = transaction.makeSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX, indexName, def); 得到 vertex
调用 addSchemaEdge(indexVertex, (JanusGraphSchemaVertex) constraint, TypeDefinitionCategory.INDEX_SCHEMA_CONSTRAINT, null); 添加关系
然后调用 updateSchemaVertex(indexVertex);
最终 new JanusGraphIndexWrapper(indexVertex.asIndexType());&lt;/p&gt;

&lt;p&gt;可以看出，这个方法其实只是添加了一个顶点，然后和另一个 constraint 顶点简历了一条关系。&lt;/p&gt;

&lt;h3 id=&#34;addindexkey&#34;&gt;addIndexKey&lt;/h3&gt;

&lt;p&gt;给已有的 index 添加一个key，这个应该很复杂，我们先跳过。&lt;/p&gt;

&lt;h3 id=&#34;createcompositeindex&#34;&gt;createCompositeIndex&lt;/h3&gt;

&lt;p&gt;创建 CompositeIndex ，GrpahIndex 分为 CompositeIndex 和 mixedIndex&lt;/p&gt;

&lt;p&gt;创建过程也是 addSchemaEdge ， updateSchemaVertex，updateIndex&lt;/p&gt;

&lt;h3 id=&#34;innerclass&#34;&gt;InnerClass&lt;/h3&gt;

&lt;p&gt;很多内部类：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IndexBuilder   -- 构建 Index
EmptyIndexJobFuture -- 提交的job
UpdateStatusTrigger -- 更新status的触发器
IndexJobStatus -- job 的 status
IndexIdentifier  --标识
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;addschemaedge&#34;&gt;addSchemaEdge&lt;/h3&gt;

&lt;p&gt;上面好几个方法都会调用 addSchemaEdge updateSchemaVertex updateIndex ，我们看看这三个方法。&lt;/p&gt;

&lt;p&gt;addSchemaEdge 是私有方法，应该是在内部会调用的。根据名字可以得出这个方法是添加边，而且添加的是 schema 的边，
我们之前已经知道实际上 schema 都是保存为 vertex，而现在就是给这些 Vertex 添加 Edge，这个边的 EdgeLabel 是 BaseLabel.SchemaDefinitionEdge。
例如 某个 PropertyKey 添加一个 Index ，实际上会有两个 SchemaVertex，然后给他们建立一个关系。
我们可以通过查看方法调用时机，基本上是修改 index 或者 schemaVertex ，一般与 updateSchemaVertex 或者 updateIndex 配合执行。&lt;/p&gt;

&lt;p&gt;方法大概步骤就是调用 transaction.addEdge(out, in, BaseLabel.SchemaDefinitionEdge) 得到 Edge，
然后调用 edge.property(BaseKey.SchemaDefinitionDesc.name(), desc);最后返回 edge。&lt;/p&gt;

&lt;h3 id=&#34;updateschemavertex&#34;&gt;updateSchemaVertex&lt;/h3&gt;

&lt;p&gt;就一句话 transaction.updateSchemaVertex(schemaVertex);&lt;/p&gt;

&lt;h3 id=&#34;updateindex&#34;&gt;updateIndex&lt;/h3&gt;

&lt;p&gt;IndexJobFuture updateIndex(Index index, SchemaAction updateAction)&lt;/p&gt;

&lt;p&gt;SchemaAction 是一个枚举，包括 REGISTER_INDEX REINDEX ENABLE_INDEX DISABLE_INDEX REMOVE_INDEX 。
IndexJobFuture 代表的是提交了的 job，等待返回结果。&lt;/p&gt;

&lt;p&gt;方法步骤：&lt;/p&gt;

&lt;p&gt;JanusGraphSchemaVertex schemaVertex = getSchemaVertex(index);&lt;/p&gt;

&lt;p&gt;更新 dependentTypes ，实际上就是为了更新 updatedTypes。&lt;/p&gt;

&lt;p&gt;根据不同的请求，调用 setStatus setUpdateTrigger setJob 。这个过程很复杂，后面再讲解。&lt;/p&gt;

&lt;h2 id=&#34;编码调试&#34;&gt;编码调试&lt;/h2&gt;

&lt;h3 id=&#34;managementsystem-构造方法&#34;&gt;ManagementSystem 构造方法&lt;/h3&gt;

&lt;p&gt;调试整个过程总是很麻烦的，我们只能专注某些部分，首先我们主要看一下 ManagementSystem 的构造过程，和使用细节。&lt;/p&gt;

&lt;p&gt;打断点进入构造方法,看这一句代码：&lt;code&gt;this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();&lt;/code&gt; 一步一步进入调用栈&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.transaction = (StandardJanusGraphTx) graph.buildTransaction().disableBatchLoading().start();
    return graph.newTransaction(immutable);
        tx.setBackendTransaction(openBackendTransaction(tx));
            return backend.beginTransaction(tx.getConfiguration(), retriever);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 Backend 的 beginTransaction 方法停下来，首先看看 &lt;code&gt;StoreTransaction tx = storeManagerLocking.beginTransaction(configuration)&lt;/code&gt; 的调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// 这个 ExpectedValueCheckingStoreManager 继承自 KCVSManagerProxy ，它内部有个 KeyColumnValueStoreManager manager 。显然是代理模式，当然也可以认为是装饰模式。
StoreTransaction tx = storeManagerLocking.beginTransaction(configuration);
    StoreTransaction inconsistentTx = manager.beginTransaction(configuration);
        return new CassandraTransaction(config);
    StoreTransaction strongConsistentTx = manager.beginTransaction(consistentTxCfg);
        return new CassandraTransaction(config);
    ExpectedValueCheckingTransaction wrappedTx = new ExpectedValueCheckingTransaction(inconsistentTx, strongConsistentTx, maxReadTime);
    return wrappedTx;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出 tx 的大概构造，里面有两个 CassandraTransaction 一个是强一致的，一个是非强一致的。&lt;/p&gt;

&lt;p&gt;然后是 &lt;code&gt;CacheTransaction cacheTx = new CacheTransaction(tx, storeManagerLocking, bufferSize, maxWriteTime, configuration.hasEnabledBatchLoading());&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// CacheTransaction 继承自 StoreTransaction 和 LoggableTransaction ，内部有一个 StoreTransaction 对象，显然也是代理模式或者装饰模式。
CacheTransaction cacheTx = new CacheTransaction(tx, storeManagerLocking, bufferSize, maxWriteTime, configuration.hasEnabledBatchLoading());
    就是一堆赋值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CacheTransaction 内部有一个 StoreTransaction 也就是 上面的 tx， 然后还有一个 StoreManager storeManagerLocking。&lt;/p&gt;

&lt;p&gt;然后是 &lt;code&gt;indexTx.put(entry.getKey(), new IndexTransaction(entry.getValue() indexKeyRetriever.get(entry.getKey()), configuration, maxWriteTime));&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;indexTx.put(entry.getKey(), new IndexTransaction(entry.getValue(), indexKeyRetriever.get(entry.getKey()), configuration, maxWriteTime));
    new KeyInformation.IndexRetriever() {...省略代码}
    new IndexTransaction()
        index.beginTransaction(config);
            return new DefaultTransaction(config);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;backend.beginTransaction(tx.getConfiguration(), retriever); 方法中 有很多 Transaction 对象，包括了 cacheTx indexTx 等。BackendTransaction 的构造方法则比较简单，就是直接赋值。&lt;/p&gt;

&lt;p&gt;构造方法讨论到这里，我们可以猜测，ManagementSystem 无论是进行简单 schema 增删改查还是操作索引，
背后都是通过这个 BackendTransaction 完成，而 BackendTransaction 内部又有 cacheTx 和 indexTx 等对象完成。
当然还有一个 transactionalConfig 也有一些任务。&lt;/p&gt;

&lt;h3 id=&#34;managementsystem-getvertexlabels&#34;&gt;ManagementSystem getVertexLabels&lt;/h3&gt;

&lt;p&gt;getVertexLabels 方法返回 Iterable&lt;VertexLabel&gt; ，这里可能是通过 guava 进行封装，所以可能调用栈比较深。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;getVertexLabels
    QueryUtil.getVertices(transaction, BaseKey.SchemaCategory, JanusGraphSchemaCategory.VERTEXLABEL)
        tx.query().has(key,Cmp.EQUAL,equalityCondition).vertices();
            1. 
            return new GraphCentricQueryBuilder(this, graph.getIndexSerializer());
            3. 
            return has(key.name(),predicate,condition);
                // 这一步实际上就加了一个 条件，就是 `~T$SchemaCategory = VERTEXLABEL`
                constraints.add(new PredicateCondition&amp;lt;String, JanusGraphElement&amp;gt;(key, predicate, condition));
            3. 
            GraphCentricQuery query = constructQuery(ElementCategory.VERTEX);
                 GraphCentricQuery query = constructQueryWithoutProfile(resultType);
                     省略一大堆复杂代码。
                     return new GraphCentricQuery(resultType, conditions, orders, query, limit);
            // 这里是基于guava实现的懒加载模式的 filter
            Iterables.filter(new QueryProcessor&amp;lt;GraphCentricQuery, JanusGraphElement, JointIndexQuery&amp;gt;(query, tx.elementProcessor), JanusGraphVertex.class);

iterator
    return new ResultSetIterator(getUnfoldedIterator(),(query.hasLimit()) ? query.getLimit() : Query.NO_LIMIT);   
        1. QueryProcessor (org.janusgraph.graphdb.query).getUnfoldedIterator:107, 
            Iterator&amp;lt;R&amp;gt; subiter = new LimitAdjustingIterator(subq);
        2. this.next = nextInternal();
            hasNext:68, LimitAdjustingIterator (org.janusgraph.graphdb.query)
                getNewIterator:209, QueryProcessor$LimitAdjustingIterator (org.janusgraph.graphdb.query)
                    execute:1150, StandardJanusGraphTx$elementProcessorImpl (org.janusgraph.graphdb.transaction)
                        new SubqueryIterator
                            indexCache.getIfPresent(subQuery); // 这里的 schema 应该都是在启动的时候 cache 到了内存中，所以直接得到了，如果是 数据，应该要查询
                        
                    
                  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里我们就已经知道了，其实这里是构造了一个 GraphCentricQuery 封装所有的查询条件逻辑，然后通过 QueryProcessor 进行处理这个 query，调用 next 的时候会进行查询。&lt;/p&gt;

&lt;p&gt;上面我们已经得到了 ResultSetIterator ，接下来我们需要遍历这个 iterator。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;iterator.hasNext
    1. next = current
    2. tryToComputeNext()
    ...
        1. hasNext:49, ResultSetIterator (org.janusgraph.graphdb.query)
            return next != null;
            
        2. ResultSetIterator (org.janusgraph.graphdb.query).next:65, 
            1. LimitAdjustingIterator (org.janusgraph.graphdb.query).hasNext:68, 
                SubqueryIterator (org.janusgraph.graphdb.util).hasNext:79, 
            2. LimitAdjustingIterator (org.janusgraph.graphdb.query).next:94, 
                SubqueryIterator (org.janusgraph.graphdb.util).next:90, 

iterator.next()  
   return result.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的代码比较杂乱，首先是 AbstractIterator 和 Iterators 类，然后是 ResultSetIterator LimitAdjustingIterator SubqueryIterator ，然后还有一个 Stream 类。&lt;/p&gt;

&lt;p&gt;AbstractIterator 和 Iterators  是 guava 提供的工具类，AbstractIterator 通过封装一个 Iterator，达到缓存和懒加载的效果。
例如 JDBC 的 ResultSet 如果做成一个 Iterator ，每次调用 next 的时候都会移动一次游标，这样就不能多次判断 hasNext。所以可以用 guava 进行封装。&lt;/p&gt;

&lt;p&gt;ResultSetIterator 和 guava 达到的效果类似，通过内部装饰一个 ResultSetIterator 。&lt;/p&gt;

&lt;p&gt;LimitAdjustingIterator 通过一个 getNewIterator 得到一个 懒加载 Iterator，其实也是和 guava 类似，只不过你可以认为它只能查看 limit 个元素，当遍历完这 limit 个元素，会重新从 0 开始 next limit次，然后再开始。
说的简单一点，如果一个数组有一千个元素，你的迭代器 limit 是 500，那么你只能得到 500 个元素，想要得到500 - 1000 的元素，要重新查询。类似 mysql 的分页&lt;/p&gt;

&lt;p&gt;SubqueryIterator 是代表依次查询的结果。先从 indexCache 查，没有就调用查询，查询结果是一个 List ，得到对应的 iterator 后放在 elementIterator 中。&lt;/p&gt;

&lt;p&gt;到这里我们就大概明白了整个查询过程，&lt;/p&gt;

&lt;h3 id=&#34;containsvertexlabel&#34;&gt;containsVertexLabel&lt;/h3&gt;

&lt;p&gt;containsVertexLabel 方法判断是否存在，直观的方法是直接调用上面的 getVertexLabels 然后判断一下，但是实际上不是这样。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mgmt.containsVertexLabel(vType.toString())
    transaction.containsVertexLabel(name);
        return getSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name))!=null;
        1. JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name) // 这一步就是在 name 前面加上标识，例如 vl rt
        2. JanusGraphSchemaVertex getSchemaVertex(String schemaName)
            graph.getSchemaCache().getSchemaId(schemaName)
            1. getSchemaCache 
            2. StandardSchemaCache.getSchemaId
                id = retriever.retrieveSchemaByName(schemaName); // 这个 retriever 是 StandardJanusGraph 中的变量 typeCacheRetrieval ，
                    typeCacheRetrieval.retrieveSchemaByName
                        StandardJanusGraph.this.newTransaction
                            QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName)
                            return v!=null?v.longId():null;
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;containsVertexLabel 会启动一个 transation 通过 name 查询这个 schema 的 typeName 对应的 vertexId。和 getVertexLabels 不太一样。&lt;/p&gt;

&lt;h3 id=&#34;makevertexlabel&#34;&gt;makeVertexLabel&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt.makeVertexLabel(vType.toString()).make();
    1. makeVertexLabel
        transaction.makeVertexLabel(name);
            StandardVertexLabelMaker maker = new StandardVertexLabelMaker(this);
            maker.name(name);
    2. make
        TypeDefinitionMap def = new TypeDefinitionMap();
        tx.makeSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL,name,def);
            1. schemaVertex = new VertexLabelVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.GenericSchemaType,temporaryIds.nextID()), ElementLifeCycle.New);
            2. graph.assignID(schemaVertex, BaseVertexLabel.DEFAULT_VERTEXLABEL);
                ....
                element.setId(elementId);
            3. addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));
                1. StandardVertexProperty prop = new StandardVertexProperty(IDManager.getTemporaryRelationID(temporaryIds.nextID()), key, (InternalVertex) vertex, normalizedValue, ElementLifeCycle.New);
                2. connectRelation(prop);
                    addedRelations.add(r); 
            4. vertexCache.add(schemaVertex, schemaVertex.longId());
            
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;makeVertexLabel 最关键的一步就是 addedRelations.add&amp;reg;, 添加关系，这样就能在 commit 的时候写到数据库了。&lt;/p&gt;

&lt;h3 id=&#34;commit&#34;&gt;commit()&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;commit
    transactionalConfig.commit();
    transaction.commit();
         1. graph.commit(addedRelations.getAll(), deletedRelations.values(), this); // 这里的两个集合分别是改变的 schema 
             
             
             1. final BackendTransaction schemaMutator = openBackendTransaction(tx); // 打开一个 transaction
             2. commitSummary = prepareCommit(addedRelations,deletedRelations, SCHEMA_FILTER, schemaMutator, tx, acquireLocks);
             3. schemaMutator.commit();
             
             4. commitSummary = prepareCommit(addedRelations,deletedRelations, hasTxIsolation? NO_FILTER : NO_SCHEMA_FILTER, mutator, tx, acquireLocks);
             5. mutator.commit();
                 1. storeTx.commit();
                     1. flushInternal();
                     2. tx.commit();
                 2. itx.commit();
                     1. flushInternal();
                     2. indexTx.commit();
          2. releaseTransaction();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实我这里的注释和官方的不太一样，官方将 graph.commit 分为三部分：&lt;/p&gt;

&lt;p&gt;//1. Finalize transaction
//2. Assign JanusGraphVertex IDs
//3. Commit
//3.1 Log transaction (write-ahead log) if enabled
//3.2 Commit schema elements and their associated relations in a separate transaction if backend does not support transactional isolation
//[FAILURE] Exceptions during preparation here cause the entire transaction to fail on transactional systems
//or just the non-system part on others. Nothing has been persisted unless batch-loading&lt;/p&gt;

&lt;p&gt;经过我的分析，其实这里分两次 prepareCommit + commit ,是根据底层是否支持事务隔离，如果不支持，先 commit 和 schema 相关的变化，否则 schema 和 data 两边一起提交。&lt;/p&gt;

&lt;p&gt;当然这个 wal-log 和 prepareCommit 就大有文章。后续在分析。&lt;/p&gt;

&lt;h3 id=&#34;createcompositeindex-1&#34;&gt;createCompositeIndex&lt;/h3&gt;

&lt;p&gt;建索引，索引类型是 createCompositeIndex&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;buildCompositeIndex:650, ManagementSystem$IndexBuilder (org.janusgraph.graphdb.database.management)
    1.checkIndexName:489, ManagementSystem (org.janusgraph.graphdb.database.management)
        getGraphIndex:424, ManagementSystem (org.janusgraph.graphdb.database.management)
            getSchemaVertex:878, StandardJanusGraphTx (org.janusgraph.graphdb.transaction) 
                 // 这里 getSchemaVertex 的内容之前已经讨论过。
    updatedTypes.add((PropertyKeyVertex) key);
    2. transaction.makeSchemaVertex(JanusGraphSchemaCategory.GRAPHINDEX, indexName, def);
        // 这个之前已经说过，我们在简单过一遍
        1. graph.assignID(schemaVertex, BaseVertexLabel.DEFAULT_VERTEXLABEL);
        2. addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));
    3. addSchemaEdge(indexVertex, keys[i], TypeDefinitionCategory.INDEX_FIELD, paras);
    4. updateIndex(index, SchemaAction.REGISTER_INDEX);
        
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;updatedTypes.add((PropertyKeyVertex) key);
schema 分析主要就是这些，我们还有一些地方没细看，接下来我们把几个复杂的过程分析一下。主要包括查询数据库和 update 索引&lt;/p&gt;

&lt;h1 id=&#34;局部调试&#34;&gt;局部调试&lt;/h1&gt;

&lt;p&gt;上面的调试过程让我们大概明白了每一步的过程，大概都在做什么，接下来我们要深入一些局部，看一下每一步具体都在做什么。&lt;/p&gt;

&lt;h2 id=&#34;1-makepropertykey&#34;&gt;1. makePropertyKey&lt;/h2&gt;

&lt;p&gt;我们从简单到复杂，首先看 makePropertyKey，看之前我们大概了解几个相关类。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;JanusGraphSchemaCategory
这个是 JanusGraph 的所有 schema 的种类，有 EDGELABEL, PROPERTYKEY, VERTEXLABEL, GRAPHINDEX, TYPE_MODIFIER 五种。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;PropertyKeyVertex
我们所有的 schema 都是以顶点的形式存在数据库中，所以我们 makePropertyKey 也会创建一个顶点，这个顶点的类型是 PropertyKeyVertex 。
他继承自 RelationTypeVertex，PropertyKey， JanusGraphSchemaVertex，InternalRelationType，RelationType，InternalVertex 等类。
他有 getBaseType getRelationIndexes getKeyIndexes 等方法，&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;BaseKey
BaseKey 和 PropertyKeyVertex 类似，PropertyKeyVertex 是我们定义的 schema，而 BaseKey 则是最基本的key，是 schema 的 ProperyKey, 他们是直接放在内存中的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;JanusGraphVertexProperty&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;JanusGraphVertexProperty 代表一个顶点的 Property，和 JanusGraphEdge 一样继承自 JanusGraphRelation。
当我们给一个 JanusGraph 添加 Property，实际上会创建一条关系，同时返回一个 JanusGraphVertexProperty。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;InternalRelation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;InternalRelation 代表一个关系，实际上就是一条边，在 janus 中，分为 VertexProperty 和 Edge 两种，无论是 Edge 还是 VertexProperty ，都是连接两个顶点。
其中 VertexProperty 是连接一个用户创建的顶点和一个 PropertyKey 顶点，而 Edge 是连接两个 PropertyKey 顶点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ElementCategory&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;元素种类，有 VERTEX, EDGE, PROPERTY 三种，可以用来判断 index 的种类。&lt;/p&gt;

&lt;h3 id=&#34;进入断点&#34;&gt;进入断点&lt;/h3&gt;

&lt;p&gt;我们进入断点到： makeSchemaVertex:830, StandardJanusGraphTx (org.janusgraph.graphdb.transaction)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;schemaVertex = new PropertyKeyVertex(this, IDManager.getTemporaryVertexID(IDManager.VertexIDType.UserPropertyKey, temporaryIds.nextID()), ElementLifeCycle.New);&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;新建一个代表 PropertyKey 的 Vertex。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;addProperty(schemaVertex, BaseKey.SchemaName, schemaCategory.getSchemaName(name));&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
1. vertex = ((InternalVertex) vertex).it();

// 新建一个 VertexProperty 的对象
2. StandardVertexProperty prop = new StandardVertexProperty(IDManager.getTemporaryRelationID(temporaryIds.nextID()), key, (InternalVertex) vertex, normalizedValue, ElementLifeCycle.New);

3.connectRelation(InternalRelation r) 
    
    success = r.getVertex(i).addRelation(r);
        r.getVertex(i) 返回的是前面创建的 PropertyKeyVertex
        addRelation 是在这个 Vertex 内部调用 addedRelations.add(r)
    
    addedRelations.add(r); // 这个 addedRelations 是 StandardJanusGraph 的全局变量

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看出，addProperty 实际上就是给 顶点和另一个 PropertyKey 建立一条边。&lt;/p&gt;

&lt;p&gt;到这里似乎就完成了，整个过程实际上就是修改了 addedRelations 。&lt;/p&gt;

&lt;h2 id=&#34;makevertexlabel-makeedgelabel&#34;&gt;makeVertexLabel makeEdgeLabel&lt;/h2&gt;

&lt;p&gt;这两个与 PropertyKey 类似，首先 new JanusGraphSchemaVertex ，分别是 PropertyKeyVertex EdgeLabelVertex VertexLabelVertex 。 然后调用 addProperty 。
addProperty 会 new 一个 StandardVertexProperty ，然后调用 connectRelation(prop) 。将 prop 中的 Relation 都建立连接，添加到 addedRelations。&lt;/p&gt;

&lt;h2 id=&#34;commit-preparecommit&#34;&gt;commit prepareCommit&lt;/h2&gt;

&lt;p&gt;//1) Collect deleted edges and their index updates and acquire edge locks
略
//2) Collect added edges and their index updates and acquire edge locks&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
// 前面所有的关系 关系类型是 InternalRelation ，实现有 StandardVertexProperty 和 StandardEdge 两种
for (InternalRelation add : Iterables.filter(addedRelations,filter)) {
    
    // 每个 Relation 联系多个顶点，如果是 StandardVertexProperty 顶点就是 JanusGraphVertex，如果是 StandardEdge，顶点就是连接的两个 JanusGraphVertex
    for (int pos = 0; pos &amp;lt; add.getLen(); pos++) {
    	// 得到对应的顶点，可能有一个或者两个
    	InternalVertex vertex = add.getVertex(pos);
    	if (pos == 0 || !add.isLoop()) {
    	    
    	    // mutatedProperties: key 是关系连接的 vertex，value 是关系
    	    if (add.isProperty()) mutatedProperties.put(vertex,add);
    	    // mutations: key 是 vertex id, 关系是 add
    	    mutations.put(vertex.longId(), add);
    	}
    	if (!vertex.isNew() &amp;amp;&amp;amp; acquireLock(add,pos,acquireLocks)) {
    	    Entry entry = edgeSerializer.writeRelation(add, pos, tx);
    	    mutator.acquireEdgeLock(idManager.getKey(vertex.longId()), entry.getColumn());
        }
    }
    // indexUpdates : IndexSerializer.IndexUpdate
    indexUpdates.addAll(indexSerializer.getIndexUpdates(add));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//3) Collect all index update for vertices&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (InternalVertex v : mutatedProperties.keySet()) {
    indexUpdates.addAll(indexSerializer.getIndexUpdates(v,mutatedProperties.get(v)));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//4) Acquire index locks (deletions first)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (IndexSerializer.IndexUpdate update : indexUpdates) {
    if (!update.isCompositeIndex() || !update.isDeletion()) continue;
    CompositeIndexType iIndex = (CompositeIndexType) update.getIndex();
    if (acquireLock(iIndex,acquireLocks)) {
        mutator.acquireIndexLock((StaticBuffer)update.getKey(), (Entry)update.getEntry());
    }
}
for (IndexSerializer.IndexUpdate update : indexUpdates) {
    if (!update.isCompositeIndex() || !update.isAddition()) continue;
    CompositeIndexType iIndex = (CompositeIndexType) update.getIndex();
    if (acquireLock(iIndex,acquireLocks)) {
        mutator.acquireIndexLock((StaticBuffer)update.getKey(), ((Entry)update.getEntry()).getColumn());
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//5) Add relation mutations&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 遍历 mutations，
for (Long vertexid : mutations.keySet()) {
    Preconditions.checkArgument(vertexid &amp;gt; 0, &amp;quot;Vertex has no id: %s&amp;quot;, vertexid);
    List&amp;lt;InternalRelation&amp;gt; edges = mutations.get(vertexid);
    List&amp;lt;Entry&amp;gt; additions = new ArrayList&amp;lt;Entry&amp;gt;(edges.size());
    List&amp;lt;Entry&amp;gt; deletions = new ArrayList&amp;lt;Entry&amp;gt;(Math.max(10, edges.size() / 10));
    
    // 这个顶点所有的 edges
    for (InternalRelation edge : edges) {
        InternalRelationType baseType = (InternalRelationType) edge.getType();
        assert baseType.getBaseType()==null;
        // 这个 InternalRelationType 的所有 type ，这里有点不太懂
        for (InternalRelationType type : baseType.getRelationIndexes()) {
            if (type.getStatus()== SchemaStatus.DISABLED) continue;
            
            // Arity 应该是数据的量，代表的意义应该是 LIST SINGLE 等
            for (int pos = 0; pos &amp;lt; edge.getArity(); pos++) {
                if (!type.isUnidirected(Direction.BOTH) &amp;amp;&amp;amp; !type.isUnidirected(EdgeDirection.fromPosition(pos)))
                    continue; //Directionality is not covered
                if (edge.getVertex(pos).longId()==vertexid) {
                    // 序列化数据
                    StaticArrayEntry entry = edgeSerializer.writeRelation(edge, type, pos, tx);
                    if (edge.isRemoved()) {
                        deletions.add(entry);
                    } else {
                        Preconditions.checkArgument(edge.isNew());
                        int ttl = getTTL(edge);
                        if (ttl &amp;gt; 0) {
                            entry.setMetaData(EntryMetaData.TTL, ttl);
                        }
                        // 添加到 additions
                        additions.add(entry);
                    }
                }
            }
        }
    }

    StaticBuffer vertexKey = idManager.getKey(vertexid);
    // 写出数据
    mutator.mutateEdges(vertexKey, additions, deletions);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//6) Add index updates&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (IndexSerializer.IndexUpdate indexUpdate : indexUpdates) {
    assert indexUpdate.isAddition() || indexUpdate.isDeletion();
    if (indexUpdate.isCompositeIndex()) {
        IndexSerializer.IndexUpdate&amp;lt;StaticBuffer,Entry&amp;gt; update = indexUpdate;
        if (update.isAddition())
            // 直接调用 update 的方法
            mutator.mutateIndex(update.getKey(), Lists.newArrayList(update.getEntry()), KCVSCache.NO_DELETIONS);
        else
            mutator.mutateIndex(update.getKey(), KeyColumnValueStore.NO_ADDITIONS, Lists.newArrayList(update.getEntry()));
    } else {
        IndexSerializer.IndexUpdate&amp;lt;String,IndexEntry&amp;gt; update = indexUpdate;
        has2iMods = true;
        IndexTransaction itx = mutator.getIndexTransaction(update.getIndex().getBackingIndexName());
        String indexStore = ((MixedIndexType)update.getIndex()).getStoreName();
        if (update.isAddition())
            itx.add(indexStore, update.getKey(), update.getEntry(), update.getElement().isNew());
        else
            itx.delete(indexStore,update.getKey(),update.getEntry().field,update.getEntry().value,update.getElement().isRemoved());
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里我们可能比较迷惑的就是 IndexUpdate 是怎么获得的。&lt;/p&gt;

&lt;p&gt;获得 IndexUpdate 的思路大概是这样：以 CompositeIndex 为例，假如一个顶点，USER，有 name 和 sex 两个 PropertyKey，并且基于 name 和 sex 做了一个 CompositeIndex。
现在有一个顶点，假设 id 为 007，我设置了他的 name 为 &amp;ldquo;deng&amp;rdquo;，然后我们需要获得这个用户的 sex ，假设为 &amp;ldquo;male&amp;rdquo;，这时候我们需要在 index 插入一条记录 (deng,male) =&amp;gt; 007。&lt;/p&gt;

&lt;p&gt;所以我们可以看 getIndexUpdates 的源代码，首先是  IndexField[] fields = index.getFieldKeys() 得到这个 index 所有的 filedKey， 然后 new RecordEntry[fields.length]，得到一个
和 fields 长度一样的 RecordEntry 数组，然后从 pos=0 开始给 IndexField 数组赋值，直到 pos &amp;gt;= fields.length。这样就得到了所以和这个属性更新相关的索引更新。
已上面的例子为例，那么得到的 RecordEntry[] 就是 [deng,male]。&lt;/p&gt;

&lt;p&gt;然后我们得到了 indexUpdate additions 就是分别将他们写到数据库了。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>janus源码分析5-复杂操作分析</title>
      <link>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%906-%E5%A4%8D%E6%9D%82%E6%BA%90%E7%A0%81/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/janusgraph%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%906-%E5%A4%8D%E6%9D%82%E6%BA%90%E7%A0%81/</guid>
      
        <description>

&lt;h1 id=&#34;源码分析&#34;&gt;源码分析&lt;/h1&gt;

&lt;h2 id=&#34;查询操作&#34;&gt;查询操作&lt;/h2&gt;

&lt;p&gt;之前已经遇到过很多查询操作&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;mgmt.containsVertexLabel(vType.toString())
    transaction.containsVertexLabel(name);
        return getSchemaVertex(JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name))!=null;
        1. JanusGraphSchemaCategory.VERTEXLABEL.getSchemaName(name) // 这一步就是在 name 前面加上标识，例如 vl rt
        2. JanusGraphSchemaVertex getSchemaVertex(String schemaName)
            graph.getSchemaCache().getSchemaId(schemaName)
            1. getSchemaCache 
            2. StandardSchemaCache.getSchemaId
                id = retriever.retrieveSchemaByName(schemaName); // 这个 retriever 是 StandardJanusGraph 中的变量 typeCacheRetrieval ，
                    typeCacheRetrieval.retrieveSchemaByName
                        StandardJanusGraph.this.newTransaction
                            QueryUtil.getVertices(consistentTx, BaseKey.SchemaName, typeName)
                            return v!=null?v.longId():null;
        
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;iterator
    return new ResultSetIterator(getUnfoldedIterator(),(query.hasLimit()) ? query.getLimit() : Query.NO_LIMIT);   
        1. QueryProcessor (org.janusgraph.graphdb.query).getUnfoldedIterator:107, 
            Iterator&amp;lt;R&amp;gt; subiter = new LimitAdjustingIterator(subq);
        2. this.next = nextInternal();
            hasNext:68, LimitAdjustingIterator (org.janusgraph.graphdb.query)
                getNewIterator:209, QueryProcessor$LimitAdjustingIterator (org.janusgraph.graphdb.query)
                    execute:1150, StandardJanusGraphTx$elementProcessorImpl (org.janusgraph.graphdb.transaction)
                        new SubqueryIterator
                            indexCache.getIfPresent(subQuery); // 这里的 schema 应该都是在启动的时候 cache 到了内存中，所以直接得到了，如果是 数据，应该要查询
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实查询操作并不复杂，这是有很多层的嵌套，导致我们看起来很麻烦而已，前面我们已经大概介绍了： 首先是 AbstractIterator 和 Iterators 类，然后是 ResultSetIterator LimitAdjustingIterator SubqueryIterator ，然后还有一个 Stream 类。&lt;/p&gt;

&lt;p&gt;我们一层一层进行查看：&lt;/p&gt;

&lt;h3 id=&#34;query&#34;&gt;Query&lt;/h3&gt;

&lt;p&gt;继承体系：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Query (org.janusgraph.graphdb.query)
	ElementQuery (org.janusgraph.graphdb.query)
	    GraphCentricQuery (org.janusgraph.graphdb.query.graph)
	    VertexCentricQuery (org.janusgraph.graphdb.query.vertex)
	BaseQuery (org.janusgraph.graphdb.query)
	    MultiKeySliceQuery (org.janusgraph.graphdb.query.graph)
	    JointIndexQuery (org.janusgraph.graphdb.query.graph)
	    RawQuery (org.janusgraph.diskstorage.indexing)
	    BaseVertexCentricQuery (org.janusgraph.graphdb.query.vertex)
	        VertexCentricQuery (org.janusgraph.graphdb.query.vertex)
	    SliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeyRangeQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeySliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	    KVQuery (org.janusgraph.diskstorage.keycolumnvalue.keyvalue)
	    IndexQuery (org.janusgraph.diskstorage.indexing)
	    IndexQueryBuilder (org.janusgraph.graphdb.query.graph)
	    GraphCentricQuery (org.janusgraph.graphdb.query.graph)
	BackendQuery (org.janusgraph.graphdb.query)
	    MultiKeySliceQuery (org.janusgraph.graphdb.query.graph)
	    JointIndexQuery (org.janusgraph.graphdb.query.graph)
	    SliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeyRangeQuery (org.janusgraph.diskstorage.keycolumnvalue)
	        KeySliceQuery (org.janusgraph.diskstorage.keycolumnvalue)
	    IndexQuery (org.janusgraph.diskstorage.indexing)
	    Subquery in JointIndexQuery (org.janusgraph.graphdb.query.graph)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们主要能发现 BaseQuery 和 BackendQuery 两大子类，&lt;/p&gt;

&lt;p&gt;BaseQuery 比较简单，里面就一个 limit 属性，应该是指返回的条数。而 BackendQuery 接口更简单，只有一个方法 updateLimit(int newLimit)，返回一个新的 BackendQuery。至于有什么用后续才能知道。&lt;/p&gt;

&lt;p&gt;基于 BaseQuery 和 BackendQuery ，有很多子类。&lt;/p&gt;

&lt;p&gt;SliceQuery 有两个 StaticBuffer 类型的属性： sliceStart 和 sliceEnd 。这应该是 bigtable 模型的 nosql 都会提供的一种功能，给一个 slice 进行查询。&lt;/p&gt;

&lt;p&gt;KeySliceQuery 继承自 SliceQuery ，扩展 SliceQuery ，增加了 StaticBuffer 类型的 key，能够查询某个 key 的 slice。&lt;/p&gt;

&lt;p&gt;KeyRangeQuery 继承自 SliceQuery ，扩展 SliceQuery ，增加了两个 StaticBuffer 类型的 keyStart keyEnd 。为何这样就要查询 bigtable 相关资料了。&lt;/p&gt;

&lt;p&gt;MultiKeySliceQuery 继承自 BaseQuery 和 BackendQuery ，内部有一个 List&lt;KeySliceQuery&gt; queries。很明显这是多个 key 一起查。&lt;/p&gt;

&lt;p&gt;IndexQuery 官方注释 在 IndexProvider 中执行的外部 query，query 由两部分组成：一个是查询应该执行的 store 的标识符，另一个是查询的条件。
IndexProvider 的代码我们介绍过，是指外部索引，例如 ElasticSearchIndex ，主要有 register mutate restore query 等方法，很明显是提供一些查询。&lt;/p&gt;

&lt;p&gt;JointIndexQuery 的静态内部类 Subquery 继承自 BackendQuery ，内部有两个主要属性：  IndexType index; BackendQuery query;
Index 可以是 MixedIndexType 或者 CompositeIndexType，对应的 query 分别是 IndexQuery 和 MultiKeySliceQuery
JointIndexQuery 则有 List&lt;Subquery&gt; queries 属性代表很多个 Subquery。
我们可以看出其实 Subquery 代表的是可以在一种索引平台上执行的查询。而 JointIndexQuery 则是很多个这样的查询，可以在各自的平台上进行查询。&lt;/p&gt;

&lt;p&gt;GraphCentricQuery 包含了一个 Condition&lt;JanusGraphElement&gt; condition 作为条件，一个 BackendQueryHolder&lt;JointIndexQuery&gt; indexQuery 保存 Query 信息。
BaseVertexCentricQuery 包含了 Condition&lt;JanusGraphRelation&gt; condition 作为添加 ，List&lt;BackendQueryHolder&lt;SliceQuery&gt;&amp;gt; queries 保存 Query 信息
VertexCentricQuery 继承自 BaseVertexCentricQuery ，添加一个 InternalVertex vertex ，至于干啥的还不知道。
他们都是 ElementQuery。&lt;/p&gt;

&lt;p&gt;看到这里我们大概能看出 ：
GraphCentricQuery 是基于 JanusGraphElement 的，查询需要 JointIndexQuery ，
JointIndexQuery 内部则是 Subquery，Subquery 主要分为 MixedQuery 和 CompositeQuery，对应的查询分别为 IndexQuery 和 MultiKeySliceQuery，对应的索引分别为 MixedIndexType 和 CompositeIndexType
VertexCentricQuery 是基于 JanusGraphRelation 的，查询需要 SliceQuery ，SliceQuery 就是查询 key + cf 对应的所有的 keyvalue 。&lt;/p&gt;

&lt;p&gt;RawQuery 继承自 BaseQuery ，没什么特殊参数，我想应该是值一些粗糙的直接查询。
剩下的 IndexQueryBuilder 和 KVQuery 先不说了。&lt;/p&gt;

&lt;p&gt;我们可以看出这些 Query 只是一些描述性的东西，并没有任何执行调用的方法。通过类的关系我们也大概能总结一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一切都是为了查出 janus 中的元素，所以 是围绕 ElementQuery 展开，ElementQuery 有两个子类，GraphCentricQuery 和 VertexCentricQuery。
GraphCentricQuery 代表以 graph 为中心的查询，例如查询 name=aaa 的所有顶点，VertexCentricQuery 代表以 vertex-centric 的查询，例如查和某个人关系为同事的所有人。
为了完成 GraphCentricQuery 包括两类：IndexQuery 和 MultiKeySliceQuery ，IndexQuery 代表使用外部索引的查询，MultiKeySliceQuery 代表使用 bigtable 自带索引的查询。
这两种合在一起就是 Subquery ，而 JointIndexQuery 内部有多个 Subquery，GraphCentricQuery 中有一个 JointIndexQuery 对象。
为了完成 VertexCentricQuery，也就是加快基于 PropertyKey 和 EdgeLabel 的查询，需要使用 SliceQuery 进行配合。SliceQuery 有很多实现，除了本身还有 KeySliceQuery 和 KeyRangeQuery。&lt;/li&gt;
&lt;li&gt;而 RawQuery 看名字猜测是直接查询。&lt;/li&gt;
&lt;li&gt;IndexQueryBuilder 就是一个 Builder，内部有一个 IndexSerializer ，它的 execute 方法，实际上就是调用 IndexSerializer 的 executeQuery。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;indexserializer&#34;&gt;IndexSerializer&lt;/h3&gt;

&lt;p&gt;从 JointIndexQuery 我们能看出，SubQuery 是在 IndexSerializer 中执行的，我们大概了解一下 IndexSerializer。&lt;/p&gt;

&lt;p&gt;内部有一个 Map&lt;String, ? extends IndexInformation&gt; mixedIndexes，IndexInformation 有很多子类，例如 ElasticSearchIndex，
还有很多内部类 IndexInfoRetriever IndexRecords IndexUpdate RecordEntry。这应该是一直设计模式吧。
而它的 executeQuery 方法，最终会调用 backendTx.rawQuery(index.getBackingIndexName(), rawQuery) 方法。这里有点奇怪的是为什么只有 MixedIndexType&lt;/p&gt;

&lt;p&gt;另外 query 方法 有两种情况，如果是 isCompositeIndex ，会得到 MultiKeySliceQuery 并调用 sq.execute(tx)，如果是 MixedQuery ，调用 tx.indexQuery。
然后都是调用 BackendTransaction 的 indexQuery，CompositeIndex 对应的是 indexQuery(final KeySliceQuery query)，MixedIndex 是 indexQuery(final String index, final IndexQuery query)。
这两个方法将会分别跳转到 KeyColumnValueStore.getSlice(KeySliceQuery query, StoreTransaction txh) 和 IndexProvider.query(IndexQuery query, KeyInformation.IndexRetriever information, BaseTransaction tx)&lt;/p&gt;

&lt;h3 id=&#34;stream&#34;&gt;Stream&lt;/h3&gt;

&lt;p&gt;Stream 是 java 自带的类，目的是实现 lambda 编程，如 map filter reduce 等。java.util.list 调用 stream() 方法就返回一个 Stream 对象。Stream 的部分方法：
peek(Consumer) 方法主要用来调试。类似 map ，但是它返回原对象。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Stream.of(&amp;quot;one&amp;quot;, &amp;quot;two&amp;quot;, &amp;quot;three&amp;quot;, &amp;quot;four&amp;quot;)
    .filter(e -&amp;gt; e.length() &amp;gt; 3)
    .peek(e -&amp;gt; System.out.println(&amp;quot;Filtered value: &amp;quot; + e)) // 打印
    .map(String::toUpperCase)
    .peek(e -&amp;gt; System.out.println(&amp;quot;Mapped value: &amp;quot; + e))
    .collect(Collectors.toList());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;limit(long ) 类似 sql 的 limit。
iterator() 返回一个迭代器。&lt;/p&gt;

&lt;h3 id=&#34;subqueryiterator&#34;&gt;SubqueryIterator&lt;/h3&gt;

&lt;p&gt;根据名字大概可以判断 SubqueryIterator 是一个查询结果迭代器，这里的 Subquery 就是上面我们介绍的，它的成员变量：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final JointIndexQuery.Subquery subQuery;
private final Cache&amp;lt;JointIndexQuery.Subquery, List&amp;lt;Object&amp;gt;&amp;gt; indexCache;
private Iterator&amp;lt;? extends JanusGraphElement&amp;gt; elementIterator;
private List&amp;lt;Object&amp;gt; currentIds;
private QueryProfiler profiler;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SubqueryIterator 的构造方法如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 传入了 subQuery 和 indexSerializer
public SubqueryIterator(JointIndexQuery.Subquery subQuery, IndexSerializer indexSerializer, BackendTransaction tx,
        Cache&amp;lt;JointIndexQuery.Subquery, List&amp;lt;Object&amp;gt;&amp;gt; indexCache, int limit,
        Function&amp;lt;Object, ? extends JanusGraphElement&amp;gt; function, List&amp;lt;Object&amp;gt; otherResults) {
    this.subQuery = subQuery;
    this.indexCache = indexCache;
    // 先从缓存里面取
    final List&amp;lt;Object&amp;gt; cacheResponse = indexCache.getIfPresent(subQuery);
    final Stream&amp;lt;?&amp;gt; stream;
    if (cacheResponse != null) {
        stream = cacheResponse.stream();
    } else {
        try {
            currentIds = new ArrayList&amp;lt;&amp;gt;();
            profiler = QueryProfiler.startProfile(subQuery.getProfiler(), subQuery);
            isTimerRunning = true;
            // 缓存没有就查
            stream = indexSerializer.query(subQuery, tx).peek(r -&amp;gt; currentIds.add(r));
        } catch (final Exception e) {
            throw new JanusGraphException(&amp;quot;Could not call index&amp;quot;, e.getCause());
        }
    }
    // 生成 elementIterator
    elementIterator = stream.limit(limit).filter(e -&amp;gt; otherResults == null || otherResults.contains(e)).map(function).map(r -&amp;gt; (JanusGraphElement) r).iterator();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;standardjanusgraphtx&#34;&gt;StandardJanusGraphTx&lt;/h3&gt;

&lt;p&gt;之前我们已经见到介绍过 StandardJanusGraphTx ，实际上这个代表的就是一个事务，内部有很多操作图的方法，我们这次主要是看看他的 elementProcessorImpl 和 edgeProcessorImpl。
他的定义：QueryExecutor&lt;GraphCentricQuery, JanusGraphElement, JointIndexQuery&gt; elementProcessorImpl ，
QueryExecutor&lt;VertexCentricQuery, JanusGraphRelation, SliceQuery&gt; edgeProcessorImpl
听名字就知道大概是执行查询的？这是一个匿名内部类，继承自 QueryExecutor，主要方法是 execute。&lt;/p&gt;

&lt;h4 id=&#34;elementprocessorimpl&#34;&gt;elementProcessorImpl&lt;/h4&gt;

&lt;p&gt;我们只看 execute 方法，如果 indexQuery.isEmpty() 会告诉你 &amp;ldquo;Query requires iterating over all vertices [{}]. For better performance, use indexes&amp;rdquo;。说明我们上面说 RawQuery 是直接查询不利用索引是错误判断。
最后返回了一个
new SubqueryIterator(indexQuery.getQuery(0), indexSerializer, txHandle, indexCache, indexQuery.getLimit(),
getConversionFunction(query.getResultType()),retrievals.isEmpty() ? null: QueryUtil.processIntersectingRetrievals(retrievals, indexQuery.getLimit()));&lt;/p&gt;

&lt;p&gt;这里 SubQueryIterator 就是上面讲的。&lt;/p&gt;

&lt;h4 id=&#34;edgeprocessorimpl&#34;&gt;edgeProcessorImpl&lt;/h4&gt;

&lt;p&gt;他的 execute 方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
final InternalVertex v = query.getVertex();
final EntryList iterable = v.loadRelations(sq, query1 -&amp;gt; QueryProfiler.profile(profiler, query1, q -&amp;gt; graph.edgeQuery(v.longId(), q, txHandle)));
return RelationConstructor.readRelation(v, iterable, StandardJanusGraphTx.this).iterator();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终会调用 BackendTransation 的  edgeStoreQuery(final KeySliceQuery query)。&lt;/p&gt;

&lt;h3 id=&#34;limitadjustingiterator&#34;&gt;LimitAdjustingIterator&lt;/h3&gt;

&lt;p&gt;QueryProcessor$LimitAdjustingIterator&lt;/p&gt;

&lt;p&gt;QueryProcessor 主要有两个属性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final Q query;
private final QueryExecutor&amp;lt;Q, R, B&amp;gt; executor;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的 query 就是上面讲的 query ，一般是 GraphCentricQuery 或者 VertexCentricQuery，executor 就是我们上面讲的 edgeProcessorImpl 和 elementProcessorImpl。
它的 iterator 方法返回一个 ResultSetIterator。
LimitAdjustingIterator 初始化的时候会调用 getNewIterator ，这时候执行 executor.execute(query, backendQuery, executionInfo, profiler)。&lt;/p&gt;

&lt;p&gt;和它类似的还有 PreSortingIterator ，加了一个排序 。&lt;/p&gt;

&lt;h3 id=&#34;resultsetiterator&#34;&gt;ResultSetIterator&lt;/h3&gt;

&lt;p&gt;ResultSetIterator 只是类似 guava 的一个封装，通过 nextInternal 方法实现 iterator 提前加载。&lt;/p&gt;

&lt;h3 id=&#34;vertexcentricquerybuilder-和-graphcentricquerybuilder&#34;&gt;VertexCentricQueryBuilder 和 GraphCentricQueryBuilder&lt;/h3&gt;

&lt;p&gt;GraphCentricQueryBuilder 是用来构造一个 Query 的。它的很多方法都和 gremin 对接，最重要的方法还是 constructQuery ，用来构造上面我们讲解的 Query。&lt;/p&gt;

&lt;p&gt;BasicVertexCentricQueryBuilder 是 VertexCentricQueryBuilder 的父类，StandardJanusGraphTx 的 query(JanusGraphVertex vertex) 会产生一个 VertexCentricQueryBuilder。&lt;/p&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;到这里我们基本搞清楚了整个查询过程。
首先我们的代码的查询会生成 GraphCentricQueryBuilder 或者 BasicVertexCentricQueryBuilder，
然后 我们调用 builder 的查询时会生成 GraphCentricQuery 或者 VertexCentricQuery，并 new QueryProcessor&amp;lt;&amp;gt;(query, tx.elementProcessor)。&lt;/p&gt;

&lt;p&gt;QueryProcessor 的 iterator 方法生成一个 ResultSetIterator 封装的 LimitAdjustingIterator ，
LimitAdjustingIterator 的 getNewIterator 会调用 QueryExecutor 的 execute 方法，生成 SubqueryIterator 或者 graph.edgeQuery(v.longId(), q, txHandle) 最终调用 edgeStore 的查询
SubqueryIterator 构造方法会调用 indexSerializer.query(subQuery, tx)，最终调用 edgeStore 或者 IndexProvider 的查询。&lt;/p&gt;

&lt;p&gt;以上使我们查看源代码的心得，要想深入了解还需要进一步 debug 代码。&lt;/p&gt;

&lt;h2 id=&#34;更新索引&#34;&gt;更新索引&lt;/h2&gt;

&lt;h3 id=&#34;index&#34;&gt;Index&lt;/h3&gt;

&lt;p&gt;Index 类继承自  JanusGraphSchemaElement ，后者我们已经讲过代表 schema 的元素，它的子类如 PropertyKeyVertex 代表 schema 的一部分。
Index 有两个子类 JanusGraphIndex 和 RelationTypeIndex ，分别代表 Graph index 和 基于 Relation 的 Index ，实现类分别是 ：JanusGraphIndexWrapper 和 RelationTypeIndexWrapper。&lt;/p&gt;

&lt;p&gt;JanusGraphIndexWrapper 包括了 composite indexes 和 mixed indexes。可以通过 JanusGraphManagement#buildIndex(String, Class) 构造，
通过 JanusGraphManagement#getGraphIndex(String) 或者 JanusGraphManagement#getGraphIndexes(Class) 获得。注意方法包括：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;getBackingIndex
getFieldKeys
getIndexedElement
getIndexStatus
getParametersFor
isCompositeIndex
isMixedIndex
isUnique
name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RelationTypeIndex 包括 EdgeIndex 和 PropertyKeyIndex ，通过 JanusGraphManagement#buildEdgeIndex(org.janusgraph.core.EdgeLabel &amp;hellip;)和 JanusGraphManagement#buildPropertyIndex(org.janusgraph.core.PropertyKey&amp;hellip;) 构造，
通过JanusGraphManagement#getRelationIndex(org.janusgraph.core.RelationType, String) 获得。主要方法包括：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;getDirection
getIndexStatus
getSortKey
getSortOrder
getType
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;indextype-internalrelationtype&#34;&gt;IndexType InternalRelationType&lt;/h3&gt;

&lt;p&gt;JanusGraphIndex 和 RelationTypeIndex 中分别有一个 IndexType 和 InternalRelationType 的属性。&lt;/p&gt;

&lt;p&gt;IndexType 又有 CompositeIndexType 和 MixedIndexTypeWrapper 两大子类， CompositeIndexType 还有一个子类是 BaseKey 的索引， 也就是 schema 默认有的索引。&lt;/p&gt;

&lt;p&gt;CompositeIndexTypeWrapper 和 MixedIndexTypeWrapper 的构造方法需要传入一个 SchemaSource 对象，也就是 JanusGraphSchemaVertex 的对象。&lt;/p&gt;

&lt;h3 id=&#34;indexbuilder&#34;&gt;IndexBuilder&lt;/h3&gt;

&lt;p&gt;IndexBuilder 是 JanusGraphManagement 内部接口，顾名思义是用来构建索引的，建造者模式。里面封装了索引的属性，例如： addKey indexOnly unique 等。&lt;/p&gt;

&lt;p&gt;实现类在 ManagementSystem 中，实现类 主要属性：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private final String indexName;
private final ElementCategory elementCategory;
private boolean unique = false;
private JanusGraphSchemaType constraint = null;
private final Map&amp;lt;PropertyKey, Parameter[]&amp;gt; keys = new HashMap&amp;lt;&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要方法还是 createCompositeIndex 和 buildMixedIndex 。都会调用宿主类的方法。
实际上创建索引过程就是创建一个 INDEX 类型的 SchemaVertex ，然后建立到 对应的 PropertyKey 的 Edge。&lt;/p&gt;

&lt;h3 id=&#34;updatestatustrigger&#34;&gt;UpdateStatusTrigger&lt;/h3&gt;

&lt;p&gt;根据名字判断是更新 status 的触发器。它的属性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final StandardJanusGraph graph;
private final long schemaVertexId;
private final SchemaStatus newStatus;
private final Set&amp;lt;Long&amp;gt; propertyKeys;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构造方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private UpdateStatusTrigger(StandardJanusGraph graph, JanusGraphSchemaVertex vertex, SchemaStatus newStatus, Iterable&amp;lt;PropertyKeyVertex&amp;gt; keys) {
    this.graph = graph;
    this.schemaVertexId = vertex.longId();
    this.newStatus = newStatus;
    this.propertyKeys = Sets.newHashSet(Iterables.transform(keys, new Function&amp;lt;PropertyKey, Long&amp;gt;() {
        @Nullable
        @Override
        public Long apply(@Nullable PropertyKey propertyKey) {
            return propertyKey.longId();
        }
    }));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;call 方法主要就是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;management.setStatus(schemaVertex, newStatus, keys);
management.updatedTypes.addAll(keys);
management.updatedTypes.add(schemaVertex);
management.commit();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;它被使用的地方是在 updateIndex 的时候，有一步： &lt;code&gt;setUpdateTrigger(new UpdateStatusTrigger(graph, schemaVertex, SchemaStatus.REGISTERED, keySubset))&lt;/code&gt;
这里的 set 方法只是将它 add 到了一个 List 中，而在调用 commit 的时候，会有个判断，然后调用 &lt;code&gt;mgmtLogger.sendCacheEviction(updatedTypes, updatedTypeTriggers, getOpenInstancesInternal());&lt;/code&gt;
这里 ManagementLogger 实际上又调用 &lt;code&gt;evictionTriggerMap.put(evictionId,new EvictionTrigger(evictionId,updatedTypeTriggers,openInstances))&lt;/code&gt; 将它封装为 EvictionTrigger 放进一个 map 中。&lt;/p&gt;

&lt;p&gt;这要从新建 StandardJanusGraph 开始说起，在它的构造方法有一句：&lt;code&gt;mgmtLog.registerReader(ReadMarker.fromNow(), mgmtLogger);&lt;/code&gt;
然后调用 KCVSLog 的 registerReader 方法，然后调用 msgPullers[pos]=new MessagePuller(partitionId,bucketId);
新建 MessagePuller 后，调用 readExecutor.scheduleWithFixedDelay 放进线程池
MessagePuller 的 run 方法会调用 prepareMessageProcessing ，然后调用 readExecutor.submit(new ProcessMessageJob(message,reader)) 放进线程池。
ProcessMessageJob 的 run 方法调用 ManagementLogger 的 read 方法，
然后会调用 EvictionTrigger evictTrigger = evictionTriggerMap.get(evictionId)，这里就取出了我们上面放进去的 evictTrigger，
调用 receivedAcknowledgement 方法，会调用 trigger.call() 方法，然后会 setStatus。&lt;/p&gt;

&lt;p&gt;我们稍微总结一下。 StandardJanusGraph 的构造方法实际上会 new 一个 KCVSLog managementLog 和一个 new ManagementLogger managementLogger，前者是日志，后者是 management 的日志。
然后调用 managementLog.registerReader(ReadMarker.fromNow(), managementLogger)，这个 managementLogger 实现了 MessageReader 接口， 也就是将 managementLogger 注册到 KCVSLog 上。
注册以后，会通过一个 ScheduledThreadPoolExecutor 定时调度，将 KCVSLog 按照分区分桶拆分成多个快，发送到 KCVSLog 的消息都会发送给 ManagementLogger。
ManagementLogger 调用 read 方法，判断 MgmtLogType，根据不同的类型，做出不同的响应。当收到 CACHED_TYPE_EVICTION_ACK 类型的消息，将会得到 evictTrigger，并且调用 call 方法。&lt;/p&gt;

&lt;h3 id=&#34;standardscanner&#34;&gt;StandardScanner&lt;/h3&gt;

&lt;p&gt;看名字是一个扫描器。内部有 KeyColumnValueStoreManager manager 和  Set&lt;KeyColumnValueStore&gt; openStores ，应该是构造的时候传进来的，来自 graph。
我们比较关心的是他的内部类： Builder ，内部有 ScanJob job，job 有 process 方法，而 Builder 则有 execute 方法，executor 会 new 一个 StandardScannerExecutor，
StandardScannerExecutor executor = new StandardScannerExecutor(job, finishJob, kcvs, storeTx,manager.getFeatures(), numProcessingThreads, workBlockSize, jobConfiguration, graphConfiguration);
executor 是继承自 Runnable 的，然后调用它的 start 方法启动这个线程。executor 的 run 方法就是关键，
StandardScannerExecutor 的 run 方法会 new Processor(job.clone(),processorQueue)，Processor 也是 Runnable ，然后调用 start ，Processor 的 run 中调用了 job 的 process。&lt;/p&gt;

&lt;p&gt;这个 job 的 process 方法就是重点。例如 SimpleScanJob 的 process 方法，就是扫描一遍数据库。&lt;/p&gt;

&lt;p&gt;StandardScanner 的使用主要是在 updateIndex 的时候，有一步： &lt;code&gt;builder.setJob(VertexJobConverter.convert(graph, new IndexRepairJob(indexId.indexName, indexId.relationTypeName)));&lt;/code&gt;
这里会设置 job，然后调用 builder.execute()，
里面会 new StandardScannerExecutor，这是一个 Runnable，然后 start。
它的 run 方法会 new Processor(job.clone(),processorQueue) ，这是一个 Runnable ，然后 start。
然后调用  job.process(row.key,row.entries,metrics)。
例如 IndexRepairJob 的 process 方法，会调用 BackendTransaction.mutateIndex 或者 restore 方法，和 IndexSerializer.reindexElement 方法，其实就是重新索引。&lt;/p&gt;

&lt;p&gt;想要了解可以在 CassandraScanJobIT 中进行简单测试。&lt;/p&gt;

&lt;p&gt;我们可以看出其实  StandardScanner 和 UpdateStatusTrigger 完成工作类似，都是通过线程调用线程，完成所以更新，只不过前者比较简单，后者操作复杂一点。&lt;/p&gt;

&lt;h3 id=&#34;managementsystem&#34;&gt;ManagementSystem&lt;/h3&gt;

&lt;p&gt;有关索引的操作也是在 ManagementSystem 中完成，最重要的就是 updateIndex 方法，&lt;/p&gt;

&lt;h3 id=&#34;reindex&#34;&gt;reindex&lt;/h3&gt;

&lt;p&gt;mgmt.updateIndex(mgmt.getGraphIndex(indexName), SchemaAction.REINDEX).get();&lt;/p&gt;

&lt;p&gt;我们发现这个步骤特别久，就算没有数据也要很久，这不科学。而且打断点也进不去，我们只能直接拍快照，通过分析某个时刻的快照，分析有没有线程死锁的情况。&lt;/p&gt;

&lt;p&gt;我们每次在程序运行的时候拍快照都会有两个线程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;Thread-61@7893&amp;quot; prio=5 tid=0x51 nid=NA waiting
  java.lang.Thread.State: WAITING
	  at sun.misc.Unsafe.park(Unsafe.java:-1)
	  at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	  at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	  at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	  at org.janusgraph.diskstorage.keycolumnvalue.scan.StandardScannerExecutor.run(StandardScannerExecutor.java:148)
	  at java.lang.Thread.run(Thread.java:745)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;Thread-65@7897&amp;quot; prio=5 tid=0x55 nid=NA waiting
  java.lang.Thread.State: WAITING
	  at sun.misc.Unsafe.park(Unsafe.java:-1)
	  at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
	  at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
	  at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	  at org.janusgraph.diskstorage.keycolumnvalue.scan.StandardScannerExecutor$Processor.run(StandardScannerExecutor.java:272)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;偶尔还能发现一个：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;&amp;quot;Thread-4@4217&amp;quot; daemon prio=5 tid=0x18 nid=NA sleeping
  java.lang.Thread.State: TIMED_WAITING
	  at java.lang.Thread.sleep(Thread.java:-1)
	  at java.lang.Thread.sleep(Thread.java:340)
	  at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
	  at org.janusgraph.diskstorage.util.time.TimestampProviders.sleepPast(TimestampProviders.java:152)
	  at org.janusgraph.graphdb.database.management.ManagementLogger$SendAckOnTxClose.run(ManagementLogger.java:208)
	  at java.lang.Thread.run(Thread.java:745)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前两个是常在的线程，在 index 的过程中几乎一致都在，后面那个是偶尔会有出现。&lt;/p&gt;

&lt;p&gt;中间还报：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;2018-06-30 14:16:35.282 ERROR   --- [      Thread-66] o.j.g.d.management.ManagementLogger      : 
Evicted [23@c0a8007113617-dengzimings-MacBook-Pro-local1] from cache but waiting too long for transactions to close. 
Stale transaction alert on: [standardjanusgraphtx[0x0fd51357], standardjanusgraphtx[0x42d0f747], 
standardjanusgraphtx[0x54168b3c], standardjanusgraphtx[0x27eff5b4], standardjanusgraphtx[0x20cfedd2], 
standardjanusgraphtx[0x7bd7769a], standardjanusgraphtx[0x1095d23a]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这三个可以给我们提供比较多的信息。前面两个可能是由于 poll 的参数等待时间是 100 ms 比较长，所以每次拍快照很大概率刚好在等待。&lt;/p&gt;

&lt;h1 id=&#34;debug&#34;&gt;debug&lt;/h1&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j企业版分析</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E4%BC%81%E4%B8%9A%E7%89%88%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E4%BC%81%E4%B8%9A%E7%89%88%E5%88%86%E6%9E%90/</guid>
      
        <description>&lt;p&gt;阅读neo4j源码是为了改造，所以研究一下企业版的源码。OpenEnterpriseNeoServer 和 CommunityNeoServer 稍微对比一下。&lt;/p&gt;

&lt;p&gt;CommunityNeoServer&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;protected static final GraphFactory COMMUNITY_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
                .newFacade( storeDir, config, dependencies );
    };

    public CommunityNeoServer( Config config, GraphDatabaseFacadeFactory.Dependencies dependencies,
            LogProvider logProvider )
    {
        this( config, lifecycleManagingDatabase( COMMUNITY_FACTORY ), dependencies, logProvider );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OpenEnterpriseNeoServer&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    protected static Database.Factory createDbFactory( Config config )
    {
        final Mode mode = config.get( EnterpriseEditionSettings.mode );

        switch ( mode )
        {
        case HA:
            return lifecycleManagingDatabase( HA_FACTORY );
        case ARBITER:
            // Should never reach here because this mode is handled separately by the scripts.
            throw new IllegalArgumentException( &amp;quot;The server cannot be started in ARBITER mode.&amp;quot; );
        case CORE:
            return lifecycleManagingDatabase( CORE_FACTORY );
        case READ_REPLICA:
            return lifecycleManagingDatabase( READ_REPLICA_FACTORY );
        default:
            return lifecycleManagingDatabase( ENTERPRISE_FACTORY );
        }
    }
    
    private static final GraphFactory HA_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new HighlyAvailableGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory ENTERPRISE_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new EnterpriseGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory CORE_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new CoreGraphDatabase( storeDir, config, dependencies );
    };

    private static final GraphFactory READ_REPLICA_FACTORY = ( config, dependencies ) -&amp;gt;
    {
        File storeDir = config.get( GraphDatabaseSettings.database_path );
        return new ReadReplicaGraphDatabase( storeDir, config, dependencies );
    };
    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终不一样的还是启动的 server的不一样而已。最终是在 PlatformModule EditionModule DataSourceModule 三个类负责的 中不一样的。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j存储结构分析</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</guid>
      
        <description>

&lt;h2 id=&#34;1-本文内容转自&#34;&gt;1.本文内容转自：&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://key-value-stories.blogspot.tw/2015/02/neo4j-architecture.html?view=magazine&#34;&gt;https://key-value-stories.blogspot.tw/2015/02/neo4j-architecture.html?view=magazine&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This post compiles some information about architecture of Neo4j, the leading graph database. Research is relevant for Neo4j 2.2 version.&lt;/p&gt;

&lt;p&gt;There are three main kinds of primitives in Neo4j: nodes, relationships and properties. Nodes are connected via relationships. Properties could be attached to both nodes and relationships. All primitives are identified by identifiers, unique among primitive kind.&lt;/p&gt;

&lt;p&gt;Node and relationship identifiers are 35 bits in length, i. e. database could hold at most about 34 billions of nodes or relationships. Property identifiers take 36 bits (reference).&lt;/p&gt;

&lt;p&gt;Also, relationships are typed (for example, &amp;ldquo;friend of&amp;rdquo; and &amp;ldquo;in relationship with&amp;rdquo; are two different types of relationships between &amp;ldquo;people nodes&amp;rdquo; in social network graph). Relationship types have 2-byte identifiers.&lt;/p&gt;

&lt;p&gt;In addition, nodes could be labelled. Label is logically another one kind of entity, with own identifiers.
Main data storage
Primitives stored on disk as records. Important, that all records or primitives of a kind are equally sized. (Actually, there are more record types and dedicated stores, and they all share this property. Dynamically sized data is stored as a linked list of constantly sized records.)
Node store format
Node records are 15 bytes (* 8 = 120 bits) long:
35 bits for first relationship identifier
36 bits for first property identifier
40 bytes for label field:
If there are at most 7 labels attached to the node, and each of label identifiers takes no more than (40 - 4  = 36) / numberOfLabels, i. e. if there are 7 labels, each label id should be below 2(36 / 7) = 5 = 32, than number of labels is stored in 36..38-th bits of the label field, and the label identifiers are packed in lower 0..35-th bits.
Otherwise, if there are more than 7 labels attached to the node, or their identifiers are too big, 39-th bit of the label field, i. e. the flag, is set, and in the lower 0..35-th bits of the label field the identifier of the dynamic record with all label ids is stored.
9 bits &amp;ndash; some flags and reserved for future use
Relationship store format
Since node keeps only a reference to the single relationship, relationships are orginized in doubly-linked lists, that makes all relationships of some node traversable from this node. Each relationship is a part of two linked lists: a list of relationships of the first node, i. e. from which this relationship starts, and a lists of relationships of the second node, i. e. at which this relationships ends.&lt;/p&gt;

&lt;p&gt;Relationship record take 34 bytes (* 8 = 272 bits):
35 bits of the first node identifier
35 bits of the second node identifier
35 * 4 = 140 bits of identifiers of the sibling relationships in two linked lists, this relationship participate in
16 bits of relationship type
36 bits for first property identifier
10 bits &amp;ndash; some flags and reserved for future use
Organazing relationships in linked lists is not particularly performant decision itself, but in some cases it becomes really disastrous &amp;ndash; for example, when some type of nodes has (on average) 100 relationships of type A and some relationships of type B. If we are only interested in traversal over relationships of type B, and they are occasionally clustered in the end of linked lists of the nodes of our type, we are required to traverse 100 relationships in which we are not currently interested to access the useful data.&lt;/p&gt;

&lt;p&gt;Apparently to optimize cases like explained above, Neo4j supports another relationship layout (called dense node), in a nutshell it links relationships of each node in a tree, rather than simple linked list. In this case, &amp;ldquo;first relationship identifier&amp;rdquo; is interpreted as an identifier of a relationship group. Each relationship group is dedicated to relationships of a certain type. Relationship group record is 25 bytes (* 8 = 200 bits) long:
35 bytes of the node identifier this relationship group belongs to
16 bits of relationship type
35 bytes of the first out relationship identifier, i. e. a relationship which has the given type and starts in the node owning this relationship group
35 bytes of the first in relationship identifier, i. e. a relationship which has the given type and ends in the node owning this relationship group
35 bytes of the first loop relationship identifier.
35 bytes of the next linked relationship group of the owning node, i. e. relationship groups form a singly-linked list
1 bit for presence flag
One more byte (8 bits) apparently reserved for future use, however I&amp;rsquo;m not sure, because seems that it would be nicer to fit 24 bytes for relationship group record, because it is more &amp;ldquo;power of 2 aligned&amp;rdquo;, i. e. plays better with cache lines, pages.
When relationship groups are used, relationships of any specified type and direction, could be traversed from from the node with much lesser overhead, skipping potentially a lot of relationships of the node we are not interested in during this traversal.&lt;/p&gt;

&lt;p&gt;There is an interesting small optimization: when the node is dense, first relationship records in the doubly-linked lists, to which relationship groups point, keep the length of the doubly-linked list in place of previous relationship link, which is otherwise unused (because first relationship in the doubly-linked list point only to the next relationship in a chain).
Property store format
As nodes and relationships reference only the first their property, they are also stored as doubly-linked lists, by owning primitive entity. Property record size is 41 bytes:
36 bits of the previous linked property identifier
36 bits of the next linked property identifier
32 bytes of &amp;ldquo;payload&amp;rdquo;, i. e. space where the property data itself is stored. It includes property type identifier, data encoding type and the data bytes. If the property data doesn&amp;rsquo;t fit the payload (i. e. it is a long string or array), the identifier of the linked dynamic data record is placed there as well.
Neo4j supports plenty of property data formats, trying to pack the data as dense as possible, but it is not the subject of this blog post.
File buffer cache
Records of different kinds are stored in separate files. Access to disk storage is proxied with file buffer cache, or page cache:
Neo4j uses multiple file buffer caches, one for each different storage file. Each file buffer cache divides its storage file into a number of equally sized windows. Each cache window contains an even number of storage records. The cache holds the most active cache windows in memory and tracks hit vs. miss ratio for the windows. When the hit ratio of an uncached window gets higher than the miss ratio of a cached window, the cached window gets evicted and the previously uncached window is cached instead.
Quote from Caches in Neo4j document.&lt;/p&gt;

&lt;p&gt;I would add, that the default page size is 8192 bytes, and it doesn&amp;rsquo;t depend on native page size, specified for the Neo4j server process, operation system or CPU platform.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t understand, why Neo4j developers don&amp;rsquo;t rely on OS file caches, which employ several heuristics, including LRU, to solve the same task. Probably user space implementation is more precise in decisions about page eviction, than native generic mechanism would be, and is more manageable, but, on the other hand,
Native page caching is fully transparent, i. e. relying on it simply throws a layer of complexity away from Neo4j project
Even with Java-level page cache, OS still caches the same pages underneath, i. e. work is doubled to some extent.
Summary
The approach to data storage, chosen in Neo4j has one very useful consequence: since all records are strictly of the same size, accessing records by identifiers is pretty cheap, because doesn&amp;rsquo;t require any associative mapping from identifiers to record locations (hash table, tree or something else), identifiers just play as indexes in &amp;ldquo;arrays&amp;rdquo; of records.&lt;/p&gt;

&lt;p&gt;Another strong point is impossibility of external fragmentation, records after removed primitives could always be reused.&lt;/p&gt;

&lt;p&gt;However, there are also major disadvantages:
Database entity identifiers hardly could simultaneously be domain identifiers, unless the system was designed to use Neo4j as primary storage from the beginning.
A lot of memory overhead for storing links between records. For example, 50-80% of 34-byte relationship record is overhead (depends on how to count).
Traversing links is slow. Partially it is excused by empirical observation, that if all relationships of the node or properties of the node or relationship are stored at once, they should reside adjacent records and their traversal won&amp;rsquo;t require page/cache line load on each step.
Neo4j&amp;rsquo;s storage design favor reliability, versatility, agility and manageability. Apparently it is driven by initial database functional requirements and equally powerful, but more efficient approach doesn&amp;rsquo;t exist (at least I don&amp;rsquo;t see such). There is a basic tradeoff in systems design: more specific and constrained systems could be implemented more efficiently, than general and schema-less, like Neo4j.
Indexes
Neo4j supports indexing of nodes and relationships by labels and property values, i. e. it allows retrieving all nodes with given label and/or property value faster, than via full scan of all nodes in the database.&lt;/p&gt;

&lt;p&gt;Apparently production implementation of indexes is fully delegated to Lucene engine. Entity identifiers are stored in Lucene documents with fields, corresponding to the indexed labels and property values. Lucene is able to search documents by individual fields and combinations of fields, empowering complex queries on Neo4j level.&lt;/p&gt;

&lt;p&gt;I can&amp;rsquo;t judge about propriety and efficiency of this solution, because I&amp;rsquo;m not familiar with Lucene implementation. This requires separate research.
Object cache
Neo4j is written in Java, known for allocation and GC issues. It has several versions of object caches, introduced to prevent too much unnecessary allocations of node, relationship and property wrapper objects. Note that Neo4j&amp;rsquo;s object caches are not object pools, i. e. objects are not reused, caches only control object&amp;rsquo;s lifecycle in managed memory environment (JVM).&lt;/p&gt;

&lt;p&gt;Community strong, weak and soft cache implementations use ConcurrentHashMap with Long keys and target cached object values. weak and soft versions additionally wrap values with WeakReference or SoftReference respectively. Object eviction is left to JVM. At least one obvious optimization is possible here: specialization of ConcurrentHashMap for primitive long keys.&lt;/p&gt;

&lt;p&gt;Enterprise hpc (high-performance cache) uses simpler data structure: basically it&amp;rsquo;s just an AtomicReferenceArray of cached entities, slot for particular entity is determined as entity.id() % array.length(). On collisions, old cached objects are evicted. Eviction algorithm is also very simple: when after insertion of the new object total memory footprint of cached objects (including JVM object headers), preserved in a counter, exceeds configured limit, slots before and after current insertion index are cleared (in interleaved order), while total size of the cached objects is higher than 90% of the limit size.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s an amusing example, how applying little knowledge about the problem and major usage patterns leads to faster solution, even with simpler implementation.
Conclusion
In my understanding, Neo4j is a reliable, agile, general-purpose database, but it is not for edge performance, despite claims on their official website. Databases that allow to specialize storage and data structures for concrete node/relationship types should be more efficient.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j导数据</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E5%AF%BC%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E5%AF%BC%E6%95%B0%E6%8D%AE/</guid>
      
        <description>

&lt;h2 id=&#34;1-修改配置&#34;&gt;1.修改配置&lt;/h2&gt;

&lt;p&gt;dbms.security.allow_csv_import_from_file_urls=true
&amp;ndash; load csv 命令&lt;/p&gt;

&lt;p&gt;dbms.directories.import=import&lt;/p&gt;

&lt;p&gt;restart neo4j&lt;/p&gt;

&lt;h3 id=&#34;2-导入数据方法1&#34;&gt;2.导入数据方法1&lt;/h3&gt;

&lt;p&gt;load csv with headers from &amp;ldquo;file:///path/to/file&amp;rdquo; as row
create (:Employee {employeeId:toInt(row.id),first_name:row,first_name,title:row.title });&lt;/p&gt;

&lt;h3 id=&#34;3-导入数据方法2&#34;&gt;3. 导入数据方法2&lt;/h3&gt;

&lt;p&gt;dbms.directories.import=/var/lib/neo4j/import/&lt;/p&gt;

&lt;p&gt;注释：&lt;/p&gt;

&lt;h1 id=&#34;dbms-security-allow-csv-import-from-file-urls-true&#34;&gt;dbms.security.allow_csv_import_from_file_urls=true&lt;/h1&gt;

&lt;p&gt;将文件放入 ：/var/lib/neo4j/import/  文件夹下，直接输入文件名即可：&lt;/p&gt;

&lt;p&gt;load csv with headers from &amp;ldquo;file:///filename&amp;rdquo; as row
create (:Employee {employeeId:toInt(row.id),first_name:row,first_name,title:row.title });&lt;/p&gt;

&lt;h3 id=&#34;4-初始化导数据&#34;&gt;4.初始化导数据&lt;/h3&gt;

&lt;p&gt;新建每个节点和关系的header文件和数据文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# vertex header
phone:ID(PHONE),isblack,ismedia,iscuishou
# edge header
:START_ID(USERID),:END_ID(PHONE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后导数据：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;neo4j-import \
 --into /data/neo4j/graph/all20180417.db \
 --skip-duplicate-nodes true \
 --skip-bad-relationships true \
 --ignore-extra-columns true \
 --ignore-empty-strings true \
 --bad-tolerance 10000000 \
  --processors 56 \
 --id-type string \
 --max-memory 170G \
--nodes:LBS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_lbs.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_lbs.txt&amp;quot;  \
--nodes:IDCARD &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_idcard.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_idcard.txt&amp;quot;  \
--nodes:GNHID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_gnhid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_gnhid.txt&amp;quot;  \
--nodes:QQ &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_qq.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_qq.txt&amp;quot;  \
--nodes:WEIXIN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_weixin.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_weixin.txt&amp;quot;  \
--nodes:EMAIL &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_email.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_email.txt&amp;quot;  \
--nodes:DEVICETOKEN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_devicetoken.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_devicetoken.txt&amp;quot;  \
--nodes:COMPANY &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_company.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_company.txt&amp;quot;  \
--nodes:IP &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_ip.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_ip.txt&amp;quot;  \
--nodes:ORDERID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_orderid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_orderid.txt&amp;quot;  \
--nodes:USERID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_userid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_userid.txt&amp;quot;  \
--nodes:PHONE &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_phone.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_phone.txt&amp;quot;  \
--nodes:WIFI &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_v_wifi.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_v_wifi.txt&amp;quot;  \
--relationships:USERID_PHONE_EMG &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_phone_emg.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_phone_emg.txt&amp;quot;  \
--relationships:USERID_PHONE_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_phone_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_phone_loan.txt&amp;quot;  \
--relationships:USERID_COMPANY_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_company_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_company_loan.txt&amp;quot;  \
--relationships:USERID_LBS_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_lbs_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_lbs_loan.txt&amp;quot;  \
--relationships:USERID_DEVICETOKEN_LOAN &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_devicetoken_loan.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_devicetoken_loan.txt&amp;quot;  \
--relationships:USERID_LBS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_lbs.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_lbs.txt&amp;quot;  \
--relationships:USERID_COMPANY_GJJ &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_company_gjj.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_company_gjj.txt&amp;quot;  \
--relationships:USERID_IDCARD &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_idcard.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_idcard.txt&amp;quot;  \
--relationships:USERID_COMPANY_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_company_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_company_gnh_users.txt&amp;quot;  \
--relationships:USERID_GNHID_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_gnhid_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_gnhid_users.txt&amp;quot;  \
--relationships:USERID_IP_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_ip_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_ip_gnh_users.txt&amp;quot;  \
--relationships:USERID_PHONE_GNH_EMG_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_gnh_emg_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_gnh_emg_users.txt&amp;quot;  \
--relationships:USERID_QQ_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_qq_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_qq_gnh_users.txt&amp;quot;  \
--relationships:ORDERID_IP_GNH_USERS &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_orderid_ip_gnh_users.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_orderid_ip_gnh_users.txt&amp;quot;  \
--relationships:USERID_ORDERID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_orderid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_orderid.txt&amp;quot; \
--relationships:USERID_DEVICETOKEN_RISKBRAIN_UMID &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_devicetoken_riskbrain_umid.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_devicetoken_riskbrain_umid.txt&amp;quot; \
--relationships:USERID_DEVICETOKEN_USER_DEVICES &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_devicetoken_t_user_devices.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_devicetoken_t_user_devices.txt&amp;quot; \
--relationships:USERID_DEVICETOKEN_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_devicetoken_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_devicetoken_user_event.txt&amp;quot; \
--relationships:USERID_COMPANY_USER_INFO_EXT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_company_user_info_ext.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_company_user_info_ext.txt&amp;quot; \
--relationships:USERID_IP_CUSTINFO &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_ip_custinfo.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_ip_custinfo.txt&amp;quot; \
--relationships:USERID_IP_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_ip_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_ip_user_event.txt&amp;quot; \
--relationships:USERID_EMAIL_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_email_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_email_user_event.txt&amp;quot; \
--relationships:USERID_EMAIL_EXTMAIL_USER_MAILACCOUNT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_email_user_mailaccount.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_email_user_mailaccount.txt&amp;quot; \
--relationships:USERID_QQ_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_qq_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_qq_user_event.txt&amp;quot; \
--relationships:USERID_WEIXIN_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_weixin_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_weixin_user_event.txt&amp;quot; \
--relationships:USERID_PHONE_USER_EVENT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_user_event.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_user_event.txt&amp;quot; \
--relationships:USERID_PHONE_CUSTINFO &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_custinfo.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_custinfo.txt&amp;quot; \
--relationships:USERID_PHONE_USERCENTER &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_usercenter.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_usercenter.txt&amp;quot; \
--relationships:USERID_PHONE_USER_EMG_CONTACT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_user_emg_contact.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_user_emg_contact.txt&amp;quot; \
--relationships:USERID_PHONE_TEL &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_userid_phone_tel.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_userid_phone_tel.txt&amp;quot; \
--relationships:USERID_PHONE_CONTACT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_phone_contact.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_phone_contact.txt&amp;quot; \
--relationships:PHONE_PHONE_TEL &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v3_e_phone_phone_tel.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v3_e_phone_phone_tel.txt&amp;quot; \
--relationships:PHONE_PHONE_CONTACT &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_phone_phone_contact.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_phone_phone_contact.txt&amp;quot; \
--relationships:USERID_WIFI &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_userid_wifi.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_userid_wifi.txt&amp;quot; \
--relationships:ORDERID_WIFI &amp;quot;/data1/neo4j/data/offline/graph_kg/header/kg_v2_e_orderid_wifi.txt,/data1/neo4j/data/offline/graph_kg/data/kg_v2_e_orderid_wifi.txt&amp;quot; \
          &amp;gt; /data/neo4j/graph/all20180417.log 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析1-编译打包启动</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E5%90%AF%E5%8A%A8/</guid>
      
        <description>

&lt;h2 id=&#34;1-打包&#34;&gt;1.打包&lt;/h2&gt;

&lt;h3 id=&#34;1-打包community&#34;&gt;1.打包community&lt;/h3&gt;

&lt;p&gt;进入community,neo4j-graphdb-api，
注释掉common的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.revapi&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;revapi-maven-plugin&amp;lt;/artifactId&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;里面好像涉及到了版本检查，如果某个类的最新发布版本已经没有这个方法，打包会失败，反正对打包有影响，不删除可能会失败。&lt;/p&gt;

&lt;p&gt;还可能要在主项目的pom里面注释掉：&lt;code&gt;maven-checkstyle-plugin&lt;/code&gt;，代码风格检查可能会通不过。
然后用maven命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests package install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-打包企业版&#34;&gt;2.打包企业版&lt;/h3&gt;

&lt;p&gt;进入enterprise,ha目录
进入management,注释掉 &lt;groupId&gt;org.revapi&lt;/groupId&gt;
还有其他问题，比如java文件没有license，这里不一一列举。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests package install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-打包完整的tar包&#34;&gt;3. 打包完整的tar包&lt;/h3&gt;

&lt;p&gt;进入项目路径&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mvn clean install -Dmaven.test.skip=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要注意两个参数的异同点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
-DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。

-Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打包的输出文件：packaging/standalone/target/neo4j-community-3.4.0-SNAPSHOT-unix.tar.gz，这个就是我们的neo4j包。解压后，放到一个目录。一方面你可以选择执行 bin/neo4j start 启动neo4j，我们要分析源码，自然会是在本地启动。&lt;/p&gt;

&lt;h2 id=&#34;二-运行&#34;&gt;二、运行&lt;/h2&gt;

&lt;h3 id=&#34;1-启动&#34;&gt;1.启动&lt;/h3&gt;

&lt;p&gt;我们在IDEA中，找到入口类：org.neo4j.server.CommunityEntryPoint，点击运行，然后会报错，我们需要添加运行参数：&lt;/p&gt;

&lt;p&gt;-server &amp;ndash;home-dir=~/neo4j-community-3.2.6 &amp;ndash;config-dir=~/neo4j-community-3.2.6/conf&lt;/p&gt;

&lt;p&gt;这里的参数是刚刚解压的neo4j目录和配置文件。然后运行成功，访问 &lt;a href=&#34;http://localhost:7474/browser/，会发现有问题。&#34;&gt;http://localhost:7474/browser/，会发现有问题。&lt;/a&gt;
通过调试前端的js代码，我们发现版本有问题，这里我们稍作修改，找到 org.neo4j.kernel.internal.Version。最后的代码注释掉，换成我们的版本，也就是将Version.class.getPackage().getImplementationVersion() 换成 3.4，然后就可以运行成功了。
打开7474端口，写cypher语言，查看。&lt;/p&gt;

&lt;h3 id=&#34;2-打断点调试&#34;&gt;2.打断点调试&lt;/h3&gt;

&lt;p&gt;既然是源码分析，我们的办法就是先看，然后打断点调试，查看调用栈，但是由于是多线程，其实还是很有难度的，容易跟丢，后续我们慢慢来吧。&lt;/p&gt;

&lt;h3 id=&#34;3-代码结构查看&#34;&gt;3.代码结构查看&lt;/h3&gt;

&lt;p&gt;看源码之前我们先大概过一下代码结构。我们主要看 community 模块的结构，里面有很多子模块。&lt;/p&gt;

&lt;p&gt;我们可以大概根据名字猜测 ：io模块是用来处理读写数据的，kernel模块是我们需要着重查看的。bolt是处理bolt连接的，server是整个项目启动的。codegen是动态生成代码的。我们要从内核部分开始看。&lt;/p&gt;

&lt;h3 id=&#34;4-架构了解&#34;&gt;4.架构了解&lt;/h3&gt;

&lt;p&gt;The node records contain only a pointer to their first property and their first relationship (in what is oftentermed the _relationship chain). From here, we can follow the (doubly) linked-list of relationships until we find the one we’re interested in, the LIKES relationship from Node 1 to Node 2 in this case. Once we’ve found the relationship record of interest, we can simply read its properties if there are any via the same singly-linked list structure as node properties, or we can examine the node records that it relates via its start node and end node IDs. These IDs, multiplied by the node record size, of course give the immediate offset of both nodes in the node store file.&lt;/p&gt;

&lt;p&gt;这段话来自&lt;Graph Databases&gt;(作者：IanRobinson) 一书。描述了neo4j的存储方式。详情可以查阅其他资料。&lt;/p&gt;

&lt;h3 id=&#34;5-源码查看&#34;&gt;5.源码查看&lt;/h3&gt;

&lt;p&gt;参考下一篇&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析2-启动源码跟踪</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E8%B7%9F%E8%B8%AA/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E5%90%AF%E5%8A%A8%E6%BA%90%E7%A0%81%E8%B7%9F%E8%B8%AA/</guid>
      
        <description>

&lt;h2 id=&#34;1-第一遍调试&#34;&gt;1.第一遍调试&lt;/h2&gt;

&lt;p&gt;第一遍就是打断点，然后查看调用栈，忽略过多的线程。&lt;/p&gt;

&lt;p&gt;找到 CommunityEntryPoint，打一个断点，调试,不断F5进入，F6单步执行，F跳出。
1. &lt;code&gt;new CommunityBootstrapper(),ServerBootstrapper.start(boot,args)&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerBootstrapper&lt;/code&gt; 中的初始化关键代码： &lt;code&gt;private GraphDatabaseDependencies dependencies = GraphDatabaseDependencies.newDependencies()&lt;/code&gt;; 这个dependencies貌似来头很大。F5进入
&lt;code&gt;public static GraphDatabaseDependencies newDependencies()&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;KernelExtensionFactory factory : Service.load( KernelExtensionFactory.class)&lt;/code&gt;
这段代码似乎跳不进去，反正最后得到了7个:&lt;/p&gt;

&lt;p&gt;0 = {LuceneKernelExtensionFactory@675} &amp;ldquo;KernelExtension:LuceneKernelExtensionFactory[lucene]&amp;rdquo;
1 = {LuceneSchemaIndexProviderFactory@679} &amp;ldquo;KernelExtension:LuceneSchemaIndexProviderFactory[lucene]&amp;rdquo;
2 = {NativeLuceneFusionSchemaIndexProviderFactory@680} &amp;ldquo;KernelExtension:NativeLuceneFusionSchemaIndexProviderFactory[lucene+native]&amp;rdquo;
3 = {BoltKernelExtension@681} &amp;ldquo;KernelExtension:BoltKernelExtension[bolt-server]&amp;rdquo;
4 = {ShellServerExtensionFactory@682} &amp;ldquo;KernelExtension:ShellServerExtensionFactory[shell]&amp;rdquo;
5 = {UdcKernelExtensionFactory@683} &amp;ldquo;KernelExtension:UdcKernelExtensionFactory[kernel udc]&amp;rdquo;
6 = {JmxExtensionFactory@684} &amp;ldquo;KernelExtension:JmxExtensionFactory[kernel jmx]&amp;rdquo;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;List&amp;lt;QueryEngineProvider&amp;gt; queryEngineProviders = asList( Service.load( QueryEngineProvider.class ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这段代码和前面一样，不过加载的是查询引擎的的class，我们暂且跳过！&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;return new GraphDatabaseDependencies( null, null, new ArrayList&amp;lt;&amp;gt;(), kernelExtensions,)&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerBootstrapper.start( Bootstrapper boot, String... argv )&lt;/code&gt;
```java&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;CommunityBootstrapper(AbstractNeoServer).start&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;server = createNeoServer( config, dependencies, userLogProvider );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;new CommunityNeoServer( config, dependencies, logProvider );&lt;/code&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;// 初始化很多属性&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;		protected abstract WebServer createWebServer();&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;			// 放在代码后面的属性
			private final Dependencies dependencyResolver = new Dependencies( new Supplier&lt;DependencyResolver&gt;()
    		{
    		    @Override
    		    public DependencyResolver get()
    		    {
    		        Database db = dependencyResolver.resolveDependency( Database.class );
    		        return db.getGraph().getDependencyResolver();
    		    }
    		} );
			// 构造方法
    		public AbstractNeoServer( Config config, Database.Factory dbFactory,
    		        GraphDatabaseFacadeFactory.Dependencies dependencies, LogProvider logProvider )
    		{
    		    this.logProvider = logProvider;
    		    // 初始化很多东西
    		}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    2. `AbstractNeoServer.start();`

        1. `init()`

            1. `this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );`

                1. `lambda$lifecycleManagingDatabase$0:47, LifecycleManagingDatabase (org.neo4j.server.database)`
                这里的 java8 lamabda表达式有点不懂，总之就是这个 dbFactory.newDatabase( config, dependencies ) 执行的是这段代码：
                 `( config, dependencies ) -&amp;gt; new LifecycleManagingDatabase( config, graphDbFactory, dependencies );`

                2. `dependencyResolver.satisfyDependency(LifecycleManagingDatabase )`
                这里的 satisfyDependency 方法有点奇怪，总之就是将 LifecycleManagingDatabase 的所有父类添加到一个临时变量，好像啥也没做。

                3. `life.add(LifecycleManagingDatabase)`
                奇怪的代码，后续我们专门讲解这个 life 的实现，这是注释：
                Add a new Lifecycle instance. It will immediately be transitioned to the state of this LifeSupport.
                将传入的dependency 新建为一个LifecycleInstance，add到 instances中。

                LifecycleInstance newInstance = new LifecycleInstance( instance );
                private volatile List&amp;lt;LifecycleInstance&amp;gt; instances = new ArrayList&amp;lt;&amp;gt;();

                4. `this.database = LifecycleManagingDatabase`

            2. 新建其他的，非内核部分我们忽略。


            this.authManagerSupplier = dependencyResolver.provideDependency( AuthManager.class );
    		this.userManagerSupplier = dependencyResolver.provideDependency( UserManagerSupplier.class );
    		this.sslPolicyFactorySupplier = dependencyResolver.provideDependency( SslPolicyLoader.class );
    		this.webServer = createWebServer();


            3. createServerModules()


            return Arrays.asList(
            new DBMSModule( webServer, getConfig() ),
            new RESTApiModule( webServer, getConfig(), getDependencyResolver(), logProvider ),
            new ManagementApiModule( webServer, getConfig() ),
            new ThirdPartyJAXRSModule( webServer, getConfig(), logProvider, this ),
            new ConsoleModule( webServer, getConfig() ),
            new Neo4jBrowserModule( webServer ),
            createAuthorizationModule(),
            new SecurityRulesModule( webServer, getConfig(), logProvider ) );


            4.创建 ServerComponentsLifecycleAdapter


            serverComponents = new ServerComponentsLifecycleAdapter();
            life.add( serverComponents );

            this.initialized = true;


        2. life.start();
        debug进入：`LifeSupport`

            1. init();
                1. status = changedStatus( this, status, LifecycleStatus.INITIALIZING );

                2. for ( LifecycleInstance instance : instances ) instance.init();
                    这时候有两个instance，分别是上面我们new出来的  new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter();

                    1. LifecycleInstance.init()
                    还好两个代码里面什么都没做，不然再F5进去，我要奔溃了。。。

                3. status = changedStatus( this, status, LifecycleStatus.STOPPED );

            2. for ( LifecycleInstance instance : instances ) instance.start();
                这时候有两个instance，分别是上面我们new出来的  new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter();

                    1. `LifecycleInstance.start() `

                    2. `LifecycleManagingDatabase.start()`


                        log.info( &amp;quot;Starting...&amp;quot; );
    					this.graph = dbFactory.newGraphDatabase( config, dependencies );
    					if ( !isInTestMode() )
    					{
    					    preLoadCypherCompiler();
    					}
    					log.info( &amp;quot;Started.&amp;quot; );



    					1. this.graph = dbFactory.newGraphDatabase( config, dependencies );
    					这里又是lambda表达式：
    					new GraphDatabaseFacadeFactory,

    					File storeDir = config.get( GraphDatabaseSettings.database_path );
                        return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
                               .newFacade( storeDir, config, dependencies );

                        主要的核心代码已经找到了：new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );
                        接下来我们主要调试这一段。

                    3. `ServerComponentsLifecycleAdapter.start()`
                        这里主要是和web，cypher有关，我们暂时忽略。
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;

## 2.调试 GraphDatabaseFacadeFactory.newFacade
上面我们已经调试到了 最后的部分，也是高潮部分。

newFacade 方法：
1. `initFacade( storeDir, config, dependencies, new GraphDatabaseFacade() );`

```java
    1.`new GraphDatabaseFacade()`
    初始化相关数据

    2.`GraphDatabaseFacade initFacade( File storeDir, Config config, final Dependencies dependencies, final GraphDatabaseFacade graphDatabaseFacade )`

    	1. `PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );`

        	1. `new PlatformModule( storeDir, config, databaseInfo, dependencies, graphDatabaseFacade );`
            这一部分代码很长很关键的感觉，这里是内核相关，先跳过，回头看。下一章节 TODO

            2. EditionModule edition = editionFactory.apply( platform );
            
            这里和上一个PlatformModule干的事情一样。下一章节 TODO

        2. `final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );`

            1. new DataSourceModule( platformModule, editionModule, queryEngine );
            和上面的 PlatformModule 一样，一大堆的新建。。。最后 life.add( platformModule.kernelExtensions ) 新建DataSource
        3. `ClassicCoreSPI spi = new ClassicCoreSPI( platform, dataSource, msgLog, coreAPIAvailabilityGuard );`
        
        4. `platform.life.start();`
 
            1. init();
            2. for ( LifecycleInstance instance : instances ) instance.start();
                这里的instance ：
           		
           		
           		0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;
		 		1 = {LifeSupport$LifecycleInstance@3730} &amp;quot;org.neo4j.kernel.impl.util.Neo4jJobScheduler@2667f029: STARTED&amp;quot;
		 		2 = {LifeSupport$LifecycleInstance@3635} &amp;quot;org.neo4j.udc.UsageData@67a20f67: STARTED&amp;quot;
		 		3 = {LifeSupport$LifecycleInstance@3658} &amp;quot;org.neo4j.kernel.impl.logging.StoreLogService@57c758ac: STARTED&amp;quot;
		 		4 = {LifeSupport$LifecycleInstance@3681} &amp;quot;org.neo4j.kernel.internal.locker.StoreLockerLifecycleAdapter@a9cd3b1: STARTED&amp;quot;
		 		5 = {LifeSupport$LifecycleInstance@3731} &amp;quot;org.neo4j.kernel.impl.pagecache.PageCacheLifecycle@13e39c73: STOPPED&amp;quot;
		 		6 = {LifeSupport$LifecycleInstance@3732} &amp;quot;org.neo4j.kernel.info.DiagnosticsManager@64cd705f: STOPPED&amp;quot;
		 		7 = {LifeSupport$LifecycleInstance@3733} &amp;quot;org.neo4j.kernel.impl.transaction.state.DataSourceManager@548d708a: STOPPED&amp;quot;
		 		8 = {LifeSupport$LifecycleInstance@3734} &amp;quot;org.neo4j.kernel.impl.util.watcher.DefaultFileSystemWatcherService@4b013c76: STOPPED&amp;quot;
		 		9 = {LifeSupport$LifecycleInstance@3735} &amp;quot;org.neo4j.kernel.impl.core.DelegatingPropertyKeyTokenHolder@53fb3dab: STOPPED&amp;quot;
		 		10 = {LifeSupport$LifecycleInstance@3736} &amp;quot;org.neo4j.kernel.impl.core.DelegatingLabelTokenHolder@cb0755b: STOPPED&amp;quot;
		 		11 = {LifeSupport$LifecycleInstance@3737} &amp;quot;org.neo4j.kernel.impl.core.DelegatingRelationshipTypeTokenHolder@33065d67: STOPPED&amp;quot;
		 		12 = {LifeSupport$LifecycleInstance@3738} &amp;quot;org.neo4j.kernel.internal.DefaultKernelData@30: STOPPED&amp;quot;
		 		13 = {LifeSupport$LifecycleInstance@3739} &amp;quot;org.neo4j.kernel.impl.core.ThreadToStatementContextBridge@7bba5817: STOPPED&amp;quot;
		 		14 = {LifeSupport$LifecycleInstance@3740} &amp;quot;org.neo4j.kernel.extension.KernelExtensions@25df00a0: STOPPED&amp;quot;
		 		15 = {LifeSupport$LifecycleInstance@3741} &amp;quot;org.neo4j.kernel.impl.proc.Procedures@6cc4cdb9: STOPPED&amp;quot;
		 		16 = {LifeSupport$LifecycleInstance@3742} &amp;quot;org.neo4j.server.security.auth.BasicAuthManager@47c81abf: STOPPED&amp;quot;
		 		17 = {LifeSupport$LifecycleInstance@3743} &amp;quot;org.neo4j.kernel.impl.cache.MonitorGc@30b6ffe0: STOPPED&amp;quot;
		 		18 = {LifeSupport$LifecycleInstance@3744} &amp;quot;org.neo4j.kernel.impl.pagecache.PublishPageCacheTracerMetricsAfterStart@2415fc55: STOPPED&amp;quot;
		 		19 = {LifeSupport$LifecycleInstance@3745} &amp;quot;org.neo4j.kernel.DatabaseAvailability@1890516e: STOPPED&amp;quot;
		 		20 = {LifeSupport$LifecycleInstance@3746} &amp;quot;org.neo4j.kernel.impl.factory.DataSourceModule$StartupWaiter@16c069df: STOPPED&amp;quot;
		 		21 = {LifeSupport$LifecycleInstance@3747} &amp;quot;org.neo4j.kernel.internal.KernelEventHandlers@2bec854f: STOPPED&amp;quot;
           	   
               每个instance的start方法具体是怎样的，我们稍后细看，这里跳过 TODO

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-学习neo4j-server的设计模式&#34;&gt;3.学习neo4j server的设计模式&lt;/h2&gt;

&lt;p&gt;上面我们调试了一遍启动过程，整个个过程可以多来几次，每一遍加深对neo4j的理解。
调试之前我们学习一下 LifeSupport 这个类的设计和使用。&lt;/p&gt;

&lt;p&gt;LifeSupport继承自Lifecycle，源码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Lifecycle interface for kernel components. Init is called first,
 * followed by start,
 * and then any number of stop-start sequences,
 * and finally stop and shutdown.
 *
 * As a stop-start cycle could be due to change of configuration, please perform anything that depends on config
 * in start().
 *
 * Implementations can throw any exception. Caller must handle this properly.
 *
 * The primary purpose of init in a component is to set up structure: instantiate dependent objects,
 * register handlers/listeners, etc.
 * Only in start should the component actually do anything with this structure.
 * Stop reverses whatever was done in start, and shutdown finally clears any set-up structure, if necessary.
 */
public interface Lifecycle
{
    void init() throws Throwable;

    void start() throws Throwable;

    void stop() throws Throwable;

    void shutdown() throws Throwable;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注释很清楚，万一看不懂百度翻译一下就明白。注意这里：init只是set up structure——初始化依赖的对象，注册处理器/监听器。只有start方法执行后才会用这个structure TOTDO，是不是看源码可以跳过init&lt;/p&gt;

&lt;p&gt;按F4发现有很多的实现类&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;PaxosClusterMemberAvailability (org.neo4j.cluster.member.paxos)
DefaultKernelData (org.neo4j.kernel.internal)
LifecycleAdapter (org.neo4j.kernel.lifecycle)
NeoStoreDataSource (org.neo4j.kernel)
TransactionPropagator (org.neo4j.kernel.ha.transaction)
ShellServerKernelExtension (org.neo4j.shell.impl)
OnlineBackupKernelExtension (org.neo4j.backup)
DummyExtension (org.neo4j.kernel)
LifeSupport (org.neo4j.kernel.lifecycle)
HighAvailabilityModeSwitcher (org.neo4j.kernel.ha.cluster.modeswitch)
KernelEventHandlers (org.neo4j.kernel.internal)
RecordStorageEngine (org.neo4j.kernel.impl.storageengine.impl.recordstorage)
JmxKernelExtension (org.neo4j.jmx.impl)
ExecutorLifecycleAdapter (org.neo4j.cluster)
KernelExtensions (org.neo4j.kernel.extension)
RecoveryCleanupWorkCollector (org.neo4j.index.internal.gbptree)
IndexImplementation (org.neo4j.kernel.spi.explicitindex)
NetworkReceiver (org.neo4j.cluster.com)
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们重点看看 LifeSupport ，我们分析发现 LifeSupport 也是一个 Lifecycle，而且有一个 LifecycleInstance 的数组 instances ，&lt;/p&gt;

&lt;p&gt;LifecycleInstance 也是继承自 Lifecycle。所以实际上 LifeSupport 就是一堆 Lifecycle 放在了一起，进行了一个类似装饰模式而已。&lt;/p&gt;

&lt;p&gt;LifeSupport的init,start,stop,shutdown方法，分别是循环instances执行init,start,stop,shutdown方法。&lt;/p&gt;

&lt;p&gt;经过上面的调试，我们发现neo4j基本上就是一个一个这样的 LifeSupport 组成的。&lt;/p&gt;

&lt;h3 id=&#34;1-第一次使用&#34;&gt;(1). 第一次使用&lt;/h3&gt;

&lt;p&gt;我们第一次遇到 LifeSupport是 在： CommunityBootstrapper.start() 时候，先创建 CommunityNeoServer，调用它的 start，start 前先是init方法。遇到了两个代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );
serverComponents = new ServerComponentsLifecycleAdapter();
life.add( serverComponents );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里的 life 就是 AbstractNeoServer(CommunityNeoServer) LifeSupport，是父类的成员变量，新建 CommunityNeoServer 的时候初始化的。然后在init方法中给他添加了两个 Lifecycle 的实现对象。&lt;/p&gt;

&lt;p&gt;AbstractNeoServer(CommunityNeoServer)执行完了init方法，就执行 life 的start方法，实际上执行的还是 new LifecycleManagingDatabase( config, graphDbFactory, dependencies ) 和 new ServerComponentsLifecycleAdapter() 的start。&lt;/p&gt;

&lt;p&gt;总结：
CommunityNeoServer 中的 出现的 LifeSupport 为：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;new LifecycleManagingDatabase( config, graphDbFactory, dependencies )
这里的 graphDbFactory 是 CommunityNeoServer 的一个匿名内部类接口的实现类，dependencies就是包含了 kernelExtensions 等内容的东西。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;new ServerComponentsLifecycleAdapter()&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-第二次使用&#34;&gt;(2). 第二次使用&lt;/h3&gt;

&lt;p&gt;我们后面还有一次用到了 LifeSupport 。就是执行life的start时候，需要上面的 LifecycleManagingDatabase 的 start 方法。里面最重要的就是 dbFactory.newGraphDatabase( config, dependencies );&lt;/p&gt;

&lt;p&gt;这个 dbFactory 我们已经说了是 CommunityNeoServer 的一个匿名内部类接口的实现类 COMMUNITY_FACTORY， 最终执行方法返回：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;TODO 这里出现了 DatabaseInfo.COMMUNITY ，如果我们想使用企业版的功能，肯定需要在这里修改源码。还有 CommunityEditionModule ，
创建的实例只能用于社区版，所以是否可以猜想，企业版就是比社区版多了几个 LifeSupport 而已&lt;/p&gt;

&lt;p&gt;然后调用 GraphDatabaseFacadeFactory的newFacade方法，&lt;code&gt;return initFacade( storeDir, config, dependencies, new GraphDatabaseFacade() );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里 new GraphDatabaseFacade(),然后初始化，实际上就是初始化一个数据库了。&lt;/p&gt;

&lt;p&gt;然后创建一个 platform ，经过一堆复杂处理后，调用 platform 的 life 的start方法。也就是我们关心的 LifeSupport 。在查看之前，我们需要知道创建这个 platform 干了啥。&lt;/p&gt;

&lt;p&gt;打开PlatformModule的构造方法，太复杂了。。。。，但是先别泄气，我们先抓 LifeSupport 吧，搞定了这个再看别的。&lt;/p&gt;

&lt;p&gt;前面几行 F6 跳过，然后直接看：&lt;code&gt;life = dependencies.satisfyDependency( createLife() );&lt;/code&gt;
这个 createLife 方法就是new了一个 LifeSupport，然后F6跳过几行，直接看：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里 createFileSystemAbstraction 就是 new DefaultFileSystemAbstraction，然后添加到 life，这时候 life 的 size 已经是1了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;jobScheduler = life.add( dependencies.satisfyDependency( createJobScheduler() ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里 createJobScheduler 就是 Neo4jJobScheduler。这时候 life 的 size 已经是2了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;dependencies.satisfyDependency( life.add( new UsageData( jobScheduler ) ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里 new UsageData ,这时候 life 的 size 已经是3了。&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看： &lt;code&gt;life.add( dependencies.satisfyDependency( new StoreLockerLifecycleAdapter( createStoreLocker() ) ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里的 createStoreLocker 就是 new GlobalStoreLocker( fileSystem, storeDir );&lt;/p&gt;

&lt;p&gt;然后 new StoreLockerLifecycleAdapter，这时候 life 的 size 已经是5了。我很好奇为啥突然加了两个。多了一个 StoreLogservice&lt;/p&gt;

&lt;p&gt;然后F6跳过几行，直接看：
&lt;code&gt;pageCache = dependencies.satisfyDependency( createPageCache( fileSystem, config, logging, tracers ) );life.add( new PageCacheLifecycle( pageCache ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后 new PageCacheLifecycle( pageCache ) 这时候 life 的 size 已经是6了。&lt;/p&gt;

&lt;p&gt;继续查看：&lt;code&gt;diagnosticsManager = life.add( dependencies.satisfyDependency( new DiagnosticsManager( logging.getInternalLog( DiagnosticsManager.class ) ) ) );&lt;/code&gt;
这里 new DiagnosticsManager( logging.getInternalLog( DiagnosticsManager.class ) )  ，这时候 life 的 size 已经是7了。&lt;/p&gt;

&lt;p&gt;一直到 createPlatform 运行完，life一共有7个 LifeSupport。然后调用：&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;直接进入 CommunityEditionModule 的构造方法&lt;/p&gt;

&lt;p&gt;直接F6: &lt;code&gt;LifeSupport life = platformModule.life;life.add( platformModule.dataSourceManager );&lt;/code&gt;
这里添加了 dataSourceManager，实际上是个 DAtaSourceManager。这时候 life 的 size 已经是8了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;life.add( watcherService );
propertyKeyTokenHolder = life.add( dependencies.satisfyDependency( new DelegatingPropertyKeyTokenHolder(
createPropertyKeyCreator( config, dataSourceManager, idGeneratorFactory ) ) ) );
labelTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingLabelTokenHolder( createLabelIdCreator( config,
dataSourceManager, idGeneratorFactory ) ) ));
relationshipTypeTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingRelationshipTypeTokenHolder(
createRelationshipTypeCreator( config, dataSourceManager, idGeneratorFactory ) ) ));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时候 life 的 size 已经是12了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;dependencies.satisfyDependency(createKernelData( fileSystem, pageCache, storeDir, config, graphDatabaseFacade, life ) );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个方法运行完成后，life一共有12个 LifeSupport。&lt;/p&gt;

&lt;p&gt;然后是：&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;
这里我们只抓取和life有关的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;LifeSupport life = platformModule.life;
threadToTransactionBridge = deps.satisfyDependency( life.add( new ThreadToStatementContextBridge() ) );
life.add( platformModule.kernelExtensions );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;和&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;
life.add( new MonitorGc( config, logging.getInternalLog( MonitorGc.class ) ) );

life.add( new PublishPageCacheTracerMetricsAfterStart( platformModule.tracers.pageCursorTracerSupplier ) );

life.add( new DatabaseAvailability( platformModule.availabilityGuard, platformModule.transactionMonitor,
        config.get( GraphDatabaseSettings.shutdown_transaction_end_timeout ).toMillis() ) );

life.add( new StartupWaiter( platformModule.availabilityGuard, editionModule.transactionStartTimeout ) );

// Kernel event handlers should be the very last, i.e. very first to receive shutdown events
life.add( kernelEventHandlers );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到这里life的size已经是22 。&lt;/p&gt;

&lt;p&gt;然后会调用platform.life.start().就会循环调用上面的所有的 LifeSupport 的start方法。&lt;/p&gt;

&lt;p&gt;所以实际上，整个代码的运行就是一个个的 lifeSupport 的运行，&lt;/p&gt;

&lt;h2 id=&#34;4-理解lifesupport后再次调试代码&#34;&gt;4.理解LifeSupport后再次调试代码&lt;/h2&gt;

&lt;p&gt;这次调试就好多了，我们可以着重看重要的代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;1. `server = createNeoServer( config, dependencies, userLogProvider );`

    1. `this( config, lifecycleManagingDatabase( COMMUNITY_FACTORY ), dependencies, logProvider );`

        1.
        
        COMMUNITY_FACTORY = ( config, dependencies ) -&amp;gt;
    	{
    	    File storeDir = config.get( GraphDatabaseSettings.database_path );
    	    return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )
    	            .newFacade( storeDir, config, dependencies );
    	};
        

2. `server.start();`

    1. `init`

        1. `this.database = life.add( dependencyResolver.satisfyDependency( dbFactory.newDatabase( config, dependencies ) ) );`

            1. `new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );`

                1. `life.add(GraphDatabaseFacadeFactory)`

            2. `this.webServer = createWebServer();`

                1. `new JettyWebServer()`

            3. `createServerModules()`

            4. `serverComponents = new ServerComponentsLifecycleAdapter();`

    2. `life.start();`

        1. for ( LifecycleInstance instance : instances ) start()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面两个 Lifecycle start 分开看。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;LifecycleManagingDatabase.start()&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;this.graph = dbFactory.newGraphDatabase( config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;return new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new ).newFacade( storeDir, config, dependencies );&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;new GraphDatabaseFacadeFactory( DatabaseInfo.COMMUNITY, CommunityEditionModule::new )&lt;/code&gt; 这里的lambda类似scala的匿名函数，钩子方法。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;newFacade( File storeDir, Config config, final Dependencies dependencies )&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;new GraphDatabaseFacade()&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;initFacade( File storeDir, Config config, final Dependencies dependencies,final GraphDatabaseFacade graphDatabaseFacade )&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;
这里就是上面我们省略的部分，&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;
start的过程启动了所有的 LifeCycle&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;ServerComponentsLifecycleAdapter.start()&lt;/code&gt;
后续的程序&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接下来我们就是一个一个分析&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这四段代码，前三段主要是新建 LifeCycle，最后一个是start是和我们整个neo4j的集群联系最紧密的。为了提高效率，我们可以将上面22个LifeCycle一个一个看。方法很简单，以第一个&lt;code&gt;0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;&lt;/code&gt;为例，我们只需要找到新建和添加到lifeCycle的地方，打断点，然后在他的init和start方法上面打断点。
我们找到新建的调用栈，应该是 LifecycleManagingDatabase.start() -&amp;gt; &amp;hellip; -&amp;gt; new PlatformModule()，然后找到对应的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后找到 FileSystemLifecycleAdapter 的 init和start方法，好像都是空的，然后打上断点进行调试。&lt;/p&gt;

&lt;p&gt;另外对于我们关心的每一部分，实际上都是在这一块进行初始化和启动，一共就三个地方：PlatformModule，EditionModule，DataSourceModule。&lt;/p&gt;

&lt;p&gt;例如我们要找neo4j的存储，可以在这三个类中寻找，我大概感觉是：PlatformModule 中新建的 dataSourceManager，在 CommunityEditionModule 中add到life中取得，&lt;/p&gt;

&lt;p&gt;以及在 DataSourceModule 中的  new NeoStoreDataSource()  ，然后 dataSourceManager.register(NeoStoreDataSource)。仔细研究发现 dataSourceManager 也是一个LifeCycle，也有start方法，而他的instances包括了 NeoStoreDataSource，而 NeoStoreDataSource 也是一个LifeCycle，它的 instances是 start 方法中添加的。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析3-LifeCycle查看</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-datasourcemanager%E6%9F%A5%E7%9C%8B/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-datasourcemanager%E6%9F%A5%E7%9C%8B/</guid>
      
        <description>

&lt;h2 id=&#34;一-复习&#34;&gt;一、复习&lt;/h2&gt;

&lt;p&gt;上一篇我们说到，接下来我们就是一个一个分析 Lifecycle 的init和start方法，首先是 &lt;code&gt;GraphDatabaseFacadeFactory.initFacade&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;PlatformModule platform = createPlatform( storeDir, config, dependencies, graphDatabaseFacade );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;EditionModule edition = editionFactory.apply( platform );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;final DataSourceModule dataSource = createDataSource( platform, edition, queryEngine::get );&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;platform.life.start();&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这四段代码，前三段主要是新建 LifeCycle，最后一个是start是和我们整个neo4j的集群联系最紧密的。为了提高效率，我们可以将上面22个LifeCycle一个一个看。方法很简单，以第一个&lt;code&gt;0 = {LifeSupport$LifecycleInstance@3583} &amp;quot;org.neo4j.io.fs.FileSystemLifecycleAdapter@353d0772: STARTED&amp;quot;&lt;/code&gt;为例，我们只需要找到新建和添加到lifeCycle的地方，打断点，然后在他的init和start方法上面打断点。&lt;/p&gt;

&lt;p&gt;我们找到新建的调用栈，应该是 LifecycleManagingDatabase.start() -&amp;gt; &amp;hellip; -&amp;gt; new PlatformModule()，然后找到对应的代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;fileSystem = dependencies.satisfyDependency( createFileSystemAbstraction() );
life.add( new FileSystemLifecycleAdapter( fileSystem ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后找到 FileSystemLifecycleAdapter 的 init和start方法，好像都是空的，然后打上断点进行调试。&lt;/p&gt;

&lt;p&gt;另外对于我们关心的每一部分，实际上都是在这一块进行初始化和启动，一共就三个地方：PlatformModule，EditionModule，DataSourceModule。&lt;/p&gt;

&lt;p&gt;例如我们要找neo4j的存储，可以在这三个类中寻找，我大概感觉是：PlatformModule 中新建的 dataSourceManager，在 CommunityEditionModule 中add到life中取得，&lt;/p&gt;

&lt;p&gt;以及在 DataSourceModule 中的  new NeoStoreDataSource()  ，然后 dataSourceManager.register(NeoStoreDataSource)。仔细研究发现 dataSourceManager 也是一个LifeCycle，也有start方法，而他的instances包括了 NeoStoreDataSource，而 NeoStoreDataSource 也是一个LifeCycle，它的 instances是 start 方法中添加的。&lt;/p&gt;

&lt;h2 id=&#34;二-datasourcemanager-预览&#34;&gt;二、DataSourceManager 预览&lt;/h2&gt;

&lt;p&gt;从上面的分析我们看出，一共22个LifeCycle，DataSourceManager 是最复杂的，我们就从它开始。
在 PlatformModule 的构造方法新建了 dataSourceManager。并且在后面调用 start&lt;/p&gt;

&lt;h3 id=&#34;1-准备工作&#34;&gt;1.准备工作&lt;/h3&gt;

&lt;p&gt;在DataSourceManager类的init和start方法打上断点，然后在 PlatformModule 的构造方法打上断点，在 CommunityEditionModule 上打断点，在 DataSourceModule打上断点。&lt;/p&gt;

&lt;p&gt;另外我们的代码反复用到了 Dependencies 这个类，我们先大概知道一下它的方法，他有个 parent 属性，一个 resolveDependency 方法和一个 satisfyDependency 方法，&lt;/p&gt;

&lt;p&gt;satisfyDependency方法是将一个类的所有父类放进一个map中，resolveDependency方法是调用 parent的resolveDependency，实际上是 DataSourceManager中的dependencies，这里可以暂时忽略。&lt;/p&gt;

&lt;h3 id=&#34;2-开始调试&#34;&gt;2.开始调试&lt;/h3&gt;

&lt;p&gt;先定位到 PlatformModule 的断点 this.dataSourceManager = new DataSourceManager();新建只是初始化几个属性：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private LifeSupport life = new LifeSupport();
    private final Listeners&amp;lt;Listener&amp;gt; dsRegistrationListeners = new Listeners&amp;lt;&amp;gt;();
    private NeoStoreDataSource dataSource;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后到 CommunityEditionModule 中，life.add( platformModule.dataSourceManager );将 dataSourceManager 添加到 LifeCycle 中。然后&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;propertyKeyTokenHolder = life.add( dependencies.satisfyDependency( new DelegatingPropertyKeyTokenHolder(
        createPropertyKeyCreator( config, dataSourceManager, idGeneratorFactory ) ) ) );
labelTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingLabelTokenHolder( createLabelIdCreator( config,
        dataSourceManager, idGeneratorFactory ) ) ));
relationshipTypeTokenHolder = life.add( dependencies.satisfyDependency(new DelegatingRelationshipTypeTokenHolder(
        createRelationshipTypeCreator( config, dataSourceManager, idGeneratorFactory ) ) ));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这几步用到了 dataSourceManager ，但是具体干啥了暂且不知道，看名字应该是属性标签和关系等存储相关，先跳过。&lt;/p&gt;

&lt;p&gt;然后是 DataSourceModule 的 dataSourceManager.register( neoStoreDataSource );这里我们需要先看看 neoStoreDataSource 是啥。 打断点到 neoStoreDataSource = deps.satisfyDependency( new NeoStoreDataSource())，然后继续看看。&lt;/p&gt;

&lt;p&gt;进入 NeoStoreDataSource 的构造方法，NeoStoreDataSource 也是 LifeCycle 的一个实现类，有start方法，它的构造方法好像就是做了很多赋值。&lt;/p&gt;

&lt;p&gt;然后是 dataSourceManager.register( neoStoreDataSource )，实际上也就是赋值 this.dataSource = dataSource;&lt;/p&gt;

&lt;p&gt;然后接下来是 ClassicCoreSPI spi = new ClassicCoreSPI( platform, dataSource, msgLog, coreAPIAvailabilityGuard );官方文档显示 ClassicCoreSPI 是 surface-layer-of-the-database&lt;/p&gt;

&lt;p&gt;然后是 graphDatabaseFacade.init()&lt;/p&gt;

&lt;p&gt;然后进入到了关键的 platform.life.start(); 我们知道这里的life的start方法会遍历 life 的 instances 调用init和start，其中就包括我们进行要调试的 DataSourceManager 。&lt;/p&gt;

&lt;h3 id=&#34;3-datasourcemanager的start方法&#34;&gt;3.DataSourceManager的start方法。&lt;/h3&gt;

&lt;p&gt;我们已经在 DataSourceManager 中打好断点，我们已经知道他也是一个 Lifecycle ，先进入init方法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void init() throws Throwable
    {
        life = new LifeSupport();
        life.add( dataSource ); // 这个DataSource是 NeoStoreDataSource
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后是start方法：其实就是 life.start(),它的life里面只有 NeoStoreDataSource 一个 instance ，然后会调用它的init和start方法，然后进入 init和start，init是空的，我们在start调试。信息量比较大，做好准备。&lt;/p&gt;

&lt;p&gt;第一步是 life = new LifeSupport();&lt;/p&gt;

&lt;p&gt;第二步是 life.add( recoveryCleanupWorkCollector );&lt;/p&gt;

&lt;p&gt;然后 life.add( indexConfigStore ) 和 life.add( Lifecycles.multiple( indexProviders.values() ) );&lt;/p&gt;

&lt;p&gt;然后是 storageEngine = buildStorageEngine()， buildRecovery(), final NeoStoreKernelModule kernelModule = buildKernel(),&lt;/p&gt;

&lt;p&gt;然后是 life.start();这里的life工有13个instance：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;instances = {ArrayList@5669}  size = 13
 0 = {LifeSupport$LifecycleInstance@5673} &amp;quot;org.neo4j.index.internal.gbptree.GroupingRecoveryCleanupWorkCollector@3b0c9195: NONE&amp;quot;
 1 = {LifeSupport$LifecycleInstance@5674} &amp;quot;org.neo4j.kernel.impl.index.IndexConfigStore@5cdd09b1: NONE&amp;quot;
 2 = {LifeSupport$LifecycleInstance@5675} &amp;quot;org.neo4j.kernel.lifecycle.Lifecycles$CombinedLifecycle@681a8b4e: NONE&amp;quot;
 3 = {LifeSupport$LifecycleInstance@5676} &amp;quot;org.neo4j.kernel.impl.storageengine.impl.recordstorage.RecordStorageEngine@305f7627: NONE&amp;quot;
 4 = {LifeSupport$LifecycleInstance@5677} &amp;quot;org.neo4j.kernel.impl.transaction.log.files.TransactionLogFiles@1bc715b8: NONE&amp;quot;
 5 = {LifeSupport$LifecycleInstance@5678} &amp;quot;org.neo4j.kernel.impl.transaction.log.BatchingTransactionAppender@24bdb479: NONE&amp;quot;
 6 = {LifeSupport$LifecycleInstance@5679} &amp;quot;org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointerImpl@7e3f95fe: NONE&amp;quot;
 7 = {LifeSupport$LifecycleInstance@5680} &amp;quot;org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointScheduler@34625ccd: NONE&amp;quot;
 8 = {LifeSupport$LifecycleInstance@5681} &amp;quot;org.neo4j.kernel.recovery.Recovery@39dcf4b0: NONE&amp;quot;
 9 = {LifeSupport$LifecycleInstance@5682} &amp;quot;org.neo4j.kernel.impl.api.KernelTransactions@21005f6c: NONE&amp;quot;
 10 = {LifeSupport$LifecycleInstance@5683} &amp;quot;org.neo4j.kernel.impl.api.KernelTransactionMonitorScheduler@32f0fba8: NONE&amp;quot;
 11 = {LifeSupport$LifecycleInstance@5684} &amp;quot;org.neo4j.kernel.impl.api.Kernel@545de5a4: NONE&amp;quot;
 12 = {LifeSupport$LifecycleInstance@5685} &amp;quot;org.neo4j.kernel.NeoStoreDataSource$2@2c1b9e4b: NONE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这12个LifeCycle什么时候加进来的我们后面有时间再看吧，我们接下来又要跳进 LifeCycle 的的init和start方法，这13个 LifeCycle 先看哪一个呢？我们发现最后一个好像是他自己的内部类？我们后面再看吧。&lt;/p&gt;

&lt;p&gt;我们先看和存储有关的 &lt;code&gt;3 = {LifeSupport$LifecycleInstance@5676} &amp;quot;org.neo4j.kernel.impl.storageengine.impl.recordstorage.RecordStorageEngine@305f7627: NONE&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;打好断点进入，这次终于没有 instance 了，感觉快进入了盗梦空间啊，直接看init：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void init() throws Throwable
{
    indexingService.init();
    labelScanStore.init();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IndexingService 的init方法，你可以选择跳进去，但是我不想跳进去了，不然进了但梦空间挑不出来。。。以后再看吧，姑且认为这个类和索引有关。&lt;/p&gt;

&lt;p&gt;NativeLabelScanStore 的init，我也先不跳进去了。&lt;/p&gt;

&lt;p&gt;再看start：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void start() throws Throwable
{
    neoStores.makeStoreOk();

    propertyKeyTokenHolder.setInitialTokens(
            neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
    relationshipTypeTokenHolder.setInitialTokens(
            neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
    labelTokenHolder.setInitialTokens(
            neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );

    neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
    loadSchemaCache();
    indexingService.start();
    labelScanStore.start();
    idController.start();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;neoStores.makeStoreOk(); 这个初始化就是读取本地存储，还是要重点查看一下：TODO&lt;/p&gt;

&lt;p&gt;然后是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;propertyKeyTokenHolder.setInitialTokens(
        neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
relationshipTypeTokenHolder.setInitialTokens(
        neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
labelTokenHolder.setInitialTokens(
        neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这几段代码都可以直接用调试的估值功能直接看出具体的值。&lt;/p&gt;

&lt;p&gt;然后是：neoStores.rebuildCountStoreIfNeeded(); 跳进去： getCounts().start();&lt;/p&gt;

&lt;p&gt;然后是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
loadSchemaCache();
indexingService.start();
labelScanStore.start();
idController.start();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后面再细看吧。&lt;/p&gt;

&lt;h2 id=&#34;三-datasourcemanager-剖析&#34;&gt;三、dataSourceManager 剖析&lt;/h2&gt;

&lt;p&gt;上面我们已经看出了，AbstractNeoServer 包含两个 LifeCycle ，其中一个是 LifecycleManagingDatabase ，&lt;/p&gt;

&lt;p&gt;LifecycleManagingDatabase  包含 22个 LifeCycle，其中一个是 dataSourceManager ，&lt;/p&gt;

&lt;p&gt;dataSourceManager 只包含一个 LifeCycle NeoStoreDataSource ，&lt;/p&gt;

&lt;p&gt;NeoStoreDataSource 里面有 13 个 LifeCycle ， 其中有和存储有关的 RecordStorageEngine 。
它的构造方法中有一句：neoStores = factory.openAllNeoStores( true ); 实际上会创建各种store，
相关的 store 和构造方法可以看：org.neo4j.kernel.impl.store.StoreType，以 NodeStore 为例，会先新建，然后 init。&lt;/p&gt;

&lt;p&gt;RecordStorageEngine 中有和存储相关的很多属性和方法。分别在构造方法赋值，init和start方法进行初始化和启动工作。&lt;/p&gt;

&lt;p&gt;这就是整个盗梦空间的五层梦，接下来我们只能从最深的一层反着往回查看了。&lt;/p&gt;

&lt;h3 id=&#34;1-recordstorageengine-分析&#34;&gt;1. RecordStorageEngine 分析&lt;/h3&gt;

&lt;p&gt;首先它的父类是 StorageEngine ： A StorageEngine provides the functionality to durably store data, and read it back.负责持久化和读数据，里面的抽象方法注释可以好好阅读。&lt;/p&gt;

&lt;h4 id=&#34;1-storageengine-预览&#34;&gt;(1). StorageEngine 预览&lt;/h4&gt;

&lt;p&gt;storeReadLayer() , return an interface for accessing data previously applied to this storage. 返回读取之前放进storage的数据的接口。&lt;/p&gt;

&lt;p&gt;allocateCommandCreationContext(), 保存需要多次执行的命令的上下文&lt;/p&gt;

&lt;p&gt;createCommands(),返回一系列在当前的事务状态下进行改变的&lt;code&gt;StorageCommand&lt;/code&gt;命令，CommandsToApply 命令可以通过调用apply方法放进存储中。&lt;/p&gt;

&lt;p&gt;apply()，执行一系列的命令到存储，&lt;/p&gt;

&lt;p&gt;其他的暂时忽略。&lt;/p&gt;

&lt;h4 id=&#34;2-recordstorageengine-属性查看&#34;&gt;(2). RecordStorageEngine 属性查看&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final StoreReadLayer storeLayer;
private final IndexingService indexingService;
private final NeoStores neoStores;
private final PropertyKeyTokenHolder propertyKeyTokenHolder;
private final RelationshipTypeTokenHolder relationshipTypeTokenHolder;
private final LabelTokenHolder labelTokenHolder;
private final DatabaseHealth databaseHealth;
private final IndexConfigStore indexConfigStore;
private final SchemaCache schemaCache;
private final IntegrityValidator integrityValidator;
private final CacheAccessBackDoor cacheAccess;
private final LabelScanStore labelScanStore;
private final SchemaIndexProviderMap schemaIndexProviderMap;
private final ExplicitIndexApplierLookup explicitIndexApplierLookup;
private final SchemaState schemaState;
private final SchemaStorage schemaStorage;
private final ConstraintSemantics constraintSemantics;
private final IdOrderingQueue explicitIndexTransactionOrdering;
private final LockService lockService;
private final WorkSync&amp;lt;Supplier&amp;lt;LabelScanWriter&amp;gt;,LabelUpdateWork&amp;gt; labelScanStoreSync;
private final CommandReaderFactory commandReaderFactory;
private final WorkSync&amp;lt;IndexingUpdateService,IndexUpdatesWork&amp;gt; indexUpdatesSync;
private final IndexStoreView indexStoreView;
private final ExplicitIndexProviderLookup explicitIndexProviderLookup;
private final PropertyPhysicalToLogicalConverter indexUpdatesConverter;
private final Supplier&amp;lt;StorageStatement&amp;gt; storeStatementSupplier;
private final IdController idController;
private final int denseNodeThreshold;
private final int recordIdBatchSize;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些field赋值是在 NeoStoreDataSource#buildStorageEngine ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private StorageEngine buildStorageEngine(
            PropertyKeyTokenHolder propertyKeyTokenHolder, LabelTokenHolder labelTokens,
            RelationshipTypeTokenHolder relationshipTypeTokens,
            ExplicitIndexProviderLookup explicitIndexProviderLookup, IndexConfigStore indexConfigStore,
            SchemaState schemaState, SynchronizedArrayIdOrderingQueue explicitIndexTransactionOrdering, OperationalMode operationalMode )
    {
        RecordStorageEngine storageEngine =
                new RecordStorageEngine( storeDir, config, pageCache, fs, logProvider, propertyKeyTokenHolder,
                        labelTokens, relationshipTypeTokens, schemaState, constraintSemantics, scheduler,
                        tokenNameLookup, lockService, schemaIndexProviderMap, indexingServiceMonitor, databaseHealth,
                        explicitIndexProviderLookup, indexConfigStore,
                        explicitIndexTransactionOrdering, idGeneratorFactory, idController, monitors, recoveryCleanupWorkCollector,
                        operationalMode );

        // We pretend that the storage engine abstract hides all details within it. Whereas that&#39;s mostly
        // true it&#39;s not entirely true for the time being. As long as we need this call below, which
        // makes available one or more internal things to the outside world, there are leaks to plug.
        storageEngine.satisfyDependencies( dependencies );

        return life.add( storageEngine );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;调试得到初始值：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;storeDir = {File@1774} &amp;quot;/Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db&amp;quot;
config = {Config@1362} &amp;quot;dbms.connector.bolt.enabled=true, dbms.connector.http.enabled=true, dbms.connector.https.enabled=true, dbms.connectors.default_listen_address=localhost, dbms.directories.import=import, dbms.jvm.additional=-Dunsupported.dbms.udc.source=tarball, dbms.security.auth_enabled=true, dbms.tx_log.rotation.retention_policy=1 days, dbms.windows_service_name=neo4j, unsupported.dbms.block_size.array_properties=120, unsupported.dbms.block_size.labels=56, unsupported.dbms.block_size.strings=120, unsupported.dbms.directories.neo4j_home=/Users/dengziming/opt/soft/neo4j-community-3.2.6, unsupported.dbms.edition=community&amp;quot;
pageCache = {MuninnPageCache@1773} &amp;quot;MuninnPageCache[ \n Page[ id = 0, address = 4516331520, filePageId = 0, swapperId = 1, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 1, address = 4516339712, filePageId = 0, swapperId = 2, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 2, address = 4516347904, filePageId = 0, swapperId = 3, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 3, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 4, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 5, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 6, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 7&amp;quot;
fs = {DefaultFileSystemAbstraction@1772} 
logProvider = {FormattedLogProvider@3221} 
propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506} 
labelTokens = {DelegatingLabelTokenHolder@2495} 
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480} 
schemaState = {DatabaseSchemaState@3478} 
constraintSemantics = {StandardConstraintSemantics@2499} 
scheduler = {Neo4jJobScheduler@1778} 
tokenNameLookup = {NonTransactionalTokenNameLookup@2487} 
lockService = {ReentrantLockService@3222} 
indexProviderMap = {DefaultSchemaIndexProviderMap@3483} 
indexingServiceMonitor = {$Proxy16@3223} &amp;quot;null&amp;quot;
databaseHealth = {DatabaseHealth@2485} 
explicitIndexProviderLookup = {NeoStoreDataSource$1@3226} 
indexConfigStore = {IndexConfigStore@3473} 
explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479} 
idGeneratorFactory = {BufferingIdGeneratorFactory@2494} 
idController = {BufferedIdController@2493} 
monitors = {Monitors@2498} 
recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501} 
operationalMode = {OperationalMode@2489} &amp;quot;single&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后构造方法走完了：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;storeDir = {File@1774} &amp;quot;/Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db&amp;quot;
config = {Config@1362} &amp;quot;dbms.connector.bolt.enabled=true, dbms.connector.http.enabled=true, dbms.connector.https.enabled=true, dbms.connectors.default_listen_address=localhost, dbms.directories.import=import, dbms.jvm.additional=-Dunsupported.dbms.udc.source=tarball, dbms.security.auth_enabled=true, dbms.tx_log.rotation.retention_policy=1 days, dbms.windows_service_name=neo4j, unsupported.dbms.block_size.array_properties=120, unsupported.dbms.block_size.labels=56, unsupported.dbms.block_size.strings=120, unsupported.dbms.directories.neo4j_home=/Users/dengziming/opt/soft/neo4j-community-3.2.6, unsupported.dbms.edition=community&amp;quot;
pageCache = {MuninnPageCache@1773} Method threw &#39;java.lang.OutOfMemoryError&#39; exception. Cannot evaluate org.neo4j.io.pagecache.impl.muninn.MuninnPageCache.toString()
fs = {DefaultFileSystemAbstraction@1772} 
logProvider = {FormattedLogProvider@3221} 
propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506} 
labelTokens = {DelegatingLabelTokenHolder@2495} 
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480} 
schemaState = {DatabaseSchemaState@3478} 
constraintSemantics = {StandardConstraintSemantics@2499} 
scheduler = {Neo4jJobScheduler@1778} 
tokenNameLookup = {NonTransactionalTokenNameLookup@2487} 
lockService = {ReentrantLockService@3222} 
indexProviderMap = {DefaultSchemaIndexProviderMap@3483} 
indexingServiceMonitor = {$Proxy16@3223} &amp;quot;null&amp;quot;
databaseHealth = {DatabaseHealth@2485} 
explicitIndexProviderLookup = {NeoStoreDataSource$1@3226} 
indexConfigStore = {IndexConfigStore@3473} 
explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479} 
idGeneratorFactory = {BufferingIdGeneratorFactory@2494} 
idController = {BufferedIdController@2493} 
monitors = {Monitors@2498} 
recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501} 
operationalMode = {OperationalMode@2489} &amp;quot;single&amp;quot;
factory = {StoreFactory@3550} 
neoStoreIndexStoreView = {NeoStoreIndexStoreView@3785} 
readOnly = {Boolean@3786} &amp;quot;false&amp;quot;
neoStores = {NeoStores@3549} 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后会调用 init 和 start 方法。&lt;/p&gt;

&lt;h4 id=&#34;3-recordstorageengine-属性分析&#34;&gt;(3). RecordStorageEngine 属性分析&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;storeDir&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;File类型，一开始启动参数设置的路径&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Config&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;配置&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;pageCache = {MuninnPageCache@1773}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;pageCache = {MuninnPageCache@1773} &amp;ldquo;MuninnPageCache[ \n Page[ id = 0, address = 4516331520, filePageId = 0, swapperId = 1, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 1, address = 4516339712, filePageId = 0, swapperId = 2, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 2, address = 4516347904, filePageId = 0, swapperId = 3, usageCounter = 1 ] OffHeapPageLock[Flush: 0, Excl: 0, Mod: 0, Ws: 0, S: 1]\n Page[ id = 3, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 4, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 5, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 6, address = 0, filePageId = -1, swapperId = 0, usageCounter = 0 ] OffHeapPageLock[Flush: 0, Excl: 1, Mod: 0, Ws: 0, S: 0]\n Page[ id = 7&amp;rdquo;&lt;/p&gt;

&lt;p&gt;通过一个 re-usable cursor 来缓存和读取 cache 的内容，可以通过运行 MuninnPageCacheTest 的单元测试查看功能。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;fs = {DefaultFileSystemAbstraction@1772}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基于java的NIO 文件系统进行一个封装，。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;logProvider = {FormattedLogProvider@3221}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;进行日志打印&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;TokenHolder&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;propertyKeyTokenHolder = {DelegatingPropertyKeyTokenHolder@2506}
labelTokens = {DelegatingLabelTokenHolder@2495}
relationshipTypeTokens = {DelegatingRelationshipTypeTokenHolder@2480}
后面的 cacheAccess storeLayer 会用到这三个 。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;schemaState = {DatabaseSchemaState@3478}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;存储一些状态，例如 cypher 的执行计划&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;constraintSemantics = {StandardConstraintSemantics@2499}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;里面的方法都是抛异常。
schemaCache 和后面的 txStateVisitor 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;scheduler = {Neo4jJobScheduler@1778}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;里面是一个 synchronizedSet ，用于放任务。
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;tokenNameLookup = {NonTransactionalTokenNameLookup@2487}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;包含了上面的三个 TokenHolder
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;lockService = {ReentrantLockService@3222}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一个读写锁，通过不区分读写实现同步
indexStoreView 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexProviderMap = {DefaultSchemaIndexProviderMap@3483}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;提供索引
indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexingServiceMonitor = {$Proxy16@3223} &amp;ldquo;null&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;indexingService 用到了他&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;databaseHealth = {DatabaseHealth@2485}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;集群健康状态&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;explicitIndexProviderLookup = {NeoStoreDataSource$1@3226}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;貌似是查找索引用的。NeoStoreDataSource$1 是啥意思还没搞懂。。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;indexConfigStore = {IndexConfigStore@3473}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;索引属性&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;explicitIndexTransactionOrdering = {SynchronizedArrayIdOrderingQueue@3479}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;和上面两个合作，&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;idGeneratorFactory = {BufferingIdGeneratorFactory@2494}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;封装 IdGenerator&lt;/p&gt;

&lt;p&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;idController = {BufferedIdController@2493}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BufferedIdController safely free and reuse ids.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;monitors = {Monitors@2498}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;监控&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;recoveryCleanupWorkCollector = {GroupingRecoveryCleanupWorkCollector@2501}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;略&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;operationalMode = {OperationalMode@2489} &amp;ldquo;single&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;略&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;factory = {StoreFactory@3550}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    {
        this.config = config;
        this.idGeneratorFactory = idGeneratorFactory;
        this.fileSystemAbstraction = fileSystemAbstraction;
        this.recordFormats = recordFormats;
        this.openOptions = openOptions;
        new RecordFormatPropertyConfigurator( recordFormats, config ).configure();

        this.logProvider = logProvider;
        this.neoStoreFileName = new File( storeDir, storeName );
        this.pageCache = pageCache;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;存储工厂实现，也可以用来创建空工厂。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;neoStoreIndexStoreView = {NeoStoreIndexStoreView@3785}&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;neoStores = {NeoStores@3549}&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;neoStores = factory.openAllNeoStores( true );&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,
                fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-recordstorageengine-init和start&#34;&gt;(3). RecordStorageEngine init和start&lt;/h4&gt;

&lt;p&gt;上面我们已经大概明白了每个类的作用，首先我们：&lt;code&gt;StoreFactory factory = new StoreFactory( storeDir, config, idGeneratorFactory, pageCache, fs, logProvider );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后是： &lt;code&gt;neoStores = factory.openAllNeoStores( true );&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后是从 neoStores 出发，新建一系列和存储有关的属性。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;indexUpdatesConverter = new PropertyPhysicalToLogicalConverter( neoStores.getPropertyStore() );
schemaStorage = new SchemaStorage( neoStores.getSchemaStore() );
NeoStoreIndexStoreView neoStoreIndexStoreView = new NeoStoreIndexStoreView( lockService, neoStores );
indexStoreView = new DynamicIndexStoreView( neoStoreIndexStoreView, labelScanStore, lockService, neoStores, logProvider );
schemaIndexProviderMap = indexProviderMap;
indexingService = IndexingServiceFactory.createIndexingService( config, scheduler, schemaIndexProviderMap,
        indexStoreView, tokenNameLookup,
        Iterators.asList( new SchemaStorage( neoStores.getSchemaStore() ).indexesGetAll() ), logProvider,
        indexingServiceMonitor, schemaState );

integrityValidator = new IntegrityValidator( neoStores, indexingService );
storeStatementSupplier = storeStatementSupplier( neoStores );
            storeLayer = new StorageLayer(
                    propertyKeyTokenHolder, labelTokens, relationshipTypeTokens,
                    schemaStorage, neoStores, indexingService,
                    storeStatementSupplier, schemaCache );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;构造方法完了就是init和start&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public void init() throws Throwable
{
    indexingService.init(); -- 所以服务
    labelScanStore.init();  -- Label存储
}

@Override
public void start() throws Throwable
{
    neoStores.makeStoreOk();

    propertyKeyTokenHolder.setInitialTokens(
            neoStores.getPropertyKeyTokenStore().getTokens( Integer.MAX_VALUE ) );
    relationshipTypeTokenHolder.setInitialTokens(
            neoStores.getRelationshipTypeTokenStore().getTokens( Integer.MAX_VALUE ) );
    labelTokenHolder.setInitialTokens(
            neoStores.getLabelTokenStore().getTokens( Integer.MAX_VALUE ) );

    neoStores.rebuildCountStoreIfNeeded(); // TODO: move this to counts store lifecycle
    loadSchemaCache();
    indexingService.start();
    labelScanStore.start();
    idController.start();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一步一步看：
1. indexingService.init();&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// Each index has an {@link org.neo4j.kernel.impl.store.record.IndexRule}
// 遍历每一个 IndexRule ，
IndexProxy indexProxy;

long indexId = indexRule.getId();
IndexDescriptor descriptor = indexRule.getIndexDescriptor();
SchemaIndexProvider.Descriptor providerDescriptor = indexRule.getProviderDescriptor();
SchemaIndexProvider provider = providerMap.apply( providerDescriptor );
InternalIndexState initialState = provider.getInitialState( indexId, descriptor );
indexStates.computeIfAbsent( initialState, internalIndexState -&amp;gt; new ArrayList&amp;lt;&amp;gt;() )
.add( new IndexLogRecord( indexId, descriptor ) );

log.debug( indexStateInfo( &amp;quot;init&amp;quot;, indexId, initialState, descriptor ) );
switch ( initialState )
{
case ONLINE:
    indexProxy =
    indexProxyCreator.createOnlineIndexProxy( indexId, descriptor, providerDescriptor );
    break;
case POPULATING:
    // The database was shut down during population, or a crash has occurred, or some other sad thing.
    indexProxy = indexProxyCreator.createRecoveringIndexProxy( descriptor, providerDescriptor );
    break;
case FAILED:
    IndexPopulationFailure failure = failure( provider.getPopulationFailure( indexId ) );
    indexProxy = indexProxyCreator
            .createFailedIndexProxy( indexId, descriptor, providerDescriptor, failure );
    break;
default:
    throw new IllegalArgumentException( &amp;quot;&amp;quot; + initialState );
}
indexMap.putIndexProxy( indexId, indexProxy );
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于我的数据库没有建索引，所以这里就不调试了，接下来建了索引再说。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;labelScanStore.init();&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过 GBPTree 实现&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;-- which is implemented using {@link GBPTree}
@link GBPTree 是一种算法，减少树结构合并时候的冲突。
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;indexingService.start();&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;labelScanStore.start();&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;idController.start();&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-recordstorageengine-分析&#34;&gt;2. RecordStorageEngine 分析&lt;/h3&gt;

&lt;p&gt;上一节我们已经大概看了 RecordStorageEngine ，他只是 NeoStoreDataSource 的 13个梦中的一个而已，我们还要醒来继续做剩下的12个梦。
我看了一下 先不看了，剩下的12个重要性稍微低一点。我们先看我们最感兴趣的。&lt;/p&gt;

&lt;p&gt;PageCache&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>neo4j源码分析4-读文件</title>
      <link>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-%E8%AF%BB%E6%96%87%E4%BB%B6/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/neo4j/neo4j%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%904-%E8%AF%BB%E6%96%87%E4%BB%B6/</guid>
      
        <description>

&lt;h2 id=&#34;一-复习&#34;&gt;一、复习&lt;/h2&gt;

&lt;p&gt;上一篇我们已经大概看了 RecordStorageEngine ，他只是 NeoStoreDataSource 的 13个梦中的一个而已，我们还要醒来继续做剩下的12个梦。&lt;/p&gt;

&lt;p&gt;然而我们可以先看看如何读数据，写数据的。第一是找到java类 &lt;code&gt;PhysicalLogCommandReaderV3_0_2&lt;/code&gt;。我们可以看到里面有很多读文件处理的方法，主要是&lt;code&gt;neostore.transaction.db.0&lt;/code&gt;这个文件，好像是日志文件。&lt;/p&gt;

&lt;p&gt;然后我们在 NodeStore 类的构造方法打断点。可以找到整个调用的栈帧：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;new RecordStorageEngine()
neoStores = factory.openAllNeoStores( true );
return openNeoStores( createStoreIfNotExists, StoreType.values() );
return new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
for ( StoreType type : storeTypes ) getOrCreateStore( type );
store = openStore( storeType );
Object store = type.open( this );
return neoStores.createNodeStore( getStoreName() );
return initialize( new NodeStore( storeFile, config, idGeneratorFactory, pageCache, logProvider,(DynamicArrayStore) getOrCreateStore( StoreType.NODE_LABEL ), recordFormats, openOptions ) );
new CommonAbstractStore()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同理，我们还可以在 RelationshipStore PropertyStore TokenStore AbstractDynamicStore 等store中打上断点，了解调用栈。所有的存储文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;CommonAbstractStore (org.neo4j.kernel.impl.store)
RelationshipStore (org.neo4j.kernel.impl.store)
RecordingRelationshipStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
MyStore in CommonAbstractStoreBehaviourTest (org.neo4j.kernel.impl.store)
MetaDataStore (org.neo4j.kernel.impl.store)
AbstractDynamicStore (org.neo4j.kernel.impl.store)
DynamicArrayStore (org.neo4j.kernel.impl.store)
SchemaStore (org.neo4j.kernel.impl.store)
DynamicStringStore (org.neo4j.kernel.impl.store)
Anonymous in newTestableDynamicStore() in AbstractDynamicStoreTest (org.neo4j.kernel.impl.store)
NodeStore (org.neo4j.kernel.impl.store)
RecordingNodeStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
RelationshipGroupStore (org.neo4j.kernel.impl.store)
TokenStore (org.neo4j.kernel.impl.store)
LabelTokenStore (org.neo4j.kernel.impl.store)
UnusedLabelTokenStore in LabelTokenStoreTest (org.neo4j.kernel.impl.store)
PropertyKeyTokenStore (org.neo4j.kernel.impl.store)
RelationshipTypeTokenStore (org.neo4j.kernel.impl.store)
TheStore in CommonAbstractStoreTest (org.neo4j.kernel.impl.store)
PropertyStore (org.neo4j.kernel.impl.store)
RecordingPropertyStore in WriteTransactionCommandOrderingTest (org.neo4j.kernel.impl.transaction.state)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对应20种存储格式：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;AbstractBaseRecord (org.neo4j.kernel.impl.store.record)
PropertyRecord (org.neo4j.kernel.impl.store.record)
IntRecord in CommonAbstractStoreBehaviourTest (org.neo4j.kernel.impl.store)
TheRecord in CommonAbstractStoreTest (org.neo4j.kernel.impl.store)
MyRecord in BaseHighLimitRecordFormatTest (org.neo4j.kernel.impl.store.format.highlimit)
MetaDataRecord (org.neo4j.kernel.impl.store.record)
SchemaRecord (org.neo4j.kernel.impl.store.record)
DynamicRecord (org.neo4j.kernel.impl.store.record)
IndexEntry (org.neo4j.consistency.store.synthetic)
PrimitiveRecord (org.neo4j.kernel.impl.store.record)
NodeRecord (org.neo4j.kernel.impl.store.record)
NeoStoreRecord (org.neo4j.kernel.impl.store.record)
RelationshipRecord (org.neo4j.kernel.impl.store.record)
LabelScanDocument (org.neo4j.consistency.store.synthetic)
RelationshipGroupRecord (org.neo4j.kernel.impl.store.record)
RelationshipGroupCursor (org.neo4j.kernel.impl.newapi)
TokenRecord (org.neo4j.kernel.impl.store.record)
LabelTokenRecord (org.neo4j.kernel.impl.store.record)
PropertyKeyTokenRecord (org.neo4j.kernel.impl.store.record)
RelationshipTypeTokenRecord (org.neo4j.kernel.impl.store.record)
CountsEntry (org.neo4j.consistency.store.synthetic)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 StoreFactory 中可以找到对应的关系。&lt;/p&gt;

&lt;h2 id=&#34;二-id文件&#34;&gt;二、Id文件&lt;/h2&gt;

&lt;p&gt;打开代码 CommonAbstractStore ：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Opens the {@link IdGenerator} used by this store.
 * &amp;lt;p&amp;gt;
 * Note: This method may be called both while the store has the store file mapped in the
 * page cache, and while the store file is not mapped. Implementers must therefore
 * map their own temporary PagedFile for the store file, and do their file IO through that,
 * if they need to access the data in the store file.
 */
void openIdGenerator()
{
    idGenerator = idGeneratorFactory.open( getIdFileName(), getIdType(), () -&amp;gt; scanForHighId(), recordFormat.getMaxId() );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IdGenerator 的功能是分配id，每一种存储格式都有自己的id，所以在 CommonAbstractStore 中都有这个属性。idGenerator负责分配和释放id，所以它里面要有最大的id，已经已经释放的id。&lt;/p&gt;

&lt;p&gt;最大的id可以用到下一次分配id，已经释放的也可以用于分配。进一步了解功能可以在 IdGeneratorImplTest 中调试。我们可以用二进制文件编辑器打开&lt;code&gt;neostore.nodestore.db.id&lt;/code&gt;看看。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0000 0000 0000 0000 0b00 0000 0000 0000
0000 0000 0000 0000 0100 0000 0000 0000
0200 0000 0000 0000 0300 0000 0000 0000
0400 0000 0000 0000 0500 0000 0000 0000
06
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里一共有 65 bytes ，第1bytes是文件头，然后8 bytes是最大的id，这里是 &lt;code&gt;00 0000 0000 0000 0b&lt;/code&gt; ，然后每8Bytes就是一个释放的id，这里是从0到6。&lt;/p&gt;

&lt;p&gt;IdGeneratorImpl 的构造方法会有一个 IdContainer ，可以分配id，可以去 IdContainerTest 的 testNextId 调试 中查看功能。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try
{
    IdGeneratorImpl.createGenerator( fs, idGeneratorFile(), 0, false );
    IdGenerator idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 3, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    for ( long i = 0; i &amp;lt; 7; i++ )
    {
        assertEquals( i, idGenerator.nextId() );
    }
    idGenerator.freeId( 1 );
    idGenerator.freeId( 3 );
    idGenerator.freeId( 5 );
    assertEquals( 7L, idGenerator.nextId() );
    idGenerator.freeId( 6 );
    closeIdGenerator( idGenerator );
    idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 5, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    idGenerator.freeId( 2 );
    idGenerator.freeId( 4 );
    assertEquals( 1L, idGenerator.nextId() );
    idGenerator.freeId( 1 );
    assertEquals( 3L, idGenerator.nextId() );
    idGenerator.freeId( 3 );
    assertEquals( 5L, idGenerator.nextId() );
    idGenerator.freeId( 5 );
    assertEquals( 6L, idGenerator.nextId() );
    idGenerator.freeId( 6 );
    assertEquals( 8L, idGenerator.nextId() );
    idGenerator.freeId( 8 );
    assertEquals( 9L, idGenerator.nextId() );
    idGenerator.freeId( 9 );
    closeIdGenerator( idGenerator );
    idGenerator = new IdGeneratorImpl( fs, idGeneratorFile(), 3, 1000, false, IdType.NODE, () -&amp;gt; 0L );
    assertEquals( 6L, idGenerator.nextId() );
    assertEquals( 8L, idGenerator.nextId() );
    assertEquals( 9L, idGenerator.nextId() );
    assertEquals( 1L, idGenerator.nextId() );
    assertEquals( 3L, idGenerator.nextId() );
    assertEquals( 5L, idGenerator.nextId() );
    assertEquals( 2L, idGenerator.nextId() );
    assertEquals( 4L, idGenerator.nextId() );
    assertEquals( 10L, idGenerator.nextId() );
    assertEquals( 11L, idGenerator.nextId() );
    closeIdGenerator( idGenerator );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;三-文件读写api&#34;&gt;三、文件读写API&lt;/h2&gt;

&lt;p&gt;ne4j有 专用的API ，neo4j的文件有它自己的特点，不能直接使用java的API，需要定义自己的API，在 org.neo4j.io.pagecache 下。我们需要了解一下。从package-info看起。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;The purpose of a page cache is to cache data from files on a storage device, and keep the most often used data in
memory where access is fast. This duplicates the most popular data from the file, into memory. Assuming that not all
data can fit in memory (even though it sometimes can), the least used data will then be pushed out of memory, when
we need data that is not already in the cache. This is called eviction, and choosing what to evict is the
responsibility of the eviction algorithm that runs inside the page cache implementation.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pagecache的功能是从文件或者存储设备缓存数据，将最常用的放在访问最快的内存。我们最少用的数据会不在内存，当我们需要的时候，这个过程是  eviction ，选择哪个 eviction 是算法最重要的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A file must first be &amp;quot;mapped&amp;quot; into the page cache, before the page cache can cache the contents of the files. When
you no longer have an immediate use for the contents of the file, it can be &amp;quot;unmapped.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文件要被 map 到cache中才能使用。&lt;/p&gt;

&lt;p&gt;通过 org.neo4j.io.pagecache.PageCache#map(java.io.File, int, java.nio.file.OpenOption&amp;hellip;) 方法将得到一个 {@link org.neo4j.io.pagecache.PagedFile} 对象。&lt;/p&gt;

&lt;p&gt;一旦一个文件被映射到页面缓存，它就不再被直接通过文件系统访问，因为页面缓存将保持内存的变化，认为它正在管理唯一权威的副本。&lt;/p&gt;

&lt;p&gt;一个文件被map多次，返回的是同一个 PageCache，对应的 reference counter +1，&lt;/p&gt;

&lt;p&gt;Unmapping decrements the reference counter, discarding the PagedFile from the cache if the counter reaches zero.&lt;/p&gt;

&lt;p&gt;If the last reference was unmapped, then all dirty pages for that file will be flushed before the file is discarded from the cache。&lt;/p&gt;

&lt;p&gt;page 是一堆data的集合，可以是 file, or the memory allocated for the page cache。We refer to these two types of pages as &amp;ldquo;file pages&amp;rdquo; and &amp;ldquo;cache pages&amp;rdquo; respectively.&lt;/p&gt;

&lt;p&gt;Pages are the unit of what data is popular or not, and the unit of moving data into memory, and out to storage.&lt;/p&gt;

&lt;p&gt;When a cache page is holding the contents of a file page, the two are said to be &amp;ldquo;bound&amp;rdquo; to one another.&lt;/p&gt;

&lt;p&gt;每个 PagedFile 对象都有一个 translation table，逻辑上存储了page file到cache里，类似 Maps 结构，key是pageid，value是page内容。&lt;/p&gt;

&lt;p&gt;几个类的逻辑视图如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;*     +---------------[ PageCache ]-----------------------------------+
 *     |                                                               |
 *     |  * PageSwapperFactory{ FileSystemAbstraction }                |
 *     |  * evictionThread                                             |
 *     |  * a large collection of Page objects:                        |
 *     |                                                               |
 *     |  +---------------[ Page ]----------------------------------+  |
 *     |  |                                                         |  |
 *     |  |  * usageCounter                                         |  |
 *     |  |  * some kind of read/write lock                         |  |
 *     |  |  * a cache page sized buffer                            |  |
 *     |  |  * binding metadata{ filePageId, PageSwapper }          |  |
 *     |  |                                                         |  |
 *     |  +---------------------------------------------------------+  |
 *     |                                                               |
 *     |  * linked list of mapped PagedFile instances:                 |
 *     |                                                               |
 *     |  +--------------[ PagedFile ]------------------------------+  |
 *     |  |                                                         |  |
 *     |  |  * referenceCounter                                     |  |
 *     |  |  * PageSwapper{ StoreChannel, filePageSize }            |  |
 *     |  |  * PageCursor freelists                                 |  |
 *     |  |  * translation table:                                   |  |
 *     |  |                                                         |  |
 *     |  |  +--------------[ translation table ]----------------+  |  |
 *     |  |  |                                                   |  |  |
 *     |  |  |  A translation table is basically a map from      |  |  |
 *     |  |  |  file page ids to Page objects. It is updated     |  |  |
 *     |  |  |  concurrently by page faulters and the eviction   |  |  |
 *     |  |  |  thread.                                          |  |  |
 *     |  |  |                                                   |  |  |
 *     |  |  +---------------------------------------------------+  |  |
 *     |  +---------------------------------------------------------+  |
 *     +---------------------------------------------------------------+
 *
 *     +--------------[ PageCursor ]-----------------------------------+
 *     |                                                               |
 *     |  * currentPage: Page                                          |
 *     |  * page lock metadata                                         |
 *     |                                                               |
 *     +---------------------------------------------------------------+
 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里有几个重要的类，我们需要大概了解一下用法，第一个是 PageCache ，可以查看 MuninnPageCacheTest 类的测试方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try ( MuninnPageCache pageCache = createPageCache( fs, 2, blockCacheFlush( tracer ), cursorTracerSupplier );
         PagedFile pagedFile = pageCache.map( file( &amp;quot;a&amp;quot; ), 8 ) )
   {
       try ( PageCursor cursor = pagedFile.io( 0, PF_SHARED_READ_LOCK ) )
       {
           assertTrue( cursor.next() );
       }
       cursorTracer.reportEvents();
       assertNotNull( cursorTracer.observe( Fault.class ) );
       assertEquals( 1, cursorTracer.faults() );
       assertEquals( 1, tracer.faults() );

       long clockArm = pageCache.evictPages( 1, 1, tracer.beginPageEvictions( 1 ) );
       assertThat( clockArm, is( 1L ) );
       assertNotNull( tracer.observe( Evict.class ) );
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出，第一步是创建 pageCache，第二步是 pageCache 的 map 方法得到 pagedFile，然后调用 io 方法得到 PageCursor ，然后cusor是一个迭代器。&lt;/p&gt;

&lt;h2 id=&#34;四-commonabstractstore-格式&#34;&gt;四、CommonAbstractStore 格式&lt;/h2&gt;

&lt;p&gt;这个是一个存储格式的基本实现类，我们现在任何一个Store上面打断点，然后在 CommonAbstractStore 中打断点，开始调试即可。以 NodeStore 为例，在构造方法打断点，在 CommonAbstractStore 的 checkAndLoadStorage 打断点。&lt;/p&gt;

&lt;p&gt;我们找到了调用栈：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;neoStores = factory.openAllNeoStores( true );
return openNeoStores( createStoreIfNotExists, StoreType.values() );
new NeoStores( neoStoreFileName, config, idGeneratorFactory, pageCache, logProvider,fileSystemAbstraction, recordFormats, createStoreIfNotExists, storeTypes, openOptions );
getOrCreateStore( type );
store = openStore( storeType );
Object store = type.open( this );
return neoStores.createDynamicArrayStore( getStoreName(), IdType.NODE_LABELS, GraphDatabaseSettings.label_block_size );

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 checkAndLoadStorage 方法上停下来，此时的storeType是 &lt;code&gt;NODE_LABEL&lt;/code&gt; ，也就是节点的Label,：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// /Users/dengziming/opt/soft/neo4j-community-3.2.6/data/databases/graph.db/neostore.nodestore.db.labels
try ( PagedFile pagedFile = pageCache.map( storageFileName, pageSize, ANY_PAGE_SIZE ) ) 

extractHeaderRecord( pagedFile );
createStore( pageSize );
loadStorage( filePageSize );
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;四-abstractdynamicstore-文件格式&#34;&gt;四、AbstractDynamicStore 文件格式&lt;/h2&gt;

&lt;p&gt;neo4j 中对于字符串等变长值的保存策略是用一组定长的 block 来保存，block之间用单向链表链接。&lt;/p&gt;

&lt;p&gt;例如 neostore.propertystore.db.arrays 和 neostore.propertystore.db.strings 类 AbstractDynamicStore 实现了该功能，文件结构在 DynamicRecordFormat 中有解释。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private static final int RECORD_HEADER_SIZE = 1/*header byte*/ + 3/*# of bytes*/ + 8/*max size of next reference*/;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>tinkerpop查看</title>
      <link>https://dengziming.github.io/post/tinkerpop/tinkerpop%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/tinkerpop/tinkerpop%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/</guid>
      
        <description>

&lt;h2 id=&#34;一-关键类&#34;&gt;一、关键类&lt;/h2&gt;

&lt;p&gt;api地址： &lt;a href=&#34;http://tinkerpop.apache.org/javadocs/current/full/&#34;&gt;http://tinkerpop.apache.org/javadocs/current/full/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GraphTraversalSource
构造方法：
GraphTraversalSource(Graph graph)
GraphTraversalSource(Graph graph, TraversalStrategies traversalStrategies)&lt;/p&gt;

&lt;p&gt;graph.traversal() 方法返回一个 GraphTraversalSource&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>tinkerpop查看</title>
      <link>https://dengziming.github.io/post/tinkerpop/tinkerpop%E7%AE%97%E5%AD%90/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/tinkerpop/tinkerpop%E7%AE%97%E5%AD%90/</guid>
      
        <description>

&lt;h2 id=&#34;一-关键类&#34;&gt;一、关键类&lt;/h2&gt;

&lt;p&gt;api地址： &lt;a href=&#34;http://tinkerpop.apache.org/javadocs/current/full/&#34;&gt;http://tinkerpop.apache.org/javadocs/current/full/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;GraphTraversalSource
构造方法：
GraphTraversalSource(Graph graph)
GraphTraversalSource(Graph graph, TraversalStrategies traversalStrategies)&lt;/p&gt;

&lt;p&gt;graph.traversal() 方法返回一个 GraphTraversalSource&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>如何在github.io搭建Hugo博客</title>
      <link>https://dengziming.github.io/post/java/first/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/first/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>如何在github.io搭建Hugo博客</title>
      <link>https://dengziming.github.io/post/java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</guid>
      
        <description>

&lt;h2 id=&#34;一-过滤器模式&#34;&gt;一、过滤器模式&lt;/h2&gt;

&lt;p&gt;过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。&lt;/p&gt;

&lt;p&gt;mongo 的查询接口有很多方法，例如 and，or，实际上就是串在一起。&lt;/p&gt;

&lt;h2 id=&#34;二-组合模式&#34;&gt;二、组合模式&lt;/h2&gt;

&lt;p&gt;树枝内部组合该接口，并且含有内部属性 List，里面放 Component。叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class Employee {
   private String name;
   private String dept;
   private int salary;
   private List&amp;lt;Employee&amp;gt; subordinates;
 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;三-装饰器模式&#34;&gt;三、装饰器模式&lt;/h2&gt;

&lt;p&gt;类似适配器，代理，桥接&lt;/p&gt;

&lt;p&gt;java 的 IO 包就是典型代表&lt;/p&gt;

&lt;h2 id=&#34;四-外观模式&#34;&gt;四、外观模式&lt;/h2&gt;

&lt;p&gt;为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。不符合开放封闭原则，如果要改东西很麻烦。&lt;/p&gt;

&lt;h2 id=&#34;五-桥接模式&#34;&gt;五、桥接模式&lt;/h2&gt;

&lt;p&gt;抽象类依赖实现类。&lt;/p&gt;

&lt;h2 id=&#34;六-责任链模式&#34;&gt;六、责任链模式&lt;/h2&gt;

&lt;p&gt;拦截器模式：以 Logger 为例，&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public abstract class AbstractLogger {
protected AbstractLogger nextLogger;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;七-观察者模式&#34;&gt;七、观察者模式&lt;/h2&gt;

&lt;p&gt;微博动态可以设计成观察者模式，每个人记录自己的观察者，发送的时候通知。&lt;/p&gt;

&lt;h2 id=&#34;八-策略模式&#34;&gt;八、策略模式&lt;/h2&gt;

&lt;p&gt;诸葛亮的锦囊妙计，每一个锦囊就是一个策略。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>如何在github.io搭建Hugo博客</title>
      <link>https://dengziming.github.io/post/titan/first/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/titan/first/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>常用maven命令</title>
      <link>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/maven%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/maven%E5%91%BD%E4%BB%A4/</guid>
      
        <description>

&lt;h2 id=&#34;一&#34;&gt;一、&lt;/h2&gt;

&lt;h3 id=&#34;1-插件&#34;&gt;1.插件&lt;/h3&gt;

&lt;p&gt;版本兼容检查&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.revapi&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;revapi-maven-plugin&amp;lt;/artifactId&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代码风格检查&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;maven-checkstyle-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-常见异常&#34;&gt;2.常见异常&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;cached in local repository &amp;hellip;
这个原因可能是上一次更新失败，会有一个update文件放在本地，去repository对应目录删除即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;can&amp;rsquo;t find jar in alimaven， 这个原因是仓库可能没这个jar，可是换一个仓库。
例如换成开源中国的仓库，但是可能又有新的错误，最好是使用 -rf 从某一个重新开始打包 &lt;code&gt;mvn clean install -DskipTests=true -rf :janusgraph-es&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;java return cannot find symbol com.sun.*
可以换成 jdk1.8.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Missing tools.jar at: /Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/Classes/classes.jar. Expression: file.exists()&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;原因，maven 的配置文件的 profiles 中有个 profile：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;profile&amp;gt;
  &amp;lt;id&amp;gt;osx-jdk&amp;lt;/id&amp;gt;
  &amp;lt;activation&amp;gt;
    &amp;lt;file&amp;gt;
      &amp;lt;exists&amp;gt;${java.home}/../Classes/classes.jar&amp;lt;/exists&amp;gt;
    &amp;lt;/file&amp;gt;
  &amp;lt;/activation&amp;gt;
  &amp;lt;dependencies&amp;gt;
    &amp;lt;dependency&amp;gt;
      &amp;lt;groupId&amp;gt;jdk.tools&amp;lt;/groupId&amp;gt;
      &amp;lt;artifactId&amp;gt;jdk.tools&amp;lt;/artifactId&amp;gt;
      &amp;lt;scope&amp;gt;system&amp;lt;/scope&amp;gt;
      &amp;lt;version&amp;gt;1.6&amp;lt;/version&amp;gt;
      &amp;lt;systemPath&amp;gt;${java.home}/../Classes/classes.jar&amp;lt;/systemPath&amp;gt;
    &amp;lt;/dependency&amp;gt;
  &amp;lt;/dependencies&amp;gt;
&amp;lt;/profile&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;activation 代表使用条件，${java.home} 代表 JRE 目录，如果这个文件存在就是用 osx-jdk。现在是因为这个文件不存在，所以只要让这个文件存在即可。&lt;/p&gt;

&lt;p&gt;解决办法：&lt;a href=&#34;https://stackoverflow.com/questions/23971229/maven-install-hadoop-from-source-looking-in-the-wrong-path-for-tools-jar&#34;&gt;https://stackoverflow.com/questions/23971229/maven-install-hadoop-from-source-looking-in-the-wrong-path-for-tools-jar&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;cd /Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/
sudo mkdir Classes
cd Classes/
sudo ln -s ../jre/lib/rt.jar classes.jar&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
neo4j-3.4/community/dbms/src/main/java/org/neo4j/dbms/diagnostics/jmx/LocalVirtualMachine.java:[23,28] package com.sun.tools.attach does not exist&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这个和上面的错误很类似，上面的错误是因为我们通过在 jre 目录下面做了一个软连接，把 rt.jar 连接到了 classes.jar，classes.jar 包中没有 com.sun.tools.attach，而它需要的是 tools.jar，&lt;/p&gt;

&lt;p&gt;解决办法：&lt;/p&gt;

&lt;p&gt;cd /Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/
sudo rm -rf Classes/classes.jar
sudo ln -s lib/tools.jar Classes/classes.jar&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;not found: type InputPosition
not found: value Eagerly&lt;/p&gt;

&lt;p&gt;解决方案：
一般是 scala 编译器没配置好。重新设置。
有时候 IDEA 运行没问题，但是打包报这个问题，解决方案？
目前不知道，重新 import 后，找个类运行一下，然后再打包就成功了。&lt;/p&gt;

&lt;p&gt;mvn -settings ~/opt/soft/apache-maven-3.5.0/conf/settings.xml -Dlicense.skip=true -DskipTests package install -rf :neo4j-cypher-util-3.4&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
inspect a maven model for resolution&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Maven -&amp;gt; Reimport&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
/Users/dengziming/opt/sourcecode/neo4j-3.4/community/cypher/interpreted-runtime/src/test/scala/org/neo4j/cypher/internal/runtime/interpreted/commands/ComparablePredicateTest.scala:53: warning: a type was inferred to be &lt;code&gt;Any&lt;/code&gt;; this may indicate a programming error.
[ERROR]     case v: Number if v.doubleValue().isNaN =&amp;gt; Seq(v.doubleValue(), v.floatValue(), v)
[ERROR]          ^&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这个问题好像没造成停止。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;应用A直接应用B，应用B依赖二方包C1、C2、C3，应用A传递依赖C1、C2、C3。现应用B升级版本，应用更新B依赖包后发现可正常引入依赖B，但传递依赖的C1、C2、C3不能引入。
　　
&lt;a href=&#34;https://blog.csdn.net/xktxoo/article/details/78005817&#34;&gt;https://blog.csdn.net/xktxoo/article/details/78005817&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;打包不包含 scala 编译文件，pom 的 build 中缺少打包scala的插件。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;java 调用 scala 代码不报错，打包报错。
参考 &lt;a href=&#34;http://xflin.blogspot.com/2013/08/mixed-scala-and-java-in-maven-project.html&#34;&gt;http://xflin.blogspot.com/2013/08/mixed-scala-and-java-in-maven-project.html&lt;/a&gt; ，混合编译&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;3-常用命令&#34;&gt;3.常用命令&lt;/h3&gt;

&lt;p&gt;mvn -pl hadoop-yarn-project -am clean install -D maven.test.skip=true -P prod&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>常用sql写法</title>
      <link>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/janus/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://dengziming.github.io/post/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/janus/</guid>
      
        <description>

&lt;h2 id=&#34;sql语法&#34;&gt;sql语法&lt;/h2&gt;

&lt;p&gt;2）删库前，执行/sdc/node1/bin/nodetool compactionstats  看下当前有没跟要删除相关的Compaction任务，如果有就执行 /sdc/node1/bin/nodetool stop命令中止,  这个是每个节点都要确认.
3)  drop keyspace后，最好删除磁盘上的物理目录, 防止复用时有影响.&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>